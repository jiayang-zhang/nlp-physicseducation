{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import utils, formats\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- unpack xml files --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input\n",
    "# dir_xml = '/Users/jiayangzhang/Library/CloudStorage/OneDrive-ImperialCollegeLondon/year4/anonymised_reports/year_1_2017/cycle_1/xml'\n",
    "# dir_txt = '/Users/jiayangzhang/Library/CloudStorage/OneDrive-ImperialCollegeLondon/year4/anonymised_reports/year_1_2017/cycle_1/txt'\n",
    "# csv_in = 'data/labels_y1c1.xlsx'\n",
    "\n",
    "# # output\n",
    "# csv_out = 'outputs/sections/labels_cleaned_y1c1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "dir_xml = '/Users/jiayangzhang/Library/CloudStorage/OneDrive-ImperialCollegeLondon/year4/anonymised_reports/year_1_2017/cycle_2/xml'\n",
    "dir_txt = '/Users/jiayangzhang/Library/CloudStorage/OneDrive-ImperialCollegeLondon/year4/anonymised_reports/year_1_2017/cycle_2/txt'\n",
    "csv_in = 'data/labels_y1c2.xlsx'\n",
    "\n",
    "# output\n",
    "csv_out = 'outputs/sections/labels_cleaned_y1c2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: GS_IHJ555_Redacted.xml file is empty\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_BPP712_Redacted\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_MFR246_Redacted\n",
      "WARNING: GS_LSK572_Redacted.xml file is empty\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_OQP549_Redacted\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_GTD911_Redacted\n",
      "WARNING: GS_NPG050_Redacted.xml file is empty\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_BMS328_Redacted\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_SCO219_Redacted\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_MOX979_Redacted\n",
      "WARNING: GS_OXY643_Redacted.xml file is empty\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_WHP087_Redacted\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_TFY667_Redacted\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_KUY555_Redacted\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_ZZF399_Redacted\n",
      "Cannot get error paragraph ...\n",
      "error filename: GS_ZZF399_Redacted\n",
      "Cannot get error paragraph ...\n",
      "error filename: GS_ZZF399_Redacted\n",
      "Cannot get results paragraph ...\n",
      "error filename: GS_UGX035_Redacted\n",
      "Total number of files: 45\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for file in os.listdir(dir_xml):\n",
    "    if file.startswith('GS_') and file.endswith('.tei.xml'):\n",
    "\n",
    "        # Count # of files\n",
    "        counter += 1\n",
    "\n",
    "        # Get StudentID\n",
    "        filename = file.rsplit('.', maxsplit=2)[0]\n",
    "\n",
    "        # Extract text from reports\n",
    "        utils.xml_to_txt(dir_xml, dir_txt, filename, alltext=False, processtext = False)\n",
    "\n",
    "print('Total number of files:', counter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- unpack csv labels and txt files ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of reports:  45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build dataframe for texts\n",
    "df_files = utils.build_files_dataframe(dir_txt, 'GS_', '.txt')\n",
    "\n",
    "# Built dataframe for labels\n",
    "df_labels = utils.build_labels_dataframe(csv_in)\n",
    "\n",
    "# Merge two dataframes\n",
    "df = pd.merge(df_files, df_labels, left_on='StudentID', right_on='StudentID')      # merged dataframe: StudentID, Content, ArgumentLevel, ReasoningLevel\n",
    "\n",
    "# Check # of reports\n",
    "print('# of reports: ',len(df.index))\n",
    "\n",
    "# Save merged dataframe as csv\n",
    "df.to_csv(csv_out, encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- join 2 csv files --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-43fdb8acfa5e>:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df= df1.append(df2, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('outputs/sections/labels_cleaned_y1c1.csv', encoding='utf-8')\n",
    "df2 = pd.read_csv('outputs/sections/labels_cleaned_y1c2.csv', encoding='utf-8')\n",
    "df= df1.append(df2, ignore_index=True)\n",
    "df.to_csv('outputs/sections/labels_cleaned_y1c1c2.csv', encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Count bar plots --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_plots(filepath):\n",
    "    df = pd.read_csv(filepath, encoding='utf-8')\n",
    "    dummy_dict = df['ArgumentLevel'].value_counts().to_dict()\n",
    "    ArgumentLevel = ['Superficial', 'Extended', 'Deep', 'Prediction', 'Expert', ]\n",
    "    counts = [dummy_dict[key.lower()] for key in ArgumentLevel]\n",
    "    print(counts)\n",
    "    formats.bar_plot(ArgumentLevel, counts, xlabel = 'Argument Levels', ylabel = 'Counts', filepath = 'outputs/counts_vs_ArgumentLevel.png')\n",
    "\n",
    "    dummy_dict = df['ReasoningLevel'].value_counts().to_dict()\n",
    "    ReasoningLevel = ['the', 'exp', 'bal', 'none']\n",
    "    counts = [dummy_dict[key.lower()] for key in ReasoningLevel]\n",
    "    ReasoningLevel = ['Theoretical', 'Experimental','Balanced', 'None']\n",
    "    formats.bar_plot(ReasoningLevel, counts, xlabel = 'Reasoning Levels', ylabel = 'Counts', filepath = 'outputs/counts_vs_ReasoningLevel.png')\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d71e2f643be86ab2fc160c762752df8c2d7cb942111b0c58fcf5178bc6c93ea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
