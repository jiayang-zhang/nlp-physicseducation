{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tool functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tools import utils, ml_tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# machine learning imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# graphing tools\n",
    "import seaborn as sns\n",
    "from scipy.stats import sem\n",
    "import matplotlib\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'ieee','no-latex'])\n",
    "matplotlib.rc('font', family='times new roman')\n",
    "\n",
    "# time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECTORY FOR PICKLED FILES\n",
    "dir_name_e = r'C:\\Users\\EfiaA\\OneDrive - Imperial College London\\Imperial academic work\\University life\\Y4\\MSci project\\Project_Coding\\nlp-physicseducation\\Pickledfiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tool functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tools import utils, ml_tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# graphing tools\n",
    "import seaborn as sns\n",
    "from scipy.stats import sem\n",
    "import matplotlib\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'ieee','no-latex'])\n",
    "matplotlib.rc('font', family='times new roman')\n",
    "\n",
    "# time\n",
    "import time \n",
    "\n",
    "# importing the NN\n",
    "from NN_tools import NN_data, NN_data_iteration\n",
    "from NN_tools import NN_optimised_parameters, NN_default_parameters, one_hot_enc_labels_bow, one_hot_enc_labels_tf\n",
    "from NN_tools import convert_to_preferred_format, nn_graph, nn_graph_loss, NN_data_ck, NN_ck"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below are the imports of several datasets. This includes: year1, year 2 and year 1 & year 2 combined. They are all in csv file format and so are imported using pandas. Moreoever, each csv file is made in to a dataframe. Also note that the documents are pre-processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y1\n",
    "dir_csv_y1 = 'outputs/labels_cleaned_y2.csv'\n",
    "df_y1     = pd.read_csv(dir_csv_y1, encoding='utf-8')\n",
    "\n",
    "#Y2\n",
    "dir_csv_y2 = 'outputs/labels_cleaned_y2.csv'\n",
    "df_y2      = pd.read_csv(dir_csv_y2, encoding='utf-8')\n",
    "\n",
    "\n",
    "#Y1Y2\n",
    "dir_csv_y1y2 = 'outputs/labels_cleaned_y1y2.csv'\n",
    "df_y1y2      = pd.read_csv(dir_csv_y1y2, encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YEAR 1 NN "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Optimised Neural Network will be ran on the default for each feature extraction technique: bow and TF-IDF. The aim is to see the effect of the optimised Neural Network on the first set of data. The code below incoporates the appropriate feature extraction techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ArgumentLevel','ReasoningLevel'] # 'ArgumentLevel', 'ReasoningLevel'\n",
    "#labels2 = ['ArgumentLevel','ReasoningLevel','ArgumentLevel','ReasoningLevel'] # 'ArgumentLevel', 'ReasoningLevel'\n",
    "features = ['tfidf','bow'] #'bow', 'ifidf'\n",
    "num_epochs = 20\n",
    "num_iter   = 10\n",
    "train_sizes = [0.5,0.6,0.7,0.8,0.9] # proportion of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 5)\n",
      "tfidf\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 258ms/step - loss: 0.7004 - accuracy: 0.2000 - val_loss: 0.6933 - val_accuracy: 0.4571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [1 2 2 4 0 1 4 0 2 1 0 2 2 4 1 0 2 0 2 4 2 0 4 4 4 0 4 4 0 1 0 2 2 2 4 4 2\n",
      " 1 2 2 0 4]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.6900 - accuracy: 0.7561 - val_loss: 0.6753 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [4 2 4 2 2 2 4 1 0 0 3 2 0 3 4 2 0 4 2 3 1 3 1 4 4 4 2 2 2 4 4 2 2 0 4 2 3\n",
      " 4 2 2 4 2]\n",
      "[]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 182ms/step - loss: 0.6880 - accuracy: 0.4327 - val_loss: 0.6635 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 4 2 0 2 2 4 4 2 0 0 2 1 0 2 0 2 2 4 2 4 4 2 4 4 3 4 4 0 4 2 0 4]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 188ms/step - loss: 0.6868 - accuracy: 0.5551 - val_loss: 0.6623 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 3 1 4 4 1 4 2 4 4 0 2 2 1 4 1 0 2 2 4 0 2 0 4 0 0 2 4 4 0 0 0 2 4]\n",
      "[]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x00000198C3E0FC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6945 - accuracy: 0.2200WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x00000198C8AFD940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6907 - val_accuracy: 0.8000\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000198C8AFD4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 4 0 1 4 1 4 0 0 4 2 2 2 2 2 4 2 4 0 0 2 0 2 2 2]\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x00000198C9C1AB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6923 - accuracy: 0.7800WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x00000198C8A208B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 168ms/step - loss: 0.6913 - accuracy: 0.7897 - val_loss: 0.6884 - val_accuracy: 0.8000\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000198C8AFDC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 0 2 4 4 2 2 1 2 4 3 0 4 0 4 4 2 2 2 4 4 0 2 2 4]\n",
      "[]\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 85ms/step - loss: 0.6926 - accuracy: 0.6273 - val_loss: 0.6869 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 2 0 4 4 3 4 2 0 4 0 2 2 4 2 2 2]\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.6853 - accuracy: 0.6091 - val_loss: 0.6629 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 0 2 4 0 4 4 2 2 3 0 2 4 2 2 4]\n",
      "[]\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 87ms/step - loss: 0.6825 - accuracy: 0.8000 - val_loss: 0.6613 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 0 2 4 1 0 1 0 1]\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 81ms/step - loss: 0.6944 - accuracy: 0.3459 - val_loss: 0.6877 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 2 1 2 0 2 4 2]\n",
      "[]\n",
      "seconds value in hours: 0.0\n",
      "seconds value in minutes: 0.0\n",
      "bow\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 161ms/step - loss: 0.6887 - accuracy: 0.6976 - val_loss: 0.6634 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [2 2 4 0 2 2 2 4 2 4 4 4 4 0 1 0 0 4 4 0 2 0 2 4 2 1 0 4 0 2 0 2 4 4 0 2 3\n",
      " 4 4 1 0 0]\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 167ms/step - loss: 0.6893 - accuracy: 0.5220 - val_loss: 0.6650 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 905us/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [4 3 0 4 3 2 0 0 1 2 2 0 2 2 0 2 2 2 1 4 3 1 2 4 4 2 4 4 2 0 1 4 2 2 2 2 4\n",
      " 4 4 4 3 3]\n",
      "[]\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 158ms/step - loss: 0.6938 - accuracy: 0.4327 - val_loss: 0.6895 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 2 4 0 2 0 2 2 4 2 2 4 4 2 1 4 2 4 0 2 4 0 4 3 2 0 2 2 1 4 4 1 2 4]\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 180ms/step - loss: 0.6900 - accuracy: 0.7633 - val_loss: 0.6803 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 2 2 2 4 1 4 4 4 1 4 3 2 4 4 2 0 4 4 0 2 2 2 3 4 0 4 2 0 2 2 2 2 2]\n",
      "[]\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 242ms/step - loss: 0.6961 - accuracy: 0.4793 - val_loss: 0.6905 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 4 0 3 4 3 4 4 4 0 2 4 1 4 0 0 1 4 4 4 2 3 4 2 2]\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.6906 - accuracy: 0.6966 - val_loss: 0.6801 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 2 2 2 1 0 2 4 0 4 4 4 2 1 4 4 2 4 3 4 2 3 2 2 3]\n",
      "[]\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 110ms/step - loss: 0.6941 - accuracy: 0.5273 - val_loss: 0.6849 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 1 2 4 0 0 0 2 1 3 0 4 2 4 0 2 2]\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_51 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.6919 - accuracy: 0.7182 - val_loss: 0.6785 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 0 1 2 1 2 1 2 2 4 4 1 4 2 2 4 3]\n",
      "[]\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 90ms/step - loss: 0.6844 - accuracy: 0.8000 - val_loss: 0.6587 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 1 4 2 2 4 4 2 1]\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_57 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 85ms/step - loss: 0.6837 - accuracy: 0.8000 - val_loss: 0.6689 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 0 4 2 2 2 4 1 2]\n",
      "[]\n",
      "seconds value in hours: 0.0\n",
      "seconds value in minutes: 0.0\n",
      "(83, 4)\n",
      "tfidf\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 187ms/step - loss: 0.6950 - accuracy: 0.4207 - val_loss: 0.6853 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 3 1 3 1 0 1 2 0 0 0 3 1 3 3 0 0 2 3 2 1 3 0 0 1 1 0 3 3 3 1 0 3 3 1 0 0\n",
      " 3 2 3 0 3]\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_63 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.6905 - accuracy: 0.7378 - val_loss: 0.6784 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [1 3 1 1 0 3 3 3 3 1 0 2 3 0 0 0 3 3 3 0 1 1 0 3 0 3 3 0 0 1 3 2 0 1 3 2 2\n",
      " 0 3 3 3 2]\n",
      "[]\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 251ms/step - loss: 0.6860 - accuracy: 0.7500 - val_loss: 0.6669 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 3 0 1 2 0 0 2 3 1 1 3 0 3 3 1 0 3 1 3 3 3 3 3 0 0 3 3 3 3 1 3 0]\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_69 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 0.6940 - accuracy: 0.4337 - val_loss: 0.6918 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 3 3 0 3 0 1 2 1 3 0 1 0 1 0 3 3 1 0 0 3 3 3 2 3 0 0 0 1 3 0 2 1]\n",
      "[]\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 197ms/step - loss: 0.6883 - accuracy: 0.7328 - val_loss: 0.6780 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 1 2 3 0 1 0 3 2 3 3 1 3 3 0 1 1 3 3 0 3 3 0 2 3]\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.6846 - accuracy: 0.7500 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 0 1 2 0 3 3 0 3 0 1 0 2 3 3 0 3 1 0 0 1 0 1 0]\n",
      "[]\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 91ms/step - loss: 0.6867 - accuracy: 0.7424 - val_loss: 0.6701 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 3 3 3 1 0 3 3 3 1 1 1 0 1 1 3 1]\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_81 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.6859 - accuracy: 0.7500 - val_loss: 0.6700 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 1 0 2 3 3 0 1 3 0 1 3 1 3 3 3 1]\n",
      "[]\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 95ms/step - loss: 0.6925 - accuracy: 0.5473 - val_loss: 0.6845 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 1 0 3 2 1 0 3 3]\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_87 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3/3 [==============================] - 1s 88ms/step - loss: 0.6910 - accuracy: 0.5541 - val_loss: 0.6833 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 0 1 0 1 3 1 0]\n",
      "[]\n",
      "seconds value in hours: 0.0\n",
      "seconds value in minutes: 0.0\n",
      "bow\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6965 - accuracy: 0.2500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mbow\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[39m# NN training \u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m t \u001b[39m=\u001b[39m NN_data_iteration(NN_optimised_parameters,  wordvec_counts, y_b, \n\u001b[0;32m     53\u001b[0m              train_sizes, num_epochs, num_iter, label, feature, \u001b[39m'\u001b[39;49m\u001b[39my1\u001b[39;49m\u001b[39m'\u001b[39;49m, dir_name_e )\n\u001b[0;32m     54\u001b[0m \u001b[39m# t2 = NN_data_ck(NN_ck, wordvec_counts, y_b, train_sizes, num_epochs, 'y1'  )            \u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[39m# adding results to list\u001b[39;00m\n\u001b[0;32m     57\u001b[0m accuracies\u001b[39m.\u001b[39mappend(t[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\OneDrive - Imperial College London\\Imperial academic work\\University life\\Y4\\MSci project\\Project_Coding\\nlp-physicseducation\\NN_tools.py:149\u001b[0m, in \u001b[0;36mNN_data_iteration\u001b[1;34m(Neural, X, y, t_size, epoch_no, it_no, str_dataname, str_featext, str_year, dir)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m X_train_b\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    148\u001b[0m model \u001b[39m=\u001b[39m Neural(Sequential(), \u001b[39minput\u001b[39m, epoch_no, X_train_b, y_train_b, X_test_b, y_test_b)\n\u001b[1;32m--> 149\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train_b,y_train_b,epochs \u001b[39m=\u001b[39;49m epoch_no, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, validation_data\u001b[39m=\u001b[39;49m(X_test_b, y_test_b), batch_size\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m )\n\u001b[0;32m    150\u001b[0m predictions \u001b[39m=\u001b[39m  model\u001b[39m.\u001b[39mpredict(X_test_b) \n\u001b[0;32m    151\u001b[0m predictions \u001b[39m=\u001b[39m  np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1607\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1608\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1609\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1610\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1611\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1612\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1613\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1614\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1615\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1616\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1617\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1618\u001b[0m )\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   1948\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[0;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1222\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m   1223\u001b[0m       original_func,\n\u001b[0;32m   1224\u001b[0m       args,\n\u001b[0;32m   1225\u001b[0m       kwargs,\n\u001b[0;32m   1226\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m   1227\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1228\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m   1229\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1230\u001b[0m       ))\n\u001b[0;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileoi3olpqn.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1713\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1708\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1709\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m     )\n\u001b[0;32m   1712\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1713\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1714\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1715\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1716\u001b[0m )\n\u001b[0;32m   1717\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1315\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1311\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1314\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1315\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2891\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2890\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2891\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3692\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3691\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3692\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1701\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1701\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtest_step(data)\n\u001b[0;32m   1702\u001b[0m     \u001b[39m# Ensure counter is updated only if `test_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1667\u001b[0m, in \u001b[0;36mModel.test_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1665\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1666\u001b[0m \u001b[39m# Updates stateful loss metrics.\u001b[39;00m\n\u001b[1;32m-> 1667\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1668\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1052\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[39m\"\"\"Compute the total loss, validate it, and return it.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \n\u001b[0;32m   1003\u001b[0m \u001b[39mSubclasses can optionally override this method to provide custom loss\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39m  is the case when called by `Model.test_step`).\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[39mdel\u001b[39;00m x  \u001b[39m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[1;32m-> 1052\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompiled_loss(\n\u001b[0;32m   1053\u001b[0m     y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlosses\n\u001b[0;32m   1054\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py:265\u001b[0m, in \u001b[0;36mLossesContainer.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[0;32m    263\u001b[0m y_t, y_p, sw \u001b[39m=\u001b[39m match_dtype_and_rank(y_t, y_p, sw)\n\u001b[0;32m    264\u001b[0m sw \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mapply_mask(y_p, sw, losses_utils\u001b[39m.\u001b[39mget_mask(y_p))\n\u001b[1;32m--> 265\u001b[0m loss_value \u001b[39m=\u001b[39m loss_obj(y_t, y_p, sample_weight\u001b[39m=\u001b[39;49msw)\n\u001b[0;32m    267\u001b[0m total_loss_mean_value \u001b[39m=\u001b[39m loss_value\n\u001b[0;32m    268\u001b[0m \u001b[39m# Correct for the `Mean` loss metrics counting each replica as a\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[39m# batch.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\losses.py:158\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m reduction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_reduction()\n\u001b[0;32m    155\u001b[0m sample_weight \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mapply_valid_mask(\n\u001b[0;32m    156\u001b[0m     losses, sample_weight, mask, reduction\n\u001b[0;32m    157\u001b[0m )\n\u001b[1;32m--> 158\u001b[0m \u001b[39mreturn\u001b[39;00m losses_utils\u001b[39m.\u001b[39;49mcompute_weighted_loss(\n\u001b[0;32m    159\u001b[0m     losses, sample_weight, reduction\u001b[39m=\u001b[39;49mreduction\n\u001b[0;32m    160\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\losses_utils.py:354\u001b[0m, in \u001b[0;36mcompute_weighted_loss\u001b[1;34m(losses, sample_weight, reduction, name)\u001b[0m\n\u001b[0;32m    351\u001b[0m weighted_losses \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmultiply(losses, sample_weight)\n\u001b[0;32m    353\u001b[0m \u001b[39m# Apply reduction function to the individual weighted losses.\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m loss \u001b[39m=\u001b[39m reduce_weighted_loss(weighted_losses, reduction)\n\u001b[0;32m    355\u001b[0m \u001b[39mif\u001b[39;00m input_casted:\n\u001b[0;32m    356\u001b[0m     \u001b[39m# Convert the result back to the input type.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(loss, input_dtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\losses_utils.py:285\u001b[0m, in \u001b[0;36mreduce_weighted_loss\u001b[1;34m(weighted_losses, reduction)\u001b[0m\n\u001b[0;32m    283\u001b[0m     loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_sum(weighted_losses)\n\u001b[0;32m    284\u001b[0m     \u001b[39mif\u001b[39;00m reduction \u001b[39m==\u001b[39m ReductionV2\u001b[39m.\u001b[39mSUM_OVER_BATCH_SIZE:\n\u001b[1;32m--> 285\u001b[0m         loss \u001b[39m=\u001b[39m _safe_mean(loss, _num_elements(weighted_losses))\n\u001b[0;32m    286\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\losses_utils.py:267\u001b[0m, in \u001b[0;36m_safe_mean\u001b[1;34m(losses, num_present)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39m\"\"\"Computes a safe mean of the losses.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \n\u001b[0;32m    258\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39m    then zero is returned.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    266\u001b[0m total_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_sum(losses)\n\u001b[1;32m--> 267\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mdivide_no_nan(total_loss, num_present, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1656\u001b[0m, in \u001b[0;36mdiv_no_nan\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1654\u001b[0m x \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(x, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1655\u001b[0m y \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(y, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype)\n\u001b[1;32m-> 1656\u001b[0m \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mdiv_no_nan(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:3243\u001b[0m, in \u001b[0;36mdiv_no_nan\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   3241\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   3242\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 3243\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   3244\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mDivNoNan\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   3245\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   3246\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3801\u001b[0m       node_def,\n\u001b[0;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[0;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:1939\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1937\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 1939\u001b[0m   op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(c_graph,\n\u001b[0;32m   1940\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m   1941\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m   1942\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   1943\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "accuracies     = []\n",
    "accuracies_sd  = []\n",
    "loss           = []\n",
    "val_loss       = []\n",
    "ck             = []\n",
    "\n",
    "feature2 = []\n",
    "labels2  = []\n",
    "\n",
    "\n",
    "times = []\n",
    "\n",
    "for label in labels:\n",
    "    for feature in features:\n",
    "        # -- Feature extraction: TF-IDF ---\n",
    "        if feature ==  'tfidf':\n",
    "\n",
    "            starttime = time.time()\n",
    "            wordvec_names, wordvec_counts = np.array(ml_tools.tf_idf(df_y1['Content'].tolist()), dtype = object)\n",
    "            y_tf                          = one_hot_enc_labels_tf(df_y1, label)\n",
    "            print(y_tf.shape)\n",
    "\n",
    "            print('tfidf')\n",
    "\n",
    "            # NN training \n",
    "            t = NN_data_iteration(NN_optimised_parameters,  wordvec_counts, y_tf, \n",
    "                         train_sizes, num_epochs,num_iter, label, feature, 'y1', dir_name_e) \n",
    "            \n",
    "            # adding results to list\n",
    "            accuracies.append(t['accuracy'])\n",
    "            accuracies_sd.append(t['sem'])\n",
    "            loss.append(t['loss'])\n",
    "            val_loss.append(t['valloss'])\n",
    "            #ck.append(t['ck'])\n",
    "\n",
    "            # column titles\n",
    "            feature2.append(feature)\n",
    "            labels2.append(label)\n",
    "\n",
    "            endtime = (time.time() - starttime)/60\n",
    "            times.append(convert_to_preferred_format(endtime))\n",
    "\n",
    "        # -- Feature extraction: Bag of Words ---\n",
    "        elif feature == 'bow':\n",
    "            starttime = time.time()\n",
    "            wordvec_names, wordvec_counts = np.array(ml_tools.tf_idf(df_y1['Content'].tolist()), dtype = object)\n",
    "            y_b                           = one_hot_enc_labels_bow(df_y1, label)\n",
    "        \n",
    "            print('bow')\n",
    "\n",
    "            # NN training \n",
    "            t = NN_data_iteration(NN_optimised_parameters,  wordvec_counts, y_b, \n",
    "                         train_sizes, num_epochs, num_iter, label, feature, 'y1', dir_name_e )\n",
    "            # t2 = NN_data_ck(NN_ck, wordvec_counts, y_b, train_sizes, num_epochs, 'y1'  )            \n",
    "            \n",
    "            # adding results to list\n",
    "            accuracies.append(t['accuracy'])\n",
    "            accuracies_sd.append(t['sem'])\n",
    "            loss.append(t['loss'])\n",
    "            val_loss.append(t['valloss'])\n",
    "            #ck.append(t['ck'])\n",
    "\n",
    "            # column titles\n",
    "            feature2.append(feature)\n",
    "            labels2.append(label)\n",
    "\n",
    "            endtime = time.time() - starttime\n",
    "            times.append(convert_to_preferred_format(endtime))\n",
    "\n",
    "df_nn_y1 = pd.DataFrame({ 'Label': labels2, 'feature extraction':feature2, 'accuracy':accuracies, 'sem': accuracies_sd, 'loss': loss, 'val_loss': val_loss, 'time':times})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df_nn_y1  = 'W5_NN_Y1_RESULTS_DF_20ephs_10iterations'\n",
    "#pickle_df_nn_y1 = utils.save_as_pickle_file(df_nn_y1, name_df_nn_y1, dir_name_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickle_df_nn_y1 = utils.load_pickle_file_to_df(name_df_nn_y1, dir_name_e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we use the nn_graph function to plot the essential values that are found in  the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAByoAAAV3CAYAAAAO0OhWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAFxGAABcRgEUlENBAAEAAElEQVR4nOzdeXhU5dn48W8SIOxrAgkgEFFBxBVUUNG2inXFtX2rXexrpVV/dtHWtVZprdpq90Vtsda2tnaxIlq7ubViASu4vYjglogIkQSQfckyvz+emWRmMpNkQjITyPdzXedK5pwzzzwZwmTm3M9933mRSCSCJEmSJEmSJEmSJGVRfq4nIEmSJEmSJEmSJKnrMVApSZIkSZIkSZIkKesMVEqSJEmSJEmSJEnKOgOVkiRJkiRJkiRJkrLOQKUkSZIkSZIkSZKkrDNQKUmSJEmSJEmSJCnrDFRKkiRJkiRJkiRJyjoDlZIkSZIkSZIkSZKyzkClJEmSJEmSJEmSpKwzUClJkiRJkiRJkiQp6wxUSpIkSZIkSZIkSco6A5WSJEmSJEmSJEmSss5ApSRJkiRJkiRJkqSsM1ApSZIkSZIkSZIkKesMVEqSJEmSJEmSJEnKOgOVkiRJkiRJkiRJkrLOQKUkSZIkSZIkSZKkrDNQKUmSJEmSJEmSJCnrDFRKkiRJkiRJkiRJyjoDlZIkSZIkSZIkSZKyzkClJEmSJEmSJEmSpKwzUClJkiRJkiRJkiQp6wxUSpIkSZIkSZIkSco6A5WSJEmSJEmSJEmSss5ApSRJkiRJkiRJkqSsM1ApSZIkSZIkSZIkKeu65XoCknYPtbW1vP766wn7Bg8eTH6+6x0kSZIkSZIkSdod1dfXs27duoR9++67L926ZSeEaKBSUqu8/vrrTJgwIdfTkCRJkiRJkiRJHWjp0qXsv//+WXksU6EkSZIkSZIkSZIkZZ2BSkmtkpz6LUmSJEmSJEmS9jzZjAcYqJQkSZIkSZIkSZKUdfaolNQqAwcObLLvmWeeYb/99sv+ZDqR6urqJr07ly5dSlFRUY5m1Dn4vKTm89KUz0lqPi+p+bw05XOSms9Laj4vqfm8pObz0pTPSWo+L6n5vDTlc5Kaz0tqPi+p+bw05XOSms9Laj4vqb322mscc8wxCftSxQM6ioFKSa2Sn980AXvw4MEUFxfnYDadW1FRkc9LCj4vqfm8NOVzkprPS2o+L035nKTm85Kaz0tqPi+p+bw05XOSms9Laj4vTfmcpObzkprPS2o+L035nKTm85Kaz0sI4CZLFQ/oKJZ+lSRJkiRJkiRJkpR1BiolSZIkSZIkSZIkZZ2BSkmSJEmSJEmSJElZZ6BSkiRJkiRJkiRJUtYZqJQkSZIkSZIkSZKUdQYqJUmSJEmSJEmSJGWdgUpJkiRJkiRJkiRJWWegUpIkSZIkSZIkSVLWGaiUJEmSJEmSJEmSlHXdcj0BSbuHoqKiVu2TAIqLi4lEIrmeRqfj89KUz0lqPi9qLX9XUvN5Sc3nJTWfF7WWvyup+byk5vPSlM+JMuHvS2o+L035nKTm86JM5Prav4FKSW1WXV3d6nOLi4s7cCaSJEmSJEmSJCleVVVVi+dkcp2/IxiolNRmEyZMaPW5ruCRJEmSJEmSJCl7hg4dmusptMgelZIkSZIkSZIkSZKyzkClJEmSJEmSJEmSpKwzUClJkiRJkiRJkiQp6+xRKanNli5dSlFRUa6nIUmSJEmSJEmSkqxZs6bFc6qrq5kwYUIWZpOagUpJbVZUVERxcXGupyFJkiRJkiRJkpLsDtfvLf0qSZIkSZIkSZIkKesMVEqSJEmSJEmSJEnKOgOVkiRJkiRJkiRJkrLOQKUkSZIkSZIkSZKkrOuW6wlI0u6suLiYSCSS62lIUpfga64kZY+vuZKUHb7eSlL2+JrbOZlRKUmSJEmSJEmSJCnrDFRKkiRJkiRJkiRJyjoDlZIkSZIkSZIkSZKyzkClJEmSJEmSJEmSpKwzUClJkiRJkiRJkiQp6wxUSpIkSZIkSZIkSco6A5WSJEmSJEmSJEmSss5ApSRJkiRJkiRJkqSsM1ApSZIkSZIkSZIkKesMVEqSJEmSJEmSJEnKOgOVkiRJkiRJkiRJkrLOQKUkSZIkSZIkSZKkrDNQKUmSJEmSJEmSJCnruuV6ApIkSZIkqfNYvRqWL4eNG2HnTujRA/r3h3HjoLQ017OTJEmStCcxUClJkiRJUhe2ciXcfz/MmweLF8OqVenPHT4cJk2CadPgvPNg5MjszVOSJEnSnsdApSRJkiRJXUwkAo8/DnfcAQ8/DPX1rbvfqlVhe+QRuPZamDEDLr0Ujj8e8vI6ds6SJEmS9jwGKiVJkiRJ6kKWLIGZM2Hhwl0bp64O5swJ25QpMHs2TJzYPnOUJEmS2pstDjonA5WSJEmSJHUBtbXw7W/D178ONTXtO/bChXDYYXDjjXD11dDNqw2S1CpeNJekjmOLg91DXiQSieR6EpI6v6qqKoYOHZqwb82aNRQXF+doRpIkSZJaq6oKzjgDFizo+MeaOhXmzgU/KkhSU140l6SO1dYWB/EKCrpWi4NcX/s3UCmpVXL9YiVJkiSpbVauhBNOCBk72TJ+PDz2mBfVJQm8aC5J2dJeLQ7idYUWB7m+9p+flUeRJEmSJElZt2ZN9oOUAMuWhcetqsru40pSZ7NkCRx1FJx4Ijz0UNuClNDYF3j69DDekiXtOk1J2q3V1sLNN4dWBO0ZpITGFgc33xweR+3PQKUkSZIkSXugmho488zsByljli8P5Wa9oCOpK/KiuSRlR1UVHHssXH99+/dhj6mpCeMfe6wL8TqCgUpJkiRJkvZAt92WnZ6UzVmwIMxDkroSL5pLUnasXBn6+GbrPe+CBeF1d+XK7DxeV2GPSkmtkus61ZIkSZJab8kSOPTQqk6RadO9ezHPP79n9/WRpBj7AktSdqxZE4KGuageMm4czJsHe8ql8Vxf+++WlUeRJEmSJElZEYnARRdBbe3Qlk/OgpqaCDNnwvz5kJeX69lIUsfJdV/gPemiuSQ1p7O0OHj6aehmlG2XWfpVkiRJkqQ9yBNPwLPP5noWiRYuDPOSpD1VZ7lo3hky6SWpo9niYM9irFdSm1VXV7f6XEvESpIkSdlxxx25nkFqd94ZMn4kaU/UmS6aX3ddbuchSR1pyRKYNatzNOedNauYGTM6d4uDqlY0Ms7kOn9HsEelpFZJVac6E77USJIkSR1v5UoYPRrq6wE6S53V8FmgoAAqKuyhJmnPY19gScqOSASmToVnn+0873OnTOncLQ7y2jgxe1RKkiRJkqSM3X9/LEgJsGYXRzsm+vWZXRwnqKsL87vyynYZTpI6BfsCS1L2dOYWB1YOaTsDlZIkSZIk7SHmzYu/tasroGOXDNpvJfUzzxiolLRn8aK5JGWPLQ72TAYqJUmSJEnaQyxenOsZNG/RovTHLrkEHngglIiNbfn5jd8ff3y4CJSpX/4S/vKX1GMWFMDYsXDttZmP+9xzIWMp1Zj5+TBgAJx5ZubjVlfDO++kHrOgALp1g732ynxcSR3Di+aSlB0rV8LcubmeRWpz54b52eKgbQxUSmqzpUuXUlRUlOtpSJIkSQJWr4ZVq3I9i+atWgWVlVBS0vTYhg0hSJfO/vu37TFfegkefDD98SlT2haofOwx+OpX0x8fO7Ztgco5c+Czn01/vF8/2Lgx83H/8hf42MfSB4ILCmD5cigszGzcV1+FL385/Zj5+fCDH8CQIZmNu24d/Pzn6ccsKICzz8583NrakP2WatzYNnIk9OmT2bjqmrxoLknZY4uDtlmzpuXnqrq6mgkTJmRhNqkZqJTUZkVFRVlrqCtJkiR1JTU1sGZNCD6OHw99+7Z8n+XLO35e7WHZstSByrq65u9XUNC2x8vVuPn5HTNuW+e7cyds2dL8OW2Z89q18Le/NX/Ot76V+bhVVS0HkI84IvNA5aZNcMwxzZ/zz3/C9OmZjQvQs2f490sV/CwoCBluZ5+d+bjnngvr1zcdLxZovfBCOOWUzMe9887wOpMuyHzEESGQn6kXXoD3308fYC4ublvwrLY2fC0o6Dy9F71oLknZY4uDttkdrt8bqJQkSZIkKUc2bIBbbgkBycrKsK1enZhZ+J//wFFHtTxW5ll2W4HKuG113PdXR8+pBUYDnwa+Ht13AfA8kA8UJG3x+4YAf4ze56/AbOCbbNp0ABs2bOCyyy6joKCA/Px8CgoKWLQo3ThHA2dQUAC/+tWvWLduHZdffjkAL774Ik899VTDGMlbfn4+r74aG+dDwFBgB/AYMAaYSEEBvPDCC2zatCnlOPH7evTowd577w3Atm2bgY1AEdADqAc2Ncw/L6+A2tpwv7wMoiqNQY/UOiqw2taxO2rclp4HaFtgtaPmCyEYHIk0BtRSHW+LZ56B995Lf/zYY9s27h13wJIl6Y9ff33bApVf+Qo8+WT645/9LPzsZ5mP+8lPwu9/H77Py2saXD3jDLjvvszH/d73EstOJwdYJ06Eb3879X33pIvmr74K//hH4+1IJPF4QQF84QuZz+Gtt8Lzmzxm/PeXX555Nvfq1fCLXzQ/7mWXweDBmY27YQN85zuJ+5Kfi899LvMS3DU14f9Uc+NecAEccEBm40JY1LF9e/pxP/axtv1fvvHG8H4k3fN75pnw4Q9nPu6tt4bfi3TjTp8e5pyp738/LJRINSbA0UfDxRdnPu7PfgZPPZV+3IMPhuuuy3zc3/wmVFFIN+7ee8N3v5v5uHPmNP7fSDVuURH86leZj/v443DbbU3HjH3fvXvLC5dSefZZuOqqpuPF+/vfoXfv3bvFgZpnoFKSJEmSpF2wc2fISioqChlVmcjPb7zok87q1a2fR6JngQrgf6K3/wZ8i8ZgZHORzfi0r2FAfEpnHVAT/Zq81cd9H98m4i3gYeAKduyAbdu2cV+rIwrbiAUq7777bl5//fWGQOXTTz/NFVdc0cpx/k0IVK4HTgf+H/CT6MX3L/DMMy1nMQ0dOpT3ohGj55//JfCF6LjHErKpShvOfe21cNEOIC8vLyHgeckll/Dd6NXHM844g/Lycl5++WUAFiz4NfANUgeCC9iwIZ+jjgrj/OQnP+Hggw9m/fr1nHfeeZxxxhlccsklANxwww0sX7684XHfeSc5ABy7PRD4JgALF87n0UcfZebMmYwZM4bNmzfzox/9qEnANj6I+9prsbEmAEdGf/qngC3AaQCsWvU2L720rNmAcuz7sWPH0qdPH3bsqAXejs4vlja5jvC7FX6O7dsL2Lo1cZz8FqKXHRUAjURSX1yN19myglt6LjpbVnD8uKkCwvGBmky89RYsWJD++KZN6Y/tSRfNFy0KAcN0CgvbFqh87TW4+urmz7n00rYFKr/2tebP+fjHMw9UbtwI3/xm8+ecdlrmgcq6upb/3h9zTNsClT/9afO/pwce2LZA5X33hf8f6Ywe3bZA5dy5ITiVzoABbQtUPvlkKHPenLYEKv/7X/jDH9If37ChbYHKV15JDFQmO+ywzMeE8G/26KPpj7e1HPTq1aHsfTqZ/h+OWb8enn66+XPq6nb/FgdqnoFKSZIkSZJasGVLWFEfy3iMz35cuzacM29eyyUlk/XtG1aIb92a/pzKStiyZQuVlZVUVlayevXqhK+x7ysqKoEPA7+M3vNW4FHgI4TAzmZgCSGYdnj0a0l0K036OhD4CuGywX+TZtSGlCUui27hQtawYcPYtm0bdXV1Ddv559fz97+nCnr2A0LQ5N5772V7XDTiIx/5CJMmTaK+vj5hrLq6uoZ9P/5xHY8/XgfEmlz2B+4FxgEhaPL//t+X+OhHP9pkjPhx6urq6N27d8NjFxUdDHweGBHd0xO4sGHeAwfW8eEPNx2jrq6OffbZp2GckU2uGHYjBIZjP38tIQs0PCf19XVUVIRxYs/F9u3beeaZZ5g4cWLDKE8++ST/+c9/WvFvUwJ8k4ICeO6557jllls4+eSTGTNmDBs3buSrzTXiTPB5GgOV1wNvEgLi8I9/PMR1132pVaM8/fTTTJs2jerqKmCf6Lg/ih6dATT+TEcckXqMESNGsHLlSgDuuusurrnmGv72t78xdepUKivfAw6jaeZuY/D2s58toH//As477zy+/OUvh5/u859n9erVPBBNDXv44YeZPXt2XIC0ueziK4F92bFjI1dcMYtjjz2WM6MNTO+++25WrlzZbBB3y5YCwv+DT0Z/wleBxcCJwFDq67czZ87fmg0ox74vLS1l9OjRAGzb9hbh92u/6Lgbgfcb5r9tWwFr16Yep1u3bmkzhfe0Ms7pxvWiuSRlz+7e4kDNM1ApSZIkSeoydu4MAa9uGX4ajkQgGq9Iq7IyszHr6uqoqqpi8OBKtm6tJAQd8oEXCEHGS4APsnp1PQMHDqQ2TT3JwsJCSktLKS0dzfr1o+OOfJkQOIuleX0kuuVWv34hw7BnUvppS0GGggIYO3Zswr7wc5emuUfw0EPJe3oTytc2jnvOOec0/+ApjBx5LCGTMmYg0FhrrayssUxlc376058m3D7kkPO5777z055fWgrRGFzcvlI2b96csO+ZZ54hEok0BEd/85s6Zs5MlfkaFBTABRdcwMknn8xe0VShoqIiFi9e3Gwg+L//reP66+sIJYJjvkEogxt88IMnMHv27GbHiW1jxowBoEePPoQSxPF1j88CDmqY+9ln19GnT9NxBg4c2HCPYcOGcfjhh9OvXwh4RyL50bnGPwfxz0sNW7fWUVNTl/Ccvvnmm6xYsaLh9ooVK/jnP//Z8LiRZtMpLyAEKjfx/e9/n/r6+oZA5T333MOC5tL5GpTSGKj8O3AFoZfhULZtW8vZrWx++YUvfIEf/vCHAKxe/UmgHIhF2+4BGlPqbr89bKk888wzHH300axatYoxY8bwhS98ge9E62UuWXIy8BzpsoLvuy+fJ54ooKSkhCejNWJ///vf88Mf/pCf/exnHHTQQVRXV/Oxj30sIUC6eHG6QPBJwMcpKIDbb7+d9evXc8sttwAwb948HnnkkWaDuC+8EBvnf4DhhGzg3wEHAlMoKIDHHnuMdevWJYyxdGmq+fQCYqlr7wErCYsi+hIy0d9KMf/Y7Vogj5A53JPwWgWwgfC7OSh6e2t0jjGRNN8DDGLZsh4UF4e/N71796Z///4AVFdXszOaih+JRFi3jjTjFAClRCKwadMm3n//fYYOHUphYSG1tbW8++67JIv//9BYtrg/EEtvfJfG0uLw/vvvU1W1NuX9k/9vjRw5kl69elFTE3s+BxGy5SFkYW9r+BneeKOx2kD8ON26dWO//fZreB4qKyvZe++96d27d3TcZWmei3D7tdegV6/wGjliRFis8tprr7Fz586GBSPvvfdewnOzfXtz/07jgb7U1OzkuedeYtiwYYwaNQqAV155peG1KPm5iN0OwfYewKTokVWEigoHAv2oqdnBM8881+R+qW6PGDGi4W/tjh0vANuBqdGj7wBvNJz7xhuRhjLPyWNOnjyZAQMGNCykGTVqVMNzvnnzs4Tf61TPRYSKilDqs7CwkA9+8IMAlJeXs2zZMqZMmcKgQYPYtm1bw+tH7PETS2THj7s3EFJV582bx7Zt2zjxxBOjP8MbLImrgZ3qd6+iIrbnOEKG/1ZClYp9gIOBsDhobXTlWnPPb69evZgxYwYAa9cuA14ETiBUodgKPNRw7tq1EX7729TjjB8/nsmTJwPwt7/9ja1btza8l6msfAWIT6dO/N3bsgV+GV3TduqppzJ06FC2bNnCH/7wBw444ACOPDIsOnr44YdZs2ZNw2Mn/qmKH7MP8HEAXn75ZRYsWMCZZ57JsGHD2Lx5M7/5zW9S/gyx20uXxm4dTGOv3gcI7yP+F4AXX3yB3/42vtZ2c/+f/ofwN3MTcDdhcdJx0WO/I7Q6AFhLY8WG9tNcdrPSM1ApSZIkSdpjbN8Of/5zYsZj/Pfr1sG//515T7e+fcOWFAtKECvRunPnTnr06AHAf//7X5599tmUmZBr1qyhPqH2YhXhQtVG4E+EnoofpLIyn0suuYSePXtSUlJCaWkpJSUlDd8PGDCAvLw8Vq+G4cPjZzQtsx8yS8aPT70/V70ZO1t5y/Z8HvLy8ujWrVt0a/7c/HwYOHBgQpCvR48eHNZC7bmamlR7j0+4NXHiAUyZklk9w969+xNKFcdLXC1w++2hh1dzzjrrLM4666yG2wMHFgPzm73Pn/8MRx6ZuO+vf/1rwu3LLruMyy67rOH21q0R+vRJFQhuzAoeMqSEFStW0KdPn4b7/e53v2Pr1q3NZvN++MN1bN8e/w84AygjBDegb99B3HfffSkDwclB3Ph/z759L2T79vVx4x5GCICGeR95ZB2HHFKfcpyhQ0NgqEePHpx00kmMGzeuYZTCwn0IwaLUweCCgvB9Xdx/ok2bNvHOO+80BM527NjBokWLEh5z587YGMkXpYuAj5OfDw8++CDvvPNOQ6Dyueee4/Z00dYmphACleuAzwJfIhao/NrXvsazzdWqbDCcEISDcEH8CkIW8FGEwGWaF8AEQwgB4+9Fb59ECBDFVijcRfL/hfTms2nTVFavXs1ee+3F5Zdfzve+F8Y9/fTTWbhwYSvGGNHw2LNnz+bLX/4y8+fPj2YoVzYsLmhZ/M90LvE/029+cw/XX9+6nyn22OvWxZ7P+HE/BjT+TCedlOYnisu6/vWvf53wM1VXv0dYEJHeBdG1LvHP5wUXXMA777zTMO5vf/vbhozsVvxUwFTef38N5557RMK4F110Ucb/TvB7wu9IGHfjxiqmTWvde4L4x66uvpTE370/Ef+794tfJPZCTPiJGp7PaqZPn54w7ttvf4n4f6dkc+aELf7fac6cOQn/TmvXruW0005r1c8U+x2JROCqq65K+Hd6+OGHM/53Cq8R5yaM+9WvfrVV/04jRoxoCFS++eZfafx3KoqO+/GGc99+Gz7xiTQ/0eWXNwQqv/GNb/DOO+80BCpfe+0fNPcasX49XHhh9CeaP5+hQ4eyfv16PvOZz3D55Zc3BCpvvfXWDH73Pk4kAo8//jhf/vKXOeiggxg2bBjvv/8+l156aSvGgPB8xgKV3yX87oVA5bx5T3H33a39dzqSEKjcQHgNvpzGQOWPSfzda/9A5Y4d7T5kl2CgUpIkSZK0x6ivT39RJybTzEcI2Y/FxVVs3ryaUM4y9rUSOBk4mcpK2G+//Rg8eHDDhZ0//elPDVlGAD179qS0tJSysjKmTp1KaWkp//pXCUuXlgCx5j5HE0p99miY71/+8iNaUloaApWduRTh8OHpy2FdeimcemoIAKbaDmr+unFaRx4ZAtixcerrE8dtaw+ofv3Cz5JqzPr6zPuVxuwOAdB4Lc23rWN31Lgd1aOyvj6PcJkt/aW2Hj0KGrJVY1oT5GlaYXVsdAt69+7Nxz/+8eSTWtSnz2eoro7fk5glfPbZcNVVzY9RVFTEww8/nLBvr71+nJTZlOh//7dppubMmTOZOXNmw+0RI0bw/vvvJ5xz6qkQ4sUREoOg4R+soCBkFsVnn3/mM5/hzDPPbDabd9asOv761zpiGVchYPAPIGS05eeHC/bV1dUJ4yxcWMcddyQHphvLQ4fX8ltozDbuB3yV1MHsOuD+6M/2URqzMiFkEsenOx5MyLiPl5fm+2Hs2AF9+vThsssu45i4+uQf/ehHOSKufvLy5Xn84x+pxhzQsGfSpElcfvnlDZnsffv2bRLkSS4JXFGRR6iYHB8o+wShzHBw2GGHc80116QdJ/77WAZjnz6x5zM+6/p/gekNty67LC+hR2VsnFhWKcDUqVOZNWtWQxnufv36E7LCE2aTcOuzn81j1CgSnr+LL76YjRsbez8fc8wx3HrrrQ23a2vha19L9+80KvozDeC2225j0qRJDUc+//nPc+655zb5GeJvX3st7NgR30v6A8D3if3u9e49oCGTurlxAA4++OCGfQMHfpn33otfofUhoLEKwOmnw8knp/53Kisri44xkJ/97GcceOCBDceGD7+G115bE//oCXM54YQ8PvYxEsqtn3jiidxzzz0N2Z6DBg3il7G0wKgf/jCPF19M+KmiX/dv2HPjjTeyNa7e/sknn8ywYcMSxkn+3fv5z+Ff/wLYN7p3MCEYvF/DeTfddBPr4tKS0z2/vXr1ati3776n89RTo+PGGQI82HB8zBj4/vdTjxNfYeK2225j27ZtDbcnTjyThx/ej0SN4wwZksevfx2+Hx9dPVZUVMRf//rXhL9J3//+99mwYUPD7SefzEvqsxobs7E55TnnnMNBBx3E/vvv3zDuE088kfJniHnuubxoH9v4Uvh3ELJ5gzPP/Ch5eYcn9QJN9/8p9lpeTFgoEl95YzahFQLAeXSEtvbq7OoMVEqSJEmSsq6mBp5+OjHrMTn78cEH4QMfyGzc3r2hf3+Iu1bYRCzzMd5bb73FokWLOPHEExk4cCArVqzgc5/7XEMGZFVVVVL2Y7x+xAKV06dPT7gIddFFF3Haaac1ZED279+/yQWaz3+euLJXkPxRPZPA6qRJ8YHKqtbfMaXYxf5dHae44bvo4v+UWp0YkaFLLw1be7vhhrC1t899Ds45J3Xws64Oundv27jHHBMyX1KNWVeXeTnkmJEjQ3ZRukBwfX3bxu7RI5TPTTdmW+e8uwVWWzN21xs3j8aSqYnjxmcEAwwYMIABAwbQnCFNEmp6EUpxN44bKz+ZODbccUdzIx8R3RruAXyzmfP/Ff36s6T9ydHi40nOWm5OYWEI6vz4xz9O2H/55Zcn3L7vPpIClYkiETjuuOM47rjjGvYNHDgwYTFOKv/4B9FAZbz/l3DrqKOmcfLJmVUB6Ncv1fP52YRbX/wixLUETmnq1KlMnTq14XYIVH6t2ftccAEcdVTyvgsSbh9xxBEJgcwdO+BrzQ9Lr179uPLKKxP2nX9++lLgMbNmJWdxHRbdgp49+3HRRV9ocZxkffuem7To4JDoFkyZApckx8ybjNGXz3428d9lyJAzmr3PxInwmc8k75uY0Ie5T58+fPrTn044Z84ckgKVTZ2UlGa7//77NwTV0nniiVigMqY3obxooxNOOKH5B05h8OB9aQx+Qnjtia8AANEq4c1KzpYtKtqbUO42tZ494ZRTkvf15OSTT07YN2XKlITbVa14Ozh69OiGPsixcT/0oQ81e59YeeZEhybcGjFiJFOnJvf0bkkhiQsZACbGfd+bjhCtNK8MGaiUJEmSJGVdXR20dE2nLZmPAMOG1bJx4xqaZj6G77/znUp+/ONKevbs2dCX6MEHH+TKK69sKCnWvXt3/v3vf1NaWsrYsWM55phjePHFEt58swQoIazOjn0fSiCuXg1//Wtiv8Fx48YllERMJV2GYUyqwGo606bBI4/Ebg1t7tQM7Oo4jWUa45J5lMagQWFrb/vtF7b2duihcO+9HTPuW2+1/7hjxsA776QPftbVwb77tjhME716we9+l37Mujpo4Vp4Wp/9bLiQmyrTuL4+/Extse++oaR1ujn37dvyGKm0lLXa2cott3XcuKS8Ti3XF82bZgR3TT4P0q5p4e10p5GuxYGaZ6BSkiRJkpRWXR28+mr6no+VlfDzn2cegOrZM6wUT6rslyA+UBmJRNi0aVNDhuMBBxxAUVERmzdv5rLLLuOII45o6IGzZs10GjNTkuVRXV3MfvuVNJQlAzjttNPYa6+92CeaelFSUsKWLVsSsh+/+EX4UTMVWNsaWN1/f/jgB0PAsrQ0fE3+vrXOOw+uvbZ12V3ZVlAQ5iflUrduIQu0vfXo0XG/30mJcO3mySc7Ztx//7sxsJocrK2ra3sgftaskL2Vrjx0WwPxJ50ExcXpx01XHnpPu2jeq1dyn+PE4Fpbs6579WoaTE8O2rUliFdY2PTfPHmctmSgd+8eMvpSjRn7vncbErHy8kLVg1T7Y1pI/k3riCNgy5b04w5t43qjI45o+noZP+6oUW0fN3khRPy4bf2/NXly4vuf2Jixr4ce2vQ+rXHYYaHHebpx46rlZuSgg+BjH0vcF/88xCUmZmTCBPjUp9KP29bX4H32gYsuSj9uWxeL7LVXYuWLVP/nevQI/z925xYHal5eJBJJ7kAtSU1UVVUxNOmdzZo1ayguLk5zD0mSJO0Jduxoudfeb38LrahM1sT++8OyZbU0rqF9G3iMWPbjfvtVUlQUApOVlZUJ/XcefPBBzjrrLGpqaigsLORjH/sYv/vd7wA49NAf8OKLb9KY8ZiY/fjhD3fj73/PfL633kpSb5xEpaWd4+LJ2WeH8mfJPZ9yJ1x2OPts+POfczwVSWpHI0a05+t+rK/aK+01IMOHw7vvtttwkpRTM2bEVw7ZVe3/mjtjBsyd227DZVWur/2bUSlJkiRJe4BIBKqrm2Y9xt++9dbQTygThYUweHDiSvJkyZmEkUiEjRs3NgQYY9vq1asZNWoU/+//hd5U779/EfBLYBvQA3gJmNkwzmuv5bFhw1BKSkoYN25cQ5/H0tJSDjzwQAC6d+/Ohg0b6Bu3NP+4477UbI+itmY+lpWFVeqpMh5LS8PWGVx6aSxQ2bm01MdKknY3u3NfYEna3SS2OOh8r7m2OGg7A5WSJEmStAeorW25tNcbb2QeqIQQgEsMVK4H/gOMA/Zl9Wr4xCc+wVtvvdUQnNy+fXvKsaZNm9YQqBwx4mAqK8+mMVA5BfgrsezHE04o5rHHWv7Y2i+pAVdLAcO2Bio/9rGmJbo6o+OPD//OCxeuyfVUGkyZEuYlSXsS+wJLUvYktjjoXK+5tjjYNQYqJUmSJCnL6utD9mOqfo+VlfCVr2SeBdG9OxQVhXHTSRWgi0QibNiwIWX2Y+z7iorVhHKsLwIjgNeA04FvA1dRWQn//e9/2bRpE6Wlpey///4J2Y/J38cce+znWbz483GzGQqc3HDrvfcyew5iSkpCFmi6fo/JPbj2NHl5MHs2HHZYMTU1uZ5N6Cs0e3bbepBJUmdmX2BJyp6RI0N51c5YOeSMMzqmB3ZXYaBSrRaJRFixYgVr1qyhsLCQMWPG0L9//1xPa7ezbds2Kioq2LhxI4WFhQwfPrxJ/WdJktTU6tWwfDls3Ag7d4YL3/37w7hxnafcotQadXXQqxfNBpBOOaVt5dpKS+MDlTuB9wgBxsHAWCorYdasWWzcuJHvfe97QLj9jW98I+2Y/fr1Iz+/BJgA7Iju3Y9QsvVIIARAly1bRn5+fsbzbU5bMx8/9Sm44IK23XdPMXEi3HgjXH99rmcS5jFxYq5nIUntz4vmkpRdtjjYMxmoVItefvllfvjDH/LII49QVdVYszkvL4/DDjuMT33qU1x00UX07t07h7Ps3CoqKpg9ezYPP/wwS5cupb6+PuH48OHDOfXUU5k5cyaHH354jmYpSVLnsnIl3H8/zJsHixfH9/9pavjw0CNo2rSwctyLMmpPdXXpsx//93/hkEMyG6+gAAYNgjXNVOVMF6CLRCJEIhHy8/PZunUrDz30UELm47vvVgKx7Me1cfe8Avguq1dDRcVjVFRUNAQqDz/8cC688MKUmY8lJSX06dOHr3wFvvvd+JkMAj7dcGv1ajIOUkLIbgQYMiR19mNbFyGYuRdcfTU8+igsWJC7OUydClddlbvHl6SO5kVzScqexhYHuZ5JI1sc7Lq8SCQSafk0dUXr16/nyiuv5J577qGlX5Phw4fzs5/9jNNOOy1Ls0vtpptu4oYbbuiw8X/5y1/y6U9/utXnv//++1x77bXMnj2bulbWATnrrLP4yU9+wvBOVo+qqqqqSebnmjVrKC4uTnMPSZIyF4nA44/DHXfAww+H8piZKigIK9svvTR8WDBgobaqr4fRo0OQPN3v4r33ti1z7+CD4eWX4/fsIGQ/hiDj8cdXcswxq9myZQu33347EN6LXnzxxfz973/ngx/8IOvWrWPIkCEJ43bv3p+amhKglFifx/D9VOBYPvQhmDNnI3369KGgoKDV8/3ud0M52nSGDGm+5Gw6O3aE/6M9emR+X7VOVVVYxLF8efYfe/x4ePpp8CODpD1ZJAJHHQULF1a1fHJWFDNlCsyf7/tgSXumJUvg0EOrqK3N9UygR49iFi/e/auH5PravxmVSmn58uWceuqpvPnmm0DInpw5cyaXXHIJ48ePZ+vWrTz99NN885vfZPHixaxatYoZM2Zwww03MGvWrJzMua6ujp/97Gcd+hijRo1q9bkvvfQSZ555JhUVFQAUFBRw0UUXccEFF7D//vvTrVs3li5dyn333cddd91FTbT215w5c3j66ad54IEH+MAHPtABP4UkSZ3TkiUwc+aur4ysqwur2ufMCSsbZ8/e/T80qPXq6kJgJjn78Ywz4IADMhsrPx9qa5sPmK9e3fI49fX1PPXUU/Tt25cjjwylUrdvvw34ByHzcTWwPuE+TzwRtvz8fL71rW9RUFDA6NGjmT59On369AFg0KBBPPDAAwnZj7Nm9SYa10ypspI2tW+IaytJcXHqzMdIJPMLooWFGU9FGSouDgtATjghu8HK8ePhsccMUkra89kXWJKya+JEmDWr2BYHexAzKtXEokWLOPHEE1m/Plws6dGjB3/4wx8488wzm5xbW1vLxz72Mf785z837Pvyl7/Md77znWxNt8GDDz7IOeec02HjDx06lFWrVrVq5flzzz3H9OnT2bBhAwClpaXMnTs3bVnXl19+mdNPP50VK1Y07OvRowcPPfQQJ598cvv8ALso16sqJEl7rtpa+Pa34etfb75nX1t17x4+PFx9NXRzmd4eKRKBI46Ad94JQcpUgcV77gllWjN16KHw4ovJe7cT6/142mmrOfXUyoTyq7Hvv/e973HuuecSiUQoLCzkpJNO4uGHHwZgn30+zZtvzqEx8zExA/Kgg0q4774QgCwqKiKvlVcbv/99uOKK9McHDYJ16zJ6CgDYtClsxcXh/5R2P1VVIWCfjTKwU6fC3LkGKSV1LTff3Dn6At98M1x3Xa5nIUkdq7YWjj029y0Onn56z7jOkOtr/3vAU6j2tGLFCk4//fSGICXA7bffnjJICdCtWzfuu+8+XnnlFZYtWwbAd7/7Xfbaay+++MUvZmPKDe64444OHf/ss89uVZDy7bff5pRTTmkIUg4ePJinnnqKcePGpb3PQQcdxFNPPcWRRx5JdbRm1s6dOznnnHOYN28ekyZNap8fQpKkTiYbF85rasJFo0cf9cJ5Z1Nb2zT7cdo02HffzMbJywvlWd97L/05LWU+RiIR1q5dS2VlJXV1dRx88MHR/b8HHgZmA32Ax4HpDff7y1/CFtOtW7eG7MZu0U+seXl5/PznP2f06NEN55199i+4/fZ7085n50448MDm55xKfOZjXl74fU/u/diWzMd+/cKm3VdxcbiQctttMGtWxy0MmTUr9KTcEy7YSFIm7AssSdnTrVv4fJ/LFgdz5/qet72YUakGtbW1HHHEEbzwwgsN+4499lj+9a9/tbiC+4knnuCEE05ouN2tWzf+85//cMQRR3TYfOO99tprjB8/vsVemrviiSee4EMf+lCz59TX13PUUUfx7LPPNuz79a9/zSc/+clWPcZf/vIXTj/99IR9ZWVlvPDCCwwYMCDzSbejXK+qkCTteVauzF0pwpEjs/eYSjRjBqxYEQKHVVUhaBbv7rvhM5/JfNxJk+D551MdiQB5fP7zcPLJf6OioiIh6zH29b333msoxX/EEUc0vJ878MCrWbLkNuB1YB/gDeAGYhmQ48aV8JOfNJZeHTx4MPn5+S3O9wc/gMsvT398wAB4//3W//wxa9fC22+HgGRxsR+clVp7ldqOZ6ltSbIvsCRl28qVcMIHa1n+RvY++Izft5bHnuy2R11XyPW1fz+2qsFtt92WEKQEuOGGG1pVZur4449nypQpLIx+0q2treUTn/gEL730Er169eqQ+ca74447GoKUvXv35hOf+AQnnXQSEyZMoLS0lF69etE9gxpVO3fuZOjQoQ1ZkcOGDeO4445r8X533XVXQpBy4sSJrQ5SApx22mmcdtpp/CVuWX55eTlXX301d911V6vHkSSps1uzJvtBSoBly8LjzpvnRZxM1daGf7dY9uOBB0IG7bsbvPBC+DCZTmVly2PU19c3ZD/GAo1btlQS+j1eSQgiLgOmAF8GvkZlJXzlK19h6dKlDeN0796dkpISSktLOfTQQxt6Pe63334N53z4w19jyZKvAz2je/YBftdwPBIJv1OZKi1NvJ2XB0OHJmY/1tVBKwp6JBgyJGxScyZOhPnzQx/UO+4Iq8Gb68WaTkFByIq/5BI4/nj7oUmSfYElKbtGspJ5kY9wBt9lAUd1+ONNZT5zI1+hmD8Ce1CkMscMVAqAiooKbrrppoR9EydO5Pjjj2/1GJ/5zGcaApUAr7/+Ot///ve5roML42/dupV7770XgGnTpnHvvfey995779KYjz32WEOQElpX9rW6upqvfvWrCfsuvPDCjB/72muvTQhUAvz85z9n5syZloCVJO0RVq2q4owzcrPSHMLjnnIKLFhQbLZZMz73OaioaCzJmpz9+POfh4ysTJWUNB+oXL0aXnzxRdasWcOJJ54IhKoTd911V0MPyPfee4/a2to0I5xDCFQWAZOIfXhcvRp++MMfkpeXl5D92NKivFGj+jZ7vDWB1VSOPRb++tfGoKTZj8q2vLxwIf2EE8L/yfvvh2eegUWLQinldIYPh8mT4Zhj4LzzzFCXpGQjR4ZFcfYFlqQOFl0BXfzmcp7mWG7jKmYxixp6tPtDdWcns5jFVdxGtzfqXAHdzvwoLAC+9a1vsX379oR9Z599dkZjnHvuuVx88cXU1dUljPu5z32OIR24rPu3v/0tGzZs4Nxzz+W3v/0tPXrs+gvRAw88kHD7ox/9aIv3mT17Nu8n1eeaPn166pObcdRRR7H//vvz6quvNuyLRCLMmjWLRx55JOPxJEnqbEaMGNrySR1s0SK47bYIHbyeKmdqahqzH/faC4YNy3yMv/89lGhNp7UBuvr6eqqrqxuyH2tqYpmPq6NfY9sM4DYqK+GKK67ghRdeaOibXllZyWOPPUZJSQkjRoxg8uTJDcHGWEbkQw+VcO+9JcDw6CMXAU8kzPeENqQ+xvd8jMnPD9mPsZ6PtbWZBxlLS5tmVUq5MnIkXHll2CD8f1m2DDZtgh07oLAw9CgdPz71/wlJUiL7AktSB6upgTPPbFgB3Y06ruNWZvAwM5nNQqa220NNYQGzmclEXmncuXx5WJHy9NO+CLcDe1SKVatWsffee7Njx46E/c899xyTJ0/OaKwjjzyS//73vwn7brnlFq699tpdnmc6hx12GL179+bJJ59slyBlTU0Nw4YNa7gwVlJSwrvvvttsr6H6+nrGjh1LRUVFw76ePXuyadMmurXhherrX/86s2bNStiXl5fHa6+9xj777JPxeO0h13WqO63Vq8Mfpo0bYedO6NED+veHceO8+ihJKSxZAgce2DlqA3bvHuH553f/fmo33BB6EsZKsq5eDdXVjcfvuitkR2bqyCMh6W1dgpkzt3LNNZWsWbOGKVOmALBo0SLuuusuLrnkEiZNmsS2bdvo169fwkK2pgYDJcBHgFkcfTRce+2jvP/++5x//vnk5eVRW1tLQUFBs9mPP/kJfP7z6R+lb98QdMnUihWhPGZ8Sdbi4sxLskqSpK7JvsCS1P6qrrsObr015bEI8DTH80su5e+cQT2Zf3groJaTmMunuZNjeYJ0n0SLb76ZPWEFdK6v/RvqFbNnz24SpOzVqxeHHnpoxmN98IMfbBKovOOOO7j66qubDfS11YIFC3j99dd59dVX2yVICfDEE080BCkBzjnnnBbnPn/+/IQgJcDIkSPbFKQEOPHEE5sEKiORCPfccw+33HJLm8ZUO4nVxZo3DxYvbrku1qRJMG2adbEkiVA29KKLcj2LRjU14aLR/Pm57au2c2fIfuzbFwYOzPz+v/51CFSmk0lp0kgk0hAM7NnzeeBlmmY/hu9nz97E7Nnhftu3b6ewsJDVq1fzi1/8gqOPPppJkybRq1cvzj33XAYNGtSQ/fjkk6X88Y8lhODkMKAwYQ6rV8Opp56asK8176nSZXnl54eM0pKSxsywTIwaBf/7v5ndR5IkKca+wJLUzpYsYWiaIGWjJ6LbCOA84BhgcvR2Ou8Ci4BnqON+HuVdHm3hUSKzZsGMGa4c2UUGKsXvf//7JvsOPPDAFnsyphJbTR9v5cqVzJs3j+OOO65N82tOaWkpf/rTnxjZjgGgtpR9nTdvXpN9/fv3b/McDj/8cHr37s3WrVsT9s+dO9dAZS5EIvD44+ETxcMPt/4TxapVYXvkEbj22vBH69JL/UQhqct64gl49tlczyLRwoVhXm2oCJqxn/wkBBRjPR9j2Y9r14bjd94JF1+c+bilpS0HKrds2dJQejXW53H16tWccsopHH300QCMGzeOsWPH8te//hWANWt+Bvw8abQhhADjkRQVlfDpT4eyq7GMyenTp7Nu3ToGxkVck99r1tXBH//Y/Hwjkcz/VB56aFhQGyvHGst+LCoy+1GSJOWWfYElqZ1kvAL6XeA70Q3CYtnxQD/CotkdwCZgGfBe5vPpLCugd3MGKru4F198kWXLljXZf9BBB7VpvP333z/l/gceeKBDApVjxoxhzJgx7TZebW0tDz30UMPt0tJSjjnmmBbv95///KfJvt69e7d5Ht26dePggw9mQVLX9aVLl/Luu+8yYkRzKz/UrtqrRktdHcyZEzZrtEjqou64I/bdml0cKfa3+ZldHCe4887WByp37AjrVXr1yvxxvvc9KC9Pf3z16szHBOjffwWwFDgO6AW8AVxHLPtx9uxK7rprc8r79uvXryFQedBBByUs/jrmmM+ybNlphMBkLPuxsYJF375w++2J4/Xs2ZOePXs2O9/m+tsVFISs0m3bINO3UmPHwjXXZHYfSZKkbLMvsCTtgl1eAf0ebQpINiebK6D3UAYqu7i///3vKfePHj26TePts88+9OjRg507dybsf/LJJ9s0XrY99dRTrI2lNdC6sq8Ab775ZpN9mzenviDYWgcccECTQCWE3k8GKrOgtha+/W34+tfbv+v9woVw2GFw441w9dU2XJbUJaxcGcpcBbva4yD2utk+vRLmzg3zi8Xo/vSnxMzHWO/HykpYtw5++tOQIJ+p0tLmA5WxEq2bN29OyHxMlQk5ZMgQHn/8cQDWrv0F8A3g/4CJQB3wJ6AIKKVPn6mccUbIfCwpafxaUlLCXnvt1fD4f/rTnxLmM2nSJO6+e1Kz821L5uMBB8CXvtSY8Zic/dgB3QIkSZI6rZLIakpYDpGNwE6I9AD6Q2QcUJrj2UlSJ9O4ArpzyWQFtJrw6ngXN3/+/JT721pKtaCggFGjRvHGG28k7H/11Veprq6mqKioTeNmS1vKvgKsW7euyb6NGzfu0lzSBYuXLFnCGWecsUtjqwVVVaHxQ4pAcbupqYHrr4dHHw1XyLPUmFiScuX++9vWiycb6urC/GKr2q+9FlKsQWrQlszH2tpaBgyoIvR33AfoD6wDZgFHAR+jshKOPvrotO/PIGQslpaWJrxXO+yw01m8eC9C1iPAvsBOoDsAgwaFPpaZamkFf21tWPmfabX7cePg+9/PfD6SJEl7hFjt13nzYPHilmu/TpoE06ZZ+1WS4lZAd646TTRdAa2MGKjs4lJl7EHbA5UAw4YNaxKojEQivPjii5zQiVcV1NXVJZR9HT58eKvKvgKsX7++yb73339/l+YzaNCglPtXrFixS+OqBStXhtUvy5dn5/EWLIBjj4XHHvMPmaQ9Wop2zp3KM880BipLSpoPVMYyH+O98847LFiwoCHzMTkDsqqqikgkEj37ceB4IB/4MbAZ+BirV8OHP/wh9tlnn4Ssx/hMyH79+pGXlMI4efJkZs+eHLcnP7oFq1e3LfNxv/3C9bDkrMfY7cGDzX6UJElqlUgEHn88ZAI9/HDrV/CtWhW2Rx4Jq+lmzAilPY4/3l5okrqeuBXQnatOE01XQCsjBiq7sHfffZfq6uqUx3YlUDl06NCU+5cuXdqpA5VPP/00a9Y0rsU499xzm1wITKdnz57UJJUHXbduHVVVVRS3MVOuV5rmV/FzVDtbsya7QcqYZcvC486bZ2alpD3W4sW5nkHzFi1q/H7YsFrC+szVhD6PldHvy4CPU1kJF154IQ8//DBVVVXk5eXx73//m09+8pMJY/bq1YvS0lL22Wcfpk2bxsqVJTz7bCkQq5owAFgJhPdOlZVw0003ZTz3ljIfd+6E998PmZWZmDABfve7jKcjSZKkeEuWwMyZoQ3MrqirgzlzwjZlCsyeDRMnts8cJWl3sDutgFZGDFR2YeXNNEnalUBlusDc66+/3uYxsyG5L1Nry74CDBkyhE2bNjXZ/8ILL3DiiSe2aT7Jgc+YrVu3tmk8taCmBs48M/tBypjly0O52aeftmelpD3O6tXNV7TKrveBl4CxwEggAlzIqlWrOOCASqqqVlNVVR3dn+wU4OOsXg2TJo1i8uTJ7Nixg549e3Lsscfy+9//PiEDMjn78e674dln48fLAxr7Tre152NZGXzoQ00zH+O/HzgwszElSZK0i2pr4dvfhq9/PVxzaE8LF8Jhh8GNN8LVV3sdQdLuraYGtm2DrVvD19iWfLuzByrjV0ArI/4V68IqKipS7u/Tpw99+/Zt87iFhYUp91emqpPWSdTX1zNnzpyG2yNHjuSoo45q9f2HDRuW8vlctGhRmwOVGzZsSLm/sWxc7qXLyG0Pbc1EbauqG2/s2J6UrbFgAcW33QbXXZfbeUhSO+vYl7UaQvZjLOsx/mv89y8S+kI+B5wI3AlcTAgW/gXYxoYNpYwbN46hQ4/jlVdKCT0fY1spsaBiZSXMmjUrYRajRo1i1KhRzc60pczHmhpYtw6GDGnNz93owAPhiScyu48kSZI6UFVVWIzckdcZamrg+uvh0UdDbzQrNElqL7W1iQHCdIHD1gQXW7Ovri7XP3H7WLUqXDBo6cP/LqiqquqQcTvyOn9rGKjswlauXJlyf+/evXdp3HSByvfee2+Xxu1IzzzzTEIgNZOyrwBHHHEEzyamSADwxz/+kevaeHV23bp1KfcP7EQpERMmTOiwsbMakF2yhKG33pq9x2tGZNas0HPC8i2S9iD//Gdb7xkBaoHu0ds/BuI/wFwLfJvU2Y8Q+jQOJQQaNxEClROBHwHxfajfBnpz551w+ulwzz3wmc+kn9V774W2GJn2Z9xrr1BONVXWY+zrgAGZjSlJkqROZuXK7LaVWbAAjj0WHnsMdqFCmqROrL6+bUHDtgYX2zsLvCtZtqxDA5Xp2u7t7gxUdmEbN25Mub+jApXpHq8z2JWyrwDHHnssP/7xj5vsf+mll1iyZAkT2xB0WpWmRl5nClTuESIRuOiiXM+iUU1N6F0xf37mtf8kqZ1EImEReHl541ZRAaecEhaGZ6q4uLnSrxuB8ritIun7K4EboufOBrYCsfcaE4FzCdmO8ZmPse+LgYKkxysFPp+0L7z32bEj3GrpM0VtLaxdm/mi9YMPhldeyew+kiRJ2o2sWZPdIGXMsmXhcefNM7NSyoZIBLZvb//MwnT7Yh9WxVpgC7Atum2Nfj0EGAJsB36VdCy23QIMAJYQliuP7ogJpmgPp5YZqOzC0vU67NWr1y6NW1CQfEEw2NFJX1AjkQgPPvhgw+299tqLKVOmZDTG9OnT6devX8o+ld/+9rf5zW9+k/G80mW8GqhsZ088kdwwLPcWLgzzOuGEXM9EUhdz8cXh2kZFRfhclKxPn7YFKgcPXgMsAg4nBA/XACcTApGpKgh0B0YBU6JfYx4gfKz4UPT2x6Nb+4ittRo+PJRfTdfzsbQU+vVrt4eVJEnSHqBq1arwZjnbQcqY5cvhlFMoXrDAnpXqeiIR2Lmz/TML0+3bti3XP3HORQiNVAA2E5quJAcHewMfiJ7zb2ABiYHDrcBUIJZC8mXgaZoGGL8BfCF6zsHAuynm81fCVYYaQpOXVK4iXFHYHh23Q+r5ddIYSGfnX60uLF2gclczKuvS1JTeuXPnLo3bUebPn5+QvZhp2VeAAQMGMHPmTL73ve81OXbffffxuc99jmOOOSbFPdMrLy9PuX+//fbLaBy14I47cj2D1O6800ClpKx76y1YujT98VTtrWtqalixYgXl5eWUl5dTUVFBeXk5VVVVPPbYYwDU1/8V+F9gLjADGERYBzkRGAOUJW3DaZoJCdCxfwNjwcdDDoEct2eQJEnSbmboiBG5ngIsWkTktts6ukm81Do1NR1fojR+XzbbSHVCEWAHIXgYq0G0HNhA0+DgscBehKDezUnHY9sdwDBgKfA/KcbIj34F+DPw6RRzOgxYHP3+b4TGLcl20BiorCIsa+5FCCiWRr+PL3r0GUJjl17RrXf0a6xBWR/gsRTHexEyLgEmA+NTzKVdpKk2qeYZqOzC0vUA3NWMyvr6+pT705WEzbVdLfsac8UVV/CLX/yCDRs2NDl24YUXsmDBAoYMGZLink39+te/5p133kl57NBDD23T/DrC0qVLKSoqyvU02m7lytBwnvBHcFfEwtDP7OI4DebODfOzv4SkNHbuhHfeSSzPGivRetpp8NWvZj5mWVmqvXWEjwEDKS+HP/zhD/ztb39rCEquXLky5d/+oUOHsnnzZvr27cv06dP4979/Tlj7CCFjsiLzCXaw8R32SUWSJEl7tCVLcj2DRrNmwYwZ0IY2RNrD1dW1f2Zhc/vSJLN0FRFCIDAW3IsF26qBV6FJ6dK+QOyq9D8Igb3kc44GYssQLgUeITGAGAFuAq6PnnM68HqKuf2ZEKjMB76e4ngeIYA5jLCEeAchAFhMYgAwllV5MHAtTYODw+LGvJTQuCU+cBg7N+bXKeaSLNV84+UDOU396ODyS2vW7OpV7NSqq6uZMGFCyyd2EAOVXVjfvn07ZNzt27en3L+rmZodIbns66hRozIu+xozYsQIZs+enTLQ+frrr3PSSSfx4IMPstdee6Ud44UXXuDGG2/kkUceSXm8e/fuHHjggW2aX0coKiqieHfufXD//aEZNeEP7a6IvZi227NRVxfmd+WV7TWipD3I+efDH/7Q8BLWRCaLuSORCFVVVZSXl7NxY6wv5DTCRyCAkcA44F+Ul8OCBQv41a9+xcCBAykrK2PSpEmUlZUlbKNHj6ZPnz4Nj3HiiWO5/vqxbflRs2b48A7tdy9JkqQ9VSQCF13U8nnZUlMDM2fC/PmQYcUwZVl9feqSoh0VSKypyfVPnHO1JAb/+tGYZbeAEERMLl96CiH7LgJcAimzD38D7E3IYJwWN0b8R/Z6QlDvSUKGYrLxNAYqFwI/TDreExgcd7sfoRZRctbgAXHnXAFspGlw8Mjo8QLg/2gaOOxBY1nXccBrKeYb75Do1pxRJDZ22WN18Aro3fpafDMMVHZh/dJE99MFGlsrXS/KXc3U7AjPPvtsQubiRz7ykV0a7yMf+QjXXnstt956a5NjixYt4qCDDuJLX/oSH/3oR9l7773ZuXMn5eXlPPHEE8ydO5d///vfAAwaNIj169c3GePQQw+lR48euzRHxZk3L9czaN4zzxiolPZgkUj4rNiWdTx9+qQPUkLIrEy2efNmHnvssYYSrbGMyIqKCrZs2ZJ09vU0Bio/Suzj0IYNcNll1zNr1qyMeianztTsXCZPzvUMJEmStFt64gl49tlczyLRwoVhXraUyUwkAtu3t39mYbrb9rKjnqZZg9sIGXp5hL6Hz6Q43gf4YnSMh4HfpTjnGBqDfRcSgom1SY9/HSFzEEIQ8qUUcxxKCCLmAb8EYs3NetAY2IuVQO0D7E9i4C+21RGCMYcBP6Bp8HBQ3GN+gVDiNDZ+ISFTMF6qMqrJ0vVqjGfudTtyBXSbGajswjoqULl58+aU+zO5oJktDzzwQMLttpZ9jXfLLbcwePBgrrrqqibldd9//31mzZrFrFmzUt53//335/vf/z4/+MEP+Pvf/97k+DnnnLPL81OcxYtbPieXHn88BCr79Wvd1rOnqyWlTmbDBnjzzVCONbk8a0UFnHoq/PGPmY/bNPC3lZAJWQUcR0VF+Bt3yy23cO+993LQQQexbt06zj777IZ79OjRg9GjR3PUUUc1ZELW1ZVx/fVlwL5xYyeu49y4sYh99slsvkOGwL77wuupas50Ehm2kpYkSZKCO+4AOmFLmTvv3P0DlZFI6HmRjWzD2CZ2AFtIDPptI1QR2zt6zqPAu0nHtwEfAQ6PnvNRUvdHfAg4CHgLSFd3ZwshQLeYxizDeKNoDFQuB/5ACHTEZxfG/2tOJGRGJgcPj44750ZS9z6M/3T8bnRfT0I2YrKRwL/T/Ewx+8TNPZ1BJAYuO63CQujVK2y9ezd+v6v7Up3TsyeccQakqUTYKbgCus0MVHZhgwalfrnb1UDlxo0bU+4fPXr0Lo3bEeIDlWPGjOGII45ol3G/8pWvcNRRR3HZZZfxwgsvtHj+pEmT+OIXv8h5551HbW0tZ511VsrzdjXjU3FWr4ZVq3I9i+Zt3Qrf+U7rzy8oaH1QszVb9+4d97NJXcQVV8A996Q/nirzMZWdO3fyzjvvNGRCPvtsORAr01oOvBc9szewmXXr8ti4sYa1a9c2ZOiPGDGCX/3qVw1ByeHDh5Ofn7gms6oKrr+eZlVUwGGHtW7eMXl58OSTMGZMrE1JVWYDNBFbB7ur44SSKQUFcN55uziUJEmSup6VK2HuXKATtpSZOzfMb+TI9hoxqKnJTrZhbGuulEwXUkf41Jcc9NtG6MfXDXiHEARMDh72Ar4VHefPwI9TjHM0EFtDewkhczDZl4DvR7//JqE8abJ9aAxUPkkIesYHBgcQSqgS/f6jScdjwcHYJ9VJwO+TjvUilD2Nn9flNB/ouCK6NSf11dhERa04J6e6d9/1gGBr9/XqBfnJeZ4dbNq0zh2odAV0mxmo7MLGjRuXcn+6jMjWev/991PuHzWqc1Whfu6553j77bcbbrd3EPCoo45i0aJFPPHEEzzwwAMsXLiQd999l82bNzN06FD23ntvPvShD3HKKacwOW61xWOPPca2FCu4Jk+eTNnuUDtvd7F8ebsPuZlQz75f0pa1cF9dHbz/ftjaQ2FhY9Cyf/9dC3r26ZP9Ny9SO9i5E95+O3w+PuigzO/f0st2LFBZV1dHXV0dPXr0IBKJcNNNN1FSUsJnP/tZAM4//3z+/Oc/pxihBCgDPhT9WkasoMykSefx9tuN0beCggI+9alPNTufoqLw+WPr1sT9AweGn6WsLGRHtsXIkTBjBsyZA6F4TnvY1XHCR+Qzzmj/6zeSJEnqAu6/v/MG0urq4BvfgNNPb99AYlh52GVFCOVKY9l0VdEtuezoKODQ6Dm/A96gaXDwU8D06DkfpjEQGT/OPwjZtmuAEWnmVE3os/g6oWRosmIaA5XrgCUkBgaLCL0OYz5AuJaVHByMzxX7DiHrMTnIGB9or04z35ghhEzI5pSSup9jvE69zL6goGOChKnG6tkTuu3h4Z7zzoNrr4W6uk62/BlXQO+iPfw3V8054IADUu6vqqqitraWbm18YauqSv3fe8yYMW0ar6N0RNnXZPn5+UyfPp3p06e3fHLUvffem3L/5Zdf3k6zEgBpMn/bKgKsAI5Kcez/CCUm3iSszupP02Dm9wirxcqB/6Q4PggY1q4zboUdO8JW3dJby1bq27f9sj0tc6t2tmxZaOOSXKL13XdDtaEjjmhb25nGQGWE8Pa3PGFbu7aCsWPLeeedt/nJT37CZz/7WfLy8vjJT37Cvvvu2xCoPOOMMygrK2PMmDGUlZXRt28Zxx03mvBRMLXycjj44Mzmm5cH110XPufEApNjxoRAZXu49NJYoLJzueSSXM9AkiRJu6V583I9g+bNnh22PVwtIajXkxC0qgVeJnX24f8QgmoVwOwUx7sDv42O+0dCOdDkEqhHAU9Hz/k68NMUc/os8LPo93cDT6U4ZzKNgcpqGgN/A2kM/vWNHh8AfJ6mwcPYBqH34b+gSXZi/KfGmdGtOZ+Kbs05uoXjnVZeXnbKlMb2Wa2sfcWtgO5cy59xBfQuMlDZhQ0ePJiSkhIqKysT9tfX17N69Wr22muvNo373nvvpdw/adKkNo3XUeIDlWVlZQlZjbmydu1aHnrooSb799lnH/7nf1paP6SM7NzZ8jkZKgW+TKhnH7/FykJsJ7yhXRPdH0tYKiQ00YbQiyLVm8GDgRej398E3EHTYOZ0GlfO/RFYmeKcfaPzhFB+owehGXhWbN4cttWrd32sbt1C4HNXMz1j256+4kwt+uMf4cYb0x9vbYnWt99+m8WLFzN9+nT69etHXt6rwLmEj8FbU9yjN3l5ZXz4wx+mJK7h+jPPPMOwYY3LEz75yU8m3CsSCZ95mmuh0to5J/vqV9t2v9Y4/niYMiUEhTuLKVPCvCRJkqSMRCKwaFGuZ9Ep1dMY1KunMRDwFmHJZnJp0n2A2FvynxGCjMnBwZmE/ocAU5PGqYnu/wdwIiHgl+4q5PHAXkAlcEuK44Pjvs8nZE4OJTE4ODHunJMJmYHJmYXxdezuIFyDSQ4w9ow7Z3Ga+cb0Bn7UwjkDgeNaOKdT6tmz48uUxvb16OHC992dK6D3SF6Z7eIOPvjgJoFKgJUrV7YpULl9+3aqU2RfFRcXM3ZsuvbI2ff888/z1ltvNdzuLL0fZ8+ezc4UAbRrrrmGgoJULZrVZj16tOtweYSsxy83c84BhDIcMXWEcrFb4vZ9EJhD+mAn0e/3ju5fRwh/bCIx4/IXwD9TzOF24CvR7/cjNAHvR1ihFwtm/oDwpn9H9OdJDnb2I7wR700Ivr4Xtz9r68Rqa9u3zG3Pnu0T8OzfP5S59U1v1kQi4dcglgG5fTt8/OOZj9NSidaqKlizZgtVVRUNfSIrKsL3kUiEOdE3yffffz/XXnstCxcu5Mgjj2T//QcSPjYfQyjLOobGEq1lQBHf+14eM2YkPt5+++3X7Hzy8kKm46uvNt4eObIxC7KsDI7uhEtc8/LCgu4DD8z1TIIePcJ8/C8rSZLUxdXVwbp1sHZt2KqrG79v7vZuUgY1QuPi6Vj2YAnhc3wdIcCXHDzcBnyOEPyqICyaTs5QhMbMwt8TehtuI1xPiJkExMK5dxJKhib7JI2BykeAR+OOdSME9U6N2zc0bn98cDB2XaQPcHPSsdj3sU4WBwPLksboRWNJVwhLTs9NMd94pybNLZXxLRzvdAoLs5Nt2KuXFbOUOVdA75EMVHZxJ598Mv/4xz+a7C8vL2fq1KkZj1dRUZFy/5QpUzIeqyNlo+xrpjZt2sR3vtP07dohhxzCBRdckIMZ7eH698/1DCgglO4YELdvZHRrziXRLVn8x6M7CAHEjSQGPKfFnXMqsCrp+LuE1Y4AG0hdvgTCysPewH9JXK1XSPigMxJ4Ibrv78A9pM7ujDUqfxNYn3S8D43N0zvc9u1hS1O6OiN5ee1b5raw0DftcZ59Fv7wh8TyrPGVnIcN25VA5U7C8oHYGtq7CIVzyoEKhg1b0+R++fn57LvvvkQiEfLy8jj99NMZMWJEQ0/hgw8upbDwNXbsaHLXBm3NfPze90IycFkZ7LVXu6+/6DATJ8K1167h1ltzPZOQRTtxYsvnSZIkaTeyY0fLwcbkY+vX52y69cD7JAb3IPQRTJVZOJ7Gnn3fI7SPSS5f+v8IQUYI2X+vpHjcOcCZ0cdPF2g7kxCo3Ej4XA/hc3p8WdIIYfF2ESEomRwcjF8Telb0dnJmYXyqxC+jY8aOpbp4PTfNfGO6Ade1cE4vErMeO7Xu3bOTbRgLHJosoc7MFdB7JAOVXdyMGTP40pe+1GT/888/z/nnn5/xeK+//nrK/aeffnrGY3Wk+EDl2LFjO0VZ2h/96EesXbs2YV9BQQF33313m/uFqhnjdpu3o60W/zZybHRrzh0tHC8CVtM0u3MTIXsUQhnZK1Icj+9/sBz4U4rxT6AxUPltQm+IZFcA341+/1lCRmpywPOjwOHRcx4ilLNNPmcwWfyDF4nApk1haw/durVPpme/fiGAupu/nixbBt//fvrj770HW7eGz1nJ6urqePfddxMyIs866ywOPvhghg/fSfjNPQf4Q/Qe/4p+Xwrswwc+MJ2jjw49ImPbyJEj6R7Xc+KAAw5I6AGdnx8yH5cvTz/ntgYqTzqpbffrDL7xjWL+9VgNCxblrl/H1Mk1XHVVzh5ekiRJLYlEQvuQTLMct2xpeewOtJPw2XVtdKuOfl0PfIsQ1PsH8MXo/nU0LhgujBvnT8A3Uox/Do2ByoXAgzQN/NXEnX8cIbiZfM4+0ePdCVWZkrMTewGjo+dMIARTe0XPT3U5/oTo1pyjoltzils43ikUFGQn2zC27eaf46V2N3Eia669FldA7zl8leviysrKOOCAA3jllcS1VYsXL27TeC+//HKTfd26dePss89u03gd4aWXXkoIqHaGsq8rVqzg1hQvrJdffnmnCKLukUpLYfhwWLUq1zNJr0cPOOCAxqDXpk0hApMl+YRSMCXNnLMvjYHEdL5IWM25mcRgZq+4c86lsZxt/Bb/Z/5dwmrSTSR+6JpIY6DyPEI5m2QLgSMJfTuPIjGI2T/69S5Cf4i3CGVm4o/Fgp2xYpyxFaNZUVsbVve21wrfXr3aL9uzlWVua2vh3XcTsyDXrYOf/CTz6Y8Z0/I5L7xQzYoVjzUEJGNByRUrVlBTU5NwbnFxMQcffDBjxvQgP/9/qa8/OO7oTwnrecNv69lnw+c/n/mcy8pCoLJ378TSrGVl4ec56KDMx9zdrV+zil/UXMAMfswbOSiEtC+v8ouaL9CNv+HbYUmSpCyorw+faVoTaIzfUrTHyZatNAYbh9PYZ/FmYE3csdg2l/D5dAWJn2XjfY2QhdiD8C50AqEU6RBChmN8kZSPEsqTpitdCvA7wtLK5j6VpauUFO/CFo53I7EaVKeTl9dxQcJU+7p3N3tKyrHib3wD/vUvWLAgd5OYOhVXQLcPr8yIT37yk1xzzTUJ+1544YWGMnaZeP7555vsmz59OkOGDElxdm50xrKvl156KVuSVvwdfvjh3HTTTTmaURcxaVLnDlSedBLMTSpoUlcXVpTGBy/bsm3cGL4mBW06SjdCuZiBaY6fGN2aE9+jYgeNwcz4Rve/pmmwcxMwInq8ltCzYhPwTvTrZkLg8RfRc14AvpDi8fcFXot+fwvwTZpmbp4A3Bg957eEbNLkcybQuHK1mrBiNqtlbrdtC9uapmVMM9ZMmdv/bDuMG5b+D+Wbi3ln00Bq65uWjrn9U/9Hr+K4+xcWpniQRIMHryeUYt1CYzHjO4EfA48Dw3n22bf48pcbqwL07duXsrIyTjrppIRsyLKysob+yfn5MHbsbBILAyT+7Wpr5uNdd4XPtkVFfpaNGToi9r/yBMK/WzaDla/yOtOZ8NK7RG67Da5rqSiUJEmSEuzcGVYetjbDMVZatb6+5bE7UCUhiBif5bgWOBSILa//FPBUdP+2uPveRWMp1e8RsiAhBBBjgcZYSLWEEJAcQqhUNCTu+1jhlw8SSrvGm590+4Do1pxOfWG3Z8+OL1Mau92jhx+2pK6mW7dw3XTatObLWHWU8ePD45vx3C58FsXFF1/MLbfcwsa4Jl8bNmxg4cKFGfep/M9//tNkX6rSsrkUH6jcd999OfTQQ3M4G/j1r3/No48+mrBv+PDhPPTQQ/Ts2TNHs+oipk2DRx4BYFc7E9ZGv+7qOAklTo45pukJBQUwYEDY2sOOHbse9IzfIpH2mVcLCqNbUdL+lvKjxwDPJe2rJ6yUjYXRjiN8ME0OdvaNu8/ewIeSjq8mBDNj/kTqvhlfB26Ifn8MIZiZRwhWxoKZPwGmEwKon4w+dnLA8yOEFa1baVoSt5AsZXw2U+a2hg082RC2TW3FkecyriH8C3Tvzpa+fano2ZPy7t0pz8+nPBKhvKaGiu3bKd+8mQ0NK6r3JnQ3hdChtY5QTGk4kS2j+cP991M2dixlZWUMGTKkVQtvysogTQVzANK0YW7R6NEtn9OlLIm/JPMuIeA8l5aLQLWH+cAZhEtTwKxZMGOGZVokSVLXFImEqj2ZllZtrzYXbVBLeNdfTeibeGR0//OEzMLkcqv7EVqEANwK/CjFmJ+mMVBZSMiePJDGAOMQYHLc+f8hfEYbQmKloJi+pC7ZmnM9emSnTGnv3mERan7WluNK6qqKi+Hxx+GEE7IbrBw/Hh57LDy+2oWBSjFgwAAuvvhibrvttoT9c+bMyShQuXjxYt57772EfYcddhgnnthSnlT2LFmyhGXLljXcznXZ11deeYVLLrkkYV+vXr2YO3cuw4cPz9GsupDzzoNrr4W6uoYSLrtqV8dpCPMVFIT5dbTCwrAVJYf82iD2Ibc9Ap4bN4asvyzIJzEIWQR8oIX7nBfdmvNzQuZlcsAzvsrn/xBW9CafEyv3s4WQmZnK8YRA5VIaS9/GdCN8aK6M3v4HoURvcrBzHxpL/CyiF88zjA2MYB2jWcNYVrMf7zKe/3I0hQ3rg1unjHTphzsIYdQevMpe/JLXOIAQkKWmhg+vX0/ykpcCYC/CSucy4CG+yHqmxJ1xWXQLVt/wG77MlRmXud277kOUDNqLsuE7KNurjjFjoGyfAsrG9aBs/57sNcoVurssEoGLLkraWQ0cC1wFzCKx4FV72Rkd+zZCUDuqpgZmzoT5812BLUmSdm+RCGzYkFmW49q1sD1V84zsqSdkFiZnOa4FriUs5l0KzIjuez/uvt0I7/LyCAtAY1e1CgiVd4YQPvfEnE4IQiZnOca3O5ndijlnv3HBLnrzzbB6sqBplRtJ2u2NHAnz5sEZZ2SnDOzUqSGT0iBluzJQKSBkPf70pz9NKD86Z86cJsHL5jz44INN9nW20qXJZV9zGahcv34955xzDlvjeg7269ePRx55hMmTJzdzT7WbkSNDJs2cObmeSVNnnBHmtzvJyws9C/v0gZLmOlu2Um1t+5S5jW1ZKnMbM5SWA9dfb+F4X0LPzVTlbEuj55QQVusmH48PuVQS+nTGytzGHAUcyGRO4a9U803C+uIKSAgVXsjbjGY/XuczhJXKyQHP8wmliyCU310PbOId8riSCO8TOrhUA28DqwjdV85gJXtzO09wBtFAJfCJ6FhjCEHJMmAk0D1uRu9wKo8zPe3zVk5Z+CbDMrc/JY87iYQf4JWkg/n5acvctmlrRZnbPdITT8Czz6Y4UEdY4/4w4fJQZhUdmrcAmEnTf9SohQvDvE44oR0fU5IkaRfU1obSqplkOa5bF1qF5ECE8FkjFmgcTKh/AqFazKs07ef4A+Cs6DmHEgKWyT5BCFT2JVSgGUXTIGMd4eLmKYRKM0VAf1K31jghunUpw4fD3nu3fJ4k7c6Ki+Hpp+G220LlpI64Bti9exj7qqss99oBfEYFQGlpKTfccANXX311w7433niDf//73xx33HEt3n/79u3cfffdCfvOOeccTjnllFbP4aGHHmLWrFm8+uqrlJSU8LnPfY5rrrmG/HYsFREfqNxvv/045JBD2m3sTGzZsoVTTz2V5XEp6YMHD+Zvf/sbRxxxRE7m1GVdemnnDFQmZdp2Sd26wcCBYWsPe1iZ25iRhP4ntRSQTz35NJ3XBdEtVuY2PphZwFqqKSbkiE6gacjzGMpZyX68Th2hvNK7wAYae7BMIryhuADi8igjwHfiZtGfUBz3sOhjDeJGaphAuFBxBiHIeXF0jPuij15OY0B0MKG0U8jW3BF9jMRCt33YTAFtu0CT6rlrUF8fMn3jyqTvku7dmw9k9u/f+qBn3767z+roO+4AQug6tVeIcBRPczy/5FL+zhnUk/nPVkAtJzGXT3Mnx/JEy6WQ77zTQKUkxVu9OpTP2rgx9KLr0SP8bRo3DkpLW76/pEbbtmWW4VhdHTIjc6yaEPiLz3KsJnz++H/Rc64Dfhk9Fn9J+HJCH0eA3xGWjUF4Tz+EEHyMXZDMB75FY6/H+EBk7NVmFPBSC/MdEN3aVbduofrQkCGNW/Ltu+6C//63vR+5/bgQXlJX0a0bXHddSEqZOTMsSm4vU6bA7Nm2jelABirV4PLLL+eBBx7guecaO7h985vfbFWg8rvf/S5r4jJWhg0bxo9+lKryf2p/+tOf+OhHP9pwe8WKFXz1q19l9erV/PjHP271OM1ZtmwZr7zSmE2Rq2zKTZs2cdZZZ7EgLhV97NixPPTQQ0z0xS77jj8+/LFpzz9eu2rKlDAvta/2LnO7ZUv7BT1bUea2njwqKaGcMioYQzllCds77MVyxjGWt9KOEStz25fGD/01vEM+ddQzBZhCCP6tJ4QIw3YLK/kh4YLCm9H7XU5YBf0iIfz4ZnTco4BBhLDkvzmFVYwl5EN+ARhNCFF9AthELe82BD430dgndBmNfTzjjQBWAofzHE+zmOX8nHzy6UUB/cljIHUcTx2xvxq/AhbRNAP0YOCQ6DkV0ecldixrb4xqasKq93Xr2me83r3bL9uzd++OKYO6cmUoj0JSP94UzuUJzuUJVjKC+zmPZziGRUxmFSPS3mc47zKZRRzDM5zH/Yzk3dbPbe7cML/dLZNdktrLypVw//2hbNbixbBqVfpzhw+HSZNCv/fzzvO1U11HrD97pqVV46ooZdtOEoOMRxGK7JcTMh2TsxzzCO/FAf5IY0Ay3lFx+/sTKqBMJjHAGF8b4/eETwNDSF/g/8qMf7I26N07daCxudv9+rX8vri6unMHKo85JtczkKTsmjgxtHd54omwWHru3LD4PFMFBaHi3SWXhOu0tovpUHmRSJZSQrRbqKioYNKkSayLu3B67733csEFF6S9z9NPP82JJ57Ijh07AOjZsydPPfUUU6ZMSXufZBMmTODVV19tsj8/P59Vq1YxbNiwDH6K1G666SZuuKHx0vdLL73EQQcd1Mw92t+KFSs47bTT+L//+7+GfR/96EeZPXs2/fv3z+pcMlVVVcXQoYmFLNesWUPxnlCPe8kSqg49NJTXybHiHj3CxSGD1l1LK8rcvllRwD7fubjZYR7rdzYnbHukxd/lzYSLFoOjtwfxFd7ndcIliwpC3mSiQsJFiSejtxcDbwEfJlygSOUiZvMLkvsRNprMczxHyCKPvRnJIwQt36Rpbmc34NPR8x4F7k86vhE4BvhF9Jzzo+cku4ZQZBRCfucLccd6EgKWdwDnRvedTbiokhzw/BShvO9W4L8pjveBljP5OqPmytxmkukZ23pEL0ndfnsokbILKhnGMsbzKfoRoZA72EE/NjGeZZTwXssDNOe22+DKrFwmk6TOIRKBxx8PF3AefrjtF3BmzAhVSryAo91JXR2sX9+6YGN8adUst5NI5f+A1TQNMs4EDiT0uZ8Y3bcp6b5vEQKLiwnBRQhBxFiQcRjwGOE97MvR75OzHIsJCxNzauDA1gUa42/37Nkxc1m5EsaMgbo6qnZxqFhI8ZldHKfhKk1BAVRUuKBEUtcWW5D3zDOwaFHLC/ImTw6LPLrYgrxcX/s3UKkmFi5cyPTp09m8eTMAhYWF3H///Zx11llNzv3DH/7ARRdd1HBuv379+OMf/8hJJ52U0WP26NGDmjRv+OfPn8/Uqbveq+rggw/m5ZdfBmD8+PEpA6MdJRKJMHv2bK666io2REu49O3bl9tvv52LL24+8NBZ5PrFqsPdfDNcf32uZxHmcd11uZ6FOsimTVBeHlqE9O2b2X137oRevZq/hvjzn8PMiyLs2LiRt199lfJlyyh/4w0qKiqY+aEPMbZvX95dsYKRV17J5488kh8deyxs2sSgXyzm/ZrnCUWVYp0hxzR8fzov8xCXpOzz0pybuY7rubnJ/lJWUUY5h/AiP+WyDEdtva2EErWxIGYsoLk34eINhK6c5TQNis4Cjif0vOkHpMp5XQIcACyNfk2WTyhQ2w14HLiWpsHMvWlcQf4ysDzFOYPpgDJW2dSjRwhYbt3aquzh1og932m6TrbNjBkNGZ+StMdbssSSWNpz7NiRGGRsTZbj+vVZa+WQrJ7wHjWW5diLUPEDQvuDZ0gMQFYTapPEGvXsT2PWY7zfERosRAjtEgaS2MtxCPBxwnvLHYRg5xBCVZScLTEoKEgMKrYm8Dh4cOfrDXb22TBnTqdZpNjwm3322fDnP+dyKpLU+VRWwrJl4SLdjh2h+lq/fjB+PJSU5Hp2OZPra/8GKpXSf//7X84880xWr17dsO/MM8/k3HPPZfjw4VRUVPDrX/+af/3rXw3Hx40bxx//+Mc2ZSkecMABLF26tMn+9sqofP3119lvv/0abn/ta1/jG9/4xi6N2Rq1tbX86U9/4vbbb+eFF0LOTn5+Pp/+9Ke5+eabKdmNXvxy/WLV4Wpr4dhjIa4kb9ZNnRoaP3e2D13KyM6dobpEeXlYvFpe3rjFktUff7xt1X1HjYJ33onfs5KwzjmUaB05spz6+nJWpVgd9qc//Ylzzz2Xuro6LrzwQj784Q9z/vnnA/Dxj6/jd7/rT7rCp4dPquO/j6zJuKTtvJVlPFI5mbL6tyireY2y7a8yesdyerIj8x8+x2ppGsw8mHBhqZpQ0ir5+PbofoC5hAtMsWOxnNdDgeej319L6M+T7GM0ZoZ+GvgXTYOZnyT0+QSYTciYTT5nPCHgGSFcIIuV2t0ddUigctiwkNHeu3dYFVBYaGaQpD1PbS18+9vw9a93TGZY9+5w441w9dW+p1XmYu0VWtvHMfZ9dOF0Lm0gLDqL7+e4lvDu+pboOXcR2husJbwXizkV+Ev0+08T2hdAyFqMBRovBD4b3f8rwvvM5CBkMSE7Mmd69sy8tGr//qGax+7u8cdh+vTOF6h87DH7sEuSWiXX1/4NVCqt9957j8svv5z7709VOK9R//79ueKKK7jmmmsoLCxs02M98MADKXtGXnbZZe3So/KWW27hq1/9asPt//u//2v3fpA1NTVs3LiR8vJyXn75ZZ566ikeffRR1q9fD8CAAQM4//zzueSSSzjwwAPb9bGzIdcvVllRVRV67Sxf3uq7rKaE5YxjI/3ZSQ96sJP+bGQcyymlsvWPPX58CFLuSc9nF7VjR4hxNPfXdfZsuCh9RVQikQiVlZWUl5cTiUQ4+uijARgz5hu8/favCeGZQuARYEbD/QoLizjooDLKysoYM2YMZWVlDdvo0aPTvkbfdBPEVcZuoqgo/PdoF7W17dfbc9OmTlGyOVMRwir2TUANMDy6/xVClmaqgOgnoud8hRCojD++GfgucEX0nL0IIexkjwKnEMqB9QV60zSY+QegBHgb+GHc/v7RrwOBk6PjbYqO1S86VjYvzHRIoDJZXl644BYLXMa25Nup9rXldvecXlqU1BVUVYU+O9lYmDd1ashS971t11VfD++/3/oMx9jtnTtzNuWtJAYZDyVkH26kMcAYH4isJrxnGkionjE9xZhDoudB6Pn4E5oGGPcHToueU0V4TzWIHC8q698/syzHoqLwfqarikTgqKPIa88s9V0QgZDlPn++C+8kSa2S62v/LnFUWsOGDeN3v/sdX/va1/jlL3/JU089xZtvvsnmzZspKirikEMO4dRTT+WTn/zkLvdXPPfcc5kzZw6zZs1i6dKllJSUcPHFF3PNNde0y8/ywAMPNHy///77t3uQ8u2332bMmDEJ+woLCznooIM46qijmDZtGqeccgq9evVq18dVOysuDishTzghbbByJSO4n/OYxzQWM4lVjEg73HDeZRKLmcY8zuN+RvJu6hPHjw8rHb2Qk3P19aECRCwD8uijoawsszEKC0NJ+3fT/HNDyLRct24d5eXlKbe3336b7du3AzB16lTmz58PwMCBEd5+uw+wnhBOmgI8TCjTOoZDD+3XpmuPyT9jYSGMHh32x7ZIpJ0+43brBoMGhW1XRSIhMtxeQc/Nm7NSAiyP0AszuUvOAaQuIRvvOyn21ZO4Kv9h4H2aBjwnRI/XAR9JOvY+8A6NF8QqgO+neKxBQKyL9e+AWPHyfELwsx9wbPQYwD3AUzQNiB4GTIues5SQYRp/vG3LntpZJBJK1bZTudoWFRS0b/CzpXMKduecWkkZW7my2fe47W7BglCt5LHHulRvnz1WTU3mpVXXrWtb39N29irhfU1yP8fTgVjDmknR85L/4v8tek4+YQEXhGoasUBjGTTUCZlAeO8UCz7G93SM+Wh0a067fyLMzw/vuzPJchw8uLHHuFonLy+sRu0si9J79AjzMUgpSdpNmFEptYOamhqWL19OXl4e/fr1Y/DgwfTNtAFdJ5frVRVZlbTaPAI8zgncwaU8zAzq27C2tYBaZvAwl3IHx/NEY+aRq81zJhKB73wH3nqrMTD59tsh7hVzzz3wv/+b+djTpsEzz2wihKK6A+8BtwLHAWdx/vnw3//uyxtvvJFwv549ezJmzJiEbMgDDjiAU045BQhV2mbNSv+4w4aFQGumVqwICb2xoGRJyZ5RgSlj9fWhj+KmTbBx464HPqPB5t3RDqCSpsHOekKQE2AeIQMz+ZyDgJ9Hz5kJ3J1i/C/QeMHvGOA/Sce7A3cCn4nePoXGfqH9CMHYPGAxMJqQ2fkHwsXD2NY7+vUQwsq8nYQLkL2i43f5yzbdu7d/8DPd7Z49vVAm5UhVVVV4bztjBrz5ZvYnMHYsPPIIxfvvn/3HVmpbt2ae5bhxY86mW0dYJBULMNYRFkUB/BWYQ9NMx5OAe6PnnEF435DsRkJPcghl9jeQGFwsIrz/GE34PLgyui+nS4979Mgsw3HIEBg4sIu+sc+Nquuug1tvzfU0KL75ZrjuulxPQ5K0G8n1tX8DlZJaJdcvVllXWwu33caSG//EzNo7WMjUdht6CguY3e1SJn79I3DVVfbvyaHhwyGuFW8TX/sapGtnu337dt5+++0m2ZAVFRX83/+Vs2PHWmABIeuxEigFLgHuYOpUOPfc77Ft27aEoOSwYcPIb+ZCwq9+BZ/+dPM/05YtXbvqUqdSUxOyNLt4mdvtNA1mDgXGRc+5D3gr7tjG6Ncv0FhCrYxwATK5A9V/gcMJmRLpkp83EbI9/0a44AghczQW0BxL+J8Koafo3aQOdn4ues4/gTfjjsWPE5tDJSH7InbMV3lCsLI9S+U2F0Dt0cPAqBSV10n+L0RqanzP294iEdiwIbMsx+rqTrGQahuwkMQSqrHv7yH8nf4b8HFCHZF4Y4HYUr9bgesIf3MH0xhknE5jEPJvwLskBiGHRM/PadH1vn0zL63ap49/3zq72tqQTZ6NEtvpTJ0aVqH6mitJykCur/37V0uSUqilG9+OXMfXuYYa2ncF6kKmchiLuTGSz9X4QpypbdtC6dSKisZMyFNPhQ98IPOxysqaD1SWl8PixYt59dVX+cQnQpfABx98kMsuu4zVKe6Yl5fHiBEjGDp0f955pwzoEz0yjBBKGdEw7hVXXNHk/q2Zb0xRUbg9ZkxiiVY/j3Yi3bt3XJnbXc343Jwc8usYeTQG64amOecTafbHK49+rSdkT04iBEFjxbWKCT04t0W3rXHfxzIfSgkZmvHHthEuXMZUAoui++M7ZM2gMVB5L5Cqe/c1hAumEPp4vhh3rHt0HrNpLPl2NIkB01hg9AZC9sZ64GdJx2PbSdH7bgJWkxg07Qnt/FernWzfHrb1yZecO0BeXvayRXv18oVXao3bbjO7pzm1teH1sbUZjrHSqjlaxBQhLB6KL6W6H6EZAcCXgVU0DUI+TljCVw18KM3Y36MxmHgwTbMc4xtv/D9CGfoBpP/bd3KGP1vG8vJC1mImpVWHDAm9FrTn6dYtVEyaNi17pbbjjR8fHt/3JpKk3YwZlZJaJderKrIpqfJrh7Lya+t8/vOweHEI8KUqbXrDDaEsaibq6+s599xK5swpJ4RBYlsFMBH4EUcfDaNGnc/999/P1q1b6dWrF//617+4+uqrG7Ig4zMiR40aRWFhIffe23LJ2K1bw/XtTGzZEkrVjhkD/fpldl8pQX19+IVqr2zPLGdnxHp5vtKBj1FHYzAzj8aA5jJCZkZ8sHMrIetySvSc2wivJMlB0WsJF2YjwN5xx7dGHw9gCeHnW0r6nqW1hEDln4FzUxw/EHg5+v0dwF0kZoj2IvQI/VL0nN8Dy6FJ0PRgEp/rCE0zSXtgGV26dWv/4Gdz+yzhp9ZasoS8TtIvLdK9Ozz/PEycmOupdLzt2zMvrfr++zmbboTG1/E3CL0a4wOQ1cCRNJZjP5uwOGhn4jD8APhi9PvhhIU0/UgMMn6L8PdyB2HxTnKW4xDCMr+c/V3p1i3z0qqDBtn3WU1luy8whCClfYElSW2U62v/LrGRJKL9e4BVq+Ccc7LXwmfBAjjqKHjggVCGdE8M/LaHRYtg4cL0xysqmu6LRCKsXbuWgoICBkUz2q644gqWLl1KeXk5b7/9NjviG1I26E/IvQrj3n775zn//PMbSrJ+4AMf4Nlnn212vmXpalDGefvt8FkyE336QCe53qjdXX5+iHa3V8Q7ucxtcsbnypWhlvJupIBQMja54/T46Nacq1o4nkdjlmhMDSFoGcvDLqMxuzM+4Lk9OjcI2SvX0jSTtCRu3DrCBeH1JAZNe8Sd8wfgoRTz/DqNgcpzCMHMZH8k9C2tJ2TSJAc7exH6je5FyK65PelYbPt09Hl5D3g9xRh9aPpv0WnU1jb+rmdDYWH7Bz/T3S4stMzg7ioSgYsuyvUsGtXUwMyZMH/+7vM7FYmE/9eZllbdujVnU64hMYtxA6EqAMCzhIUryeVW9yGUYYXQY/r2FONupjFQOT76OLHgYyzAeHTc+S8R3lGnyxksBC7L6Cdrg969My+t2q/f7vP7qc5t5EiYN88V0JIktZIZlZJaJderKjpap+nfswe8JEci4RpNeXliedbycjjzTLjkkszHPP98uD9VrUU2AeVMmFDOzJmhR+RXv/pVhg4dyqJFizj88MO5+eabuS5aamzChAlUVFQ0ZEFu317Gk0+OIYQEYltjmc68vFBqNtPKTG+/DWPHwqhRiWVZ48u0lpR4HURdzIgRYTVIO8hGRuWeLEIIYMZWLMbK8yUHPMcDE6Ln3EUojZucSXo5MJkQDJ2WYoxthOzQvQmB18NTzKeQEIAF+A3wqRTnHExjOd2bgJ/QNNh5CqFXGdHjS2kaFD2WUDoY4F+EAGtycHUo6S+udzl5eaG/aEdki6Yas3t3/zi2l8cfh+nTqdrFYY6Jfn1mF8dp+MTw2GMhyyjb6upC1mImWY5r14YAaw5Eolt+9OvjJGY5xgKN3yIsBFkOHEHo85yshvB6/yBh0Uk3EgOMBxCy7yH0fl5K0yzHQTQuksmJAQMyL62aaekSqSPU1obS17NmdczrSffuYeyrrrLcqyRpl+T62r9/xSSpE6mt3b0/X3z842Eh55YtqY8PH962QGX//suBJ0ks0VoOrANg6VK4/PJw7rnnnsvQoUMZO3YsF110EYccckjDOPPnz2fAgAENgeknnwxbOpFICDrut19m8x01KlT92p3/LaV2N2lSuwUqO8Sxx8LNN4dMmG3bGrddvb1tW3gx6UTySPwQMDy6NefiFo4XEi5wN+cgYAVNg53xl+0mA9+nabAzfn7FhGzS2LH1hHK88b9dfwH+kWIOt9MYqLwgOp9kfwFOjT7+YFL3CZ0bndMbwI00DXb2B2KdiMuBF+KOxc4bSAgwQGM5304XootEGn+Ps6GgoONL58bf3pPLNd4RQk+7elkh9lrRbpcn7rxz1wOVO3dmnuW4fn3OXovrCZmN8UHG4YQSqAC3EBZixPdyrCZkN36K8LpwBuH1LtllhNeRQYRAZXKW4xBCoBPCYo4NhHKs6V5rjohuHaagAAYPzqy06uDBvqnW7qtbt9Cfd8aMkFXeXJmgTE2ZArNnd42S2pKkPZ7v9iSpE7nttvA5Jtfq69vWAquuLn2QEkJWZbyamhreeecdysvL6du3L0ceeSQAl156KU8//TRLliwBYNu2ecCl0XvlASMI67/LCMUGy/jnP8sYN66MESNGADBo0CBmz56d8HgDBw5MuN1SidaionB9K1N5eV5PkZqYNg0eeSTXs0jvtNPgmGNaPi9TkQjs2NH+wc9056Qsad059KAxMJfO/tGtORfTcuD0z8AWmvYJHRV3zm2E5S7JWaD7RI/XAdNTjLGGxsyi1cDvUjz+QBoDlf9MM9+pwPzo918BfgT0JDHgeR6hBC/ADYRMp+RM0hnRsSCU8a1PGqMXMI4QnKgn1CLoDXRPMaecq6sLZaQ3b87O43Xv3rGlc+Nv9+yZvWzRlSvDyrHOaO7cML+RI8Pr49atmWU4rl2bvTLLKdTR+P//HWAxTbMc9wJmRc+5gvB/u45ElwI/jX7/OPAU4XVjCDCSkEUev5491ms4ORDZM3p8KPBYC3PvGXd+uygsTAwutibw2L+/fXbVNU2cGEpfP/FEWEgyd2740J2pgoJQTvaSS+D4461CIEnaY3gZVVKXF42FdQqzZoXFlh29KLKmBlasaCzJmlyi9bTT4O67Mx+3aeAvQshzKQcqePHFcv73f0OJ1vLyclauXEl99APamWeeyZw5cwDo3r07ffr0YceOHRQWFnLyySfx61//kxCUHEWqonxlZSGTMRN77QWHHgqjRyeWZY2Vae3baRuiSbuh886Da68NgYjOpqAgzK8jxEpn9uwJgwa1fP6uqq8PKd3tGfxs7nZtbcf/TG3Qh8Z+n+n8TwvH+wEthdaPIZS9TQ52xj8rJxCCmckBz9K4cw4Czko6vo3ED2sLCAGNZHvRGKi8jBAoSfYk8EFCYDaWGVdAYkBzESEA8hLwZZoGO4sIZXcBXgb+Q9Og6TAg1kp5PSFbNnasU37wrKmBDRvClg09e3Zs6dzYvt/8pm0XwLOhrg4OPzwEq9auzeniim00DTKeSnjteIsQbEzOcgR4P/r1n0CqLqCTaQxUjgdOo2mW40Fx58+l5f8jqUpit6t+/TIvrdq7t0ESKRN5eSGj/IQTwoKN+++HZ56BRYuarzoyfDhMnhwW1J13XljoIUnSHsYelZJaJdd1qjtKJBL6zj/7bOfp4DNlSlhs2ZGf+//nf+CPf0x//EMfCos9WxKJRKiurmbIkCHk5+dz002vc8MN3wXOJVyajQADCPkbjQYMGEBZWRllZWUN/SIPOeQQpk2blvJx3nwT9tkn5aEG//wnTJ/e8pwl5dDZZ8OcOZ2vZ9rZZ8Of/7yLo3VRtbXtH/xs7nZnDb5kSYTQzzM+MFpEY3flfxL+4iaXzv04IaC5npC9mVx+dxshmNmP0LvzzOi+nXGPXUpjed0fEPqTJvsQEHv78Fkgvq5Bd0Iw5v8RSl3GzllG09K5nyb0PI09FtCkdO5R0Z+7lrAcKn6MnoTeftp1u0NP4Ajh9yCWJfxvYCVNg4xfIgT1dxKyF1OVUl1KyOp+BZhI+F2Kz2IsAu4n/H69SVhAkNzPcQA5LOOcl9e20qo9euRqxpIAKith2bKQMb5jR8hY7tcPxo+HkpJcz06S1AXk+tp/p1zYKmn3UF2das1+ap01oPnEE/Dss9CZOvgsXBjm1Vz7nkgE1qwJ129bKl+aypgxzR+PL9G6YcMGysvLqaioaMiEjG0VFRVs2bKF8vJyxowZQ1HRFuBnhNKsJxAu01xNuMwTyrQ+/3wZhx6aWVbRqFFh4X3y9elu3cKxsrLwWU5SJ3fppTBnDkNbPrNVdnWchtV6bWmeq6Bbt3AhrV+/jn+sSCRkwHVk6dz429u3d/zPlKE8GoNxqZzYwv0HAb9o4ZwP0JgxVkdjQDO+l+i5hMzJ5GBn/KXUDxDeHSVnksbngVQCy+PGiOVbT6MxUPnV6LFkC4EjCcHTVK2kexLK9PYD5hECpMnBzhGEspwQFj48AU0ySUcDR0fPeZvG0rnxgdEedML+orupOkJAPT7TsR/h9wnCu8x/kBiEXEt4t/nN6DlfIvR8THYaIVDZg/B/pS9NS6nGMp3HE8pH925mrmOjW4fp0SOzDMeiIhg40NKq0u6opMSApCSpw1RVtbxcPJPr/B3BQKWkNpswYUKrz+2sydt33JHrGaR2550hUPnWW/Dii03Ls1ZUhGuoxx8Pj6eqA9eC1MHNfxO6bX2MFSvgpz+9i6997TrWr1/f5Mzu3bszevRojjrqKMaMGUNeNP3zuOMOIFx2jA8ffDXhvuvWZT7f7t3h85+HAQMSy7OOGBEqNkraTRx/PEyZElZkdBZTpoR5qfPLywsX7nv0CBfjO1okEoKVHRkMjb+9c2fLc8qyAkIwJ7kS+kgSA46pnB/dmvNw0u0aQtAyPrfraZoGO7fSGCDqA1xL06DpNhr78dUQSvSuTzFGLFD5NI3lOuOdRmMJ4OuB+1KccxXw7bjzX6dpwPMrNAbbrqIxwzT+vNMJwbJthN6HyWP0IgTtdpeg6A4ag7jVhHeasezG2NcC4J7o+T8GvkjcIpKo42l87l4glEodTHiu9iEErOOD1TdHHzs+y3Ewib9XD7Uw9wKaD1JmrE+fzEur9u1raVVJkiTtsuRMyc7IQKWkLmvlytDDvjOaOzfM78474TvfSX9efOZjOjU1NbzzzjsJmZDz54eekSHr8RvRM79OuCz2P9TV5ZGfX8yBBx7YUKI1vkzr8OHDKUgRIRw7tjt5ecNoLi7dmjmn8oMftO1+kjqRvDyYPRsOPLDlc7OhR48wHy8EK5W8vMbef4MHd/zj1dV1TB/RdLc7Yb/Y7jSW74yZ1MJ9htBYSjadDxEyN+NFSMwS/RwhULgtaYuvlXEOIbiZHDQ9NO6cvoSA2CZCRmfsvE/GPe7taeb5UvTneZvGjNJkOwnP0aPAhTTN7twHuDd67qPRLTnYuT9wUvScFwm9S5ODpoNoDFBHgM00LaX6AWB49NhnaZrluJmwBK6EUOL33BQ/T/z/rH0Jz3FyKdW94875AXAHzZf2PaWZY+1i0KDMSqsOGWLpD0mSJKkZBioldVn33995W13V1YX5tVTWdcUKqKmp5733VtG3b18GDhxIbW0tM2fObAhKrly5kvqUP+gwQlGrmFnEd6MaP/4c/v3vczKad2FhyHJcubJxXywLcsyY8PWAA9LeXVJXMHFirmfQ6MYbO9d81LUVFIQMqr7J+YsdpKamfYKfrb1PJ5NHYoZdLCjWnDOjW3N+34rHXkHqPqGxt33FwPeTjm0j9CeNBXJ7E7IIY8fWRb/Gv+NbCNyZ4vE/SmOg8ptAqg69N9KYYfoWIZMz2UPAGYTn8X4aS6kOAcaR+HxOAH5HYgCyiJARG3NS3LzS6dnC8Yx065Z5adVBgyznIUmSJLWzvEhnrccoqVNJ1VA3E53xpWbGDHjkkZbPa51Y9O2V9hqQGTPg4ovhlFMiQBUhA7I8bvsRUMg99/yFCy88nbvvvpvPfOYzAAwePJhIJJKQDRmfEVlSMoYhQ5ovaPWLX8CFF2Y+7/vvD0lKsfKsgzJrRympC6havTq8yC1alLtJTJ5M8YIF4UK1pI4VicCOHR1bOjf+9o4duf6JO4XtwEaals4dSOM718cJpWqTg6YnEfo4HkDoAzqDxF6OQ4CjCBmVEEqt5jRnsFevzEur9u9vRr0kSZL2eHltfM+7Zs0aiouLWz6xHXhlRlKbLV26lKKiolxPo80WL871DFJ5ntDBp5x//KOcpUtjJVq3pDj3y8B+9Oo1kcsuu4zx48c3HFmxYgV9W8jIGD4cVq1Kf7ytJVrPO69t95PUdRSXlsJf/wrTpsHy5IKMWTB+fHh8g5RSduTlQc+eYcvGCqb6+qaBz/YunRu/r7a243+mNuhJyxmIJ0S35gwHftXCOe0apBwwIPPSqr16tecMJEmSpD3GmjVrWjynurqaCRMmZGE2qXl1RlKbFRUVZW1VRXtbvbr5IF3720pjRmQpcFh0/zlAJfCf6O2/Al8DYMeO7tTUjCasVy8DxkS/xrbw3G/fPoYf//jHCY/WUpASQrbjqlXh2uHIkYnlWcvK4Igj2vijSlJrFBfD44/DCSdkN1g5fjw89lh4fEl7pvx86NMnbNlQW9v+wc/mbnfW3gWZmDkTjjwydWnV7smdSiVJkiS11e5w/d5ApaQuqf2viUeAGuAxmpZoLQfiV65cTGPHoL5A/7hj5wPHEYKSw7n33gLOOw8qK9M/clszH++6KyQ2jBoVSrVKUtaNHAnz5sEZZ8CCBR3/eFOnwty5Biklta9u3aBfv7B1tEgEdu5MH8hcuRI+/vGOn8eu+sY3oKQk17OQJEmS1AkYqJTUJW3c2N4jRoA3CN184pUAYwlFtcYQMiEnxR1PLqS1d3QLNm0K2Y3NBSorKto244kT23Y/SWpXxcXw9NNw220waxbU1LT/Y3TvHsa+6irLvUraveXlQWFh2AYOTH3OlVdmu3RIZoYPN0gpSZIkqYFXaiR1STt3tveI+UAR8HUay7SOAXatX86OHSFQ+dJLjSVZ48uzlpXB3nu3OIwkdW7dusF118GMGaEc4MKF7Tf2lCkwe7arMyR1HZMmde5A5eTJuZ6BJEmSpE7EQKWkLqljSp0OBS5t1xELC+Huu+G++8ICeknao02cCPPnwxNPwB13hDKtbenFVlAQyslecgkcf7wvoJK6lmnT4JFHcj2L9I45JtczkCRJktSJGKiU1CX179/yOZ1Bv37Qa9eSMiVp95KXByecELaVK+H+++GZZ2DRouYzhIYPD1k6xxwD550X+l9KUld03nlw7bVQV5frmTRVUBDmJ0mSJElRBioldUnjxuV6Bq0zfnyuZyBJOTRyZOi1duWV4XZlJSxbFhr47tgR0s779QsvlvY7k6Rg5MhQSnvOHKp2caja6NddHac49s0ZZ7iQRJIkSVICA5WSuqTS0pB805nb9wwf7nV3SUpQUuILoyS1xqWXwpw5DG2n4XZ1nEjsm0su2cWRJEmSJO1p8nM9AUnKlUmTcj2D5k2enOsZSJIkabd0/PEwZUquZ5FoypQwL0mSJEmKY6BSUpc1bVquZ9C8Y47J9QwkSZK0W8rLg9mzcz2LRj16hPnk5eV6JpIkSZI6GQOVkrqs886DgoJczyK1goIwP0mSJKlNJk7M9Qwa3Xhj55qPJEmSpE7DHpWSuqyRI2HGDJgzJ9czaeqMM8L8JEmSpLZas2pVeMO7aFHuJjF5Mlx1Ve4eX5IkSVKnZqBSUpd26aWxQGXVLo5UG/26q+MUA3DJJbs4jCRJkrq84tJS+OtfQ8+D5cuzP4Hx48Pjd/PSgyRJkqTU/LQgqUs7/niYMgUWLhzaTiPu6jgRpkwJ85IkSZJ2WXExPP44nHBCdoOV48fDY4+Fx5ckSZKkNOxRKalLy8uD2bNzPYtGPXqE+eTl5XomkiRJ2mOMHAnz5sHUqdl5vKlT4emn7WUgSZIkqUUGKiV1eRMn5noGjW68sXPNR5IkSXuI4uIQPLz5ZujevWMeo3v3MP7TT5tJKUmSJKlVDFRKUidy1VW5noEkSZL2WN26wXXXwfPPh/4H7WnKlDDuddfZk1KSJElSq/npQZKANWvWUF0Np58Ob76Z/cffZx94+GGv6UiSJCkLJk6E+fPhiSfgjjtg7lyor898nIICOOMMuOSS0GTd/gWSJEmSMuQlcUkCiouLKS6Gf/0LTjgBli/P3mOPHw+PPWYLH0mSJGVRXl5443vCCbByJdx/PzzzDCxaBKtWpb/f8OEweTIccwycd55vYiVJkiTtkrxIJBLJ9SQkdX5VVVUMHTo0Yd+aNWso3gN7z1RVhYXhCxZ0/GNNnRoWsO+BT6MkSZJ2V5WVsGwZbNoEO3ZAYSH06xdW2JWU5Hp2kiRJktpRrq/9m1EpSUmKi+Hpp+G222DWLKipaf/H6N49jH3VVZZ7lSRJUidTUmJAUpIkSVJW5Od6ApLUGXXrBtddB88/D1OmtO/YU6aEca+7ziClJEmSJEmSJKnrMlApSc2YOBHmzw89JM86C/Lb+KpZUABnnx3GmT8/jCtJkiRJkiRJUldmLo8ktSAvD044IWwrV8L998Mzz8CiRbBqVfr7DR8OkyfDMcfAeefByJHZm7MkSZIkSZIkSZ1dXiQSieR6EpI6v1w31O2sKith2TLYtAl27IDCQujXD8aPt62PJEmSJEmSJKlzy/W1fzMqJWkXlJQYkJQkSZIkSZIkqS3sUSlJkiRJkiRJkiQp6wxUSpIkSZIkSZIkSco6A5WSJEmSJEmSJEmSss5ApSRJkiRJkiRJkqSsM1ApSZIkSZIkSZIkKesMVEqSJEmSJEmSJEnKOgOVkiRJkiRJkiRJkrKuW64nIGn3VV1d3epzi4uLO3AmkiRJkiRJkiQpXlVVVYvnZHKdvyMYqJTUZhMmTGj1uZFIpANnIkmSJEmSJEmS4g0dOjTXU2iRpV8lSZIkSZIkSZIkZZ2BSkmSJEmSJEmSJElZZ6BSkiRJkiRJkiRJUtbZo1JSmy1dupSioqJcT0OSJEmSJEmSJCVZs2ZNi+dUV1czYcKELMwmNQOVktqsqKiI4uLiXE9DkiRJkiRJkiQl2R2u31v6VZIkSZIkSZIkSVLWGaiUJEmSJEmSJEmSlHUGKiVJkiRJkiRJkiRlnYFKSZIkSZIkSZIkSVlnoFKSJEmSJEmSJElS1hmolCRJkiRJkiRJkpR1BiolSZIkSZIkSZIkZZ2BSkmSJEmSJEmSJElZZ6BSkiRJkiRJkiRJUtYZqJQkSZIkSZIkSZKUdQYqJUmSJEmSJEmSJGWdgUpJkiRJkiRJkiRJWWegUpIkSZIkSZIkSVLWGaiUJEmSJEmSJEmSlHUGKiVJkiRJkiRJkiRlnYFKSZIkSZIkSZIkSVlnoFKSJEmSJEmSJElS1hmolCRJkiRJkiRJkpR1BiolSZIkSZIkSZIkZZ2BSkmSJEmSJEmSJElZZ6BSkiRJkiRJkiRJUtYZqJQkSZIkSZIkSZKUdQYqJUmSJEmSJEmSJGWdgUpJkiRJkiRJkiRJWWegUpIkSZIkSZIkSVLWGaiUJEmSJEmSJEmSlHUGKiVJkiRJkiRJkiRlnYFKSZIkSZIkSZIkSVlnoFKSJEmSJEmSJElS1hmolCRJkiRJkiRJkpR1BiolSZIkSZIkSZIkZV23XE9A0u6rurq61ecWFxd34EwkSZIkSZIkSVK8qqqqFs/J5Dp/RzBQKanNJkyY0OpzI5FIB85EkiRJkiRJkiTFGzp0aK6n0CJLv0qSJEmSJEmSJEnKOgOVkiRJkiRJkiRJkrLOQKUkSZIkSZIkSZKkrLNHpaQ2W7p0KUVFRbmehiRJkiRJkiRJSrJmzZoWz6murmbChAlZmE1qBioltVlRURHFxcW5noYkSZIkSZIkSUqyO1y/t/SrJEmSJEmSJEmSpKwzUClJkiRJkiRJkiQp6wxUSpIkSZIkSZIkSco6A5WSJEmSJEmSJEmSss5ApSRJkiRJkiRJkqSsM1ApSZIkSZIkSZIkKesMVEqSJEmSJEmSJEnKOgOVkiRJkiRJkiRJkrLOQKUkSZIkSZIkSZKkrDNQKUmSJEmSJEmSJCnrDFRKkiRJkiRJkiRJyjoDlZIkSZIkSZIkSZKyzkClJEmSJEmSJEmSpKwzUClJkiRJkiRJkiQp6wxUSpIkSZIkSZIkSco6A5WSJEmSJEmSJEmSss5ApSRJkiRJkiRJkqSsM1ApSZIkSZIkSZIkKesMVEqSJEmSJEmSJEnKOgOVkiRJkiRJkiRJkrLOQKUkSZIkSZIkSZKkrDNQKUmSJEmSJEmSJCnrDFRKkiRJkiRJkiRJyjoDlZIkSZIkSZIkSZKyzkClJEmSJEmSJEmSpKwzUClJkiRJkiRJkiQp6wxUSpIkSZIkSZIkSco6A5WSJEmSJEmSJEmSss5ApSRJkiRJkiRJkqSsM1ApSZIkSZIkSZIkKesMVEqSJEmSJEmSJEnKOgOVkiRJkiRJkiRJkrKuW64nIGn3VV1d3epzi4uLO3AmkiRJkiRJkiQpXlVVVYvnZHKdvyMYqJTUZhMmTGj1uZFIpANnIkmSJEmSJEmS4g0dOjTXU2iRpV8lSZIkSZIkSZIkZZ2BSkmSJEmSJEmSJOn/s3ff0VFV7dvHr0mnhpBCL9KbdJCOUiwU6aCCFOlYUCzYkCYWLChNARVEQZEuD4qCgCIiSC+h956EEkpCSNnvH3kzP4ZMIGUmkwnfz1qzzNlzzr3vM+HhWWsu9j7IdASVAAAAAAAAAAAAADIdz6gEkG6hoaEKCgpydRsAAAAAAAAAAOA2YWFhdz0nIiJClSpVyoRu7COoBJBuQUFBCg4OdnUbAAAAAAAAAADgNu7w/T1bvwIAAAAAAAAAAADIdASVAAAAAAAAAAAAADIdQSUAAAAAAAAAAACATEdQCQAAAAAAAAAAACDTEVQCAAAAAAAAAAAAyHTZNqiMjY3V6dOntWPHDl27du2O5x45ckTGmEzqDAAAAAAAAAAAAEC2CirPnDmjMWPGqEmTJsqTJ4+KFy+umjVraufOnSles3fvXpUvX14BAQFq3769li1bpoSEhEzsGgAAAAAAAAAAALj3ZIug8urVqxoyZIhKly6t0aNHa/369bp582aqVklWrFhR+/btU+/evfXbb7+pffv2KleunJYsWeL8xgEAAAAAAAAAAIB7lNsHlXv27FHt2rU1bdo0xcTEyBgjY4wsFkuqa5QuXVqfffaZ9u3bp5YtW+rIkSPq1KmT2rZtq8uXLzuveQAAAAAAAAAAAOAe5dZB5f79+9W4cWMdOnTIGk4mvdKjRIkSWrFihV577TUZY/TLL7+oTp06Cg0NdXDnAAAAAAAAAAAAwL3NbYPKyMhItWnTxrriMb3hpD0ffPCBevXqJWOMDh8+rBYtWujIkSMOqw8AAAAAAAAAAADc69w2qBw3bpwOHz6cLKBM2vo1Nc+nvJOJEycqODhYFotF586d0yOPPKJr165lqCYAAAAAAAAAAACARG4ZVJ47d06TJ0+2CSmNMfLz89MDDzygDh06qEePHhmaI0+ePOrbt691S9kjR45o7NixGW3drRljdPz4cf3333/auXOnrly54uqW3FJ0dLROnDihbdu2aevWrTp27JiuX7/u6rYAAAAAAAAAAAAylVsGlUuXLtWNGzesx97e3ho1apQuXLigDRs2aOHChZo9e3aG52nTpo31Z2OMPv/8c509ezbDdd3Nzp071bdvXxUoUEAlS5ZU3bp1Va1aNeXLl0+1a9fWxIkTFRUV5eo2s7QdO3bopZdeUo0aNZQ7d26VKFFCNWvWVK1atXTfffcpT548qlq1qp577jlt2bLF1e0CAAAAAAAAAAA4nVsGlb/++quk/1tFuXr1ar3zzjvy8/Nz6DyVKlWyOY6NjdWiRYscOkdWdunSJfXr10/Vq1fXN998o/DwcJv3jTHasmWLhg4dqrJly+p///ufizr9P2PHjpXFYnHaa9asWWnq58CBA2rdurWqV6+uzz77TNu3b1dCQkKy84wx2rVrl6ZMmaLatWurWbNm2rdvn4M+FQAAAAAAAAAAgKzHLYPK/fv3S5IsFoumTZumBg0aOGWe3LlzJxvLCmFcZti/f7/q1Kmjr7/+2rr97YABA7Rt2zZFR0frwoULWrx4sWrVqiVJOnPmjB5//HGNGjXKZT3Hx8dr2rRpTp2jePHiqT53wYIFql27tn755RfrWKNGjfTNN9/owIEDunr1qqKjo3Xs2DH98MMPatWqlfW8NWvWqFatWg5ZGQwAAAAAAAAAAJAVebm6gfQ4f/68LBaLateuneFnUd7JuXPnrD9bLBYZY3T48GGnzZdVbN68WQ8//LAuXbokSfLx8dG8efPUvn176zl+fn5q37692rRpoyeeeEILFy6UMUajR4/WtWvX9PHHH2d630uXLtXp06edVj8kJERNmzZN1bk//vijnnrqKRljJCU+8/Srr75S165dk51bokQJlShRQk888YR++eUXPfXUU4qMjFRUVJR69+6t+Ph49enTx6H3AgAAAAAAAAAA4GpuuaLy2rVrkqTu3bs7dR57oeSt4WV2dOLECbVt29YaUkrSRx99ZBNS3srLy0vff/+9KlSoYB375JNP9Pnnnzu71WSmTp3q1PodO3aUp6fnXc/buHGjevXqZQ0pc+TIoV9//dVuSHm7Vq1aadGiRdZ5jDHq37+//v7774w1DwAAAAAAAAAAkMW4ZVCZJ08eSVLlypWdOs/ChQuTjd28edOpc7pSXFyc2rdvbxPGNmnSRM8///wdr/Pz89PkyZNtxl555RVt2rTJKX3ac+DAAa1evdqpc3Tp0uWu5yQkJGjw4ME2f05GjRqlhg0bpnqeZs2a6ZlnnrEex8fHa8CAAYqNjU1bwwAAAAAAAAAAAFmYWwaVJUuWlJQYrDnL9evX9cMPP8hisdiMBwUFOW1OVxs/fry2bdtmM/bOO+8k+wzsad68uerVq2c9jouLU48ePRQdHe3wPu2ZOnWqdQVjzpw5NWDAAC1atEj79u1TZGSkbt68KWNMql8xMTHy9/e31i9QoECqtn1dsGCBzWeYK1euuwa99jz77LM2x3v37tWKFSvSXAcAAAAAAAAAACCrcsugsmbNmpISV9E5y6uvvqoLFy5Yj40xslgsqlSpktPmdKVjx45p7NixNmNVqlRR8+bNU12jb9++NscHDx7UhAkTHNLfnURFRWnWrFmSpMaNG2vXrl2aNm2aOnTooPLlyytv3rzy9vZOU82VK1cqMjLSepzabV9/+uknm+MGDRooR44caZpbkqpWrar8+fPbjC1YsCDNdQAAAAAAAAAAALIqtwwqH3nkERljtGjRIqfUX7p0qaZNm2Z3JeFDDz3klDld7YMPPtCNGzdsxjp27JimGp07d04W5n3wwQc2ga8zzJkzR5GRkercubNWrVqlUqVKZbjm7aFgap4vKSnZ9rOBgYHpmt9isahYsWI2YwcPHkxXLQAAAAAAAAAAgKzILYPKtm3bKn/+/Prrr7+0atUqh9b++eef9cQTT9h9z2Kx6KmnnnLofFnBmTNnrCsSb9W2bds01cmXL59q1aplM3b16lVNnz49I+3d1RdffKGGDRtqzpw58vHxyXC92NhYLV261HpcsGBBNWnS5K7XRUVF6dKlSzZjZ86cSXcfuXPntjm+ePFiumsBAAAAAAAAAABkNW4ZVPr6+urll1+WMUa9evXKUBiUJCEhQePGjVPXrl0VExMjSdZnHiZt+9qlSxeVKFEiw3NlNTNmzLDec5IcOXKoRo0aaa5lb8Xp1KlTlZCQkO7+7mTDhg06ePCgfvzxR4eElJL0xx9/2ASOnTp1kofH3f+ncntIKUk7d+5M9tmm1tWrV22OCxQokK46AAAAAAAAAAAAWZFbBpWS9PLLL6t8+fI6e/asGjZsqJ07d6a71sqVK1W3bl298847unnzpnXL11u3fs2TJ4/Gjx+f4b6zoh9//DHZ2P3335+qZzLerl69esnGTp06pXXr1qWrt7spVKiQ5s+fr6JFizqsZnq3ffX39082dvnyZZvVmalljNHhw4dtxho1apTmOgAAAAAAAAAAAFmV2waVPj4+mjdvnnLlyqUTJ06odu3aGjx4sLZu3XrXa6Ojo7Vu3TqNGzdOZcqU0aOPPqpt27ZZV05KyVdTzpgxI9kzA7OD7du3a9++fcnGq1atmq56FStWtDt+e/jnKCVLltSjjz7qsHpxcXFasmSJ9bhQoUKpDghz586t4sWLJxsfNWqUbt68maY+Nm/erOvXr1uPLRaLevbsmaYaAAAAAAAAAAAAWZmXqxvIiKpVq2rRokVq166dbty4oenTp2v69OkKCQlRlSpVrOeNHj1avr6+ioyMVHh4uA4dOqT4+HhJ/xdISrIJKS0Wi/W9jz76SF26dMnEO8s8K1assDue3i1uy5QpIx8fn2TB3OrVq9NVL7OtWbNGFy5csB6ndtvXJM2bN9fMmTNtxvbu3asxY8bo3XffTXWdb7/91ua4a9euKl++fKqvBwAAAAAAAAAAyOrcdkVlkpYtW+rPP/9UqVKlZIyRMUbnz5+3BmPGGK1atUrLly/X33//rX379ikuLs56rsVisb6Sgsmkn3Pnzq3vvvtOw4YNc+UtOtU///xjdzy9W6l6enraXVW4d+9eRUREpKtmZkrvtq9JUlr1OG7cOM2ePTtVNY4cOaJvvvnGehwUFKRPPvkkTX0AAAAAAAAAAABkdW4fVEpSnTp1tH37dvXs2dPmuZJJAaQku8HkrecmnZ90Xp06dbR161Z17949U+8ls23YsMHueEae+VigQIFkY8YYbd++Pd01M0N8fLzNtq+FCxdO83MhH3zwwRSv6devn00AaU9sbKx69eql6OhoSZKvr68WLlyoIkWKpKkPAAAAAAAAAACArC5bBJVS4vMBZ82apf379+vZZ59Vrly5rKHjrSslb3frOcYYtWjRQr/++qs2btyoMmXKZPZtZKrTp0+nuMoxI0FlSEiI3fHQ0NB018wMf/31l8LCwqzHnTt3tvtn5m6mTZsmPz+/ZOOxsbHq27evXnvtNSUkJNi9dvDgwfr7778lJf6ZXr58uZo0aZLmHgAAAAAAAAAAALI6t35GpT1lypTRpEmT9NFHH2nTpk36559/tGHDBp08eVKXLl3SpUuXFBUVpbx58yp//vwKCgpS9erV1bhxYzVu3DhDAZ27OXr0aIrvZeRzCA4Otjt+8ODBdNfMDPPnz7c5Tuu2r0kqVaqkKVOmqG/fvnbf/+ijj3TgwAHNmTNHuXLlso6/+uqr+vrrryVJJUuW1MKFC1WzZs109QAAAAAAAAAAAJDVZbugMomfn5+aNGnCarQ7OHbsmN3xXLlyKXfu3Omu6+vra3f83Llz6a7pbAkJCVq8eLH1uGjRomrQoEG66z3zzDM6ffq03nnnHbvvL126VI0aNdLPP/+sYsWK6dVXX9XHH38sSWrTpo1mz56tgICAdM+fWZz53NGUAm8AAAAAAAAAAO414eHhTqnrzO/5UyPbBpW4u1OnTtkdz5kzZ4bqphRUnj9/PkN1nenvv/+2CVLTu+3rrUaMGKGbN2/q3Xfftfv+9u3bVbduXTVt2lTz5s1T3rx59cknn6hfv34ZmjczVapUyWm1k7ZsBgAAAAAAAADgXpfSY/fcnds+ozI0NFTt2rVT1apV9dxzz+nKlSuubsntpPSZOSuozMq/I0dt+3q7sWPH6v3330/x/XPnzmnevHny9fXV+vXr3SqkBAAAAAAAAAAAyAi3XFF56NAhNWzYUFeuXJExRnv27NG+ffu0atUqV7fmVqKiouyO58iRI0N1PT097Y7HxMRkqK6zGGO0aNEi63GxYsVUr149h9V//fXXVbhwYfXr10+xsbF2z4mJiVGXLl20ZMkSlS9f3mFzAwAAAAAAAAAAZFVuuaLy7bffVmRkpCTJYrHIGKM1a9boyJEjLu7MvaQUVGZ0RWV8fLzd8Zs3b2aorrP8888/OnPmjPXYEdu+3q5nz55asWKFvLxS/rcB+/bt0wMPPKBffvnFoXMDAAAAAAAAAABkRW65ovKPP/6wGyTFxcW5oBv3ldIzADO6ojIhIcHueEpbwrqas7Z9vdXFixf10UcfKS4uTg888IC2bt1qd3VlZGSkHn/8cU2ZMkUDBw50eB+OFhoaqqCgIFe3AQAAAAAAAABAthYWFuaUuhEREapUqZJTaqeGWwaV165ds/5sjJHFYlGtWrVUrlw5F3blfnLnzu2Uujdu3LA7ntGVms5w+7avxYsXd+i2r5K0fft2tW/fXsePH1f37t01a9Ys/fPPP+rcubPCw8OTnR8fH69Bgwbp5MmTevfddx3ai6MFBQUpODjY1W0AAAAAAAAAAJCtZdfv4t1y69fbA0kfHx/NmDHDRd24rzx58tgdTyloTK2UnkWZ0ZWazrBx40adPHnSetylSxeH1v/tt9/UpEkTHT9+XK1atdKsWbPk5eWlJk2aaOPGjapYsWKK144bN06vvvqqQ/sBAAAAAAAAAADIKtwyqHzqqadkjLGuphw1apSqVavm1DnXrVun6Ohop86R2ZwVVN664vVW+fLly1BdZ1iwYIHNsSO3fV24cKHatGmjq1evqkSJEpo7d67NMyrvu+8+bdiwQQ8++GCKNT7++GONHj3aYT0BAAAAAAAAAABkFW4ZVD7//PMqVaqU9Xjw4MFOnS8qKkoPPvigjh496tR5MltAQIDd8YwGlVeuXLE7XqJEiQzVdYZbg8qSJUuqbt26Dqm7fPlyPfnkk9bnpn711Vfy9/dPdp6/v79WrFihzp07p1hr9OjRNtvTAgAAAAAAAAAAZAduGVTmzJlTCxYssK4IXLVqlVPnO336tIwxTp3DFcqXL293PKUVkal1+fJlu+PFixfPUF1H+++//3T8+HHrsaO2fd23b5+efPJJxcbGSpIeeeQRtWjRIsXzfX19NW/ePPXp08fu+8YYDR48WBcvXnRIfwAAAAAAAAAAAFmBWwaVklS9enX99ttvyp8/v3r37q01a9Y4ba7ly5fLYrE4rb6rVK5c2e54eHi4dSVgeoSHh9sdL1myZLprOoMztn2Nj4/XE088oatXr1rHXnzxxbte5+Hhoa+//lq9e/e2+35YWJhGjhyZ4f4AAAAAAAAAAACyCrcNKiWpXr162rhxo8qXL69HHnlE48aNU3x8vEPnOHPmjN5//32H1swq8ufPr4IFCyYbT0hI0NmzZ9Nd9/z583bHa9Wqle6aznBrUHnfffepdu3aGa755ZdfaseOHdbjgIAAtWzZMlXXWiwWffXVV2rfvr3d92fOnKlLly5luEcAAAAAAAAAAICswK2DSkkqVaqUNmzYoBEjRmjcuHGqWbOmVq5cmaGa165d0+7du/X555+rdu3aKa4QzA6qVatmd/zUqVPpqnfjxg1FREQkGw8ODlbp0qXTVdMZtm7dqiNHjliPHbHta0JCgj755BObsaZNm8rT0zPVNTw9PTVnzhxVr1492XvXr1/XkiVLMtglAAAAAAAAAABA1uDl6gbSI6XgxxijXbt26dFHH3XYXNnx2ZS3euyxx/Tbb78lGz969Kjq16+f5nrHjh2zO16vXr0013ImZ2z7umHDBh09etRmrEqVKmmukzNnTv3000+qVq2aoqOjbd5bvXp1is+yBAAAAAAAAAAAcCduuaIyICBAxphkr6TnSNp7L72v7Phsyls9/vjjdse3bt2arnoHDx60O962bdt01XOWW4PK0qVLO2Rb2nXr1iUbs7e1bmqULVtWQ4cOTTZ+6NChdNUDAAAAAAAAAADIatwyqHziiSckJT7T79aXvbGMvrK7++67T5UrV042vmXLlnTV27lzZ7IxLy8vdezYMV31nGHHjh02gaojtn2V7G+X6+fnl+56AwcOTDZ28eLFdNcDAAAAAAAAAADIStwyqOzVq5f156SVj0i/p59+OtnYtm3b0vW52luJ2bJlSwUGBqarN2dwxravkv1tgi9fvpzueiVLllSxYsVsxvLly5fuegAAAAAAAAAAAFmJWwaVderUUYUKFST93wpKR273euvrXjBo0CDlzZvXZiwyMlL//vtvmmutX78+2diLL76Y3tac4tagsmzZsqpRo4ZD6trb5vXcuXMZqlmkSBGb40KFCmWoHgAAAAAAAAAAQFbh5eoG0qtnz5568803rSFlixYtVLduXeXPn185cuSQt7e3PD0907WFa3x8vGJiYnT69Gl9++23On36tJPuImvw9/fXoEGDNH78eJvxxYsXq379+qmus2XLFp0/f95mrGbNmnr44Ycd0qcj7N69W/v27bMeO2rbV0mqW7dusrENGzZkqOaNGzdsjhs1apShegAAAAAAAAAAAFmFxbjpssHTp0+rRIkSMsZo0qRJGjJkiFPmuXLlipo0aaJdu3Zp165dqlSpklPmcbWzZ8+qbNmyun79unWsTJkyNs9yvJu33npL7733ns3Y8uXL1apVK4f1mVGjRo3S6NGjrcfbtm1T9erVHVI7JiZGISEhunLlinXM29tbJ0+eVIECBdJcLzY2VkFBQTb1Dh8+rFKlSjmk37QKDw9XSEiIzVhYWJiCg4Nd0g8AAAAAAAAAAMgYV3/375Zbv0qJW2I+9NBDkqQ+ffo4bZ68efPqnXfecVr9rKJQoULJ7vPQoUP6888/U3X9jRs39NVXX9mMderUKU0h5ZIlS1S9enX5+vqqRIkSeu+995SQkJDq61Pj1m1fy5Ur57CQUpJ8fX01dOhQm7HY2FhNnjw5XfV+++03m5CyY8eOLgspAQAAAAAAAAAAHM1tg0pJ6tWrlyQpOjraqfPcK9ttvvTSS6pTp47N2Lvvvpuqaz/55BOFhYVZjwsUKKCJEyemeu758+erQ4cO2rFjh27evKkTJ07orbfeShb8ZcS+ffu0Z88e67Ejt31N8vLLL6to0aI2Yx9//LF27dqVpjqxsbF66623rMd+fn76+OOPHdIjAAAAAAAAAABAVuDWQWWnTp2UK1cubdq0yanzhISEyE13yE0Tb29v/fTTT8qfP791bNWqVfr222/veN1ff/2lsWPHWo/9/Py0ZMkSFS5cONVzjxw50u741KlTkz33Mr3mz59vc9y1a1eH1L2Vv7+/5s2bJy+v/3v8640bN9ShQwcdO3YsVTXi4+PVp08f7dy5U5JksVg0c+ZM3XfffQ7vFwAAAAAAAAAAwFXcOqjMkSOHNmzYoObNmzt9roSEhGz7fMpblSxZUsuXL1fu3LmtYwMHDtTixYvtnj9v3jy1bt1aMTExkqQ8efJo8eLFqlevXprmPXTokN3xhIQEHTlyJE21UnLrtq8VKlRQ1apVHVL3dg0aNND8+fPl5+dnHTt8+LAaNGiQ4ueY5NChQ2rZsqXmzJkjKTGknDBhgp544gmn9AoAAAAAAAAAAOAqFnMvLBVEmm3atEnt27fX2bNnrWPt27dX586dVbhwYR07dkyzZ8/W2rVrre+XL19eP/30U7oCwMqVKys0NDTZuIeHh86cOaMCBQqk6z6SHDx4UOXKlbMejxgxQmPGjMlQzbtZt26dOnfubLMlriRVr15dHTp0UOXKlZU/f35dvXpVhw8f1h9//KEVK1YoPj5ekhQYGKjvv/9ejz76qFP7TC1XP1AXAAAAAAAAAAA4lqu/+yeoRIrOnz+vl156ST/88MMdz8ubN6+GDRum119/Xb6+vumaa8GCBXafGfncc89p0qRJ6ap5q/fee8/mmY+7du1SlSpVMlz3bq5cuaLx48drwoQJioqKStU1uXPn1oABA/Tqq6+qYMGCTu4w9Vz9lxUAAAAAAAAAAHAsV3/3n22Dyvj4eP39999au3at/v77b506dUoRERG6cuWK8uTJo8DAQFWqVEk1atTQI488ogceeMDVLWdZe/fu1cyZM7VmzRodPnxY165dU1BQkKpXr67WrVvr6aefVt68eTM8z5IlSzRq1CiFhoaqYMGCGjRokF5//XV5eGR8h+KaNWtq27ZtkqSKFSvaXb3pTFevXtXKlSv166+/avv27QoPD1d4eLiMMQoMDFRwcLBq166tZs2a6ZFHHlFAQECm9pcarv7LCgAAAAAAAAAAOJarv/vPdkHl5cuXNW3aNE2ePFlnzpyxjtu7TYvFYv05JCREzzzzjAYMGKASJUpkSq+AO3H1X1YAAAAAAAAAAMCxXP3df8aXqmUh33//vcqUKaM333xTp0+fljHG+rJYLMlet75//vx5ffDBBypbtqwGDRpk82xGAAAAAAAAAAAAAI6VLYLKK1eu6PHHH1evXr108eJFu8GkPfaCy7i4OM2YMUMVK1bUjz/+mMl3AgAAAAAAAAAAANwb3D6oPH/+vBo1aqTly5fbBJTpcWtgeeXKFXXv3l2vvPKKgzsGAAAAAAAAAAAA4OXqBjLi6tWreuSRR7R7925JshtQpucRnEl1jDGaMGGC4uLi9Nlnn2WoVwAAAAAAAAAAAAD/x62DykGDBmnnzp3JAsqkcNLX11fVqlVTjRo1VKNGDZUvX17+/v7Kmzev/P395enpqevXr+v69es6d+6c9u3bpz179mj58uU6cuSItdakSZNUp04dde/ePdPvEQAAAAAAAAAAAMiOLCY9Sw6zgN9//12PPvqoTUiZtPVrw4YN9fTTT6tr167y9/dPV/0tW7Zo+PDhWr16tSQpT548OnTokIKDgx3SP+BuwsPDFRISYjMWFhbG/yYAAAAAAAAAAHBTrv7u322fUfn222/bHBtjVKNGDf3999/666+/1L9//3SHlJJUq1YtrVq1Sh999JEk6dq1axo7dmyGegYAAAAAAAAAAACQyC2Dym3btmnz5s2yWCwyxsjT01MTJ07U5s2bVb9+fYfO9fLLL+utt96SMUZff/21rl275tD6AAAAAAAAAAAAwL3ILYPKZcuWSUpcRenn56dly5bpueeeS/asSkcZOXKk7rvvPt24cUOLFi1yyhwAAAAAAAAAAADAvcQtg8r169dLkiwWi95//3098sgjTp3Py8tLPXr0kDFGa9eudepcAAAAAAAAAAAAwL3Ay9UNpMf+/fslSaVKldLQoUMzZc7q1atLkrZs2ZIp8wHuICIiItXnZtaDdwEAAAAAAAAAgBQeHn7Xc9LyPb8zuGVQeeHCBVksFvXo0SPT5gwICJAknTlzJtPmBLK6SpUqpfpcY4wTOwEAAAAAAAAAALcKCQlxdQt35ZZbv8bExEiSKleunGlznj17VpJ05cqVTJsTAAAAAAAAAAAAyK7cMqjMly+fJCkoKCjT5ly9erUkydvbO9PmBAAAAAAAAAAAALIrtwwqixUrJkk6depUpsx39uxZ/fjjj5KkwMDATJkTAAAAAAAAAAAAyM7c8hmVderU0bZt2/Trr786/TmVxhj16dNH169fl8ViUcWKFZ06H+BOQkNDM3VlMwAAAAAAAAAASJ2wsLC7nhMREaFKlSplQjf2uWVQ2apVK02fPl0LFy7Uu+++q/vuu88p88TGxqpXr176/fffrWONGzd2ylyAOwoKClJwcLCr2wAAAAAAAAAAALdxh+/v3XLr18cee0yBgYGKjY3V008/rZiYGIfPsWPHDtWrV0/z5s2TxWKxjnfs2NHhcwEAAAAAAAAAAAD3GrcMKr29vTVs2DAZY7RhwwY1b95cx44dc0jtbdu2qXv37qpdu7a2b98uY4yMMbJYLGrWrBlbvwIAAAAAAAAAAAAOYDHGGFc3kR7Xr19XpUqVdOrUKRljlCNHDvXv31/9+/dX5cqV01Rr//79Wr58uRYvXqx//vlHUuKzKSXJYrHIGCNPT09t3LhRNWvWdPi9AO4gPDxcISEhNmNhYWFusXQcAAAAAAAAAAAk5+rv/t02qJSkP//8U82bN7dZ9ShJ9913n+rVq6cKFSqoaNGiypMnj3x9fRUdHa1r167pypUrOnr0qEJDQ7Vnzx6dO3fOWvPWgDLp2GKx6K233tKYMWMy/yaBLMLVf1kBAAAAAAAAAADHcvV3/16ZMouTNG3aVNOmTdOAAQOsKx8l6ciRIzp69Giqatye0976PMoknTp1IqQEAAAAAAAAAAAAHMgtn1F5q759++qbb76Rr6+vLBaL9ZW0yvJur1uvuTXslBJDzKefflpz58514R0CAAAAAAAAAAAA2Y/bB5WS1KtXL61fv14VK1a02bo1NS/JdlVlUliZO3duTZ06Vd9++628vNx64SkAAAAAAAAAAACQ5WSLoFKSatSooZ07d2rSpEkqWLCgdcVkatwaWBpj1KlTJ+3du1eDBg1yZssAAAAAAAAAAADAPSvbBJWS5OHhoWeffVbHjx/Xd999p2bNmsnT0zNVW8D6+/vrueeeU2hoqObPn6/ChQu7+nYAAAAAAAAAAACAbMtiUrvs0E1FRkbqr7/+0rZt23Tw4EFdvnxZN2/eVEBAgAIDA1WuXDk1btxY1atXl4dHtsptAYcKDw9XSEiIzVhYWJiCg4Nd1BEAAAAAAAAAAMgIV3/3n+0fvujv76+2bduqbdu2rm4FAAAAAAAAAAAAwP/HEkIAAAAAAAAAAAAAmY6gEgAAAAAAAAAAAECmI6gEAAAAAAAAAAAAkOnu+aBy+vTp6t27t+bOnauwsDBXtwMAAAAAAAAAAADcE7JFUHn8+HENGTJEJUuWlL+/vx5//HGdPn06VdfWrl1b165dU8+ePVW0aFF169ZN69atc3LHAAAAAAAAAAAAwL3NYowxrm4iI5YsWaLevXvr6tWrSroVi8WiFi1a6Lfffkt1nR07duill17S2rVrZbFY1KpVK02ZMkXFixd3VuuAWwkPD1dISIjNWFhYmIKDg13UEQAAAAAAAAAAyAhXf/fv1isqlyxZom7duunKlSsyxshischiscgYozVr1iguLi7VtapVq6bVq1drwoQJ8vT01C+//KLKlStr0aJFTrwDAAAAAAAAAAAA4N7ktkHl0aNH1bNnT8XGxloDylvFx8crJiYmzXWHDh2quXPnSpKuX7+ubt26acaMGQ7pGQAAAAAAAAAAAEAitw0qn332WV27di1ZQCklbv1aqVIl5cqVK121O3furFdeeUVSYuA5ePBg/fLLLxnqFwAAAAAAAAAAAMD/ccugMjQ0VCtWrEgWUhpjZIyRj4+PJk6cmKE5Ro8erYIFC8pisSghIUFPP/20Tp48maGaAAAAAAAAAAAAABK5ZVD5448/Wn82xkiSKlWqpN69e+vjjz/W3r179dBDD2VoDj8/Pw0cOND67MvLly/r7bffzlBNAAAAAAAAAAAAAIncMqhcv3699efGjRvryJEj2rVrl7755hsNGzZMJUuWdMg8rVq1sv5sjNHcuXN18OBBh9QGAAAAAAAAAAAA7mVuGVQmhYVFihTR77//rhIlSjhlnrJly9ocJyQkaP78+U6ZCwAAAAAAAAAAALiXuGVQeeHCBVksFg0ZMkS+vr5OmydPnjzJxn777TenzQcAAAAAAAAAAADcK9wyqIyLi5MkVahQwanzXLhwwfqzxWKRMUZHjx516pwAAAAAAAAAAADAvcAtg8p8+fJJknLnzu3UeTZv3pxsLCwszKlzAgAAAAAAAAAAAPcCtwwqk54deerUKafOM2fOnGRjPj4+Tp0TAAAAAAAAAAAAuBe4ZVBZr149GWP0+++/O22O7du366effpLFYpEkGWMkSSVKlHDanAAAAAAAAAAAAMC9wi2DyjZt2kiSlixZoiNHjji8/sWLF/XEE08oPj7eZtxisahevXoOnw8AAAAAAAAAAAC417hlUPnggw+qbNmyiomJ0dNPP62oqCiH1T5x4oQeeughHThwQBaLxbqSMkmnTp0cNhcAAAAAAAAAAABwr/JydQPp9c477+jpp5/Wv//+q5YtW2ru3LkZ2pY1Li5O06ZN09tvv60rV65Yt3xNCistFosqVqyoRx991FG3ALi9iIiIVJ8bHBzsxE4AAAAAAAAAAMCtwsPD73pOWr7ndwaLuX3JoBtp0aKFVq9eLYvFopw5c+rtt9/WgAEDFBAQkOoaly9f1rx58zR+/HgdO3bMuoLy1oAy6b+//vqrHn74YWfdDpClhYeHKyQkJN3Xu/FfNQAAAAAAAAAAuJ2kRXlpFRYWlmmLj9w6qDx37pxq1aqlc+fOWcNEX19ftW3bVo0bN9YDDzygIkWKKF++fPLz81NkZKQuX76sQ4cOacuWLVq/fr1Wrlyp2NhYm4BSUrKQ8oUXXtCECRNcebuASxFUAgAAAAAAAADgPggqM8HOnTvVrFkzXbp0KVnYmBr2rkkKJ5N+7tChgxYsWJDuXyiQHRBUAgAAAAAAAADgPtwhqPTIlFmcqGrVqlq7dq2KFSsm6f+2bE3ty2Kx2ISSSTWSjvv376+ffvqJkBIAAAAAAAAAAABwIC9XN+AIVapU0ZYtWzRw4EAtWrQo3aHirQFlYGCgpk+frg4dOjiyVSBbCQ0NVVBQkKvbAAAAAAAAAAAAtwkLC7vrOREREapUqVImdGNftggqJSkwMFALFizQqlWrNGrUKP3zzz/W9+4WXN66JWXBggU1aNAgDRkyhAAGuIugoKBMW/4NAAAAAAAAAABSzx2+v882QWWSFi1aqEWLFtqzZ48WLlyoVatWadu2bbp+/brd8729vVWtWjU1bNhQTZs2VevWreXt7Z3JXQMAAAAAAAAAAAD3Fou5dTlhNnbu3DmdO3dOUVFR8vT0VEBAgPLnz6+AgAB5enq6uj0gywsPD1dISIjNWGY+UBcAAAAAAAAAADiWq7/7z3YrKlNSsGBBFSxY0NVtAAAAAAAAAAAAAJDk4eoGAAAAAAAAAAAAANx7CCoBAAAAAAAAAAAAZDqCyv/PGKOIiAhduXLF1a0AAAAAAAAAAAAA2d49H1T++uuvat26tfLmzasCBQooICBAuXPnVqtWrTRnzhxXtwcAAAAAAAAAAABkS/dsUHn16lV16NBBbdq00YoVK3T9+nUZY2SMUVRUlH777Tf17NlTDRo00JEjR1zdLgAAAAAAAAAAAJCteLm6gfQoW7asLBbLXc87cOCA3fHIyEg9+OCD2rlzp4wxkmS3njFG//77rx588EGtXbtWpUqVyljjAAAAAAAAAAAAACS5aVDZs2dPjRs3Tjdv3rSOWSwWGWPk7e2t5s2bq2PHjnavNcaoU6dO2rFjhywWS4oBZVJNSTp16pQef/xxbdmyRb6+vk64IwAAAAAAAAAAAODe4pZbv44YMULdu3eX9H9hYo4cOfTmm2/q2LFj+uWXX9SvXz+713766adavXq19bqkUDLpZ09PT1WpUkUPPPCA/P39ZYyRxWLR3r17NXLkSCffGQAAAAAAAAAAAHBvcMugUpLCw8OtP9evX1979uzRu+++q0KFCqV4zblz5zRq1CibVZRJKzEtFouGDx+u8+fPa+fOndqwYYPCwsI0adIkeXt7yxijKVOm6OLFi069LwAAAAAAAAAAAOBe4JZB5Y0bN7RmzRpZLBbVrVtXq1atUokSJe563ejRo3X9+nWbMWOMPDw89N133+n9999XQECA9T0vLy89++yz+uGHHyRJUVFRmj17tmNvBgAAAAAAAAAAALgHuWVQuXr1al2/fl0eHh6aPXu2cuTIcddrTp06pZkzZ9qspkxaSfnKK6/oySefTPHaDh066LHHHpMxRitXrnTIPQAAAAAAAAAAAAD3MrcMKn/77TdJUqtWrVS2bNlUXfPhhx/q5s2b1uOkkLJixYoaO3bsXa/v3LmzJGn37t3p6BgAAAAAAAAAAADArdwyqFy/fr0sFosefvjhVJ1/7tw5ffXVVzarKZN8/vnn8vb2vmuNkiVLSrJ9NiYAAAAAAAAAAACA9HHLoPLEiROSpFKlSqXq/PHjxysmJsZ6nLSasnXr1mrevHmqakRFRUmS3bATAAAAAAAAAAAAQNq4ZVB59epVSVLOnDnveu758+c1bdq0ZAGjxWLRuHHjUj3noUOHJEkhISFp6BQAAAAAAAAAAACAPW4ZVAYFBUlK3NL1bsaOHavo6GjrcdJqyq5du+r+++9P9ZzLli2TJFWsWDGN3QIAAAAAAAAAAAC4nVsGlRUqVJAkrV69+o7nbdmyxe5qSi8vL40dOzbV823evFlr1qyRxWJRvXr10t4wAAAAAAAAAAAAABtuGVS2bNlSxhjNmTNHR44csXvOpUuX9OSTTyo+Pt46lrSasl+/fipdunSq5oqJidHgwYNljJGkVD/TEgAAAAAAAAAAAEDK3DKo7NOnj3LlyqXo6Gi1bt1ahw8ftnl/y5Ytaty4sQ4dOpRsNWVwcHCqn02ZkJCgPn36aMuWLZKkAgUKqGHDho65CQAAAAAAAAAAAOAe5uXqBtIjODhYr7/+ukaMGKEDBw6oSpUqatasmfLly6e9e/dqx44d1hWQSZJWU06cOFH58uW76xyXLl3SU089pd9//12SZLFY1KFDB2fcDgAAAAAAAAAAAHDPccugUpLeeustbd68WUuXLtXNmze1YsUKSbIJKG9dTWmxWDRo0CB17dr1jnWjoqL01VdfacyYMbp06ZJNvSZNmjj4LgAAAAAAAAAAAIB7k1tu/ZpkwYIFGjJkiIwx1kDRYrFYX5Ks7/Xp00eTJ0+2Wyc8PFwLFy5U//79VahQIb300ku6dOmSTT1J1i1gAQAAAAAAAAAAAGSMxdy+R6ob2rhxoz744AOtWrVK169ft457eHioXr16euWVV9S+ffsUr/fwSF1ea7FYFB8fn9F2AbcUHh6ukJAQm7GwsDAFBwe7qCMAAAAAAAAAAJARrv7u3223fr3VAw88oMWLF+vmzZs6fvy4IiIi5OfnpzJlyihPnjx3vf7o0aOZ0CUAAAAAAAAAAACAJNkiqEzi4+OjsmXLqmzZsmm6rkSJEk7qCAAAAAAAAAAAAIA9bv2MSgAAAAAAAAAAAADuiaASAAAAAAAAAAAAQKYjqAQAAAAAAAAAAACQ6QgqAQAAAAAAAAAAAGQ6L1c3AMB9RUREpPrc4OBgJ3YCAAAAAAAAAABuFR4eftdz0vI9vzMQVAJIt0qVKqX6XGOMEzsBAAAAAAAAAAC3CgkJcXULd8XWrwAAAAAAAAAAAAAyHUElAAAAAAAAAAAAgExHUAkAAAAAAAAAAAAg0/GMSgDpFhoaqqCgIFe3AQAAAAAAAAAAbhMWFnbXcyIiIlSpUqVM6MY+gkoA6RYUFKTg4GBXtwEAAAAAAAAAAG7jDt/fs/UrAAAAAAAAAAAAgExHUAkAAAAAAAAAAAAg0xFUAgAAAAAAAAAAAMh0BJUAAAAAAAAAAAAAMh1BJQAAAAAAAAAAAIBMR1AJAAAAAAAAAAAAINMRVAIAAAAAAAAAAADIdG4ZVI4ZM0ZxcXGubgMAAAAAAAAAAABAOrllUDl69Ght377d1W0AAAAAAAAAAAAASCe3DCqNMXr//fdd3QYAAAAAAAAAAACAdHLLoFKSlixZoh49euj69euubgUAAAAAAAAAAABAGrltUClJP/zwg0qUKKHhw4fr4MGDrm4HAAAAAAAAAAAAQCq5dVApSRcvXtTHH3+sChUq6KGHHtKPP/6o2NhYV7cFAAAAAAAAAAAA4A7cOqg0xlj/a4zRX3/9pe7du6tw4cJ65ZVXtH//fhd3CAAAAAAAAAAAAMAetw0qmzRpot9//10LFy7UG2+8oXLlylkDywsXLmjChAmqVKmSmjZtqrlz5+rmzZuubhkAAAAAAAAAAADA/2cxScsS3YiHh4e2b9+uqlWr2oyvW7dO06dP18KFC3Xjxg1JksVikSQFBASoZ8+e6t+/vypWrJjpPQPuLjw8XCEhITZjYWFhCg4OdlFHAAAAAAAAAAAgI1z93b/bBpU3btyQj4+P3fcvX76s2bNn66uvvtLu3but40mhZYMGDTRw4EB16dJFvr6+mdIz4O5c/ZcVAAAAAAAAAABwLFd/9++WW7+uWbMmxZBSkvLly6cXXnhBO3fu1D///KPevXsrV65c1q1h//nnH/Xq1UuFCxfWiy++qD179mRi9wAAAAAAAAAAAADcckVlely9elXff/+9vvrqK23bts06nrTKsl69eho4cKC6du0qPz8/V7UJZFmu/lcVAAAAAAAAAADAsVz93b9brqhMjzx58mjw4MHasmWLNm/erAEDBihPnjzWVZb//vuv+vTpo8KFC+uFF17Qrl27XN0yAAAAAAAAAAAAkG3dM0HlrWrWrKkvv/xSZ8+e1YwZM1S3bl1rYHn58mVNmTJF1atXV/369TVr1ixFR0e7umUAAAAAAAAAAAAgW7kng8okOXPmVN++ffXvv//q888/l4eHhywWizW03LRpk/r27avChQvrueee044dO1zdMgAAAAAAAAAAAJAt3NNBpSQtW7ZMDRs21Isvvqikx3VaLBabwDIyMlJffPGFatasqQceeEDffPONoqKiXNw5AAAAAAAAAAAA4L7uyaAyISFBc+bMUdWqVdW+fXv9+++/1lAyKayUEgPLJEnvbd68Wf3791fhwoU1ZMgQbdu2zRW3AAAAAAAAAAAAALi1eyqojImJ0dSpU1WmTBn17NlTu3fvtgaQSasok8LJpPFWrVrpzz//1Jo1a/TEE0/Ix8dHxhhduXJF06ZNU+3atdWoUSMtXbrUxXcHAAAAAAAAAAAAuA+LuXUJYTZ19epVTZkyRZ9//rnCwsJSXDUpJQaUXl5e6tatm4YPH64qVarYvH/x4kXNmjVLX331lfbt22dTo1atWpo8ebLq1q3r5DsCMl94eLhCQkJsxsLCwhQcHOyijgAAAAAAAAAAQEa4+rt/t1xRWapUqVSdFxYWpjfeeEPFixfXW2+9pfPnz9tdPSklBpQ5cuTQc889p0OHDum7775LFlJKUv78+TVs2DCFhoZqzZo1ateunfX6zZs3q0GDBho9erRjbhQAAAAAAAAAAADIptxyRaWHh4fOnz+fYpp77NgxjR8/Xt9++61u3LhhXUF5++pJKTFgzJ8/v5577jk9//zzCgwMTHM/Sc+t3LFjh3WeLl266IcffrA7J+COXP2vKgAAAAAAAAAAgGO5+rt/t1xRKUnLly9PNrZjxw716NFD5cqV07Rp0xQdHW2zgjJJ0vMnixYtqgkTJujEiRMaNWpUukJKSapdu7Y2bNigZs2aWevPnz9fAwcOTN/NAQAAAAAAAAAAANmcl6sbSK8XXnhBFy5cUMWKFRUaGqpFixZp48aNkpTiCsqk8cqVK+u1117Tk08+KS8vx3wEfn5+mjNnjkqVKmVdxfn111/rwQcf1FNPPeWQOQAAAAAAAAAAAIDswm23fk1pG1cp5YCyYcOGGj58uNq0aeO03ho2bKgNGzbIYrHIGKPg4GAdOXJEuXLlctqcQGZw9fJvAAAAAAAAAADgWK7+7t9tV1RK/xdAJrEXUFosFrVt21bDhw9XgwYNnNpPdHS0du3aZdNHRESEZsyYoRdffNGpcwOuEBERkepzCTQBAAAAAAAAAMg84eHhdz0nLd/zO4NbB5X2VlVKiQGlt7e3nnzySb322muqVKlSpvSzdOlSXbt2LVlfCxYsIKhEtpSW/2254eJtAAAAAAAAAADc1u0rJbMitw4qk1ZM3nqcK1cu9evXTy+//LKKFi2aqf389NNPNsdJ27+GhoZmah8AAAAAAAAAAABAVufWQWVSSGmMUb58+fTSSy/pueeeU0BAgEv6SXo25e1iYmJc0A0AAAAAAAAAAACQdbl1UJm0onLgwIF67733XBZQJrk9kEzqr0qVKi7qCAAAAAAAAAAAAMia3DqoDA4O1pw5c9SiRQtXtyJJql27tlatWmVdVZn036FDh7qyLcBpQkNDFRQU5Oo2AAAAAAAAAADAbcLCwu56TkREhCpVqpQJ3djntkFlQECANmzYoFKlSrm6FatPPvlEzZs3V0REhKTEoHL48OF66qmnXNwZ4BxBQUEKDg52dRsAAAAAAAAAAOA27vD9vdsGlS+++GKWCikl6f7779e+ffu0YsUKXbhwQQ899BDbvgIAAAAAAAAAAAB2uG1Q2a1bN1e3YFf+/PlZQQkAAAAAAAAAAADchVsGlQkJCa5uAQAAAAAAAAAAAEAGeLi6AQAAAAAAAAAAAAD3nns+qNyzZ4/Wrl2r2NhYV7cCAAAAAAAAAAAA3DOyTVC5adMmjRo1SkOHDtXChQtTfd2aNWvUqlUrBQQEqF27dvr111+d2CUAAAAAAAAAAAAASbIYY4yrm8iIixcvqk+fPvrf//5nMz5ixAiNGjUqVTXCw8P1wQcfaMqUKYqNjVXp0qX1/vvvq1OnTk7oGHBP4eHhCgkJsRkLCwtTcHCwizoCAAAAAAAAAAAZ4erv/t06qDx//rwefPBBHThwQLffRp48eRQZGZmmegcPHlSPHj3033//yWKxqHXr1vr6668JYgC5/i8rAAAAAAAAAADgWK7+7t9tt36Ni4tT69attX//fhljZLFYrC9JunbtWpqDyrJly2r9+vXq1KmTjDFavny5GjVqpBMnTjjjFgAAAAAAAAAAAIB7ltsGle+++662bt1qDSdvX1Hp7+8vf3//NNf18vLSDz/8oNq1a8sYo4MHD6pRo0Y6f/68o1oHAAAAAAAAAAAA7nluGVRevXpVEyZMsK6elGT9OSmwfPbZZ9Nd38vLS99//708PT1lsVh06tQpdevWTQkJCRlrHAAAAAAAAAAAAIAkNw0qf/jhB129etV6bIyRMUaenp6qUqWK3nvvPY0ZMyZDc5QrV07dunWzBp/r1q3T5MmTM1QTAAAAAAAAAAAAQCK3DCrXrFlj/dnX11ejRo3Sf//9pxs3bmjnzp16/fXXbVZbplfXrl0lybq17Lhx43T9+vUM1wUAAAAAAAAAAADudV6ubiA9tm7dKilxi9a///5bNWvWdMo8derUsTmOiIjQokWL9PTTTztlvqzOGKMTJ04oLCxMvr6+KlmypPLmzevqtgAAAAAAAAAAAOCG3HJFZXh4uCwWi3r16uW0kFKSgoODk43973//c9p8WdXOnTvVt29fFShQQCVLllTdunVVrVo15cuXT7Vr19bEiRMVFRXl6jYBAAAAAAAAAADgRtwyqEx6PmXjxo2dOk9MTIz156TtX7dv3+7UObOSS5cuqV+/fqpevbq++eYbhYeH27xvjNGWLVs0dOhQlS1bNkuEuGPHjpXFYnHaa9asWXft4dixY/L09HRaDw8++KDTP0cAAAAAAAAAAABnc8ugMleuXJKkokWLOnWeffv2JRs7e/asU+fMKvbv3686dero66+/ljFGFotFAwYM0LZt2xQdHa0LFy5o8eLFqlWrliTpzJkzevzxxzVq1CiX9RwfH69p06Y5dY7ixYvf9Zwvv/xSCQkJLu0BAAAAAAAAAAAgq3PLoLJYsWKSpIsXLzp1nuXLlycbi42NdeqcWcHmzZtVv359HT58WJLk4+OjRYsWadq0aapevbr8/PyUP39+tW/fXv/++686deokKXGF5ejRo/XKK6+4pO+lS5fq9OnTTqsfEhKipk2b3vGcmJgYffPNN07rQZK6dOni1PoAAAAAAAAAAACZwS2DymrVqklKDNSc5fr16/riiy9ksVhsxu09tzI7OXHihNq2batLly5Zxz766CO1b9/e7vleXl76/vvvVaFCBevYJ598os8//9zZrSYzdepUp9bv2LGjPD0973jO/Pnzk22R60j+/v565JFHnFYfAAAAAAAAAAAgs7hlUNmyZUsZY/Tjjz86bYXj0KFDdf78eetx0vanSSFpdhQXF6f27dvr3Llz1rEmTZro+eefv+N1fn5+mjx5ss3YK6+8ok2bNjmlT3sOHDig1atXO3WO1KxkdHZY+vjjj8vHx8epcwAAAAAAAAAAAGQGtwwqO3bsqJw5c+rEiRMaM2aMw+u/9dZb+uabb2SxWGSMsXnvsccec/h8WcX48eO1bds2m7F33nkn2apSe5o3b6569epZj+Pi4tSjRw9FR0c7vE97pk6dav1d5cyZUwMGDNCiRYu0b98+RUZG6ubNmzLGpPoVExMjf39/a/0CBQrcddvX7du3a8OGDdbjJk2a6Msvv9TmzZsVFham6OjoNPVgjNHgwYNt5ujatasDPzUAAAAAAAAAAADX8XJ1A+mRJ08eDRw4UBMmTNB7772n/Pnz66WXXspw3bCwMA0cOFA///yzdezWkC5nzpzq3r17hufJio4dO6axY8fajFWpUkXNmzdPdY2+ffvq33//tR4fPHhQEyZM0JtvvumwPu2JiorSrFmzJEmNGzfWrFmzVKpUqQzVXLlypSIjI63Hqdn2dcqUKZKkgIAAffHFF+rWrVuGekhISNCiRYusx/ny5dPDDz+coZoAAAAAAAAAAABZhVuuqJSkt99+WyEhIZIStxlt06aNTp06la5akZGRGjFihMqUKaOff/7Zus1r0gq9pOOXX37ZZpVddvLBBx/oxo0bNmMdO3ZMU43OnTsnC/M++OADXbhwIcP93cmcOXMUGRmpzp07a9WqVRkOKSVpwYIFNsd3W8kYGRmpuXPnqlChQlq3bl2GQ0pJWrdunc32w+3atWPbVwAAAAAAAAAAkG24bVAZEBCgr776ynr866+/qnTp0urWrZt+/fVXXb169Y7Xnzt3TgsXLlSXLl1UuHBhvffee7p27ZpNSJm0mtJisej+++/XW2+95dR7cpUzZ85YVyTeqm3btmmqky9fPtWqVctm7OrVq5o+fXpG2rurL774Qg0bNtScOXMcEuTFxsZq6dKl1uOCBQuqSZMmd7xm1qxZMsZo2bJlqly5coZ7kNIelgIAAAAAAAAAALgTt9z6NUmbNm30wQcfaPjw4bJYLIqNjdWCBQu0YMECWSwWlS9fXkWKFFG+fPnk5+enyMhIXb58WYcOHdK5c+esdZJWTiYFk7eGlMYYFShQQEuXLpW3t3fm32QmmDFjhmJiYmzGcuTIoRo1aqS51kMPPaRNmzbZjE2dOlXDhw+Xh4fjc/ENGzbo4MGD2rt3r8NWG/7xxx+6dOmS9bhTp0537f3LL7/Ue++9lyyoTS9jjM22rwEBAWrZsqVDagMAAAAAAAAAAGQFbh1UStKrr76quLg4vfXWWzbhojFGe/fu1b59+5JdkxRMJrn1OZS3h5SFCxfWypUrVaJECSfehWv9+OOPycbuv//+uz6T0Z569eolGzt16pTWrVunpk2bpqu/OylUqJDmz5+vokWLOqxmWlcyxsXFafjw4Xr66acd1sP69et15swZ63H79u2zbVAOAAAAAAAAAADuTW679eut3njjDf3444/y9/e3Bo1Jr6TQ8tbXre/fGlJKsrnm8ccf1/bt21WxYkUX3Znzbd++3W6YW7Vq1XTVS+mzuj38c5SSJUvq0UcfdVi9uLg4LVmyxHpcqFAhNWrU6I7XeHl5qXfv3ukKdlPCtq8AAAAAAAAAACC7yxZBpZQY5OzatUtPPfWUJNvtXO8UTN4qKaAsVaqUvvnmGy1ZskRBQUGZ0r+rrFixwu54eleQlilTxu4WrKtXr05Xvcy2Zs0aXbhwwXqcmm1fHc0Yo4ULF1qP8+fPr+bNm2dqDwAAAAAAAAAAAM6WbYJKSSpSpIi+//577d+/X8OGDVOJEiXsrqi098qXL58ef/xxLV26VAcPHlTv3r1dfTuZ4p9//rE7nt6tVD09PVW8ePFk43v37lVERES6amamrLCS8d9//9WpU6esx2z7CgAAAAAAAAAAsiO3f0alPWXKlNHHH3+sjz/+WEeOHNGWLVt0+PBhnTt3TlFRUfL09FRAQIDy58+vkJAQ1a5dW5UqVXJ12y6xYcMGu+MZeeZjgQIFdOjQIZsxY4y2b9+uFi1apLuus8XHx9ts+1q4cOG7bvvqDFkhLAUAAAAAAAAAAHC2bBlU3qpUqVIqVaqUq9vIkk6fPp3iKseMBJUhISF2x0NDQ7N0UPnXX38pLCzMety5c+c7bhXsLLdu+xoYGMi2rwAAAAAAAAAAIFvKVlu/Im2OHj2a4nsZCSqDg4Ptjh88eDDdNTPD/PnzbY5dsZJx06ZNOn78uPW4Q4cO8vLK9v+eAAAAAAAAAAAA3INIQFLw33//qUOHDqpfv75mzpyp3Llzu7olhzt27Jjd8Vy5cmXofn19fe2Onzt3Lt01nS0hIUGLFy+2HhctWlQNGjTI9D7cbdtXZz53NKXAGwAAAAAAAACAe014eLhT6jrze/7UIKhMQZ06dTR79my1bt1aTZs21YoVK7JdcHLq1Cm74zlz5sxQ3ZSCyvPnz2eorjP9/fffNkGqq7Z9vTWoDAoKUrNmzTK9h7Rw5rNdjTFOqw0AAAAAAAAAgDtJ6bF77o6tX++gWbNmmjRpkrZt26aWLVvqypUrrm7JoVK6H2cFlVn588sK275u2bLFZjvejh07ytPTM9P7AAAAAAAAAAAAyAwElXfRrVs3SdKuXbvUq1cvF3fjWFFRUXbHc+TIkaG6KYVrMTExGarrLMYYLVq0yHpcrFgx1atXL9P7uH3b1y5dumR6DwAAAAAAAAAAAJmFoPIOLl68qI8//lhSYpj1888/a9myZS7uynFSCiozuqIyPj7e7vjNmzczVNdZ/vnnH505c8Z6nBW2fQ0ODtZDDz2U6T0AAAAAAAAAAABklmzxjMqtW7dq6dKlCg0N1blz5xQZGambN28qNjY2Tc+5M8YoPj5eN2/e1PXr161BnsVisdaZNGmS2rZt65T7yGwpfTYZXVGZkJBgdzylLWFdLSts+7p9+3YdOnTIeuwu276GhoYqKCjI1W0AAAAAAAAAAJCthYWFOaVuRESEKlWq5JTaqeHWQeXly5fVv39/m207pZQDuPSyWCzWsHLjxo0Ore1KuXPndkrdGzdu2B3P6EpNZ7h929fixYtniW1fXRGWpkdQUJCCg4Nd3QYAAAAAAAAAANladv0u3m2DymvXrumhhx7Szp077QaTrti6093kyZPH7nhKQWNqpfQsyoyu1HSGjRs36uTJk9ZjVz0XcuHChdafCxQooKZNm7qkDwAAAAAAAAAAgMzitkHlW2+9pR07dlhXOzqDMcamtsVi0cMPP+yUuVzBWUHltWvX7I7ny5cvQ3WdISusZNy9e7f27dtnPXaXbV8BAAAAAAAAAAAywi2DygsXLmjGjBl2A0pHbfuaVPvWetWqVdOkSZMcUj8rCAgIsDue0aDyypUrdsdLlCiRobrOcGtQWbJkSdWtWzfTe8gKz8gEAAAAAAAAAADIbG4ZVC5dulQ3btxIFiZWqFBBFStWVJEiRZQrVy75+flp9erV+vvvv9WoUSM1a9Ys1XNMnz5d586dU4cOHdSsWTPVqFFD9evXd8r9uEr58uXtjqe0IjK1Ll++bHe8ePHiGarraP/995+OHz9uPXbVtq+3hqUFCxZUkyZNXNIHAAAAAAAAAABAZnLLoHL16tXWny0WiwYPHqxXXnlFJUuWTHZu8+bN1aRJE12+fFkjR45M9Rx16tRRmzZttHXrVn399dfy9/d3ROtZSuXKle2Oh4eHKy4uTl5e6fvjER4ebnfc3u/HlbLCtq979+5VaGio9bhTp07y8PDI9D4AAAAAAAAAAAAym1smIrcGO1OnTtXkyZNTDMEaNWqkMmXKaPfu3dq4cWOq52jVqpV69Oih48ePq2/fvhltOUvKnz+/ChYsmGw8ISFBZ8+eTXfd8+fP2x2vVatWums6w61B5X333afatWtneg+3b/vqqlWdAAAAAAAAAAAAmc0tg8oTJ07IYrGoUaNGGjBgwF3P79u3r4wxmjJlSprmGTdunHx8fLR48WJNnz49ve1madWqVbM7furUqXTVu3HjhiIiIpKNBwcHq3Tp0umq6Qxbt27VkSNHrMdZYdvXQoUKqXHjxi7pAwAAAAAAAAAAILO5ZVCZ9AzFbt26per8Pn36yNvbW/Pnz1dYWFiq5ylWrJi6d+8uY4yGDRtmE2xlF4899pjd8aNHj6ar3rFjx+yO16tXL131nCUrbPt64MAB7dq1y3rMtq8AAAAAAAAAAOBe4papiMVikSSVKVMmVeeHhISoXbt2unnzpiZPnpymuXr06CFJio6OzpZbwD7++ON2x7du3ZquegcPHrQ73rZt23TVc5Zbg8rSpUu7ZFva27d9dUVYCgAAAAAAAAAA4CpuGVTmy5dPkuTp6Znqa55//nkZYzR58mRdvnw51ddVr17d+vNff/2lP/74I9XXuoP77rtPlStXTja+ZcuWdNXbuXNnsjEvLy917NgxXfWcYceOHTaBalbY9rVw4cJq1KiRS/oAAAAAAAAAAABwBbcMKoODgyVJoaGhqb6mcePGql69uiIjIzVixIhUX+fl5WVzPG/evFRf6y6efvrpZGPbtm2TMSbNteytxGzZsqUCAwPT1ZszZIVtXw8fPqzt27dbjzt37mxdKQwAAAAAAAAAAHAvcMugsnr16jLG6KuvvlJ8fHyqr3vllVdkjNGXX36pv/76K1XX3LqC0hijv//+O839ZnWDBg1S3rx5bcYiIyP177//prnW+vXrk429+OKL6W3NKW4NKsuWLasaNWq4tAeJbV8BAAAAAAAAAMC9xy2Dyvr160uSdu/erQEDBqQ6rHziiSdUpkwZxcfHq2vXrjp8+PAdz7927ZrefPNNm5Vup0+fTn/jWZS/v78GDRqUbHzx4sVpqrNlyxadP3/eZqxmzZp6+OGHM9SfI+3evVv79u2zHrtq29dbn09ZpEgRNWjQwCV9AAAAAAAAAAAAuIpbBpVdu3aVr6+vJGnWrFmqWLGiXnnlFY0ZM0Zjx47Vl19+aRNGJfHw8NCoUaMkSWFhYWrYsKF+//13u3OcOHFCDz/8sPbu3WsznpCQ4NibySJefPFF5cqVy2YsrUHlokWLko2NHTs2Q3052u0rGV0RVB47dszmGaBs+woAAAAAAAAAAO5FFpOeBxFmAX379tXMmTNlsVhkjEkW9Hh6emrq1Knq169fsmvr16+vTZs2Wa+rV6+eWrVqpUKFCuny5cv6999/tWzZMt28edN6TtLHVLFiRe3ZsydT7jGzjR8/XsOHD7cZW7t2rZo2bXrXa2/cuKESJUooLCzMOtapU6dkweCdLFmyRKNGjdLevXtVsGBBDRw4UK+//ro8PByXp1epUsX6+ytXrpz279/vsNqp9fHHH+vVV1+1Hq9fv94tVlSGh4crJCTEZiwsLMz6zFgAAAAAAAAAAOBeXP3dv9sGlRcvXlSVKlWsW43au418+fLp4sWLycb37NmjWrVqKTY21m7IeWu9pPeSzhs6dKg+/fRTR95KlhEbG6uGDRvqv//+s461aNFCK1euvOu148aN09tvv209LlCggLZu3arChQunau758+fbfU7jc889p0mTJqWqxt3s27dPFStWtB6/9dZbevfddx1SOy0eeOABbdq0SZJUrFgxHT9+3C1WVLr6LysAAAAAAAAAAOBYrv7u3y23fpWk/Pnza/78+dbtSi0Wi81Lkq5cuaIbN24ku7Zy5cr65JNPbFZL3v66tU4SHx8fDR061Pk35yLe3t766aeflD9/fuvYqlWr9O23397xur/++stmi1c/Pz8tWbIk1SGlJI0cOdLu+NSpU5M99zK9bn0upCS7waiznTx50iYIZttXAAAAAAAAIBOdPSutXSv9/LO0YEHif9euTRwHAGQ6L1c3kBENGzbUb7/9pieeeEInT55MFvi0aNFCfn5+dq999tlndejQIX3++ed3DYqSVldOnDhRJUqUcEzzWVTJkiW1fPlytWzZUteuXZMkDRw4UHnz5lWHDh2SnT9v3jz169dPMTExkqQ8efLop59+Ur169dI076FDh+yOJyQk6MiRIypQoEAa7yS5W7ehrVChgqpWrZrhmunp4dbVv64ISwEAAAAAAIB7xqlT0g8/SOvWSVu2SGfOpHxu4cJSrVpS48bSk09KRYtmXp8AcI9y2xWVSerXr6/du3dr7NixqlKlinLkyKECBQromWee0Zw5c+547YQJEzR27Fh5enra3TpWSgwp/fz8NH36dPXv398Zt5Dl1KtXT3/88YcKFSokSYqJiVHHjh3VoUMHzZkzR2vWrNHMmTP10EMP6YknnrAGmuXLl9fff/+tRx99NM1zli1b1u64h4eHSpUqlf6b+f8OHjyonTt3Wo+7dOmS4ZrpceuqzuLFi6c50AUAAAAAAABwF8ZIK1dKHTpIJUpIr70mLVt255BSSnx/2bLE80uWlDp2lFatSqwHAHAKt31GpSOFhobqs88+09KlSxUeHm4dL1eunNq0aaOhQ4eqWLFiLuzQNc6fP6+XXnpJP/zwwx3Py5s3r4YNG6bXX39dvr6+6ZprwYIFdsNDRz2j8r333tNbb71lPd61a5eqVKmS4bppcfr0aRUrVswair/88sv6+OOPM7WHjHD1PtUAAAAAAADAXe3eLfXvL/37r+Nq1qsnzZghZfL3iQCQGVz93T9B5W2io6MVGRmp/Pnzy8fHx9XtZAl79+7VzJkztWbNGh0+fFjXrl1TUFCQqlevrtatW+vpp59W3rx5MzzPkiVLNGrUKIWGhqpgwYIaNGiQXn/9dXl4ZHzhb82aNbVt2zZJUsWKFRUaGprhmmk1ceJEm2ecbty4UXXr1s30PtLL1X9ZAQAAAAAAACmKi5M+/FAaPVqKjXV8fW9vaeRIafhwycutn6gGADZc/d0/QSWAVHH1X1YAAAAAAACAXeHhUrt20oYNzp+rfn1p6VKJ78QAZBOu/u7fbZ9RGRoaqnbt2qlq1ap67rnndOXKFVe3BAAAAAAAAADITKdOSY0bZ05IKSXO06RJ4rwAgAxzyzXqhw4dUsOGDXXlyhUZY7Rnzx7t27dPq1atcnVrAAAAAAAAAIDMEBYmtWgh7d+fufPu25c477p1rKwEgAxyyxWVb7/9tiIjIyVJFotFxhitWbNGR44ccXFnAAAAAAAAAACni42V2rfP/JAyyf79idvNxsW5Zn4AyCbcMqj8448/ZLFYko3H8X8KAAAAAAAAAJD9jR+fedu9pmTDhsQ+AADp5pZB5bVr16w/G2NksVhUq1YtlStXzoVdAQAAAAAAAACcbvduafRoV3eRaNSoxH4AAOnilkHl7YGkj4+PZsyY4aJuAAAAAAAAAACZwhipX7/ErV+zgthYqX//xL4AAGnmlkHlU089JWOMdTXlqFGjVK1aNafOuW7dOkVHRzt1DgAAAAAAAADAHfzxh7Rxo6u7sPXvv4l9IUNCQ0PVp08fVahQQfny5dNjjz2mrVu3asyYMQoICNDvv/+eqjoxMTGaNWuWatWqpVGjRqV43oYNG/TEE0+oZMmSCgoKUteuXXXo0CEH3Q2QNkeOHNGrr76qwMBAHTt2zNXtZCq3DCqff/55lSpVyno8ePBgp84XFRWlBx98UEePHnXqPAAAAAAAAACAO5g61dUd2PfFF06f4qeffpK/v78sFov1NWzYsBTPj4iIUIkSJeTl5WU938PDw+Z6i8WiTp06ydxhRWiFChXk4+NjPd/X11ctW7Z06L2tWbNGHTp00AcffKDQ0FANGTJEK1asUOPGjfXtt9/q8uXL+vnnn+9a5+DBg3rmmWc0ePBgbd26NcXz5s6dq+eff15fffWVDh48qMcee0zz589Xo0aNdPPmzXTdw6BBg7R69ep0XYv0ue++++Tt7Z3sz3RQUJBmz57t6vZSbe7cuRowYIA+/vhjXbx40dXtZDq3DCpz5sypBQsWKE+ePJKkVatWOXW+06dP3/EvagAAAAAAAACAk506JS1d6uou7Fu6NLE/J+ratasuXryo+fPnKyAgQJI0YcIEff/993bPDwoK0vHjx7Vv3z7lypVLLVu2VHR0tBISErRq1SoVK1ZMkrRo0SKNGzcuxXn37dunU6dOqVixYqpatarCwsK0cuXKNPWekJCg9evX230vNjZWPXv2VNOmTVWgQAF5eHho3Lhx6tmzpwIDAzVy5EjVq1dPffv2ves8ZcuW1Zw5c9S9e/cUzwkLC9OgQYPUsWNH5c6dW97e3poxY4YefvhhBQUFKSEhIU33JkkXL17Ud999p0mTJqX5WqTeX3/9ZXN89OhRHTt2TIUKFZIk+fv7a9OmTYqIiFDPnj1d0WK6PPXUU/r999+VM2dOV7fiEl6ubiC9qlevrt9++01t27ZV7969FRAQoIceesgpcy1fvlwWi8UptQF3FhERkepzg4ODndgJAAAAAAAAsr0ffpDSESJlivj4xP5efdWp03h6eqpz584KCAhQixYtJEkDBgxQpUqVVLNmTbvXlClTRpUrV1a7du3k6+srSWrevLnWrFmjMmXKSJJGjhypGjVqqHXr1nZrhISEqH79+ipevLj8/f3T3PfChQu1Z88eNWzYMNl7a9eu1alTpxQYGGgds1gs+vbbb63HaQ2dChQokOJ7S5cu1dWrV23m8/Pz02+//ZamOW41Y8YMRUVFadmyZTp+/LhKlCiR7lqwb9OmTZo5c6aaNGliM16kSBE1aNBACxcuVNOmTVWnTh0XdZgxHh4eCggIUFRUlEPrhoeH3/WctHzP7wxuG1RKUr169bRx40Z169ZNjzzyiEaOHKnXX39dnp6eDpvjzJkzev/99x1WD8hOKlWqlOpzWZUMAAAAAAAAu27ckA4fvvt5v/zi/F4y4tdfpVat7nxO6dKSn1+GpypdurSkxOAyOjpa7du315YtW1JcLJAjRw7lypUrxRrx8fHq3r27Nm3apHLlyqW6RmqcO3dOL7/8sp555hm77+/du1eS5OPjk+baKfH29k7xPUfPFxcXpylTpihPnjy6evWqpk6dqg8//NAhtZHo+vXrGjhwoKpVq2b3/dy5c9v81115eTk+sgsJCXF4TUdzy61fb1WqVClt2LBBI0aM0Lhx41SzZs00Lzu/3bVr17R79259/vnnql27dqoSZwAAAAAAAABAOhw+LFWpcvfX2rWu7vTO1qy5+z2kJpBNg/Hjx0uSTp48qS5duiguLi7NNT788ENZLBZFRkaqXbt2unLlisP6i4iIUJs2bXTy5MkUz7l06ZIkZdquho6eb9GiRSpYsKDefvttSdJXX32l6Ohoh9SGFBUVpS5dumj79u13PZedMd2TWwaVnp6eNi9fX1+NGjVKN27c0K5du/Too48mOyctL39/f1WrVk3Dhg3TuXPnXH27AAAAAAAAAAAkM2zYMOtKxT///FMvvvhimmt06tRJo0ePlpT4PMoePXo4ZHe0Y8eOqX379jpy5IgkaeLEiSpTpozKlCmjc+fO6fnnn1eZMmX0+eefJ3v/hx9+kJT47MdPP/1U5cqV06xZs+zOs27dOj366KMqU6aMChUqpG7duiksLCzZeR06dFCZMmW0cOFCSdLw4cOt861bty7d9/nZZ59p2LBh6t+/v3LlyqWLFy9q7ty5d7zm5MmTeuWVV5Q3b15J0k8//aTChQvr/vvv19mzZ63nzZgxQzVq1FCxYsUUFBSk7t27Jwt9O3fuLC8vL1ksFlksFh07dkxSYsAXEhJiHX/wwQdtrjt69Kj69Olj3UJ4586datGihXLmzKlatWpp06ZN1nOnTZumcuXKKVeuXGrdurXOnz9v976WL1+u5s2bq1y5csqdO7eaNWuW7NmkUVFR+vTTT1WwYEEdO3ZM165d03PPPafAwEAVKVJEU6dOtZ4bGRmpDh06aMuWLZISQ+Gk31nSWEbFxcVp4sSJeuCBB1S0aFEFBQWpR48eNp9z0aJFrZ+jxWJRjhw5tGrVKuv748ePV44cOWSxWJQzZ06dPn3a+t7JkyfVv39/Va1aVXnz5lW5cuX00UcfpetZqNmWcUOBgYHGYrEke3l4eNgdz8grqaaHh4fZs2ePq28dcJmwsDAjKd0vAAAAAAAAwK7du42R7o3X7t0O+ciOHj1q/c4tJibGNG7c2Po93DfffJPs/KZNm5qZM2cmG5dkjh49aowxplu3btYaI0aMSHZur169zMiRI9Pc68iRI42kFK9N6f1169aZjh07Gk9PTyPJbv8zZ840np6eZvLkySYhIcFERUWZwYMHW+/D3py9evVKsV5abdq0yRQvXtzExsYaY4x17mrVqqV4zYgRI0z+/PmtPf75558mMDDQevzVV18ZY4zp37+/sVgs5qeffjLGGHPo0CFTvHhx4+vra4oWLWoqVKhgBg8ebIwxZs+ePcbLy8vm95lk7NixRpJp2rSpMSbxz8vw4cNNzpw5reP//fef8ff3N8WKFTMeHh5GkilQoIC5cuWKefnll42fn58pUqSItccWLVoku68xY8aYevXqmZMnTxpjEn9/AQEBxtvb2/z+++/GGGN++OEHU7FiRWudHTt2mFq1apmgoCDj7+9v85ncaubMmUaS6dWrl93PNOl32r1795R/WXbcvHnTPPLII6Zfv34mKirKJCQkmMmTJxtJpnDhwubMmTPWz6x3797W/s6ePZus1vz5803x4sXNhQsXrGNbt241xYsXN0uWLDHGGHPhwgXz8MMPG0mmd+/eyWqUKFHC7u8wI9L7fX5YWJjDergbt1xR+cQTT0iSTYKdtKT39rGMvgCkLDQ0VGFhYal6AQAAAAAAAHA8Hx8fLVy4UCVLlpQkDR48WBs3bkxznZkzZ6p27dqSpHfffVeLFy92ZJtp1qhRIy1cuFDNmjWz+/7OnTs1YMAA9e7dW88++6x1pdvEiRNVqlSpTOnxs88+0wsvvGB9tuDQoUNlsVi0Y8eOFFdpjhkzRhs2bLAez549W6dPn9a8efPUvXt3Pf7441qzZo1mzJih5s2bq0uXLpISnyk6cuRIxcTEKF++fNq7d6919WGlSpVUqFAhu/PVr1/f5tjHx0ejRo3ShAkTJElnzpzRN998ox07dujEiRPau3evAgMDdf78eXXv3l3e3t4KDw/XqVOntGbNGlksFq1atcpmN8rVq1frvffe07x581S0aFFJib+/N954Q7GxsRo4cKDi4+PVsWNHbdq0yfp80DfeeEMjR45UWFiYIiIi1Lx5c0m664pUR3n33Xd1+vRpffnll9YVkc8++6xatWqlM2fO6PXXX7d+ZhMnTpS/v78k6cKFC8lqbd68WcOHD1f+/PklSbGxseratauGDBmidu3aSZLy58+v2bNny8PDQ7NmzdKaNWucfo+p+e4+NDTU6X3ciVsGlb169bL+bIxxyDJ0AGkXFBSk4ODgVL0AAAAAAAAAOEdwcLB+/vln5c6dWzExMerYsWOaH2uWI0cOLVmyRIUKFZIxRj179nR5gCEpxe8WX3/9dcXGxmrIkCE2415eXmrdurXT+zp79qx+++039e/f3zpWvnx5PfbYY5KkSZMmpXjtrUHqsGHD5Ovrq65du+r7779XcHCw/ve//0mS7r//fpvrkkLL3bt36+jRozbveXjYj3s8PT2Tjfn5+alEiRKSpLx582rq1KnW43Llyql9+/aSEsPR999/X7lz55YkPfjgg6pQoYIk6cSJE9Z6n3zyiWrVqqXixYvbzFO1alVJidvMbt26VT4+PsqdO7cCAwMlSaNHj1bbtm1lsVjk5eVlzX5ure0sN2/e1MSJE9WuXbtkn1FS34sXL7Zu0ZonTx5rfzNmzLA5PzY2VgsXLlTPnj2tY0uWLNGhQ4fUqVMnm3MLFCigkJAQSdKCBQsce1N2pOa7+6CgIKf3cSduGVTWqVPH+j+GpJWPSYGlo18AAAAAAAAAAGR1999/v+bMmSMPDw+dOXNGnTp10s2bN9NUo0iRIlq6dKn8/Px07do1tWvXTpcvX3ZOw6nk7e2dbCwsLEwrVqyQr6+vqlWrluz9pFVtzjRlyhT16tXL+pzJJEnPCV28eLHNswpvlbQCU0pcDXm7lH5vefLkUUBAgCSlOYi+na+vryRZQ8hbFS5cWJKsKwhvlRRqRUdHS5Li4+P1559/ateuXapQoYLNa8iQIQoMDFRgYKDNZ5H0O709IEtaFZpU25m2bdumy5cv6+uvv07W95w5cxQYGCgfHx+b1ZNJK3dnzZql69evW8cXL16sli1b2nyWq1evliS1adMmWf2EhAQFBgbaXZl5L/K6+ylZU8+ePfXmm29aQ8oWLVqobt26yp8/v3LkyCFvb295enqmawvX+Ph4xcTE6PTp0/r2229T/MsEAAAAAAAAAICs4vHHH9e4ceP0xhtv6J9//tHzzz+vadOmpalGnTp19M033+ipp57SoUOH9OSTT2r58uV2z23Xrp3Wr1+fbPy1117Ta6+9lq57SI3NmzfLGKN8+fLZXTGYHj/++KOee+65ZOPFixfX1q1bbcZu3LihGTNmKFeuXHY/Gx8fH928eVNffPGF3n333TT3Ur9+fU2ePFnHjx9P9l7SAquUtnp1hJRWZ976XlIfFy9e1PXr19W1a1fNmzcvVfVTymySAtzMWESWtGrznXfe0eDBg1N1Tbly5dSiRQutXLlS33//vQYOHChJmjZtmj7//HO79bdt26YcOXI4sPPsx22Dyqefflpvv/22jDGaPHlysuXdjvLaa6+pSZMm2rVrl1PqAwAAAAAAAADgKK+//rr27Nmj77//XtOnT1eNGjXSXOPJJ5/Unj17NG7cOK1YsUJvvvmm3fMiIyPtrgqLiopK85xpcenSJUmJW246yo0bN+zei70Vh3PmzFHDhg21aNEiu7U+++wzvfTSS5o+fbpGjBhhXb2YWl26dNGUKVP0+++/6/Lly8qXL58k6eTJk7p8+bJq1aplfSapq8XFxUmSDhw44OJO0ia9fT/77LNauXKlpkyZooEDB+rAgQOKjY1VlSpVUqxvb9Uv/o9bbv0qJS5Bf+ihhyRJffr0cdo8efPm1TvvvOO0+gAAAAAAAABwTytdWtq9++6v//9ctywrJOTu91C6dKa0MmPGDD3wwAOSpBdeeCFdIdLYsWPVoUMHSdKHH36oNWvWJDtn7dq1dh+pNmrUqAz1fzdJW7teunRJV65ccUjN3r17272XY8eOJTv3888/17PPPptirV69esnPz0/h4eH68ccf09yLt7e3fv/9d5UrV04DBw7U1atXFRkZqWeffVb+/v766quvkl2T1p0lHSUwMFDe3t7asWOH9u/fb/ecM2fOpPheZjt48KCio6OtK1IXLVpkDRVv988//ygmJsZmrG3btipRooR27dqlP//8U19++aXdFZlJ9e+0yjRpe9h7ndsGlZKsDy519n7FjRo1cmp9AAAAAAAAALhn+flJlSvf/fX/g7csq169u9+Dn1+mtOLn56clS5aoaNGiio2N1dmzZ9Ncw2Kx6LvvvrOuBkvayjI9de4kPdt81qlTR56enjLG3DHssVc7o9uK/vHHH4qJiVHz5s1TPCcgIECdO3eWJE2cODFd80yaNEmnT59WVFSUqlatqrp16yowMFCbN29W9erVk52ftL3oxYsXbcYjIyMlpfzcy4zy8fFRvXr1ZIxR37597eY1b7/9tt2VqanlyBB26tSpypEjh2rXrq0cOXLoxIkTGj58eLLzoqKi9NFHHyVbDevh4aFBgwZJkj755BP9+uuv6tSpU7LrmzRpIkmaMGGCNm3alOz9tWvXauPGjY64Jbfn1kFlp06dlCtXLru/ZEcKCQnJlD2RAQAAAAAAAAApaNzY1R3cWSYueLl+/bqkxO1KU1KwYEH9/PPPypkzZ7pr5MqVSz///LMKFCiQ7l6TArSU5rl27Zok6erVq3bfTwrYbt3mNSgoSE8++aQkady4cSmuiLMXmt1tvrt577339MQTT9z1vKTwauvWrfr9999t3ktISLD+bG+b3H///VdvvvmmxowZo/nz5+vgwYPau3evZs6cqTJlytidr0SJEpISn5cYHx+vhIQEzZ07V++9954k6fjx44qLi7NmHUmfp73PLqm/+Pj4ZO/dfr0kvfTSS5Kk9evXq0GDBlq2bJlOnz6tbdu26ZlnntHVq1dVpEgR6/lJfxZS+r3dvqXv3f4MJfWUUr0kv/zyi/U5mLlz51b//v0lSZ9++qm6dOmif/75R6dPn9Yff/yhli1bqkWLFnbr9OvXT76+vlq2bJnat28vHx+fZOc88cQTKlSokG7cuKHmzZtr/PjxOnjwoI4cOaJp06apd+/e6tmzp937duSWxu7ArYPKHDlyaMOGDXf8lwuOEBsbq4SEBFWqVMmp8wAAAAAAAAAAUvDkk5Knp6u7sM/TM7G/TJL0bMRly5bd8bwaNWro22+/tbsiLbU1ihcvrkWLFqX5OYtJKleuLEnasGGDjDFavHixdu3aJSkxLEwK8VauXJlsG9eoqCjrQqW1a9favPfZZ5+pQoUK2rx5s7p162ZdSbhx40bNnDlTkvTnn39qy5YtOn/+vCTp3LlzWr9+vfW+07rK8PPPP9fq1at18eJFm7DRnqQgWJKGDBmiw4cPW4//+ecf689z585Ndu2hQ4dkjNHAgQOVI0cOeXt7y9PTUx4eHsqTJ48aNmyoFStW2FyTtIJz+vTpCgkJUXBwsGbOnKkxY8ZIStx+tVq1atbf97p16yQlboWa9MxPKTGc/PvvvyVJ//33n01YGR4err1799pcL0kdOnTQ888/L0navn27Hn/8cRUtWlQ1a9bUH3/8oS+++MJ67sGDBxUeHp7sc5CkLVu2SJL27duniIgI63jSn6EtW7YoJiZG//77r1auXGl9P+n3u2vXrmRbtUqJYfe3336rrl272qx+fP/991WvXj1J0oIFC9SwYUMVLVpULVq0UEBAgIYMGZKslpQYlHfr1k0eHh4aOHCg3XNy5sypefPmKVeuXLp27ZqGDx+ucuXKqXTp0ho8eLA+/PBDm/D20KFDOnfunCTZ3WY5WzO4o2eeecYMGTLE1W0ALhcWFmYk2bzCwsJc3RYAAAAAAADuJR06GCNlvVfHjply+19++aXJnz+/zXd0hQoVMv/73//ueN3o0aPNzJkzjTHG/O9//zMFChSwqREcHGy+/PLLO9aYNWuWGTVqVJp7TkhIMIMHDzY5c+Y0Dz74oPnll1+MMcaMGDHC5MqVy6aPnDlzmtKlS5uLFy+aZcuWmbx58ybr8+zZs9baFy5cMIMHDzbBwcEmd+7c5uGHHzbjx483r7/+uilWrJh55plnzA8//GAiIyNNnz59jK+vr029vHnzmqpVq6bqPsqVK2dzbUBAgFm7dq3dc+vWrZvsu1QPDw8zaNAg07lzZ2OxWGzeK1WqVLLPrHfv3ua+++4zhQoVMjlz5jQeHh4213h6epotW7bYXDdixAgTGBhoAgMDzYsvvmiio6PNmjVrTPHixc2kSZNMdHS0McaYsmXLJvvcx4wZY37//Xfj7+9v856/v7/55ZdfzJgxY4yfn5/Ne+XKlbOZ/9tvvzW1atUyvr6+JjAw0PTq1cucOXPG+v4777xjfHx8rNdbLBZTvnx5c/36dVO0aFGb2jly5DDTp0+3XjtmzBiTJ08eU7t2bfP9998bY4xZu3ateffdd42np6fN7/S+++4zpUuXNqVLlzZFihQxXl5eRpIpUqSISUhIsOk5KirKjBw50pQqVcr4+PiYkiVLmnfeecfExMTc8c/Dxo0bTevWre94jjHGhIaGms6dO5uAgADj5+dn6tevb1asWGFzzscff5zsz2alSpXuWttRXP3dv8UY9jS9k88//1zvvPOOzpw5o1y5crm6HcBlwsPDFXLbA8vDwsIUHBzsoo4AAAAAAABwz1m1SmrZ0tVdJLdypZTCNpFAWp09e1a9e/fWzz//nGwla0xMjE6ePKnhw4erVKlS+uijj1zUJbILV3/379Zbv2aG0qVL6+rVq/r+++9d3QoAAAAAAAAA3NuaN5f+/1aNWUa9eol9AQ7Ss2dP9erVy+52u76+vipTpoyeeeaZe+5ZhsieCCrvImm/6qlTp7q4EwAAAAAAAAC4x1ks0owZkre3qztJ5OOT2I+dZ0AC6bFixQqtWrVKXl5edzxv7ty5euyxxzKpK8B57vwnPQs7ceKEQ+slJCQoNjZWN27c0LVr13Ty5EktWbJE8+bNkyTt3r1b69evV8OGDR06LwAAAAAAAAAgDapUkUaOlN5+29WdJPZRpYqru0A2cuTIEUnSkCFDdPXqVXXu3Fn+/v7W948dO6YxY8YoOjpajzzyiKvaBBzGbZ9R6eHhIUsm/CuVpI/HYrHoqaee0nfffef0OYGsyNX7VAMAAAAAAABWcXFSkybShg2u66F+femvv6S7rHwD0uLatWt67LHH9Pfff0tKzCYKFSqknDlzKjIyUuHh4erSpYtmz54tPz8/F3eL7MDV3/279davxhinvywWiywWi4wxWrBggSIiIlx92wAAAAAAAABwb/PykpYulcqXd838FSokzk9ICQfLnTu31q5dqxkzZqhp06bKmzevwsPDde3aNTVq1EjLly/XTz/9REiJbIMVlXeRFFYm/ff999/Xa6+95vR5gazG1f+qAgAAAAAAAEjm1CmpRQtp//5UnX5WBbVf5XVFeXVTPvLRTeXVFZXXfhXSudTNWaGCtHKlVLRoBhoHgKzB1d/9E1SmUcmSJXX48OFMnxdwNVf/ZQUAAAAAAADYFR4utWtndxvYUyqiH/Sk1qmxtqiWzqhIimUK67RqaYsaa52e1A8qqtPJT6pfP3ElJd+JAcgmXP3dv9sHlc5o/051LRaL4uPjHT4nkNW5+i8rAAAAAAAAIEVxcdL48dKoUTKxsVqlFpqqIfpZjytBnmku56k4Pa6fNURT1Vx/yOLtLY0aJb32Gtu9AshWXP3dv9v/jVqrVi099dRTKleunHLlypXhVZZXr15V//79FRMTo+nTpxPCAAAAAAAAAEBW5+Ulvfmmdlfsov49b+jfa/dnqFy8vLRYHbVYHVUv9y7NmO2nKh3KOqhZAEASt15R+dhjj2nZsmXy8PBwaO3du3erSZMmKlSokFauXKnChQs7tD7gjlz9ryoAAAAAAACAlMTFSR9+KI0eLcXGOr6+t7c0cqQ0fDgLKgFkL67+7t+xCV8mGzp0qMNDSkmqUqWKFixYoAMHDuihhx7S+fPnHT4HAAAAAAAAACDjwsOlJk2kt992TkgpJdZ9++3EecLDnTMHANyL3DaotFgsql69utPqN2vWTCNGjNDBgwfVokULXbp0yWlzAQAAAAAAAADS7tQpqXFjacOGzJlvw4bEsPLUqcyZDwCyO7cNKo0xyp8/v1PneOONN1S8eHGFhoaqc+fOio+Pd+p8AAAAAAAAAIDUCQuTWrSQ9u/P3Hn37Uucl5WVAJBxbhtUXr16VV5O3gzc29tb/fr1kzFGa9eu1ejRo506HwAAAAAAAADg7mJjpfbtMz+kTLJ/v9SuXeKzMQEA6ee2QWWuXLkyZZ4OHTpISlzB+eGHH+oUa/oBAAAAAAAAwKXGj8+87V5TsmFDYh8AgPRz26Ays5QuXVpS4jMx4+Li9PXXX7u4IwAAAAAAAAC4d+3eLWWVze9GjUrsBwCQPgSVd3H9+nWb4xUrVrioEwAAAAAAAAC4txkj9euXuPVrVhAbK/Xvn9gXACDtCCrvYu3atdafjTHat2+f65oBAAAAAAAAgHvYH39IGze6ugtb//6b2BeSu3z5sj777DOVK1dOs2bNcnU7QJa1c+dODRw4ULlz53Z1K5mOoPIO4uLi9N5779mMRUVFuagbAAAAAAAAALi3TZ3q6g7s++IL58/x008/yd/fXxaLxfoaNmxYiudHRESoRIkS8vLysp7v4eFhc73FYlGnTp1k7rAktEKFCvLx8bGe7+vrq5YtW96133/++Uf9+vXTyy+/rIMHD6brnt1Jq1atdOjQIVe3cc84ffq0SpQoIU9Pz2R/pgsUKKDVq1e7usVUmzhxogYMGKDp06cn2+XzXkBQmYILFy6oa9eu2rZtmywWi3U8KCjIhV0BAAAAAAAAwL3p1Clp6VJXd2Hf0qWJ/TlT165ddfHiRc2fP18BAQGSpAkTJuj777+3e35QUJCOHz+uffv2KVeuXGrZsqWiNZvmzwABAABJREFUo6OVkJCgVatWqVixYpKkRYsWady4cSnOu2/fPp06dUrFihVT1apVFRYWppUrV9613wYNGmjBggVq3rx5Ou7Wvezdu1crVqzQlClTXN1KtpWQkKD169dbj4sUKaLjx49r165d8vPzkySVKFFCBw4c0Pnz59WsWTNXtZpmL7zwgpYsWeLqNlzGy9UNpNfs2bMdWi8uLk7Xr1/XmTNntH37dq1Zs0axt2x0boyRxWJR/fr1HTovAAAAAAAAAODufvhBSkhwdRf2xccn9vfqq86dx9PTU507d1ZAQIBatGghSRowYIAqVaqkmjVr2r2mTJkyqly5stq1aydfX19JUvPmzbVmzRqVKVNGkjRy5EjVqFFDrVu3tlsjJCRE9evXV/HixeXv75+mnkNCQtJ0vjuaOHGijDGaOXOm3n33XeXKlcvVLWU7Cxcu1J49e9SwYUOb8UqVKqly5crasmWL2rVrp7Jly7qow4y5lxfJuW1Q2bt3b5uVjo6WtNT99jn69evntDkBAAAAAAAAANKePcnHfvkl8/tIi19/lVq1sh2rXNk5c5UuXVpSYnAZHR2t9u3ba8uWLQoODrZ7fo4cOZKFZ7fWiI+PV/fu3bVp0yaVK1cu1TVSw8vLbWOIVLl06ZLmzp2rnDlzKjIyUrNnz9bgwYNd3Va2cu7cOb388st65pln7L6f9FxHd36+Y3b/38mduP3Wr8YYp7yS9jJOYrFY1KFDBz366KMuvFsAAAAAAAAAyP6qVEn+WrvW1V3d2Zo1yXt2tvHjx0uSTp48qS5duiguLi7NNT788ENZLBZFRkaqXbt2unLliqPbzNZmzJihRx55RL169ZIkTZ482cUdZS8RERFq06aNTp48eddznbm4Dc7j9kHl7Q9JddTrVsYYNW3aVN99952L7hLImiIiIhQeHp6qFwAAAAAAAADHGjZsmHWV2Z9//qkXX3wxzTU6deqk0aNHS0p8HmWPHj2sOw462oULF9SrVy/ly5dPISEheuGFF3T16lW754aGhqpXr16qVq2aChYsqIoVK2rUqFGKioqynjNv3jx5eHhYv9fPmTOn/vzzTx05ckT58+e3+c4/X758OnDggCRp48aNyp07tywWi7y8vLRu3bp03U98fLymTJmiYcOGaejQobJYLAoNDdUff/xxx+v27dun/v37q0KFCpISt44NDAxUkyZNdP36dUmJj6v74IMPVKlSJRUtWlQFCxbU4MGDdenSJZtadevWtfkMkhw4cECBgYHW8d69e9tct3PnTnXo0EF9+vSRJP3111964IEHlDNnTjVt2lQHDx603uN7772n4sWLK0+ePOrRo4e1x9vNnj1bjRo10n333Sd/f3+1a9dOe25bHn3p0iW98847ypcvnyQpLCxMPXr0kL+/v0qXLq2FCxdazz127Jjat2+vI0eOWD+nMmXKqEyZMjp37twdP+PUioqK0pgxY1SrVi0VKFBAhQoV0pAhQ3Tx4kVJ0tWrV5UzZ06bP0t58+bV3r17rTVeeOEFeXt7W9+7VWhoqJ588klVqVJFuXPnVtWqVfXNN984pPfUSM139xEREZnWj13GTVksFuPh4eGUl8Visb7y5s1r3n33XRMXF+fqWwZcKiwszEhK9wsAAAAAAABILSl7vJzl6NGj1u/cYmJiTOPGja3fw33zzTfJzm/atKmZOXOmnc9Z5ujRo8YYY7p162atMWLEiGTn9urVy4wcOTLNvfbq1ctIMp9++qkpX768KViwoPH397fOVbduXXPjxg2ba3755ReTN29eM2vWLJOQkGBiY2PNRx99ZCSZ+++/30RERFjPXb9+vfHx8TGSzLx586zjcXFx5rHHHjOSTI0aNZJ9x79//37j7e1tNmzYkOZ7SvLTTz+ZBg0aWI+T5mvXrl2K1/Tv39/kyJHDSDIlSpQwc+bMsfk8Vq1aZe09R44c5q+//jLGGLNp0ybj7+9vcubMaYoXL24qVKhgxo4da4wx5vfff7f7PWxCQoLp16+fkWR69epljDHmwoULZvDgwcbLy8s6vmzZMpMzZ05TtGhRa53KlSubuLg407VrV5M7d25TsGBB63v9+vVLdl/PPPOMadOmjbl48aIxxpiFCxcaHx8fkzdvXrNz505jjDGTJk2ymePEiRPmvvvuM4UKFTI5c+Y0koyXl5c5dOiQTe2RI0caSSn++WvatKmRZN56662Uf1l2XLp0ydSsWdOMHDnSxMbGmps3b5o33njDSDJVqlQx165dM8YYc+XKFfPoo48aSSZfvnwmKioqWa2PPvrI1KpVy0RHR1vHVqxYYUqWLGnWrVtnjDHm5MmTpnr16kaSGTVqVLIazvguPb3f54eFhTm0jztx+xWVxgHbvEqSt7e3NbF/6KGH9Oyzz+rHH3/U2bNn9dZbb8nT09PFdwoAAAAAAAAAgC0fHx8tXLhQJUuWlCQNHjxYGzduTHOdmTNnqnbt2pKkd999V4sXL3Zkm/riiy80efJknT17VuHh4Ro1apQkadOmTfr000+t5507d049evRQ+/bt1atXL+uqx1deeUU9e/bUrl27rKsAJalBgwZ68sknJUlHjx61jnt6elrnuHTpkjw8bOOQXbt26cknn1S9evXSfU+fffaZhg0bZj1+6aWXJEnLli3TsWPH7F4zffp0LVmyRJJ0/fp1/f3337pw4YKmTp2qvn37qmHDhpo9e7Z+/fVXde/eXY0bN5Yk1alTRy+88IKioqJ0//33a+/evXr77bclSc2bN7c7l8ViSXZ/efPm1aRJk/Tqq69aP4c1a9bo+PHjOnnypDZs2CBvb2/t2bNHXbt2Vb169RQREaGzZ89q1qxZkqS5c+cqPj7eWnPmzJn63//+pzlz5iggIECS1LFjR/Xr109XrlzRc889J0kaMGCAzWrT1157Td99953OnDmj8+fPq3LlyoqLi9P8+fPv+tk7wtChQxUSEqJRo0bJy8tL3t7eGjdunCpXrqzdu3dbt1bOkyePvvjiC3l4eOj69eu6ceNGslqbN2/WmDFj5OfnJylx9fBTTz2lDz74QI0aNZIkFS1aVNOnT5ckjRkzRocOHcqU+8zq3D6o7NGjhzZv3qwrV64oPj5eCQkJaX7Fx8frxo0bunjxog4cOKA//vhDkyZNUteuXZUzZ05X3yIAAAAAAAAAACkKDg7Wzz//rNy5cysmJkYdO3ZM89aYOXLk0JIlS1SoUCEZY9SzZ0+FhoY6rMfhw4erRYsWkhIXDo0cOVKtWrWSlBh0Jfn000918eJFdezYMVmN119/XVJiELhlyxbreN++fSXp/7F331FRXV0bwJ+hI0XpvSiIqAjWiBrRqGjsvRCNsRs1GmOPiTUaS6LGLvYau2LvYkSxd8SCFVCRKqh0uN8ffHNfhhmUPgw+v7VmvcyZc/fZd4b4rjWbfQ62b98uM/+rr75CpUqV8OLFC5w9e1bmtU2bNonXFcT169cRERGBzp07i2Pe3t6oXr06MjMzsWLFilyvrVSpEgAgKSkJM2bMgLq6OoYNG4a1a9dCR0cHhw8fBgDUqFFD5rru3bsDAI4fPy5zHmnOImx2OZuwNDQ0oK6uDgcHBwCAo6MjFixYAFNTUwCAp6cnvLy8AABeXl745ZdfoK2tDQDo27cv9PT0kJiYiJiYGDHm33//DW9vb7ltT93d3QFkbSsbFRUFLS0tsaAOAEuXLkWjRo0AAPr6+ujZsycAIDQ0NNf7KSpv3rzBtm3b0LVrV5lxiUQivu979uwRxx0dHdGuXTukpaVh06ZNMtdERUXh7t27aN26tTi2fv16vH//Hh06dJCZK31PMjMzi/yPAVSVShcqu3Xrhs2bN6N27driftJERERERERERERERF+aGjVqYNu2bVBTU8Pr16/RtWtXpKam5iuGjY0NDhw4AB0dHXz48AEdO3bEu3fviiQ/RbsWSrsRQ0JC8OHDBwBZ3XoAZApaUlWrVkXFihUBAEeOHBHHGzduDCcnJ9y5cwf37t0Tx0NDQ/HmzRsAwNq1a8XxyMhIPHnyRCzIFcQ///yD0aNHyxUJf/75ZwDAunXrkJSUpPBaDQ0NAICpqSnMzMzkXs/tc5MWFzMyMhAVFVXg3AGIxUcDAwO516ytrQEA5cuXlxmXSCQwNjYGAPHe3r59i+DgYBw/fhyurq4yj7lz58LExAQmJiYICwsDkFWklpIWR6WsrKxkYhen8+fPIyMjAzNnzpTLOyAgACYmJkhISJC5RtoZumLFCplzXDds2IB+/frJ1KjOnj0LQRBQq1YtmdgeHh7iexIZGVns96kKNJSdQGGMGjVK2SkQfdGCg4Pl/s+EiIiIiIiIiIiIlKNDhw6YPXs2fv31VwQGBmLkyJHw9fXNV4x69eph/fr1+O677/DkyRP4+PjIFAWz69ixIy5evCg3PmHCBEyYMOGza7m6uoo/x8fHIzMzE69evQKAXBuTqlatiufPn8t13fXr1w9TpkzBpk2b8PfffwPIKib++eefmDRpEvbv34+YmBiYmJhg69at6NOnj8z18+fPF7f6zK5Ro0Y4cOCAzNibN2+wf/9+XLlyBcuXL5d5LSMjAxoaGoiNjcW2bdswaNCgz74POTVo0ACHDx/Gy5cvZcalxTEtLS2xYFgcPtWhKX1Nmov0cxg4cCDmzZv32difajiTFnCzFwGLizRvX19fmU7IT2nRogVcXFzw+PFjnDx5Eq1atYIgCNi8eTPOnTsnF9/Y2BgPHz4s6tTzJS/F0OjoaFSrVq0EslFMZTsqJRKJUt84IvrfX/zk5UFERERERERERETFb9KkSWIRbvXq1Vi1alW+Y/j4+OC3334DkLXN6OTJkxXOi4+PR0xMjNwjMTExT+uYm5uLP1eoUEHmOmnBMifpGYg5txn94YcfoKamhm3btiEjIwPx8fE4duwYRowYgc6dOyMlJQVbtmwBAGzZsgU//PCDzPXS7UxzPuLj4+VyWLFiBYYOHYqQkBA8fPhQ5hESEoIRI0YAyNratCCGDx+OypUrY9++fTJbvN69excA0L59e7EjUtmk+T1+/FjJmeRPQfKWSCQYPnw4AGDZsmUAgFOnTqFWrVpyDT3p6emIiooqso7kgsrLd/fKbkZS2UKlIAhybcdEREREREREREREpPqCguQf2WpapZK5uXzOyrJmzRrUr18fQNbOhAUpIv3xxx/i+Yvz5s2Dv7+/3Jxz585BEAS5x/Tp0/O0RlxcHADA2dkZenp6MDMzE7ciffTokcJrpAWmnOc32tnZoVmzZoiIiMDJkyexatUq9O/fH5qamuJZlGvXrsWNGzdgbW0NGxsbmeunT5+u8F5ydsolJydj9erVGDZsWK73NXToUABZhcX//vsvT+9FdhUqVMDFixeRnp6OCRMmIDk5GRERERg/fjxsbGzwzz//5DtmcZFu13rq1Cnx88zp/v37pWabU2mxV5r3rl27cp2b81xTIKtzV09PD0ePHsXz58+xatUqsXiZnfSs19ziK/rd+lKpbKHy/fv3n2w/JiIiIiIiIiIiIiLVVL26/OP/626llqenfM7KoqOjAz8/P9ja2iItLU08pzE/JBIJtmzZAg8PDwCQ22q1KNy4cQMA8N133wHIOseyTZs2AIDt27crvCYsLAxaWlro1KmT3Gv9+/cHkFWQ3LBhg1gwbN68OSpWrIj79+9j5MiRGDBgQIFz3rZtGzw8PFC5cuVc51StWhVff/01AGDJkiUFWmfKlCnQ1tbGvXv3ULVqVTRr1gz16tXD9evXYWtrKzdfV1cXABAbGyszLu0Ize95pXnl6OgIOzs7fPz4EUOHDkVmZqbM6xkZGfj9998L1Xj2qe1i82vDhg0Ass41BYDAwECFna9RUVFYv3693Hj58uXRp08fZGZmYsqUKQgNDUWDBg3k5knPP/3tt9/w7Nkzudc3bdqE169fF+peygqVrfTp6ekpOwUiIiIiIiIiIiIiKiH/X1cotf6/LlUiPn78CCCruy83lpaWOHjwIMqVK1fgGHp6ejh48CAsLCwKkW0WRecOLl++HBUrVsTYsWPFsd9//x0aGhq4evUqLl++LDM/Ojoa169fx7hx48QtYLPr3Lkzypcvj3379qFNmzZicUwikYhFzJCQEHTo0KFA95Ceno758+fDx8fns3O7du0KAPDz88ODBw9kXpMW83LbInfnzp3w9fXFsmXLcPjwYTx58gRBQUFYunQpLC0tFV7j4OAAIGtbWgBIS0vDkiVLxGLb06dPAfzvc0hLSxPvKSdpfhkZGXKv5bweAH755RcAwO7du9GiRQucOXMGr169QmBgIDp37gxnZ2dxq9rsv2+K1s4ZG/hfETa331VpTrnFk1q5ciWcnJwAAE5OTuLvwahRo/Djjz/i5s2bCAsLw6FDh/DNN9+gV69eCuNIt/bdtm0bBg8erHDOkCFDoKenh+joaDRo0ACrVq3C8+fP8fjxY8yfPx9z5syR+T3Mfs8577+sU9lCZVHZv38/pk+fjsDAQIX/0RERERERERERERGR8vn4AOrqys5CMXX1rPxKyr59+wAAhw4d+uS8WrVqYdOmTQo70vIaw97eHvv27SvwmYgVK1YEAEybNg2nT58GkFWImTx5MoKDg3H8+HGZ8ybd3Nzg6+sLNTU19OrVC3fu3AGQVaTs2bMnWrRogSlTpihcS1dXFz179oSGhgZGjx4t81r//v2hpqaGPn36QFNTM9/3kZGRgUmTJuHx48eIjo7+7HxpITgzMxP9+/fH27dvxdcCAwMBZHXtSd+T7EJCQgAArVu3ho6ODjQ0NKCurg51dXVUqFAB3t7euHbtmsw13bp1A5DViWlpaQlTU1PcuHFDfB+uXr2K+vXr49KlSwCAgIAAAFlboaakpIhxEhMTxdg5C8WPHz9GRESEzPUA8PPPP4sdrv7+/mjRogVsbW3RqFEjvHr1CrNmzZK795w/A8DNmzcBANevX0dSUpI4Xv3/25MvXboEQRCwf/9+3Lt3T3xd+t7evHlTrqMTyPosFixYgJ9//hldunQRx1evXi12xvr6+qJOnTqwt7dHhw4d0KRJE7Rr104uFpC17bCXlxcMDQ3F82BzsrW1xfr166GhoYHIyEgMGzYMlSpVQpUqVTB16lSsXbsW+vr64vzs76eibZbLNKEMiI+PF+bNmyc0adJEcHd3F0aOHCnEx8fn6drjx48LdevWFSQSiWBiYiJMmDBBeP78efEmTKSCIiMjBQAyj8jISGWnRUREREREREREX5DOnQUBKH2PLl1K5v5XrVolGBsby3xHZ2VlJRw+fPiT182YMUPYsGGDIAiCcPjwYcHCwkImhpmZmbBq1apPxti4caMwffr0AuV97tw5oUePHoKFhYVgZWUl1K1bV5g8ebIQFxeX6zXnz58XWrduLRgZGQmVK1cWvvrqK2HFihVCenr6J9e6dOmS4OPjo/C1Nm3aCHfv3s13/omJiUKFChVk3jNzc3MhJCRE4fyc7y8AQUNDQ/jzzz+Fr776Su61b775Rub65ORkwdvbW3BxcREsLCwEXV1dQU1NTeYafX19ITw8XLwmNTVVGDp0qGBoaChYW1sLf/zxh5CRkSFs2LBBqFq1qrB582YhLS1NiI2NFczNzWViGRoaCuvXrxfWr18v6OnpybxmYmIi3Lt3TxgyZIigqakp81rLli3F9dPT04VFixYJ1apVE7S0tAQrKyth1KhRwrt378Q5/fv3F9TV1cXr1dXVBW9vb+Hx48eCpaWlTGwDAwPh6NGjgiAIQmZmpjBs2DChXLlyQtOmTYWjR48KycnJwpkzZ4QxY8bIXGdkZCRUqlRJcHJyEipVqiRYWVmJ713Dhg3lPquYmBjh559/FmxtbQUtLS2hSpUqwj///CNkZmZ+8ndi586dwogRIz77uxMYGCi0atVKMDAwEPT09ARvb2/hypUrMnNGjx4taGhoiPegpqYmfPvtt5+NXVSU/d2/RBAU9FurkCtXrqBnz54ICwsDkNXiK5FI0L17d+zYsSPPcQ4dOoTx48fj8ePHUFdXx48//og///xTPLiX6EsXFRUF8xwnlkdGRsLMzExJGRERERERERER0Zfm9GnA21vZWcg7dQpo0ULZWVBZERQUhOnTp2P37t1y3bBJSUl49uwZhg4dCh8fH3EbUqKCUvZ3/yq99WtgYCC8vb0RGhoKQRDEIqUgCPDz81PY4pub9u3b4+7du/j555+RkZGBFStWoFq1amIbNBEREREREREREREpV/PmgKensrOQ5emZlRdRUUhNTUXPnj0xZswYhVv26urqonr16vDx8fnizjKkskllC5VRUVHo3LkzPnz4AIlEIj6k0tLSxD2g80pLSwuLFi3CggULIAgCXr16BW9vbxw9erSo0yciIiIiIiIiIiKifJJIgDVrgAIcMVgstLSy8lFQTyIqkPXr1yM4OBgaGhq5zsnIyMDu3bvRqlWrEsyMqHiobKFy9OjRiIqKUvgXBRKJBA4ODgXetvWXX35B3759AWQdHNulSxdcvXq1UPkSERERERERERERUeG5uQHTpik7iyzTpmXlQ1RUnj17BgDo0aMHdu/ejaSkJJnX79+/j06dOqF27dqoWrWqMlIkKlIqeUZlaGgonJyc5LZ2ld6KRCLB9u3b0aNHjwKvER8fD0dHRyQkJEAQBNjb2+PmzZswNjYuVO5EqkrZ+1QTERERERERERFJpacDXl6AMk/uatAAOH8e+ETjG1G+vXnzBs2aNcPDhw8BAOrq6rC2toa2tjZiYmIQFxeHUaNGYdGiRVBTU9leNCpFlP3dv0r+Fm/btg0ZGRnic0EQYGBggKZNm+Knn35CQEBAoYqUAFC+fHkMHjxYPPcyLCwMM2fOLGzqRERERERERERERFRIGhrAgQNAlSrKWd/VNWt9FimpqFlZWeHmzZv4+++/Ub9+fejq6uLt27dISUlB69atcfHiRSxevJhFSiozVLKjsk2bNjh+/DgkEgkqV66M1atXo3Hjxgq3gS2MgIAANGnSBBKJBIIgQFtbG0+ePIGNjU2RrkOkCpT9VxVEREREREREREQ5hYcDLVoAjx6V3JqursCpU4CtbcmtSURUXJT93b9K/r1HcHAwAMDIyAiXL19GhQoVimWdatWqyTxPTU3F7t27MXr06GJZj4iIiIiIiIiIiIjyztYWCAgAOnbM4zaw+m8A00eAdgKgngpkaAEphkB0FeCD1Wcvb9Agq5OSf7tPRFQ0VLJQGRsbC4lEguHDhxdbkRKAwthHjx5loZKIiIiIiIiIiIiolDAzyzorcv58YPp0IC0t24uG4YDbdsAhALC6ARi+zj1QgjXwpg7wsjEQ5AMk/K9lUlMzK/aECdzulYioKKnkP6nJyckAAHd392JdJz4+XvxZuv1rSEhIsa5JRERERERERERERPmjoQFMngx06AAMGizgSuRpoN4KoMpBQC0zb0EMX2c9qhwCWvwKPOoAXBuO+ubNsXaNBG5uxXsPRERfIpUsVBoaGiIuLg7GxsbFus7t27flxt6+fVusaxIRERERERERERFRAZkHQTJwMPDqcuHiqGUAVfcDVfdDYuMJmK8BwEolEVFRU1N2AgXh5OQEAIiIiCjWdXbv3i03pqamkm8ZERERERERERERUZmVnpmO2edno7ZvbVwubJEyh8uvLqO2b23MPj8b6ZnpRRqbiOhLp5JVt3r16kEQBJw9e7bY1nj+/Dk2btwIiUQiM25ra5vLFURERERERERERERU0qI+RsFrgxd+9/8daZlpn7+gANIy0/C7/+/w2uCFqI9RxbIGEdGXSCULla1btwYA7Nmzp1i2Yk1OTkbv3r2RkpIijgmCAIlEgnr16hX5ekRERERERERERESUf+EJ4Wi8oTEuhV8qkfUuhV+C10YvhCeEl8h6RERlnUoWKr/99ltYW1vj/fv3GDJkCDIz83gYch4kJCSgffv2uHz5MiQSCQRBkHm9Y8eORbYWERERERERERERERVM5MdItNjcAo9iHpXoug+jH6LF5hbsrCQiKgIqWahUV1fHpEmTIAgCDh8+jO7duyM+Pr7QcY8cOQIPDw+ZLWWzb/1qa2uLzp07F3odIiIiIiIiIiIiIiq4tIw0dNrRqcSLlFKPYh6h446OPLOSiKiQVLJQCQDDhg1DzZo1AQB+fn6oXr06du7cme/uSkEQcOLECTRu3BgdOnTAy5cvxW1epd2U0udz586Furp6Ud8KEREREREREREREeXD/IvzS2y719xcCr+E+RfnKzUHIiJVJxFy7m2qQh49eoT69evj/fv3YjHR0tISffr0QePGjVG/fn2YmZnJXCMIAp48eYIbN27g4sWL2LNnDyIjI8XXpB2U2YuVEokEPXr0wPbt20v8HolKi6ioKJibm8uMRUZGyv03RkREREREREREVJyCIoNQ27c20jLTlJ0KNNU0cXPoTbiZuyk7FSKiAlH2d/8qXagEgDNnzqB9+/ZISUkROyCzb9eqoaGB8uXLQ0dHB/Hx8fjw4YPM9dlvP2eRUvpzw4YNcfr0aejo6BT37RCVWsr+x4qIiIiIiIiIiEgQBDRY1wBXXl1RdioiT1tPBA4IlPlemohIVSj7u3+V3fpVqnnz5jh8+DDKly8PiUQidkFKH2lpaYiOjkZ4eLjYeZn9Ib0m+1av2YuULVu2xPHjx1mkJCIiIiIiIiIiIlKyM8/PlKoiJQBcDr+MM8/PKDsNlRccHIz+/fvD1dUVFSpUQOvWrXHz5k3MnDkTRkZGOHnyZJ7ipKSkYOPGjahTpw6mT5+e67xLly6hV69ecHR0hKmpKXr06IEnT54U0d182QRBwLfffouKFSvi9evXyk5HZT179gzjx4+HiYkJXrx4oex0io3KFyoBoFmzZrhy5Qrq1asnV3z83CO77AVKLS0tLFiwAMePH4e+vr4ybouIiIiIiIiIiIiIsllxbYWyU1Bo5fWVxb7Grl27ZBp2JBIJxowZk+v86OhoODg4QENDQ5yvpqYm9x15165d8amNF11dXaGlpSXO19bWhre3d5Hem7+/Pzp37oy5c+ciODgYw4cPx/Hjx9G4cWNs2rQJ7969w8GDBz8bJyQkBAMGDMCwYcNw8+bNXOf9+++/GDlyJNauXYuQkBC0bt0au3fvxtdff43U1NRcrxk6dKjMeyGRSKCpqQldXV3Y2NigadOmWLx4MRITEwv8XpQF0dHROHHiBF68eIHAwMASXbtixYrQ1NSU+z03NTXF5s2bSzSXwvj3338xZMgQ/P3334iNjVV2OsWqTBQqAaBy5coIDAzE6tWrYW9vL3ZM5pV0vpaWFvr164dbt27hl19+KcaMiYiIiIiIiIiIiCivwhPCceDRAWWnodCBhwcQnhBerGv06NEDsbGx2L17N4yMjAAAixYtwtatWxXONzU1xcuXL/Hw4UPo6enB29sbSUlJyMzMxOnTp2FnZwcA2LdvH2bPnp3rug8fPkR4eDjs7Ozg7u6OyMhInDp1Kl+5Z2Zm4uLFiwpfS0tLQ9++fdGkSRNYWFhATU0Ns2fPRt++fWFiYoJp06bB09MTAwcO/Ow6lStXxrZt29C7d+9c50RGRuLHH39Ely5doK+vD01NTaxZswYtW7aEqakpMjMzFV733XffwdfXF2PHjgUAmJubIzw8HKmpqQgNDcWsWbMQFBSE0aNHo2HDhoiKisrDO1M2mZmZYdSoUfj222+LvKj9Oc+fP8eLFy9gZWUFAChfvjyuXr2K6Oho9O3bt0RzKYzvvvsOJ0+eRLly5ZSdSrErM4VKAFBTU8OgQYPw9OlTHDp0CP369YONjY3cdq85H6ampujYsSMWLlyIsLAwrF+/Hq6ursq+HSIiIiIiIiIiIiL6f9vvbUemoLiIpGwZQga239te7Ouoq6ujW7du2L17tzg2ZMiQT3YPOjs7o3r16ujYsSO0tbUhkUjQvHlz+Pv7i3OmTZuGI0eO5BrD3NwcDRo0QMuWLVG+fPl85713795ci5vnzp1DeHg4TExMxDGJRIJNmzYhNDQUffv2xaVLl1CrVq08r2dhYZHrawcOHMD79+9l1tPR0cGJEycQFBT02WPgnJycAACampqwsbGBRCKBmZkZ+vfvj3379kEikeDOnTtffCPU4sWLcezYsQL9vhSWjY0NGjZsCABo0qQJ6tWrV+I5FAU1NTXxjxLKMg1lJ1Ac1NTU0LZtW7Rt2xZA1kGgT58+RUREBBITE6Gurg4jIyMYGxvD3Nwc9vb2Ss6YiIiIiIiIiIiI6MuUnJ6Mp7FPPzvvaMjREsim4I49OYY2ldt8co6TsRN0ND5dCMsLabFMXV0dSUlJ6NSpE27cuAEzMzOF83V1daGnp5drjIyMDPTu3RtXr16Fi4tLnmPkRUREBMaOHYsBAwYofP3BgwcAAC0trXzHzo2mpmaurxV2PQ2N3MsqXl5eqFOnDq5fv47du3dj48aNn5xPxUd6pJ+qH+33Jfz+lP07RFabcW7/QBMRERERERERERGR8jyNfQq3lW7KTqPQ/F/4f/Y+goYFobp59SJbc/78+Rg7dizCwsLQvXt3nD59Ot+FjXnz5mH8+PGIj49Hx44dceXKFRgaGhZJftHR0WjXrh3CwsJynRMXFwcgq4uyJBT3ek5OTrh+/TpSU1ORkJAAY2PjYlmH8qakfq+o4MrU1q9ERERERERERERERF+KMWPGiJ2K//33H0aPHp3vGF27dsWMGTMAZJ1H2adPHwiCUOjcXrx4gU6dOuHZs2cAgCVLlsDZ2RnOzs6IiIjAyJEj4ezsjMWLF8u9vn171ja6sbGxWLhwIVxcXLBx40aF6wQEBODbb7+Fs7MzrKys0LNnT0RGRsrN69y5M5ydnbF3714AwMSJE8X1AgICCn2/UiEhIQAAa2vrXIuUMTExGDt2LGrWrAljY2M4ODhg8uTJSE5Olpu7d+9efP3116hRowYqVKgADw8PLF68WO4zEgQBK1euhLu7O+zs7KCmpgaJRIKaNWvKxczIyMCKFSvQoEEDVKlSBebm5mjfvj0uXLggNzcuLg5Tp05FhQoVAGSd8dmnTx+UL18eTk5O4vuZ8z0YO3YsTExM8OLFC5nXzp49iyZNmmD69OkAgB07dqBq1arQ19dHt27dkJCQoPA9O3fuHLy9vWFnZwcjIyM0a9Ys13NPCys9PR1LlixB/fr1YWtrC1NTU/Tp00em4G5rawuJRCI+dHV1cfr0afH1+fPnQ1dXFxKJBOXKlcOrV6/E18LCwjB48GC4u7vD0NAQLi4u+Ouvv3I9H7WsY6GSiAosOjoaUVFReXoQERERERERERFR0Vu5ciUaN24MAFi+fDk2bNiQ7xhTpkxBz549AQCHDh3CtGnTCp2Xo6MjLly4gFGjRgEARo0ahSdPnuDJkyewtLTE0qVL8eTJE4Wv+/j44MKFCxg8eDAmTJggFv9y2rhxI7755hu0b98eISEhePbsGUxMTLBy5Uq5ufv378eTJ0/QpUsXAFmdpNL1pO9fYe3evVs8L3TKlCkK54SGhqJ+/fpwdXXFrVu3EB4ejqZNm2LOnDlo164dMjIyxLlz5sxBt27dMGrUKNy7dw9Pnz6FtrY2Ro8ejbVr18rEXbJkCZYuXYoTJ04gLCwMz58/h6enp9z6KSkpaNeuHbZt24b9+/fj0aNHCAwMxIsXL+Dl5QVfX19x7rJly+Du7o4//vgD8fHxCAsLg6enJ86ePYv09HQ8e/YMvXr1wtOn/9u6ed26dRg4cCAWLlyI2NhYcfzp06fo1q0bmjdvjvPnzwMAZs+ejf79++P9+/f4+PEj9u7dq7DYvnXrVjRv3hzVqlXDy5cvER4eDk1NTXh5ecHS0hKurq6oW7duHj6hz0tLS0O7du1w7949nDt3DmFhYZgxYwa2bdsGT09PvHnzBgDw7Nkz9OvXT7zu+fPnaNGihfh8woQJ2LJlC+zt7REeHg4bGxsAwK1bt/D111+jXbt2uHv3Ll68eIGKFStiwoQJGDhwYJHcQ3Z5+e4+Ojq6yNfNjy++UJmQkICUlBRlp0GkkqpVqwZzc/M8PYiIiIiIiIiIiKjoaWlpYe/evXB0dAQADBs2DFeuXMl3nA0bNojFnlmzZmH//v1FmWa+ff3119i7dy+aNWum8PW7d+9iyJAh6NevH0aMGCF2tS1ZsgSVKlUqsTwFQcDjx4/x66+/onfv3tDU1MS0adPw448/Kpz//fffw9vbG4MHDxa77Xx9fWFsbIwzZ85g8+bN4tz58+cDALp37w4AMDExwYgRIwAAR4/Kntm6ZMkStGnTBlZWVgAABwcHbNu2TW4r4BkzZuDEiRPYsmULLC0tAQDOzs7Ys2cPNDQ0MGLECFy7dg0AMGTIEJw5c0a8Vlp8e/36Nd6+fYvq1asjPT0du3fvFucMHDgQ/v7+0NXVlVnX3t4ee/bsgY+PD4CsgviHDx8QGRmJ8PBwrF+/HgCwa9cumWJtfHw8RowYAX19fcydOxdqamrQ09PD8uXLAWR13fr7++P69eu5fEL5M2vWLLx69QqrVq0SOyJHjBiBNm3a4PXr15g0aRKArP/ulixZgvLlywPI6pLN6fr165g4caLYWZuWloYePXpg+PDh6NixIwDA2NgYmzdvhpqaGjZu3Ah/f/8iuQ+pvHx3X61atSJdM7/KTKEyJSUF586dw/79+2VaaD/nzz//hJGREby9vbFo0SKZCj8RERERERERERERUWlnZmaGgwcPQl9fHykpKejSpQsiIiLyFUNXVxd+fn6wsrKCIAjo27cvgoODiynjvDMzM1M4PmnSJKSlpWH48OEy4xoaGmjbtm2x5/XmzRu4urrCzMwMVapUwdy5czFu3Di8ePFC3NY0p2vXruH8+fPo2rWrzLiOjg5cXFwAAHv27BHHnZ2d4eHhIXPOoq2tLYCsAl52kZGR2LNnD96+fSuOVapUSabQGxcXh4ULF8LDw0OumFulShV07twZGRkZmDlzJoCsYpy0AA4AS5cuRaNGjQAA+vr6YhduaGioTCx1dXUYGRnJjGlqagKAGK9BgwaYM2cODAwMAGQVcLW1tfHx40eZot/58+eRkJAAJycnmeKns7MzatasibS0NBw/fhxFITU1FUuWLEHHjh2hrq4u85q7uzuArM5c6RatBgYG+OGHHwAAa9askZmflpaGvXv3om/fvuKYn58fnjx5Ivf5W1hYiM0+2T//L0WZKFQuWrQINjY2aN68Obp16wYXFxf4+fnl6dq5c+di586diI+Px9ixY2FnZ4dBgwbJ/YdFRERERERERERERFRa1ahRA9u2bYOamhpev36Nrl27IjU1NV8xbGxscODAAejo6ODDhw/o2LEj3r17VzwJ55G0wJVdZGQkjh8/Dm1tbXh4eMi9ntvZkEUpMzMTDx8+REhIiLit582bN8WORkXOnj0LABg6dChcXV1lHi9evICJiQni4uLE+VeuXBG3kk1LS8POnTsxa9Yscf3svvnmG7x8+RLu7u5YuXKl+NlLuzKBrPMuU1JSZIqP2UkLvKdOnRKvz/7+m5qaysyX3mtSUpJcLEWfW/bxnLE0NDTEsezxPvU77ODgAAD5Lsrn5tatW3j37h3WrVsn9/ls27YNJiYm0NLSkimkSrt5N27ciI8fP4rj+/fvh7e3N/T19cUx6effrl07ufiZmZkwMTFR2JlZ1ql0oTIjIwM9evTAuHHjEBsbC0EQIAgCkpKS8nVocPv27XH16lVs2LAB2tra2LBhA6pXr46FCxcWyaHBRERERERERERERETFrUOHDpg9ezYAIDAwECNHjsx3jHr16onbcErPi8xZFJPq2LEjTE1N5R7Zi2PF4fr16xAEARUqVJDrfCuoHTt2KLyX2rVrf/I6IyMjbNy4ERKJBCdOnMDChQtznSttkDp8+DAePnwo83jz5g2io6MRGBgozldTU0NycjLmzZuHtm3b4v379xg7dqzC2L6+vvD09ERkZCSGDx8OZ2dnbNq0SabGIe2Qzd6hmV3VqlUBZO1gGRkZ+cm5AMRtZfNTR8lvvK+++grq6uoKm8uk8z5VHM4P6RpTp06V+3xCQ0MRHR2N6OhomS5fFxcXtGjRAvHx8di6das47uvrK9ftK41/69Ytufhv375FdHQ0duzYUST3okpUulA5aNAg7NmzB4IgQCKRiA8ACAsLw4cPH/IV74cffsCtW7fg4uKCjx8/Yvz48ejWrVu+/+qE6EsRHByMyMjIPD2IiIiIiIiIiIio+E2aNAl9+vQBAKxevRqrVq3KdwwfHx/89ttvAIDjx49j8uTJCufFx8cjJiZG7pGYmFjwG8gDaddhWlpakcVMTk5WeC95OS6uRYsWYlF48uTJYhdkTunp6QCAx48f5ymnW7duiR2jx48fx6BBg2Q69LKzsrLCxYsXsW7dOtjb2yMsLAz9+vVDr169xEKz9HPJ7fi87Nu1Ghoa5inH4mZnZ4cxY8YgJiYGp0+fFscFQUBQUBDKlSuHNm3aFMla+f18pKTnhkrPzXz8+DHS0tLg5uZWJPELIy/f3St7i2eNz08pnXbu3IlNmzblWn3X1NSUO6w1LxwcHHD27FnUrl0bb9++hZ+fH9q0aYPjx4/LHTpL9KUzNTXNdY94IiIiIiIiIiKivHAydkLQsKDPzmu2uRkiP5beP4g31zPH2b5nPznHydipRHJZs2YNQkJCcOXKFYwaNUpum828+OOPPxAcHIz9+/dj3rx5sLe3R//+/WXmnDt3rogyzh/p1q5xcXFISEgokqJav3790K9fvwJfP2/ePJw6dQoPHjxAr169cPPmTbmiorTzb+fOnejYsaPCOGfPnkWzZs0QERGBli1bwsvLCxMnTsxTDmpqahgwYAB69+6NBQsWYPr06di1axfat2+PPn36wMkp6/fv6dOnyMjIkOtGlRbS7O3tS02hEsh6bxMSEvDzzz/j8OHDsLOzw9y5c/H06VOsXbtWPN+xoEJCQmBrayt+Pvv27cNff/2lsCYUGBiIOnXqQFtbWxxr3749HBwccO/ePfz33384cOAAhg0bJndt9s9f0ZbFwP8+/6KiCt/fq2RHZWZm5if/w5RIJOjUqVOBW76trKywYcMG8bm/v3++tpIlIiIiIiIiIiIiorzR0dBBdfPqn33Ut6mv7FQ/ydPW87P3oKOhUyK56OjowM/PD7a2tkhLS8ObN2/yHUMikWDLli1iQUXR1pt5jfMpBTl+rV69elBXV4cgCOK5f3mNXVzHveno6GDr1q3Q1NRESEiI2GWXnZeXF4CsbWYPHDgg9/qjR4/g5+cHANizZw+io6PFcxhzyrkd75AhQ8SftbW1MXnyZCxYsAAAxO1k27VrBwCIiYnByZMn5WKGhYUBAHr06PHJey1p/v7+2LlzJ6pUqYKWLVvC1dUVly5dwqlTpzBgwIBCx1+xYgV0dXVRt25d6OrqIjQ0VGENKjExEX/99ZdMkRLIKhD/+OOPAIAFCxbg2LFj6Nq1q9z10s9/0aJFuHr1qtzr586dw5UrVwp9P6pGJQuVBw8eRGhoqPgPnPRsSunD29sbK1euLNQa3377Lby8vMSYK1euxNGjR4sifSIiIiIiIiIiIiLKp8b2jZWdwid9bfd1ia318eNHAFnblebG0tISBw8eRLly5QocQ09PDwcPHoSFhUWBc5XufJjbOtIj3N6/f6/wdenRbNm3eTU1NYWPjw8AYPbs2WInYE5JSUn5Xu9zsm9rmzN+7dq1MX36dADA5s2bsWjRIpnXv/nmG9SsWROCIKB79+6YPHky7t+/j5cvX2L79u1o3bq12LUqLUTu2LFD5mzDmTNnAgCio6ORnp6Offv2AQD8/Pzw5MkTmfWaNm0KALCxsQGQdQZlr169AACLFy+Wu7djx47ByMgI48ePF8eyf265vc+KtuBV9Lllj5dbrJzXfPz4ET169EDHjh2xefNmPHjwAI8ePcKRI0fQvHnzXGNIC9KfWgcAjh49KnZO6uvrY/DgwQCAhQsXonv37ggMDMSrV69w5swZeHt7o0WLFgrjDBo0CNra2jh06BA6deoELS0tuTm9evWClZUVkpOT0bx5c8yfPx8hISF49uwZfH190a9fP/Tt21fhe1GU2xyXNipZqDx+/Lj4syAI+Oabb/DXX3/h3LlziIqKwvHjx2X2Ui4oaZu3RCKBIAj49ddfCx2TiIiIiIiIiIiIiPLPp4YP1CUF20WvuKlL1OFTw6fE1pMWpw4dOvTJebVq1cr1CLW8xrC3t8e+ffvkusjyqnr16gCAS5cuQRAE7N+/H/fu3QOQVSyUdvadOnUKCQkJMtcmJiaKnWc5t5n9559/4OrqiuvXr6Nnz57iWZJXrlwRd0z877//cOPGDbx9+xYAEBERgYsXL4r3LS2m5VVycrLY8QhA5mepiRMnomHDhgCAMWPGYNSoUXj58iWArFrDv//+C3Nzc6SlpWHOnDlwc3ODo6MjvvvuOwwbNgy1atUCADRv3hzq6up48+YNKleuDFtbW3Tp0gWDBg0CADx48AC2trbi1p6JiYlo06YNLly4ACCrQLdy5UrY2trKdFuuWrUKHh4eOHHiBCZOnIiUlBQIgoAdO3Zg06ZN2LZtm8xWqtJuzJw/AxDP4rx+/bpM0fbhw4eIiIgAIPu5ZWRkiB2Dly9flukKDQsLQ1RUFAAgICBAHI+OjkZcXBw2bdoEAwMDaGpqQkNDAxKJBLq6uqhWrRr++ecfuc9B+pnfu3cPKSkpcq+npqZi06ZN6NGjh0z345w5c+Dp6Qkgq6u1UaNGsLW1RYsWLWBkZIThw4fLxQKyiuc9e/aEmpoahg4dqnBOuXLlsHPnTujp6eHDhw+YOHEiXFxc4OTkhGHDhmHevHliURkAnjx5Ir6P/v7+CmOWBSpZqLx8+bL487Jly3DmzBmMHTsWXl5eMDExKbJ1pG24UkFBQTJFUiIiIiIiIiIiIiIqGbaGtuhQpYOy01Coo2tH2BraFvs6vr6+MDExwdSpUwFkbdFpbW2NI0eO5HpNt27dxC4/ADhy5AgsLS3Fzq0JEybA3Nwcvr6+ucZo2LAhfH19P7uNqyJt2rTBsGHDcP36dTRr1gw6OjqoUaMGpk6dCisrKwQFZZ1Peu/ePVhZWcHZ2RlxcXE4fPgwrKys8PTpUwAQC3zSwo2JiQkuXryIYcOGISAgAA4ODmjVqhXOnz+P7777DnZ2dnBzc0NISAh0dXUxYMAAODo6igWsU6dOwczMLNezAnPq3bs3jI2NcerUKXHsu+++g42NjUxhTV1dHVu2bBHPp1y6dCkcHR3FTsmqVavixo0b6N+/P8zNzaGlpYWaNWti69atMp2M1atXx8aNG1GxYkVoamqiUaNGuHr1Knr27IkGDRrA1tYWq1evRuPG/+s0DgkJQePGjWFkZIQaNWogNTUV165dkzmnsHz58ggMDMSUKVOwb98+2NjYwMPDA8eOHUNAQABat24tzh0wYABatmwpPm/WrBlatmyJkJAQWFlZYenSpQCAx48fw8LCAseOHcNvv/0GDw8PsaNx6NChaNy4MYKCgmBubi4WLs+cOQNTU1McP34cI0aMgIuLi9itOmjQILFz0cHBAWvXroWFhQUcHBxgYGAgHvuXnJyMBw8e4JdffhE7RP/77z/Mnj0bp0+fBgAEBwfD3NwclSpVgrOzM5ydnWFraws9PT3069cPFSpUQP36/9tWuly5cjh79iymTZuGSpUqQUtLC46Ojpg6dSr27dv3yf8GRowYgdatW8PR0THXOY0bN8a1a9fQrVs3GBkZQUdHBw0aNMCxY8fQs2dPcd6CBQvg5uYmFnOHDh0qFv3LGolQXBsyFyMLCwtER0fD29u7WAuHycnJKFeunNhRKZFIMGTIkEJvK0ukiqKiouQOJY6MjFSJw3iJiIiIiIiIiKhsOP3sNLy3eCs7DTmnvj+FFpUUbwlJRAWXkZGBzp07Y9GiRXBycpJ5LT09HVFRUVi3bh0OHDiAa9euKSlL1abs7/5VsqPy3bt3AIAuXboU6zo5K+OCIMi1NhMRERERERERERFRyWhesTk8bT2VnYYMT1tPNK+Y+1l5RFRwc+fOhaWlpVyREgA0NDRgZWWFX375pUyf4VjWqWShUlNTEwBQsWLFYl1Hum808L+i5evXr4t1TSIiIiIiIiIiIiJSTCKRYE37NdBU01R2KgAALXUtrGm/pkBbohLRp8XGxmL27NnQ0ND45Lx///1XZstaUi0qWai0sLAAkLU1a3FSdDhpzsN8iYiIiIiIiIiIiKjkuJm7YVqTacpOAwAwrck0uJm7KTsNojIpIiICSUlJ8PX1xe+//47Q0FCZ19+9e4e///4bCxYswMSJE5WUJRWWShYqq1WrBgB4+PBhsa6j6CzKChUqFOuaRERERERERERERPRpE7+eiAa2DZSaQwPbBpjQaIJScyAqy6pVq4aff/4ZmZmZmD17NhwcHGBqaorKlSvD1tYWxsbG2LhxI06cOMHajQpTyUJl06ZNIQgC9uzZU2xrLF26FHfv3hVb9gVBgEQigaura7GtSURERERERERERESfp6GmgQO9DqCKSRWlrO9q6ooDvQ5AQ+3TW1ISUeH8888/OHXqFLp06QJLS0vEx8cjNjYWTk5OWL58OW7dugUHBwdlp0mFIBEEQVB2EvkVFhYGR0dHAMD27dvRo0ePIo1/9OhRdO7cGenp6eKYtFA5depUTJtWOrYVICpJUVFRMDc3lxmLjIyEmZmZkjIiIiIiIiIiIqIvXXhCOFpsboFHMY/yNN/4vTHsou2gl6IHjQwNpKun46P2R4SZhiHWIDZPMVxNXXHq+1OwNbQtTOpERKWCsr/7V8k/97Czs0PHjh3h5+eHwYMHw87ODg0aFE2b/z///IOJEyciLS1N7gBkiUSC77//vkjWISIiIiIiIiIiIqLCsTW0RUD/AHTc0RGXwi/JvW4ab4rmQc1R42UNuLxxgdn73L94jzKIwmOrx7jncA9n3M4guny03JwGtg1woNcBmOnxj/eJiIqCSnZUAsCDBw9Qq1YtpKWlQVtbGzNmzMC4cePkiot5debMGfz666+4ceOG2D2Z8399fHywdevWIr4TItWg7L+qICIiIiIiIiIiyk16ZjrmX5yP6eemIy0jDXWe1UHHax3R8FFDqAvq+Y6XIcnAxSoXcaDeAdysdBOa6pqY3nQ6JjSawO1eiahMUfZ3/ypbqASAP//8E7///juArG7HqlWrYsSIEejTpw8MDAw+e31UVBR27dqFrVu34urVqwD+t8VrdoIgwMTEBPfu3YOlpWXR3wiRClD2P1ZERERERERERESfc/u/27g74C7sn9kXWczQSqFwX++Omk1qFllMIqLSQtnf/at0oRIAunbtiv3798t0PmpoaKBGjRqoX78+bGxsUKFCBejo6CA+Ph7v3r3DkydPcOPGDTx58gTS25f+r6IipaamJg4fPgxvb+8Svz+i0kLZ/1gRERERERERERHlJjM9E2HzwvBixgsIaUX/lbdEUwLHaY6wm2gHNQ21Io9PRKQsyv7uX+ULlampqejcuTOOHTsmFiulPrUNbM7bls7N3lEpCAI0NDSwZcsW9OzZsxiyJ1Idyv7HioiIiIiIiIiISJHUqFQEdQxCwqWEYl/LsIEh3A64QctMq9jXIiIqCcr+7l/l//RDS0sLBw8exLBhw8Qio/QhCEKuj+zzshc4sxcp7ezscPr0aRYpiYiIiIiIiIiIiEqh5PBk3Gp8q0SKlACQcCkBt71uIzk8uUTWIyIq61S+UAkA6urqWL58OQ4ePAhHR0eZomNuj5xydlT27dsXd+/ehZeXV4neCxERERERERERERF9XmpkKu60uIOkR0klum7iw0TcaXEHqVGpJbouEVFZVCYKlVLt2rXDw4cPsXr1atSuXVthJ6WUotcqVKiAX375BSEhIdi4cSPKly+vxLshIiIiIiIiIiIiIkUy0zIR1CmoxIuUUkmPkhDUMQiZ6ZlKWZ+IqKxQ+TMqPyU0NBSnT5/GjRs38PTpU0RERCAxMRHq6uowMjKCsbExzM3NUbduXTRq1Ag1atSAmlqZqt0SFRll71NNREREREREREQk9XL2Szz//bmy00DF2RXhMNlB2WkQERWYsr/7L9OFSiIqOsr+x4qIiIiIiIiIiAgAPgR9wI3aNyCkKf+rbYmmBHVu1oG+m76yUyEiKhBlf/fP9kEiIiIiIiIiIiIiUgmCIODRoEelokgJAEKagMeDH4P9QEREBcNCZT6EhYUhIyND2WkQERERERERERERfZHizsTh/ZX3yk5DRsLlBMSdiVN2GqXSu3fv8M8//8DFxQUbN25UdjpUQhITE1GrVi3UqlULiYmJyk5HZd29exdDhw6Fvn7Z7thmoTKP0tLS4OjoiEePHik7FSIiIiIiIiIiIqIv0usVr5WdgkKvVxZ/Xrt27UL58uUhkUjEx5gxY3KdHx0dDQcHB2hoaIjz1dTUZK6XSCTo2rXrJztCXV1doaWlJc7X1taGt7f3Z/MNDAzEoEGDMHbsWISEhBTonkuTFStWoE+fPnLvoaamJvT09GBvb49WrVphw4YNSEtLU3a6SnX//n3cvn0bt2/fRnBwcImt++rVKzg4OEBdXV3u99zCwgJnz54tsVwKa8mSJRgyZAhWr16Njx8/KjudYsVCZR69fPmS7ftERERERERERERESpIcnozoA9HKTkOh6APRSA5PLtY1evTogdjYWOzevRtGRkYAgEWLFmHr1q0K55uamuLly5d4+PAh9PT04O3tjaSkJGRmZuL06dOws7MDAOzbtw+zZ8/Odd2HDx8iPDwcdnZ2cHd3R2RkJE6dOvXZfBs2bIg9e/agefPmBbjb0mf48OHYunUrevbsCQCoWbMm3r59i7S0NISEhODnn3/GhQsXMGDAALRp0+aL7iSsVasWevXqhV69eqFmzZoltq6NjQ1evnyJe/fuQUdHBwDg4OCAx48f4+3bt2jWrFmJ5VJYo0aNgp+fn7LTKBEsVObRqVOnIJFIlJ0GERERERERERER0RcpcnskkKnsLHKR8f/5FTN1dXV069YNu3fvFseGDBmCmzdv5nqNs7Mzqlevjo4dO0JbWxsSiQTNmzeHv7+/OGfatGk4cuRIrjHMzc3RoEEDtGzZEuXLl89Xzubm5vmaX9o5OTkBAPT09MR7s7a2xtixY7Fq1SoAwOnTp/Hnn38qLUdl09DQwPbt27F9+3ZoaGiU+PrVqlVD9erVAQAdO3ZE5cqVSzyHomBqaqrsFEoEC5V5kJiYiIULFyo7DSIiIiIiIiIiIqIvwsf7H+UesUdjlZ3WJ8Uei5XLubhIi2Xq6upISkpCp06dEBUVlet8XV1d6Onp5RojMzMTvXv3xuPHj/MVIy+UUagqTp+6n++//14sLv37778llRIpID3XUZXPdyxr/+3khoXKz/j48SO6deuGp0+fKjsVIiIiIiIiIiIioi/CNbdrco93594pO61Peuf/Ti7n4jZ//nwAQFhYGLp374709PR8x5g3bx4kEgni4+PRsWNHJCQkFHWaXxRpATg6unRuU/yl4U6ZpR8LlZ9w9OhR1KhRAydOnFB2KkREREREREREREREMsaMGYMBAwYAAP777z+MHj063zG6du2KGTNmAMg6j7JPnz4QBKEo0xTFxMTghx9+QIUKFWBubo5Ro0bh/fv3CucGBwfjhx9+gIeHBywtLVG1alVMnz5d5uzHnTt3Qk1NDRKJBBKJBOXKlcN///2HZ8+ewdjYWByXSCSoUKGC2DF65coV6OvrQyKRQENDAwEBAUVyfxkZGXj27BkAoEaNGrnOCwsLw+DBg+Hu7g5DQ0O4uLjgr7/+Qmam7N7GmZmZWLt2LerVq4eqVavCyMgI9evXV3guaVpaGmbOnInq1avD2tpavO9OnTrJzU1KSsKcOXNQp04dODs7w9LSEr169cL9+/fl5r569QqjRo1C1apVAQBPnz5F+/btoa+vjxo1auD8+fNy19y6dQtDhgyR62YUBAH79u1DzZo1sXHjRgDA0qVL4ejoiPLly+PHH39EWlqawvds3759aNSoEWxtbWFsbIwOHToozLcoJCYmYubMmahTpw4sLCxgZWWF4cOHIzY2q6v7/fv3KFeunMzvl6GhIR48eCDGGDVqFDQ1NcXXsgsODoaPjw/c3Nygr68Pd3d3rF+/vljuRRWwUKnAmTNn0LRpU7Rv3x4vXrwotn+UiYiIiIiIiIiIiIgKY+XKlWjcuDEAYPny5diwYUO+Y0yZMgU9e/YEABw6dAjTpk0r0hwBIC4uDo0aNcLJkycBAFFRUVi6dClatGiBlJQUmbnHjh1DgwYN0KxZM9y+fRvh4eEYOHAgZsyYAU9PT8TExAAAevbsiQsXLkBLSwsAsHHjRjRp0gSVKlVCVFQUWrduDQCoVasWYmJi4OLiAgCoX78+bt68CU1NTVy4cEF8/wpr4cKF4ha8U6ZMUTjn1q1b+Prrr9GuXTvcvXsXL168QMWKFTFhwgQMHDhQZu6wYcPw448/YsmSJXjw4AHu3LmDqKgofP/99zh16pTM3AkTJsDf3x+BgYF4/fo17t69q/BsxtjYWHh5eeH69es4e/Ysnjx5giNHjuDChQuoXbs2Dh8+LM6dNm0aatSogaVLlyIpKQl37tyBp6cnbt++jbS0NAQFBaFTp06Ij48Xr5k7dy4GDhyINWvW4OPH/21/fP36dbRq1Qpdu3bFnTt3AGSdr/rrr78iOTkZCQkJ8PX1xZw5c+Ry/vPPP9G1a1d06dIF4eHhePjwIcLCwlCrVi1YW1vD1dUVHTt2/NzHkyfv3r1D48aNkZmZiStXriA8PBz9+/fHypUr0aRJE3z8+BEGBgZ4+/Ytvv32WwBAhQoV8PbtW7GYCwBLliwRi8GRkf87v/bEiRNo27YtRowYgaCgIDx8+BDq6uri7/eXiIXK/5eUlIR169bBw8MDLVu2REBAAARBEKvhRERERERERERERESljZaWFvbu3QtHR0cAWcWtK1eu5DvOhg0bULduXQDArFmzsH///qJMEytXrsSyZcvw5s0bREVFYfr06QCAq1evYuHCheK8iIgI9OnTB506dcIPP/wgdj2OGzcOffv2xb1799C/f39xfsOGDeHj4wMAeP78uTiurq4urhEXFwc1NdlyyL179+Dj4wNPT89C3VdmZibu3LmDH3/8ERMnToSenh5WrVolFrGyS0tLQ48ePTB8+HCxsGZsbIzNmzdDTU0NGzduhL+/v5jzmjVrYGNjgwYNGgAA7O3t8cMPPwDI2hFSKj09HStXrkTXrl1Rvnx5AFkdnWvXrpXL4aeffsLjx4+xfv16cW6dOnWwefNmpKamwsfHB6GhoQCA3377DTt27AAAfPjwAbNnz4a/vz/CwsLw8uVLWFhYIC4uDseOHRPjT5o0SabYKeXu7o6TJ0+K97Jq1Sq4uroiOjoaERERmDp1KgD5sz2fPHmCqVOnonLlyhgzZgwAwNzcHAsWLEBaWhrS0tJw+/ZtHDhw4BOfUt79/PPPMDc3x/Tp06GhoQFNTU3Mnj0b1atXR1BQkLjdsoGBAVauXAk1NTV8/PgRycnJcrGuX7+OmTNnQkdHB0BWR/F3332HuXPn4uuvvwYA2NraYvXq1QCAmTNn4smTJ0VyH6rkiy9UPn78GKNHj4aNjQ2GDBmCe/fuQRAEsUhJRERERERERERERFSamZmZ4eDBg9DX10dKSgq6dOmCiIiIfMXQ1dWFn58frKysIAgC+vbti+Dg4CLLceLEiWjRogUAQFNTE9OmTUObNm0AQKYLdOHChYiNjUWXLl3kYkyaNAlAVtfnjRs3xHFpJ+L27dtl5n/11VeoVKkSXrx4gbNnz8q8tmnTJrkOxvy4fv06qlSpAmNjY9SsWROrV6/GwoULERYWhqFDhyq8xs/PD0+ePEHXrl1lxi0sLGBubg4A2LNnDwCgXLlysLGxQa1atWTm2traAoBMF2N8fDxSUlKwadMmfPjwQRz38vISu0iBrC1Ht2/fjmbNmolFSqlmzZrhq6++wocPH/DXX38ByCqCSwvg0kKqm5sbAMDS0hJt27YFALGwKWVmZiZ379KuV2m8bt26YcyYMWIRb9CgQQpjHTt2DBkZGXBzc5Op2TRr1gzGxsaIjo7GpUuX5NYriDdv3mDbtm1yn49EIhG38pV+PtJ7adeuHdLS0rBp0yaZa6KionD37l2xqxcA1q9fj/fv36NDhw4yc93d3QFkFb2L+g8EVMEXWajMzMzE3r170aJFC1StWhVLly7Fu3fvxC1epV2U0oIlESkWHR2NqKioPD2IiIiIiIiIiIio+NSoUQPbtm2DmpoaXr9+ja5duyI1NTVfMWxsbHDgwAHo6Ojgw4cP6NixI969e1ck+amrq8uNSTvkQkJCxAKbtKNOWtDKrmrVqqhYsSIA4MiRI+J448aN4eTkhDt37uDevXvieGhoKN68eQMAMt2FkZGRePLkCby8vAp8P5aWlnj06BFu3rwJfX19CIKABw8ewMjIKNdrpMXSdu3awdXVVeaRmZkJExMTcVtbbW1tPH/+XCxcJSYmYu3atVi+fDkAyJxnaWJiAnd3d1y/fh0eHh7YsWOH+Lq0AxD49HsLQCw8Zn9vNTU1AWQVTsuVKycz38rKCkDWjpXZSa9RRPqaqalpnmJ96nfYwcEBAPJdlM/N+fPnkZGRgZkzZ8p9PgEBATAxMUFCQoLMNT/99BMAYMWKFTL1pA0bNqBfv34yxdWzZ89CEATUqlVLJraHhwdMTExgYmIis01sUcjLd/fR0dFFumZ+fVGFyjdv3mDGjBmwt7dHjx494O/vL9M9mbNAyW1fiT6tWrVqMDc3z9ODiIiIiIiIiIiIileHDh0we/ZsAEBgYCBGjhyZ7xj16tXD+vXrAWRtu+nj4yNTFMuuY8eOMDU1lXtkL459iqurq/hzfHw8EhIS8OrVKwDI9bt56TmAOTvv+vXrBwAynW3//PMP/vzzT2hra2P//v1iEXDr1q3o06ePzPXz589XeC+fO/uwUqVK+OeffwAAq1evxt69e3OdK8351q1bePjwoczj7du3iI6OFrdaBQANDQ3ExcVh8uTJ6N69OwwMDHLt1ty5cyeqVKmCZ8+ewcfHB25ubjh06JDMHGmHbH7e20/VSDQ0NAAgXw1fucWTxspJulXsy5cv5V6TristchaW9L59fX3lPp/w8HBER0cjLCxM5poWLVrAxcUFISEh4vmrgiBg8+bNGDBggFx8Y2NjudgPHz5EdHQ0oqOjxW7WopKX7+6rVatWpGvm1xdRqDx79iy6desGR0dHzJw5E69fv1ZYjMzZUZl9jIiIiIiIiIiIiIiotJs0aZJYhFu9ejVWrVqV7xg+Pj747bffAADHjx/H5MmTFc6Lj49HTEyM3CMxMTFP62RvcKhQoYLMddKCZU7SjkVDQ0OZ8R9++AFqamrYtm0bMjIyEB8fj2PHjmHEiBHo3LkzUlJSsGXLFgDAli1bxLMepRITExXeS/YtVnMzcOBAsaA5ePBguSKqVHp6OoCsI+ny4vTp0/Dw8ICrqyuOHDmCnj17QltbW+FcV1dX3LlzB3///TdMTU3x4MEDdOjQAePGjZO5RyD/760yNWzYEN27d8ft27dl3rePHz/i6dOnsLa2RsOGDYtkrfx+PkBWPWn48OEAgGXLlgEATp06hVq1asl1jaanpyMqKqrIupTLijJbqExISMDixYtRtWpVeHt7Y//+/UhLS1PYPSmVvZtSEAQ4ODjA3d1dYUs6ERERERERERERERWPekH15B6a5rlvJ1kaaJpryuWsLGvWrEH9+vUBAKNGjcpX4UXqjz/+QOfOnQEA8+bNg7+/v9ycc+fOyXynLn1Mnz49T2vExcUBAJydnaGnpwczMzMYGBgAAB49eqTwGmkxSXpmoJSdnR2aNWuGiIgInDx5EqtWrUL//v2hqakpnkW5du1a3LhxA9bW1rCxsZG5fvr06Qrv5dy5c3m6lzVr1sDc3BxxcXHo3bs3MjIy5OZIO/927tyZaxzp9rBBQUHo0KEDevTogb59++YpB21tbYwdOxZPnz7F6NGjAQALFizAxYsXAQBOTk4A8v/eKtu2bdvQunVrDB48GFFRUUhOTsbYsWORkpKC9evXi+dfFtTdu3cB/O/z2bVrV65zc551CmR18+rp6eHo0aN4/vw5Vq1aJRYvs5Oe/5pb/Pz8vpUlZa5QeevWLQwePBg2NjYYM2YMHj169NnuSelzQRDQsGFDrFy5Eq9fv8azZ89w+/Zt3L9/P9c9m4mIiIiIiIiIiIioaOlV15N7GNYvPV1eihh6GsrlrCw6Ojrw8/ODra0t0tLSxHMa80MikWDLli3w8PAAIL/ValG4ceMGAOC7774DkHWOZZs2bQAA27dvV3hNWFgYtLS00KlTJ7nX+vfvDyCrILlhwwZxm9TmzZujYsWKuH//PkaOHCm3JWdRMDMzE8/BvHDhAmbOnCk3R3om5qJFi3D16lW518+dO4crV64AADZu3IikpCTxHMacsm/HGx0dLdP1amhoiEWLFolngEoLle3btwcA3LlzBw8ePJCLKd3WtEePHp+525K1c+dOXLx4EcbGxqhfvz7c3d0RExODS5cuoVWrVoWOv2HDBgBZZ50CWdsmL126VG5eVFSUuC1yduXLl0efPn2QmZmJKVOmIDQ0VNyyNjvp5//bb7/h2bNncq9v2rQJr1+/LtS9qKIyUahMTU3F5s2b4enpibp162L9+vX4+PGjXPckIFuglBYnDQ0NMXLkSAQHB+PChQsYOnQoLC0txfiVK1cW9/Umov8JDg5GZGRknh5ERERERERERESFUb5xeWWn8Enlvy65/D5+/AgASE5OznWOpaUlDh48iHLlyhU4hp6eHg4ePAgLC4tCZJtF0TFry5cvR8WKFTF27Fhx7Pfff4eGhgauXr2Ky5cvy8yPjo7G9evXMW7cOHGb0uw6d+6M8uXLY9++fWjTpg3Kl8/6TCQSiVjEDAkJQYcOHQp8H9LtU5OSkuRea9++PQYPHgwAmDVrltx5lb169YKVlRWSk5PRvHlzzJ8/HyEhIXj27Bl8fX3Rr18/sXtSWohcu3YtYmNjAWQVMhcvXiy+Fx8+fMCRI0cAZBU2o6OjZdZr2rQpAIjdo61atRILaNI42R07dgxOTk5iByrwv98PabelImlpaTLPU1NTc30tv/FCQ0MxcOBA/PTTT9i2bRseP36MBw8eYPfu3ahdu3auMaS/b59aBwBWrlwpdpo6OTmJvxujRo3Cjz/+iJs3byIsLAyHDh3CN998g169eimMM2LECABZ3Z/S34GchgwZAj09PURHR6NBgwZYtWoVnj9/jsePH2P+/PmYM2eOzO9m9vch5/uYV3n57l56dqmyqHSh8tmzZ5gwYQJsbGzQv39/XLt27ZPdk9Jx6ZxatWphzZo1ePXqFRYvXixzcG9OTZo0KZF7IlIlpqamMDMzy9ODiIiIiIiIiIioMMx9zIHSekqX+v/nV0L27dsHADh06NAn59WqVQubNm0SvysvSAx7e3vs27cv17MRP6dixYoAgGnTpuH06dMAsooukydPRnBwMI4fPy5zJqKbmxt8fX2hpqaGXr164c6dOwCyCnM9e/ZEixYtMGXKFIVr6erqomfPntDQ0BC3PpXq378/1NTU0KdPH2hqFmwb4bi4OJw4cQJAVgHo0qVLcnMWLVoEJycnZGZmwsfHB9OnTxcbOcqVK4edO3dCT08PHz58wMSJE+Hi4gInJycMGzYM8+bNkykqAsC9e/dga2sLKysrjBkzBoMGDQKQdXZo9erVUblyZQDAmzdv0LZtW9y7dw9AViF13bp1cHd3R7du3QBkFWx37twJOzs7rF69GosXL0ZmZiYyMjKwePFiXLx4ETt27ICOjo54P4GBgQCAt2/f4unTp+K4IAi4deuWOCd7h2f27Uuz/5ycnCxzTXbS7loACAgIEH8ODQ1FamoqZs2aBT09PWhqakJDQwNqamrQ09ND7dq1sXXrVrnP4e3btwCAmzdvyuQm9fHjRyxYsAA///wzunTpIo6vXr1afE99fX1Rp04d2Nvbo0OHDmjSpAnatWsnFwvI2i7Xy8sLhoaG4hmxOdna2mL9+vXQ0NBAZGQkhg0bhkqVKqFKlSqYOnUq1q5dC319fYXvg6Ktl/MiL9/d5zxLs6SpXKFSEAQcOnQIrVu3houLCxYsWICYmBiFBUqpnM+7dOmCy5cv48aNGxg4cGCuf1GSnaWlpcK/+CAiIiIiIiIiIiKi4qdjqwPTDsr9Qj03ph1NoWOr8/mJheTr6wsTExNMnToVQNYWndbW1mJXnSLdunWTOTPyyJEjsLS0FDv3JkyYAHNzc/j6+uYao2HDhvD19VVY8PycadOm4dy5c2jQoAH69OkDa2trNGzYEBKJBDdv3oSLi4vcNQMGDMC5c+dQrVo1fPPNN3BxcUHbtm3RrVs3HDx4UKaQllP//v3RvXt32Nvby4zb2tri22+/LfC2r15eXrCwsBDPMwSARo0awd7eXmYbTz09PWzZsgXq6upIS0vDjBkzYGFhgRkzZgDI2l702rVr6NatG4yMjKCjo4MGDRrg2LFj6NmzpxinVatW+Ouvv2BlZSVudRsQEIDevXvDxcUFLi4u2L59u8z7d/XqVbi7u8Pc3Bx169aFs7MzAgICZIrMdnZ2uHXrFkaOHImFCxfC2toatWrVQkhICK5du4a6deuKc1u0aCEWRtPT01GtWjUMHDgQ/v7+MDMzw8GDBwFkFSNNTU0RFBSEH374Qdy+FwBat26N3r174/jx4zA3NxfPS92wYQMsLCzEszizb5XasmVL8XP6+uuvMXXqVNja2sLW1hb6+vpQV1eHIAhITEzErVu38P333+PAgQNISUnB2bNnMXbsWPEczlOnTsHU1BROTk5wdnaGk5MTrK2tYWhoiHHjxqFevXqwtrYW17awsMDly5fx888/w9bWFlpaWqhSpQr++ecfLFu27JO/IyNGjMD3338PPb3ct33u0aMHzp8/j1atWsHAwAB6enrw9vbG+fPnxa1nAeCXX36R2da2devWaN269SfXV1USQUWqb1FRUVizZg1Wr14t7pOc85xJ6VjO5wBQpUoVPHr0CBKJBAEBAWjYsGG+czh//jzq1asHXV3dwtwKkUqKioqCubnsX4VFRkayW5KIiIiIiIiIiEpM7OlY3PW++/mJJcz9lDuMWxgrOw2iMufDhw/o3Lkzdu7cCWNj2f/GpOevzps3D5GRkdi9e7eSslRtyv7uv9R3VAYEBOC7776DnZ2deAjpp7Z3zf5cTU0NnTt3xqlTp4pkj10vLy8WKYmIiIiIiIiIiIiUxKi5EQw9DT8/sQQZehrCqLn8eYlEVHi//PILvvnmG7kiJQBoamrC3t4ew4cPL/AZjqR8pbJQ+fHjR6xcuRLu7u5o2rQpdu7cidTUVJnipKLtXaUFTHNzc/z+++948eIF9u7di+bNmxeoJZ2IiIiIiIiIiIiISg+JRAKXNS6QaJaO73slWv+fD79/JipyDx48wLp166ChofHJef/++2+Z3Rb1S/DpT7eEBQUFYcWKFdi2bRs+fPggcyZkXrZ3bdy4MYYPH46uXbt+9heXiIiIiIiIiIiIiFSPvps+HKc54vnvz5WdChynOULfTV/ZaRCVSc+fP4cgCJg2bRrU1dXRt29fme1I3759i0WLFuHcuXMICAhQYqZUGErvqExPT8eOHTvg5eUFDw8P+Pr64v379zJbuSrqngSyCpR6enr48ccfcffuXfz333/o2bMni5REREREREREREREZZjdRDsYNlDuFrCGDQxhN8FOqTkQlWUtW7ZEt27dkJycjHHjxsHc3ByWlpZwcXGBlZUVLC0tcenSJRw9ehSamprKTpcKSGkVvejoaCxatAjr1q1DVFQUAPlzJqVjironq1atiuHDh6Nv374wMDAowcyJiIiIiIiIiIiISJnUNNTgdsANtxrfQtKjpBJfv5xrObgdcIOahtJ7gYjKLA0NDezevRu7d+/G+vXrce3aNcTExCAzMxO1a9fGggUL4OPjw62XVZzSCpXnz5/HnDlzAPyvMKmoICk9exLI+qXs1KkThg8fjqZNm5ZswkRERERERERERERUamiZacHjtAfutLhTosXKcq7l4H7KHVpmWiW2JtGXrHv37ujevbuy06BiorQ/9+jcuTP8/Pzg7e0NADLnUQKyRUsrKytMmzYNL1++xK5du1ikJCIiIiIiIiIiIiLo2OqgVkCtEtsG1rCBIWqerwkdW50SWY+IqKxTWqFSIpGgQ4cOOHHiBB48eIARI0bAwMBArmAJAG3atEGPHj1gZWWlhEyJiIiIiIiIiIiIqLTSMtNCzfM1UXF2RUg0i2cLSImmBBVnV0TN8zXZSUlEVIRKxQbaLi4uWLp0KV69eoWlS5eiSpUqMgXL9evXw83NDd7e3jh06JDCYiYRERERERERERERfZnUNNTgMNkBdW7WgaFn0XZXGnoaos7NOnCY7MAzKYmIilip+ldVT08PI0aMQHBwME6ePIkOHTqIZ1QKgoCzZ8+iU6dOcHJywsKFC/Hu3Ttlp0xEREREREREREREpYS+mz5qBdaC+yl3mHY2Lfg34OqAaRdTuJ9yR63AWtB30y/SPImIKItEKOXtiaGhoVi+fDnWr1+PmJgYAP87v1JXVxd9+vTBTz/9BDc3t8/GUlNTg0QiQUBAABo2bFiseZdFgiAgNDQUkZGR0NbWhqOjIwwNS2bv9y9RdHQ07t+/j6dPnyI2NhYfP36EIAjo168fHB0dSzyfqKgomJuby4xFRkbCzMysxHMhIiIiIiIiIiLKi+TwZERuj0T8hXi8v/4eqa9Tc52rZa0Fg7oGKP91eZj7mPMcSiL6Iij7u/9SX6iUSklJwb///ovly5fj5s2b4ri0aNmkSROMGjUKHTt2FMdyYqGyYO7evYvFixfj0KFDiIqKEsclEglq166Nvn37YtCgQShXrpwSs1R9GRkZOH/+PPbv34/Tp0/jwYMHMq/r6+ujYsWK2LJlCzw8PEo8P2X/Y0VERERERERERFRYKREpSHyYiIz3GchMyYSathrUDdRRzrUctC21lZ0eEVGJU/Z3/ypTqMzu0qVLWLp0Kfbu3Yu0tDQA/ytY2tnZYcSIERg4cCCMjY1lrmOhMn/i4uIwfvx4rF+//rPnglpbW8PX1xft2rUroewU++OPPzB16tRii79hwwb069evSGMmJCRg9erVWLp0KUJDQ8VxU1NTtG3bFq1atcJXX30FJyenIl03v5T9jxURERERERERERERERUtZX/3X6rOqMyrBg0a4N9//0VoaCimTZsGa2tr8RzLsLAwTJo0CXZ2dhg8eDDu3r2r7HRV0qNHj1CvXj2sW7cOgiBAIpFgyJAhuHXrFpKSkhATE4P9+/ejTp06AIDXr1+jQ4cOmD59utJyzsjIgK+vb7GuYW9vX2SxBEHAxo0b4eLigvHjx4tFyipVqmDr1q149eoVNm7cCB8fH6UXKYmIiIiIiIiIiIiIiIqaShYqpSwsLDBt2jS8ePEC27dvR6NGjcSCZVJSEtavX49atWqhadOm2LNnT6HXe/XqFTIyMoog89Lt+vXraNCgAZ4+fQoA0NLSwr59++Dr64uaNWtCR0cHxsbG6NSpEy5fvoyuXbsCyCq8zZgxA+PGjVNK3gcOHMCrV6+KLb65uTmaNGlSJLEiIiLg7e2N/v374+3btwAAHR0d/PXXXwgKCkLv3r2hpaVVJGsRERERERERERERERGVRipdqJTS0NBAz549ERAQgFu3bmHAgAHQ1dUVi5YBAQHo2bOnOL+gxUYnJyc8evSoqNIulUJDQ9G+fXvExcWJY3/99Rc6deqkcL6Ghga2bt0KV1dXcWzBggVYvHhxcacqZ8WKFcUav0uXLlBXVy90nLNnz8LDwwNnzpwRxypVqoRr165h3Lhx0NDQKPQaREREREREREREREREpV2ZKFRm5+HhgbVr1yI8PBzz5s1DxYoVxYKl9BzLtm3b4qeffsKDBw/yHPfNmzdITU0trrRLhfT0dHTq1AkRERHimJeXF0aOHPnJ63R0dLBs2TKZsXHjxuHq1avFkqcijx8/xtmzZ4t1je7duxc6xqZNm/Dtt98iMjJSHPvqq69w7do1uLm5FTo+ERERERERERERERGRqihzhUopIyMjjB8/Hk+ePMGBAwfg7e0NIGt70g8fPmDlypVwc3ND8+bN4efnB0EQPhnvxo0bYqGzrJo/fz5u3bolMzZ16tQ83Xfz5s3h6ekpPk9PT0efPn2QlJRU5HkqsmLFCvEzLFeuHIYMGYJ9+/bh4cOHiI+PR2pqqliwzssjJSUF5cuXF+NbWFgUetvXOXPmoF+/fkhLSxPHGjRogDNnzsDY2LhQsYmIiIiIiIiIiIiIiFRNmS1USkkkErRv3x4nTpzAgwcP8NNPP8HQ0FAsSJ07dw5du3aFo6Mj5s6di+joaIVxduzYUcKZl6wXL17gjz/+kBmTFnLzauDAgTLPQ0JCsGjRoiLJ71MSExOxceNGAEDjxo1x7949+Pr6onPnzqhSpQoMDQ2hqamZr5inTp1CfHy8+Lyw277Onz8fkydPlhlzcnLCwYMHoa+vX+C4REREREREREREREREqqrMFyqzc3FxwZIlS/Dq1SssXboUVatWFQuW4eHh+O2332Bra4vu3btj586dePXqFd6+fYtp06bh33//VXb6xWru3LlITk6WGevSpUu+YnTr1k2umDd37lzExMQUOr9P2bZtG+Lj49GtWzecPn0alSpVKnTMPXv2yDzv0aNHgWOtWLECEydOlBkzMjLCkSNHYGpqWuC4REREREREREREREREqkwifG7P0zLuzJkzWLp0KY4cOYKMjAwAULjVqfSMy3v37qFatWolnWaxev36NSpVqoSUlBSZ8WvXrqFu3br5ilW/fn25syn//PNP/Prrr4XOMze1a9dGuXLlcPbsWWhpaRU6XlpaGiwsLBAXFwcAsLS0xKtXr6Cmlv+6/tmzZ9GyZUvxd0vq6NGjaN26daFzLUlRUVEwNzeXGYuMjISZmZmSMiIiIiIiIiIiIiIiosJQ9nf/X1RHpSLSMyqfPn2K8ePHo0KFCgrPLCzL1qxZI1ek1NXVRa1atfId65tvvpEbW7FiBTIzMwuc36dcunQJISEh2LFjR5EUKYGs4rW0SAkAXbt2LVCRMiwsDL169ZIrUn733XcqV6QkIiIiIiIiIiIiIiIqal98oVLK3t4e8+bNQ1hYGBYtWgRLS0sAWd2VijosyxJF52/WqFGjQGcyenp6yo2Fh4cjICCgQLl9jpWVFXbv3g1bW9sii1lU27727dsXUVFRMmPGxsYlcm4nERERERERERERERFRacdCZQ56enr4+eef8fTpU8ycObPIuvRKq9u3b+Phw4dy4+7u7gWKV7VqVYXjOYt/RcXR0RHffvttkcVLT0+Hn5+f+NzKygpff/11vuOsW7cO586dkxufNWuWXAs1ERERERERERERERHRl4iFylzo6uri999/x61bt1C5cmVlp1Nsjh8/rnDcwcGhQPGcnZ0VFnfPnj1boHglzd/fHzExMeLzgmz7GhMTg/Hjx8uN29raYuDAgYXOkYiIiIiIiIiIiIiIqCxgofIzXF1dceHCBVhYWCg7lWIRGBiocLygW6mqq6vD3t5ebvzBgweIjo4uUMySVBTbvv79998yZ1xKjRo1qsx36BIREREREREREREREeUVC5V5YGpqiuHDhys7jWJx6dIlheOFOfNRUVFXEATcvn27wDFLQkZGhsy2r9bW1vne9jUmJgbLli2TG9fW1kb//v0LmyIREREREREREREREVGZwUJlHnXo0AGCICg7jSL16tWrXLscC1OozO0MxuDg4ALHLAnnz59HZGSk+Lxbt26QSCT5irFy5Up8+PBBbrxt27YwNTUtdI5ERERERERERERERERlhYayE1AVNWrUQPPmzaGnp6fsVIrM8+fPc32tMIVKMzMzheMhISEFjlkSdu/eLfM8v9u+CoKADRs2KHytV69e4s+ZmZn477//cObMGZw/fx6hoaGIjIyElpYWbGxsULt2bfTo0QPffvstNDU1838jREREREREREREREREKoCFyjxSU1PDqVOnlJ1GkXrx4oXCcT09Pejr6xc4rra2tsLxiIiIAscsbpmZmdi/f7/43NbWFg0bNsxXjPPnz+PZs2dy49ra2mjTpg3ev3+PtWvXYtmyZQrnJSUlIT4+HsHBwdi6dSuqVKmC5cuXo3nz5vm/oRJSnOeO5lbwJiIiIiIiIiIiIiL60kRFRRVL3OL8nj8vWKj8goWHhyscL1euXKHi5laofPv2baHiFqcLFy7IFFILsu1r9kJndl5eXjh06BDGjh2L169fAwDU1dVhYWGBzMzMXAu4jx49QosWLTBlyhTMnDkzX7mUlGrVqhVb7LK21TIRERERERERERERUUHlduyequMZlV+whIQEhePFVajMbb3SoLDbvgLAmTNnFI5fvHgRPj4+iIiIQPfu3XH06FG8f/8er169wps3bxAbG4vVq1fDwcFB4fV//PEHRo4cme98iIiIiIiIiIiIiIiISjMWKr9giYmJCsd1dXULFVddXV3heEpKSqHiFhdBELBv3z7xuZ2dHTw9PfMVIzIyEkFBQQpfS0xMRJs2bXDv3j3s2rULrVu3lnmPjYyMMHjwYNy9exetW7dWGGPZsmVYu3ZtvnIiIiIiIiIiIiIiIiIqzVio/ILlVqgsbEdlRkaGwvHU1NRCxS0ugYGB4pasQMG2fb1z547CcU1NTRw4cABHjhz57DaphoaG2L9/P7766iuFr48aNQqPHj3KV15ERERERERERERERESlFc+o/ILldgZgYTsqMzMzFY7ntiWsshXFtq8PHz5UOO7g4IAOHTrkOY62tja2bNkCd3d3uQ7UpKQkzJo1C1u2bMl3fsUlODgYpqamyk6DiIiIiIiIiIiIiKhMi4yMLJa40dHRn220Kk4sVH7B9PX1iyVucnKywvHCdmoWh5zbvtrb2+d721cACAkJUTju6OiY71guLi7o168ffH195V7bsWMHZs2alet5liXN1NQUZmZmyk6DiIiIiIiIiIiIiKhMK6vfxXPr1y+YgYGBwvHcCo15ldtZlIXt1CwOV65cQVhYmPi8e/fuBYoTExOjcNzGxqZA8caNGwc1Nfn/PNPT07F///4CxSQiIiIiIiIiIiIiIipNWKj8ghVXofLDhw8KxytUqFCouMVhz549Ms8Lsu0rALx//17huKWlZYHiOTs7o0mTJgpfO3fuXIFiEhERERERERERERERlSYsVH7BjIyMFI4XtlCZkJCgcLy0bFeaXfZCpaOjI7766qsCxUlMTFQ4bmJiUqB4ANC+fXuF41euXClwTCIiIiIiIiIiIiIiotKChcovWJUqVRSO59YRmVfv3r1TOG5vb1+ouEXt2rVrePnypfi8oNu+AoCmpqbCcUNDwwLHbNWqlcLxqKgoZGZmFjguERERERERERERERFRacBC5ResevXqCsejoqKQnp5e4LhRUVEKxx0dHQscszgU1bavAKCnp6dwXEtLq8AxXVxcFF6fkZGRazGYiIiIiIiIiIiIiIhIVbBQ+QUzNjZWeIZiZmYm3rx5U+C4b9++VThep06dAscsDtkLlRUrVkTdunULHMvCwkLheEpKSoFjamho5Nr1mpqaWuC4REREREREREREREREpQELlV84Dw8PhePh4eEFipecnIzo6Gi5cTMzMzg5ORUoZnG4efMmnj17Jj4vzLavAHK9t9jY2ELFza0AWpizL4mIiIiIiIiIiIiIiEoDFiq/cK1bt1Y4/vz58wLFe/HihcJxT0/PAsUrLkW57SsAuLm5KRwv6PsoZWBgIDdmaGiY65mYREREREREREREREREqqLMFSpfvnyJ9evXo1+/fvD29katWrVw69atXOfHxMSgadOm+Omnn+Dn51eosxlVUYcOHRSO37x5s0DxQkJCFI63b9++QPGKS/ZCpZOTU6G3pfX09ISamvx/TkFBQYWKq+jsy9yKokRERERERERERERERKqkzBQqr1y5gvbt26NSpUoYPHgwtmzZgjNnzuDu3btISkrK9TpBEODl5YV9+/aha9eusLW1xfTp0/Hx48cSzF55KlasiOrVq8uN37hxo0Dx7t69KzemoaGBLl26FChecbhz545MQbWw274CWV2O9evXlxu/fft2oc6T/PDhg9xY48aNCxyPiIiIiIiIiIiIiIiotFD5QqUgCJg4cSIaNmyIo0ePQhAE8ZEXpqammDlzJp49e4bZs2cjMTERf/zxB6pUqYK9e/cWc/alw/fffy83duvWrTy/h9kp6sT09vYuVWcqFvW2r1I9e/aUG0tOTsaFCxcKHPPdu3dyY82aNStwPCIiIiIiIiIiIiIiotJCpQuV6enpaNOmDf7++2+xOCmRSMRHfujo6GDSpEm4fv06qlWrhtevX6NHjx4YM2YMMjMzi+kOSocff/wRhoaGMmPx8fG4fPlyvmNdvHhRbmz06NEFTa1YZC9UVq5cGbVq1SqSuN999x10dXXlxg8fPlzgmA8fPpR57ujoiBYtWhQ4HhERERERERERERERUWmh0oXKoUOH4sSJEzIFyvx0Uyri4uICf39/uLi4QBAELF68GF27di3Txcry5cvjxx9/lBvfv39/vuLcuHEDb9++lRmrXbs2WrZsWaj8ilJQUJBM8a8otn2VMjMzQ//+/eXG//333wKdfRoeHo6IiAiZsWHDhik8C5OIiIiIiIiIiIiIiEjVqGzFY9euXdiwYYNc92RBuilzMjU1xZYtW6Curg5BEHDw4EEMGTKksCmXaqNHj4aenp7MWH4Llfv27ZMb++OPPwqVV1HLue1rURYqAeC3336DgYGBzNjbt2+xe/fufMfKufWwjY0Nhg0bVqj8iIiIiIiIiIiIiIiISguVLFSmp6fj999/lxvPfj5lYboqAaBevXro0KGDGHfDhg35LtypEisrK0ydOlVm7MmTJ/jvv//ydH1ycjLWrl0rM9a1a1e0adMmzzn4+fmhZs2a0NbWhoODA/78888i72TNXqh0cXFBzZo1izS+tbW1wuLs9OnTkZaWluc4GRkZ8PX1lRn7559/5IqgREREREREREREREREqkolC5UnTpzAkydPxM5JQRBQpUoVbNy4EQ8ePEB8fHy+ikK56d27NwCIW8qOHTu2SOKWVr/88gvq1asnMzZr1qw8XbtgwQJERkaKzy0sLLBkyZI8r71792507twZd+7cQWpqKkJDQ/Hbb7/h559/znOMz3n48CHu378vPi/qbkqpUaNG4dtvv5UZe/z4MWbMmJHnGH/99RcePHggPu/SpQu6detWZDkSEREREREREREREREpm0oWKo8ePSrzfMSIEbh9+zb69u2LKlWqwMDAAOrq6oVep379+jLPX758iePHjxc6bmmlqamJXbt2wdjYWBw7ffo0Nm3a9Mnrzp8/L9NFqKOjAz8/P1hbW+d57WnTpikcX7Fihdy5lwWVc/vVHj16FEncnCQSCbZu3YrKlSvLjM+dOzdPXblHjx6VeT+qVauGjRs3FnWaRERERERERERERERESqWShcpLly6JP/fs2RNLly6FlpZWka9jbm4uN1aWt38FAEdHRxw5cgT6+vri2NChQ3O97507d6Jt27ZISUkBABgYGGD//v3w9PTM17pPnjxROJ6ZmYlnz57lK1Zusm/76urqCnd39yKJq4iJiQnOnDkDBwcHcSwjIwM+Pj65Fn4FQcDKlSvRpUsXpKamAgCqVKmCM2fOcMtXIiIiIiIiIiIiIiIqczSUnUBBREREAABMTU2xevXqYlvnw4cPMs8FQcCNGzeKbb3SwtPTE2fOnEGnTp3w5s0bpKSkoEuXLujUqRO6desGa2trvHjxAps3b8a5c+fE66pUqYJdu3YVqABYuXJlBAcHy42rqamhUqVKhbkdAEBISAju3r0rPi+ubV+zs7OzQ2BgILp06YIrV64AAFJSUtCvXz+sXLkSPj4+qFq1KjIyMvDgwQNs2bIFt2/fFq9v27Yttm7digoVKhR7rkRERERERERERERERCVNJQuVMTExkEgk6Nu3r0znX1ELCwsTf5aeU/nmzZtiW680+eqrr3Dr1i388ssv2L59OwDAz88Pfn5+cnMNDQ0xZswYTJo0Cdra2gVab8aMGQqLh8OHD4eFhUWBYmZXUtu+5mRtbY3//vsPc+fOxcKFC5GQkAAAuHLlili8zMnZ2RkzZszAd999VyI5EhERERERERERERERKYNKbv0q3ea1cePGxbqOv7+/3Ni7d++Kdc3SxMLCAv/++y+Cg4Mxfvx41K1bF0ZGRtDU1ISVlRVat26NZcuWISwsDNOmTStwkRIAunXrhv3798PDwwOampqws7PD7NmzsXjx4iK5l+zbvlatWhVubm5FEjcvtLW1MW3aNDx//hyrVq1Cx44dUalSJejr60NTUxMmJib46quvMGLECJw4cQKPHj1ikZKIiIiIiIiIiIiIiMo8iSAIgrKTyK/KlSvj2bNnOHPmDJo2bZrrPDU1NUgkEgQEBKBhw4b5Xqd27dq4ffs2JBIJgKytXytUqIDY2NiCpk6ksqKiouTObY2MjISZmZmSMiIiIiIiIiIiIiIiosJQ9nf/KtlRWa1aNQDA69evi22NXbt2yRUpARTJeYlEREREREREREREREREXzqVLFQ2bdoUgiDg7NmzxRI/MjISP/30k1iklJJIJPD09CyWNYmIiIiIiIiIiIiIiIi+JCpZqOzWrRvU1NSwc+dOREREFGns6OhoeHt7Izo6GsD/OimlOnfuXKTrEREREREREREREREREX2JVLJQaWdnh86dO+Pjx48YOnRokcV98uQJmjVrhnv37kEikUAQBJn/dXV1RfPmzYtsPSIiIiIiIiIiIiIiIqIvlUoWKgHgzz//hI6ODg4fPowhQ4YgMzOzwLEEQcDChQtRs2ZN3L9/P9d5c+fOLfAaRERERERERERERERERPQ/KluorFy5MubOnQtBELBu3To0btwYV65cyVeMV69eYebMmXB0dMT48eORmJgo10Up/d++ffuiffv2xXQ3RERERERERERERERERF8WDWUnUBijRo1CcHAwVq9ejcuXL6Nhw4aoXr062rVrh+rVq4vzrl27hoiICMTHxyMqKgq3bt3C1atX8eLFCwD/O4dSIpGIz6U/A0DDhg3h6+tbcjdGREREREREREREREREVMZJBGmVToWNHTsWixYtAgCZAmPOAmR22W9b0evSOd7e3ti7dy/09fWLMmUilRMVFQVzc3OZscjISJiZmSkpIyIiIiIiIiIiIiIiKgxlf/evslu/ZrdgwQIcOnQIZmZmYgFS2hUp3b4150P6Wm5FTHV1dcyZMwfHjx9nkZKIiIiIiIiIiIiIiIioiJWJQiUAtG3bFvfv38dvv/0GU1NTALIdlTkfOUkLmGpqaujZsyeuXbuGiRMn5tptSUREREREREREREREREQFVya2fs0pJSUFe/bswZkzZxAYGIjHjx9/cr6+vj4aNGgALy8vfP/997C3ty+hTIlUh6L27+DgYPEPAz6HW8QSEREREREREREREZWcqKioz86Jjo5GtWrVZMZKcuvXMlmozCk2Nhbh4eGIi4tDXFwcEhMTYWhoCGNjY5iamsLZ2RlqamWmuZSoWCgqVObHF/BPDRERERERERERERFRqVHQXUNLslCpUSKrKJmxsTGMjY2VnQYRERERERERERERERER/T+2ERIRERERERERERERERFRiWOhkoiIiIiIiIiIiIiIiIhKnEpv/dquXTtcu3YNDRs2xP79+4t9vYiICBw8eBAPHjxARkYG7Ozs4OXlhfr16xf72kSlUXBwMExNTZWdBhERERERERERERER5RAZGfnZOdHR0ahWrVoJZKOYShcqT5w4gYyMDJw+fbpY1xEEAVOnTsWCBQuQkpIi97qLiwvmz5+P9u3bF2seRKWNqalpiR2oS0REREREREREREREeacK39+r9NavGRkZMv9bXHr37o0///wTycnJEAQBgiDA3t4etWvXhr6+Ph49eoROnTqhT58+SEtLK9ZciIiIiIiIiIiIiIiIiMoClS5UloQlS5Zgx44d4nOJRIKVK1fi+fPnuHbtGiIjI7F06VLo6upi+/btaN26NT58+KDEjImIiIiIiIiIiIiIiIhKP4kgCIKykygoNbWsOquOjg4SExMBAJcuXYK/vz/u37+PuLg46OrqwsbGBl5eXmjbti10dXXzHD85ORnW1taIj4+HIAiQSCRo0aIFTpw4ITf3zp07aNasGd69e4eWLVviyJEjYn5EZUFUVBTMzc1lxiIjI1WidZyIiIiIiIiIiIiIiOQp+7t/lT6jEsjqcASA8+fPY+TIkQgKClI4b/ny5dDX18fvv/+OX375BRoan7/1AwcO4N27d+IaANChQweFcz08PODn54dvvvkGJ0+exOTJkzF37twC3BERERERERERERERERFR2VcmWv5SUlLQrFkz3Lt3TzxDUtHj/fv3mDRpEho3bozY2NjPxj1//rzcWI0aNXKd37hxYwwZMgSCIGDBggW4fPlyoe6LiIiIiIiIiIiIiIiIqKwqE4VKQRCQmZkJIKvD8lMPQRBw5coVfP3113j37t0n496/f19uzMbG5pPXTJ06FWpqasjMzMQvv/xS4HsiIiIiIiIiIiIiIiIiKstUtlD5/v178efshcjPkc559OgRBgwY8Mm5kZGRcjFNTEw+eY2lpSWaNGkCQRBw9epVhedZEhEREREREREREREREX3pVLZQ+ffffysc/9TWr9KHtLPywIED2LNnT65rZC+GSunq6n42t5YtW4o/L1++PA93Q0RERERERERERERERPRlUclCZXJyMv755x+x21FagHRxccGUKVNw4MABPH36FDExMUhLS0NCQgKePXsGPz8/9O/fHzo6OuJ18+fPz3WdxMREuTEtLa3P5ufm5ibGP3nyJBISEgpym0RERERERERERERERERllkoWKg8dOiR2OwqCADc3N5w9exYPHjzAjBkz0L59e1SsWBFGRkZQV1eHvr4+HB0d0aFDB6xbtw53796Fh4cHAODGjRu4d++ewnVSU1PlxvKyvayrq6s4Ny0tDSdPnizorRIRERERERERERERERGVSSpZqDx16pT4c//+/XHz5k00bdo0z9c7OTnh5MmTsLS0BACcO3dO4by0tDSZ52pqeXu7KlSoIPP8ypUrec6NiIiIiIiIiIiIiIiI6EugkoXKmzdvQiKRoEmTJli3bh00NDTyHcPMzAy//vorBEHItZCYkZEh81xdXT1PsfX19WWe3717N9/5EREREREREREREREREZVlKlmoDA8PBwDMnj27UHE6dOgAAHj79q3C1zMzM2We57UgqqmpKf4sCAJevHhRsASJiIiIiIiIiIiIiIiIyiiVLFS+e/cOBgYGaNCgQaHiWFtbAwBiY2MVvi4IgsxzbW3tPMVNTEyUeR4VFVWA7IiIiIiIiIiIiIiIiIjKLpUsVGppacHU1LTQcd69ewcg72dP6urq5mnex48fZZ7nLFwSERERERERERERERERfelUslBpampaJF2K/v7+ALLOq8wpZzclAJQrVy5PcXPbSpaIiIiIiIiIiIiIiIiIsqhkodLOzg4fPnxAQEBAgWNkZGRg7ty5kEgkqFixotzr6enp4s/SomX58uXzFPvRo0cyz/N6HREREREREREREREREdGXQiULlU2bNoUgCJg4cSIyMjIKFGPw4MG4ffs2AMDLy0vu9ZzbtUokEhgZGeUp9oMHD2Ses1BJREREREREREREREREJEslC5WtWrUCAFy5cgW9evWSOxPyU+7fv4+GDRti06ZN4pidnZ3cvNevX8uNKdoiVpHTp0+LP0skEoXxiYiIiIiIiIiIiIiIiL5kKlmobNiwIerWrQsA2LdvH6pVq4b58+fj/v37yMzMlJmbmZmJe/fuYd26dWjRogU8PDxw5coVCIIAiUQCQRDQs2dPPHz4UOY66fmV2dna2n42t7i4OFy6dEmMDQC1atUq6K0SERERERERERERERERlUkqWagEgBkzZoiFwLCwMPz6669wd3dHuXLlYGFhAXt7exgZGUFLSws1a9bEkCFD4O/vL1fInDlzJhITE1GvXj0sWLAAb968wdWrVzFnzhxIJBKZuW/evPlsXitWrJDbjrZOnTqFvFsiIiIiIiIiIiIiIiKiskUiSKt9KmjUqFFYtmyZTPfi52QvPjZr1gynTp2Cv78/WrdujbS0NPG17PGk8SUSCTp37oyNGzdCX19fLnZcXBwqV66MuLg4MYampiZevXoFU1PTgt4mUakQFRUFc3NzmbHIyMg8b4lMRERERERERERERESli7K/+1fZjkoAWLhwIVq1aiUWEfPyALIKiI6Ojti2bRsA4JtvvsH27duhrq4OQRDEImX2ombVqlXRu3dv7Nu3D9WrV4efn59MLqmpqejduzdiY2PFNSQSCVq0aMEiJREREREREREREREREVEOGspOoDA0NDRw+PBhDBkyBBs2bJDbqlURQRBQo0YNHDp0SKZC3LlzZ+zduxc+Pj5ITEyUiaWpqYmNGzeiXr16MDAwwMqVK9G1a1c4OTnB29sbhoaG2L9/P0JCQuRyGDhwYNHdMBEREREREREREREREVEZodJbv2Z39OhRjB07Fo8ePcp1joGBAcaMGYNJkyZBW1tb4ZxHjx5h/PjxOHz4MACgXLlyWLt2LXr16iXO+e233+TOsMzehSntpqxXrx4uX75cFLdHpHTKbv8mIiIiIiIiIiIiIqKipezv/stMoVLq+vXrOHz4MJ49e4bIyEhoaWmhYsWKaNSoEdq1a4dy5crlKc7r168REhKC6tWrK9y6denSpRg7diwyMjLEwqSUIAhQU1PDf//9h0aNGhXZvREpk7L/sSIiIiIiIiIiIiIioqKl7O/+y1yhsiQFBgaiT58+ePHihVyhcurUqZg+fbrykiMqYsr+x4qIiIiIiIiIiIiIiIqWsr/7VyuRVcqohg0bIigoCBMmTICBgQEEQYCOjg7mzJnDIiURERERERERERERERHRJ7CjsoikpqbixYsXsLW1zfP2skSqRNl/VUFEREREREREREREREVL2d/9a5TIKl8ALS0tuLi4KDsNIiIiIiIiIiIiIiIiIpXArV9zce3aNXTt2hXLly9XdipEREREREREREREREREZQ47KnNRr1491KtXDyNHjsTt27exevVqSCQSZadFVKpER0fneS63iCUiIiIiIiIiIiIiKjlRUVGfnZOf7/mLAwuVnzBp0iS8efMGy5YtQ1JSErZu3arslIhKlWrVquV5Lo/DJSIiIiIiIiIiIiIqOTnPniyNuPXrZ/z+++8QBAHbt2/H9OnTlZ0OERERERERERERERERUZnAQuVn3Lp1C0BWN9js2bNx9+5dJWdEREREREREREREREREpPrKxNavqampuHjxIoKDgxEREYH4+HikpqYiLS0tX9tNCoKAjIwMpKam4uPHj3j58iWCg4MhkUggCAIyMzPx119/YcuWLcV4N0RERERERERERERERERln8oXKpcvX46ZM2cWy2Gf0iKnRCIRi5WnTp0q8nWIVFVwcDBMTU2VnQYREREREREREREREeUQGRn52TnR0dGoVq1aCWSjmEoXKn/44Qds3bo1X12T+SWRSGSex8fHF9taRKrG1NQUZmZmyk6DiIiIiIiIiIiIiIhyUIXv71W2ULl8+XJxC9acxcTiIpFIULt27RJZi4iIiIiIiIiIiIiIiKgsU8lCZVpaGmbNmpVrgTJ7h6V0y9b8UnSdnp4eFixYkO9YRERERERERERERERERCRLJQuVR44cwdu3b8VCZfaCopGREWxsbKCnpwcdHR08efIEr1+/hqOjI+zt7fO8xuXLl5GamgoPDw84OzujVq1a+P7772Fra1vk90NERERERERERERERET0pVHJQuXJkyfFnwVBgLu7O0aPHo02bdrA3NxcZu6ePXvQo0cPuLi44NixY3le46+//sLEiRNhZGSEXbt2FVnuRERERERERERERERERASoKTuBgrhz5474c//+/XHz5k3069dPrkgJAB07doSJiQlOnTqFly9f5nmNcePGoX79+jh37hxmzpxZJHkTERERERERERERERERURaVLFQ+e/YMEokETk5O8PX1hZpa7rehqamJ3r17IzMzE6tWrcrzGhKJBAsXLoQgCPjjjz8QGBhYFKkTEREREREREREREREREVS0UJmQkAAA+OGHH6Ch8fndawcPHgwAWLduHVJSUvK8ToMGDdC6dWtkZGSgT58++PDhQ8ESJiIiIiIiIiIiIiIiIiIZKlmoTEtLAwDUrFkzT/OrV6+Ohg0bIiYmBps3b87XWv379wcAvHz5EuPHj8/XtURERERERERERERERESkmEoWKsuXLw8A0NPTy/M1I0aMgCAI+Ouvv5CZmZnn6xo1agQAEAQBa9asQXBwcP6SJSIiIiIiIiIiIiIiIiI5KlmoNDIyAgCEhobm+Zru3bvD2toaT58+xYoVK/J8nbGxMYCsMysFQcC2bdvylywRERERERERERERERERyVHJQmX16tUhCAJ2796d52s0NDQwcuRICIKAKVOmICwsLE/X3b59W/xZEAScOHEiv+kSERERERERERERERERUQ4qWaj86quvAABHjx7FunXr8nzd8OHDUaFCBSQkJKB79+5ISkr67DV//PGHzPP8dHESERERERERERERERERkWIqWajs0qWL+PPQoUPRv39/HD58GOfPn0dAQAAePnyIjIwMuesMDAwwZswYCIKAa9euoVWrVoiMjFS4RmZmJkaOHImjR49CIpGI4+/fvy/6GyIiIiIiIiIiIiIiIiL6wkgEQRCUnURBNG/eHP7+/gAgU0iUcnBwwL///gtPT0+Z8cTERFSpUgWvX78GAJQvXx7Dhw9H69atYWVlhXfv3uHy5ctYuXIlgoODIQiCGF8QBNjb2+PFixfFe3NEpVBUVBTMzc1lxiIjI2FmZqakjIiIiIiIiIiIiIiIqDCU/d2/yhYqg4KCULduXaSlpSG3W3B2dsbjx4/lxg8ePIhOnTpBIpHIFCKzk8bMXqSUSCTo3bs3Nm/eXIR3QqQalP2PFRERERERERERERERFS1lf/evklu/AoCbmxsWLlwoFhBzPgDg6dOnCs+h7NChA/r37y9eKwiC3AOA+Fp2Q4cOLf6bIyIiIiIiIiIiIiIiIirjVLZQCQDDhw/H4sWLoa6urrCr0sXFBbq6ugqvXblyJRo1apRroTNnt6VEIsGgQYPQqFGjYr0nIiIiIiIiIiIiIiIioi+BShcqAWDkyJEIDAxE8+bNAUDsiKxcuTK2bduW63VaWlo4fvw4vL29c906Nnu3pY+PD1asWFEs90BERERERERERERERET0pVHZMyoViY2NxbNnz2BoaAhnZ2eoqf0fe3ce3lSZ/338k6UbpWVry1Y2kR2URRRUUAF3Nh11ZMZd0BF1dMZt9HEUR51x30UZ9xVGHQHXn4MIggIqu2wFQYRSoC1LW7onOc8fJ0mTNG3atE3a8n716tXk5M597hYo7fnk+71rlsPOmjVLzzzzjDIyMio9NnToUN111126+OKL63u5QJMS7T7VAAAAAAAAAACgfkX72n+zCirravPmzdq5c6fy8vLUtm1bHXfccerQoUO0lwU0CtH+ZgUAAAAAAAAAAOpXtK/92yNyliaiX79+6tevX7SXAQAAAAAAAAAAADR7TTaoLC4u1ssvv6xff/1Vo0aNojUrAAAAAAAAAAAA0IQ0yaCyoKBAo0eP1vr16yVJL774olasWKEnn3wyyisDAAAAAAAAAAAAUBPWaC8gHDNmzNC6detkGIb3/dlnn1VOTk60lwYAAAAAAAAAAACgBppkUPnf//5XFovF+y5JhmEoKysryisDAAAAAAAAAAAAUBNNMqjcu3dvpWMdO3bUwIEDo7AaAAAAAAAAAAAAALXVJIPKTp06eW8bhiGLxaKnnnpKNpstiqsCAAAAAAAAAAAAUFNNMqgcP368DMOQJFksFl122WW65JJLorwqAAAAAAAAAAAAADXVJIPKu+66Sy1btvSGlf/85z8b9Hzl5eWy2WzatGlTg54HAAAAAAAAAAAAOFo0yaAyPT1dL7/8siwWiyQpJyenQc+Xk5PjDUUBAAAAAAAAAAAA1F2TDCol6Q9/+IOee+45WSwW/eEPf9C+ffsa7FyLFy/2hqIAAAAAAAAAAAAA6q7JBpWSdOONN+qjjz5SVlaWTjjhBC1durTez1FeXq4nnnii3ucFAAAAAAAAAAAAjmb2aC+griZPnqx169Zp6tSpOuOMMzRt2jQ9+OCDSklJqfPc69at02233aa1a9dSUQkEkZubW+OxqampDbgSAAAAAAAAAADgqyZbJ9bmOn9DsBhNcPPFMWPGBD2+fPlylZWVKSkpSUOHDg1rbpfLpSNHjmjnzp06dOiQJMkwDFksFv3888/q379/2OsGmrKcnBylpaWF/fwm+K0GAAAAAAAAAIAmK9wivOzs7IgVHzXJisply5apvLw86GOGYSg/P1/ffvtt2PP7BipUUgIAAAAAAAAAAAD1r0nuUTl+/HhvmGgYht+7xWKRxWKpdLw275K88wAAAAAAAAAAAACof00yqLzyyiu9tz2BYmCwGHi8tu8AAAAAAAAAAAAAGk6TbP167rnnKjU1tdIGnw2xBx6hJVC1TZs2KSUlJdrLAAAAAAAAAAAAAbKzs0OOyc3NVf/+/SOwmuCaZFBpt9s1ZcoUPffcc942r0lJSRo0aJDatm2rhIQExcTEyGazhVUh6XQ6VVpaqj179mj58uUN9FkATV9KSkrENtQFAAAAAAAAAAA11xSu3zfJoFKSrrrqKj333HPe2y+99JLi4uLq/TwrV67UeeedpwMHDtT73AAAAAAAAAAAAMDRqknuUSlJgwcP1oABAyRJjz/+eIOElJJ0wgknaMaMGQ0yNwAAAAAAAAAAAHC0arJBpSRdeeWVkqT4+PgGPc+5557boPMDAAAAAAAAAAAAR5smHVRedtllslqt2rhxY4Oep2vXrjIMo0HPAQAAAAAAAAAAABxNmnRQ2aFDB82aNUsdO3Zs0PPYbDYtXrxYPXr0aNDzAAAAAAAAAAAAAEcLe7QXUFfXXHNNRM4zevToiJwHAAAAAAAAAAAAOBo06YrKmsjLy5PD4ah2TGlpaYRWAwAAAAAAAAAAAEBqZkFlSUmJ3n77bV1xxRXq3r27YmNj1a5dO/34449VPmfLli1q3bq1Bg4cqFtvvVXr16+P4IoBAAAAAAAAAACAo1OzCCqdTqcee+wxde/eXVdffbXee+897dq1Sw6HQ4ZhVPvcvn376vPPP9exxx6r5557TkOGDNHpp5+u1atXR2j1AAAAAAAAAAAAwNGnyQeV+/bt0+mnn667775b2dnZMgxDhmHIYrHUeI4xY8Zo3rx5+v777zVw4EAtWbJEJ554om6++WaVl5c34OoBAAAAAAAAAACAo1OTDir37dunESNGaNmyZd5w0vMejpEjR+rHH3/UlClT5HK5NHPmTI0ePVpZWVn1vHIAAAAAAAAAAADg6NZkg8qSkhJNnDhRu3btkqSww8lAcXFxeuedd3TuuefKMAz98MMPGjNmjHJzc+tlfgAAAAAAAAAAAABNOKh85plntHLlyqABpaf9a7isVqtee+01JSUlyWKxaOvWrTrvvPNoAwsAAAAAAAAAAADUkyYZVB4+fFiPPvqoX0jpCSfT0tI0ZMgQnXrqqXU6R4cOHXTllVd6A89Vq1bp6aefrtOcAAAAAAAAAAAAAExNMqj85JNPlJeX571vGIauuuoq7dy5U3v37tWqVau0ZMmSOp9n8uTJksy2soZh6OGHH9ahQ4fqPC8AAAAAAAAAAABwtGuSQeWXX34pyQworVarPvjgA73++uvq2rVrvZ7n+OOP97t/5MgRzZs3r17PAQAAAAAAAAAAAByNmmRQuX79eklmpeO//vUvXXTRRQ1ynlatWlU6Nn/+/AY5FwAAAAAAAAAAAHA0aZJBZXZ2tiwWi/r27avbb7+9wc6Tk5Pjve1p/5qRkdFg5wMAAAAAAAAAAACOFk0yqPTsT3nFFVc06Hl27txZ6djevXsb9JwAAAAAAAAAAADA0aBJBpWJiYmSpCFDhjToeT755JNKx4qLixv0nAAAAAAAAAAAAMDRoEkGlV26dJEkWa0Nt3yHw6F3331XFovF73ibNm0a7JwAAAAAAAAAAADA0aJJBpXHH3+8JGnHjh0Ndo6HHnpIe/bs8d43DEMWi0V9+vRpsHMCAAAAAAAAAAAAR4smGVSeeeaZMgxDn332WYPMv2LFCv3rX/+qVE0pSaeddlqDnBMAAAAAAAAAAAA4mjTJoPKCCy5QYmKivvjiC61evbpe5/7hhx907rnnyuFwSDIrKX1deuml9Xo+AAAAAAAAAAAA4GjUJIPKpKQk3XDDDXK5XPrjH/+o/Pz8epn3vffe09lnn628vDxJFe1ePR/POuss9e/fv17OBQAAAAAAAAAAABzNmmRQKUn33nuvOnXqpK1bt2rMmDHau3dv2HNt3bpVkyZN0hVXXKH8/Hxvy1ff1q+xsbF64okn6rxuAAAAAAAAAAAAAE04qExOTtY777wjm82mNWvWqH///nr00UeVk5NTo+fv3r1b7733nsaMGaN+/frps88+81ZOShUtXz3HHn30UQ0YMKDBPh8AAAAAAAAAAADgaGIxAjdhbGLefvttXXPNNd5g0WazadiwYRo4cKBee+01WSwWXX755UpOTlZeXp5ycnK0du1a7d+/3zuH57m+IaXv7T//+c965plnIvuJAY1MTk6O0tLS/I5lZ2crNTU1SisCAAAAAAAAAAB1Ee1r/00+qJSk+fPn69prr9XBgwclqVJVpG8LV9/jHlUFlDabTQ888IDuueeeBl0/0BRE+5sVAAAAAAAAAACoX9G+9t9kW7/6mjRpktauXavTTjtNkn9AabFYZBiG37vnuOfdwzek7Nq1qxYvXkxICQAAAAAAAAAAADSAZhFUSlJ6eroWLVqkBQsW6Pzzz/cLKKsKJj18Q8xevXrppZde0pYtW3TKKadE4TMBAAAAAAAAAAAAmj97tBdQ38aOHauxY8dq9+7dWrRokZYtW6bly5dr9+7dysvL82v7GhMTo3bt2mnw4MEaNWqURo8eTTgJ1EJubm6Nx9IiFgAAAAAAAACAyMnJyQk5pjbX+RtCs9ijsqYMw1BeXp6KioqUnJysli1bRntJQJMRrE91bRxF32oAAAAAAAAAAIi6YF1GayKSe1Q2u4rK6lgsFrVu3VqtW7eO9lIAAAAAAAAAAACAo1qz2aMSAAAAAAAAAAAAQNPRJIPK3bt3a8yYMSotLY32UgAAAAAAAAAAAACEoUm2fi0qKtK3336rjRs3aujQodFeDnDU2rRpk1JSUqK9DAAAAAAAAAAAECA7OzvkmNzcXPXv3z8CqwmuSQaVkmQYhp544gm9//770V4KcNRKSUmJ2Ia6AAAAAAAAAACg5prC9fsm2frV4z//+Y8uvPBC7du3L9pLAQAAAAAAAAAAAFALTTqolKT58+erV69euvXWW7V169ZoLwcAAAAAAAAAAABADTT5oNIwDBUWFur5559Xv379NG7cOH300UdyOp3RXhoAAAAAAAAAAACAKjTpoDIhIUFXXnmlzj77bCUkJMgwDH3zzTf6/e9/r/T0dN1777367bffor1MAAAAAAAAAAAAAAGadFD55ptv6o033tCXX36p7OxsvfPOOxo9erQMw9D+/fv1r3/9S8cee6wmTJigzz//XIZhRHvJAAAAAAAAAAAAANSEg0qLxaKzzjrLe79Fixb64x//qMWLF2vz5s269dZb1aZNGzmdTn3xxReaOHGievTooYcfflj79u2L4soBAAAAAAAAAAAANNmg0jAMJScnB32sT58+euqpp5SVlaV33nlHp556qgzD0K5du3TfffepW7duuvjii/X1119HeNUAAAAAAAAAAAAAJMliHCX9UDMyMvTyyy/rnXfe0cGDB2WxWCRJxx57rK6//npdddVVatu2bZRXCTReOTk5SktL8zuWnZ2t1NTUKK0IAAAAAAAAAADURbSv/TfZisra6tOnj55++mnt2bNHb7/9tk4++WQZhqFt27bpjjvuUHp6uq644gp9//330V4qAAAAAAAAAAAA0OwdNUGlR1xcnC677DItXbpUmzZt0p///Ge1adNGJSUleu+99zR69Ggdd9xxeumll1RQUBDt5QIAAAAAAAAAAADN0lEXVPrq27evnnnmGe3Zs0dvvfWWTjnlFBmGoQ0bNuimm25S586ddf3112v16tXRXioAAAAAAAAAAADQrBzVQaVHXFycLr/8cr344os644wzJEmGYejIkSN69dVXNXz4cJ144ol64403VFxcHOXVAgAAAAAAAAAAAE3fUR9UOhwOzZkzR6NHj9bgwYO1ePFiWSwW77thGDIMQ6tWrdLUqVPVuXPnaC8ZAAAAAAAAAAAAaPLs0V5AtOzevVsvv/yyXn/9dWVnZ0syqyh9ecJK38f69+8f2YU2IoZhaNeuXcrOzlZcXJy6d++u5OTkaC8LAAAAAAAAAAAATdBRV1H51VdfadKkSTrmmGP0yCOPaP/+/d6qSd9KSt+AskWLFpo2bZrWrFmj7777LsqfQeStX79e1157rdq3b6/u3bvrxBNP1PHHH6/WrVvrhBNO0HPPPaeioqJoL7NJGDduXKW/ZzV9t9ls2r59e7Q/BQAAAAAAAAAAgHrRJIPKffv26Zprrqnx+EOHDunJJ59Ur169dN555+mzzz6T0+msFE56eILL3r1769lnn9WePXs0a9YsHX/88Q3x6TRahw4d0tSpUzV48GC9/vrrysnJ8Xvc0xL3lltuUa9evfTZZ59FaaUVHnzwwbCDwJq8v/nmm2GvbeXKlVq4cGHYzz/33HPVs2fPsJ8PAAAAAAAAAADQmDTJoDIvL09vvfWWSktLqx33008/6eqrr1Z6erruvPNObd++vVL1pC/DMGSz2XThhRfq66+/1ubNm3XzzTcfle1NMzIyNHz4cL322mver9d1112nNWvWqLi4WAcOHNDcuXM1bNgwSVJWVpYmTpyoGTNmRG3NTqdTs2bNatBzdO3aNeznPvLII3U690033VSn5wMAAAAAAAAAADQmTXaPSsMw9NNPP+nUU0/1O15SUqL3339fL730klavXu0dK6lSMOn7WMeOHTV16lRdf/316tSpUwOvvnFbuXKlzjrrLB06dEiSFBsbq//85z+aPHmyd0x8fLwmT56s8ePH69JLL9V///tfGYahBx54QEeOHNETTzwR8XXPnz9fe/bsabD509LSdNppp4X13K1bt2ru3Llhn7tXr146++yzw34+AAAAAAAAAABAY9Nkg0pJuvbaa/XMM8+oR48e2rFjhz755BN9+OGHOnz4sDeAlKoPKE877TRNnz5dF1xwgez2Jv3lqBe7du3ShAkTvCGlJD3++ON+IaUvu92ud999Vxs3btSWLVskSU8++aS6dOmiW265JRJL9po5c2aDzn/hhRfKZrOF9dzHHntMLpcr7HPfdNNNQf8eAwAAAAAAAAAANFUWwzfRayIyMjLUr1+/agNIqeqAMikpSZdffrmmT5+u/v37N+hamxKHw6ETTzxRa9as8R4bPXq0Fi9eHDIkW7hwocaNG+e9b7fb9f333+vEE09ssPX62rp1q/r27auG/Ou8cOFCjRkzptbPy8rKUo8ePVRWVhbWeVu2bKk9e/ZEvQVxTk6O0tLS/I5lZ2crNTU1SisCAAAAAAAAAAB1Ee1r/01yj0pfnj0nA/ee9A3WPI8NGDBAM2fOVFZWll544QVCygCPPfaYX0gpSffdd1+NKvnGjh2rESNGeO87HA5ddtllKi4urvd1BjNz5kxvSNmiRQtdd911+vjjj7Vlyxbl5eWprKys0t+V6t5LS0vVqlUr7/zt27cPu+3rU0895Q0pFy5cWKt1GIahgoKCqIeUAAAAAAAAAAAA9a3J9zqtLkQzDEMxMTG68MILNX36dI0aNSqCK2tadu7cqQcffNDv2MCBAzV27Ngaz3HttddqxYoV3vvbtm3T008/rXvuuafe1hlMUVGR3nzzTUnSqFGj9Oabb+qYY46p05wLFixQXl6e9364bV8PHTqkf//735Kkk046KayKTAAAAAAAAAAAgOaoWVRUBt43DEOdO3fWP/7xD+3atUuzZ88mpAzhkUceUUlJid+xCy+8sFZzXHTRRZXCvEceeUQHDhyo8/qq89577ykvL08XXXSRvv766zqHlJL00Ucf+d2/5JJLwprnxRdfVEFBgSQ1eGALAAAAAAAAAADQlDT5oNJTUekJLMeNG6ePP/5YO3fu1L333qv27dtHc3lNQlZWlrci0deECRNqNU/r1q01bNgwv2MFBQXeisKG8tJLL+mUU07Re++9p9jY2DrPV15ervnz53vvd+jQQaNHj671PMXFxXruueckSYMGDar11xMAAAAAAAAAAKA5a/JBpae967Rp07R582b973//0+TJk2W1NvlPLWJeeeUVlZaW+h1LSEjQkCFDaj3XGWecUenYzJkz5XK5wl5fdZYvX65t27Zpzpw59RJSSuY+kocOHfLe/93vfhfW36fXXntNOTk5kqS//e1vNdrrEwAAAAAAAAAA4GjR5NO8fv36afXq1Zo1a5Z69+7doOd65513lJ+f36DniIY5c+ZUOjZo0KCw9mQcMWJEpWOZmZlaunRpWGsLpWPHjvrwww+Vnp5eb3PWR9tXh8OhJ598UpLUs2dP/f73v6+XtQEAAAAAAAAAADQXTTqobNu2rRYuXKj+/fs3+LmKi4t11VVXKTMzs8HPFUlr167Vli1bKh0/7rjjwpqvX79+QY8Hhn/1pXv37jrnnHPqbT6Hw6F58+Z573fs2FGnnnpqreeZM2eOdu7cKUnKzs7WxIkT9Y9//EP/+9//dPjw4fpZLAAAAAAAAAAAQBNmj/YC6uLuu+9Whw4dInKuLVu2ePfBbE7+7//+L+jxbt26hTXfscceq9jYWJWVlfkd/+abb8KaL9IWLVqkAwcOeO+H2/b1scce894uKCjQF198oS+++EKSZLPZdNZZZ+nqq6/WxIkTFRcXV/eFAwAAAAAAAAAANDFNuqLy3HPPjdi55s6d2yz3GFy2bFnQ4+G2UrXZbOratWul45s3b1Zubm5Yc0ZSfbR9/fzzz/Xzzz9X+bjT6dSXX36pSy65RJ06ddLf/va3ZtlSGAAAAAAAAAAAoDpNMqjs2LGj3njjDfXt2zci59u5c6eee+65iJwr0pYvXx70eF32fGzfvn2lY4ZhaO3atWHPGQlOp9Ov7WunTp3Cavv6yCOP1HjswYMH9eijj6pPnz568803m2XVLgAAAAAAAAAAQDBNMqhMTk7WlVdeGZEKx7Vr1+qMM85olhVve/bsqbLKsS5BZVpaWtDjmzZtCnvOSFiyZImys7O99y+66KJa/x1btmyZvvvuu1qfe9++fbr66qt1+umnN4nKUwAAAAAAAAAAgLpqkkFlJBw+fFh33nmnTjrpJO3atSvay2kQv/76a5WP1SWoTE1NDXp827ZtYc8ZCR9++KHf/XDavv7rX/+q0xqWLFmiESNGKCMjo07zAAAAAAAAAAAANHb2aC+gsdm/f79eeOEFvfjii8rLy5NhGM1yb0rJbGkbTGJiolq2bBn2vHFxcUGP79u3L+w5G5rL5dLcuXO999PT03XyySfXep5XX31VRUVFKikpUW5urjIzM/Xbb79p1apV+vHHH2sUem/fvl0jR47UZ599FtYaIqkhqz+rCrwBAAAAAAAAADja5OTkNMi80e7ySFDptmzZMr300kv66KOPVFZW5t0rsLmGlJKUmZkZ9HiLFi3qNG9VQeX+/fvrNG9D+u677/yC1HDavkrB9+f0tW7dOs2ePVuzZs3S4cOHqxx36NAhjR8/XsuWLYvYXqzh6N+/f4PNzX6dAAAAAAAAAACYqtp2r6k7qlu/FhUV6d///reGDBmiUaNG6f3331dpaam3irI5h5SSqtx3s6GCysa8z2d9tH2tieOPP16PPPKIdu7cqRkzZighIaHKsYcOHdLFF1+s4uLiBlkLAAAAAAAAAABANB2VQeXmzZt18803q1OnTrrhhhu0bt06GYZRKaD0HGuuioqKgh6vLjyrCZvNFvR4aWlpneZtKIZh6OOPP/be79Kli0aMGNGg52zVqpXuv/9+rVu3rtr2rhs2bNBDDz3UoGsBAAAAAAAAAACIhqMmqHQ6nfrwww91xhlnaODAgZo5c6by8/P9Wrz6BpSBx5qjqoLKulZUOp3OoMfLysrqNG9DWbZsmbKysrz3w237Go5evXrp22+/1ZVXXlnlmCeffFJ79uyJyHoAAAAAAAAAAAAipdnvUblnzx7NmjVLr776qnePxGD7T3qqKX2PN/d9KquqFq1rRaXL5Qp6vKqWsNEWqbavVbHb7XrzzTeVnJys559/vtLjpaWleu655/Too49GdF01sWnTJqWkpER7GQAAAAAAAAAANGvZ2dkNMm9ubq769+/fIHPXRLMNKhcsWKCZM2fq888/l9Pp9AvlggWPgeFknz59NHLkSCUnJ+t///uftmzZEpmFR1DLli0bZN6SkpKgx+taqdkQAtu+du3atcHbvlblmWee0Y4dO/T5559Xeuz999/XI4880uhC85SUFKWmpkZ7GQAAAAAAAAAANGvN9Vp8swoqDx8+rDfeeEMvv/yyfvnlF0mhqyd9x3Tq1ElXXXWVLr/8cvXp08f7eGlpqc477zwtXrw4Ap9F5CQlJQU9XlXQWFNV7UVZ10rNhvDDDz9o9+7d3vsXX3xx1NZitVr13nvvqW/fvtq3b5/fY5mZmdqwYYMGDRoUpdUBAAAAAAAAAADUr2axR+XKlSt1zTXXqHPnzrr99tu1bds2GYbhDSR9qyV9Q0pPQDlu3Dj997//1W+//aaHHnrIL6SUzJald999d2Q/qQhoqKDyyJEjQY+3bt26TvM2hI8++sjvfqTbvgZq1aqVnnnmmaCP/fjjj5FdDAAAAAAAAAAAQANqshWVpaWlev/99/XSSy9p1apVkkLvKekbULZp00ZXXXWVbrjhBh177LEhzzd06NB6Wnnj0aZNm6DH6xpU5ufnBz3erVu3Os3bEHyDyu7du+vEE0+M4mpMv//97/Xggw9q48aNfse3b98epRUBAAAAAAAAAADUvyYXVP7yyy966aWX9Oabb+rw4cNV7j1ZVXtXi8Wihx56SH/9618VHx9f4/O2bdvW71zNQWDlqEdVFZE1dfjw4aDHu3btWqd569tPP/2k3377zXs/mm1fA91000264YYb/I4dPHgwSqsBAAAAAAAAAACof02i9athGJo3b57OOuss9e3bV88884wOHTrkFz4GVlH6Vk+2aNFC1113nfex008/vVYhpYfL5VL//v3r8Jk0LgMGDAh6PCcnRw6HI+x5c3Jygh7v3r172HM2hMbW9tXXxIkTKx1zuVxRWAkAAAAAAAAAAEDDaNRB5f79+/Xggw+qW7du+t3vfqeFCxfK5XL57T1psVgqVTp69qLs3bu3nn32We3Zs0cvv/xylD6Lxqtt27bq0KFDpeMul0t79+4Ne979+/cHPT5s2LCw52wIvkFljx49dMIJJ0RxNf46deqknj17+h2rak9RAAAAAAAAAACApqhRtn799ttvNXPmTM2bN08OhyNke1ff6kmbzaaJEyfqxhtv1JgxYyK+9qbm+OOP1759+yodz8zMVJcuXWo9X0lJiXJzcysdT01NrRS8RdPq1au1Y8cO7/3G1PbVo0ePHn77Uja21rkAAAAAAAAAAAB10WiCyoKCAr311lt66aWXtGXLFkn++0oG41tN2aFDB02bNk3XX3+9OnXqFJlFNwPnnnuuvvrqq0rHf/31V40cObLW8+3cuTPo8REjRtR6robUmNu+eqSkpPjdHzhwYJRWAgAAAAAAAAAAUP+i3vp13bp1+tOf/qTOnTvrlltu0ebNm72tWwOrJX15xowaNUpz5szRrl279MADDxBS1lKwvRAls+IwHNu2bQt6fMKECWHN11B8g8qePXs2ura0klRcXOy9HR8fr5NPPjmKqwEAAAAAAAAAAKhfUauo3Lx5s6ZOnaoVK1ZIUq3au7Zs2VKXXXaZbrzxRg0YMCCyC29mevTooQEDBmjjxo1+x1etWhXWfOvXr690zG6368ILLwxrvoawbt06v0C1MbZ9lfz3+jzvvPOUkJAQxdUAAAAAAAAAAADUr6hVVGZnZ2v16tWVqic97Vx9j3tu9+vXTy+88IKysrI0c+ZMQsp6cvnll1c6tmbNmkpVrDURrBLzzDPPVLt27cJaW0NoCm1fS0pKtG7dOu/96dOnR3E1AAAAAAAAAAAA9S9qQeVpp52m3bt366GHHlKXLl28YaQkvwpKSbrooou0aNEibdiwQdOnT1fLli2jtexm6U9/+pOSk5P9juXl5XmrXWvj+++/r3Ts1ltvDXdpDcI3qOzVq5eGDBkSxdUEt2jRIm/r17POOktjx46N8ooAAAAAAAAAAADqV1T3qExJSdE999yjX3/9VR9++KFOP/30SoGlJG3cuFGbN29WUVFRNJfbbLVq1Up/+tOfKh2fO3dureZZtWqVX7tSSRo6dKjOOuusOq2vPm3YsEFbtmzx3m+sbV8fe+wxSWbb3KeffjrKqwEAAAAAAAAAAKh/UQ0qPaxWq373u9/pm2++0c8//6zrrrtOLVq08AaWW7Zs0Y033qjOnTvrtttu044dO6K84ubn1ltvVWJiot+x2gaVH3/8caVjDz74YJ3WVd8C2742xqBy/vz5Wrx4sSTpr3/9q/r37x/dBQEAAAAAAAAAADSARhFU+howYIBefvll7dmzR0899ZR69uzprbLMy8vTM888o969e2vixIlasGBBtJfbbHTs2FH33Xef37FffvlF3377bY2eX1JSoldffdXv2O9+9zudd955NV7DvHnzNHjwYMXFxalbt2765z//KZfLVePn14RvUNm7d28NHjy43uZ2uVxatGiR5syZo61bt4Y1x9atW3XllVdKks477zz985//rLf1AQAAAAAAAAAANCaNLqj0SE5O1q233qqtW7fq888/13nnnSer1SrDMORyufT555/rnHPOUd++ffXiiy+qsLAw2ktu8v7yl79o+PDhfsceeuihGj33ySefVHZ2tvd++/bt9dxzz9X43B9++KEuuOACrVu3TmVlZdq1a5f+3//7f7rllltqPEcoW7Zs0caNG73367Oasri4WKNGjdKYMWM0ZcoU9e3bV5dffrkOHDhQ4zk2bNigM888U3l5eTr++OM1Z84c2Wy2elsjAAAAAAAAAABAY9Jog0pf5557rj777DNt3bpVt956q1q3bu2tsty2bZv+/Oc/q3Pnzrr11lu1bdu2aC+3yYqJidEHH3ygtm3beo99/fXXeuutt6p93pIlS/xavMbHx2vevHnq1KlTjc99//33Bz0+c+bMSvtehuvDDz/0u3/JJZfUy7yS2SZ32bJl3vuGYejdd9/VgAED9MEHH1T7XJfLpddff12nnnqqdu3apbPPPlvffvutkpKS6m19AAAAAAAAAAAAjU2TCCo9jjnmGD311FPas2ePXn75ZQ0aNMgbWObn5+v5559Xv379dP755+v//u//or3cJql79+76/PPP1bJlS++x66+/vsr9Kv/zn//o/PPPV2lpqSQpKSlJc+fO1YgRI2p13l9++SXocZfLVW97kvq2fe3bt6+OO+64eplXkhISEoIe379/v37/+9/rxBNP1Kuvvqrt27ertLRUhw4d0vr16/X4449r8ODBuvbaa5Wfn6+//OUv+vzzz9WqVat6WxsAAAAAAAAAAEBjZDEMw4j2IupiyZIlev755zV//nw5HA5JksVikST17NlTN998s6666iolJSXJarXKYrFo6dKlOvnkk6O57Ebvxx9/1OTJk7V3717vscmTJ+uiiy5Sp06dtHPnTr399ttavHix9/E+ffrogw8+CCsAHDBggDZt2lTpuNVqVVZWltq3bx/W5+Gxbds29e7d23v/73//u/7xj3/UaU5f5eXlGj58uNatWxfW84cPH64XX3yxUuvdxiQnJ0dpaWl+x7Kzs5WamhqlFQEAAAAAAAAAgLqI9rX/JlVRGczo0aP14YcfaufOnbrnnnuUlpbmrbLcvn27br31VnXu3Fk33XRTnc81Z84c5efn18OqG78TTzxRa9as0ZQpU7zH5s2bp8suu0xjxozRNddc4w0pk5OTNWPGDK1bty7sKsUHHngg6PHp06fXOaSUGrbtq2S2zf3qq6902mmn1ep5nr+/P/zwQ6MOKQEAAAAAAAAAAOpbk6+oDFReXq7//Oc/euGFF/Tjjz96j1ssFhmGIYvFoldeeUXXXHNNreZ1Op2Kj4/XunXr1L9///pedqO2efNmvfHGG1q0aJG2b9+uI0eOKCUlRYMHD9b555+vyy+/XMnJyXU+z7x58zRjxgxt2rRJHTp00J/+9Cf97W9/k9Va9zx96NChWrNmjSSpX79+Qas368tXX32ljz/+WKtWrdLOnTtVUFAgwzCUnJyszp07a+DAgTrllFM0fvx4de3atcHWUd+i/aoKAAAAAAAAAABQv6J97b/ZBZW+Vq1apeeee04ffPCBSktLvS1hJTOsuummm3T55ZcrMTEx5Fy//PKLevfurQ0bNhx1QSUgRf+bFQAAAAAAAAAAqF/Rvvbf5Fu/VmfYsGF66623tHv3bj300ENKT0/3toXdvHmzbrzxRnXu3Fm33nqrtm7dWu1cy5cv9ws6AQAAAAAAAAAAAISvWQeVHikpKbrnnnv066+/6qOPPtLpp5/uDSzz8/P1/PPPq3///jrnnHP06aefyuVy+T3f6XRq1qxZUVo9AAAAAAAAAAAA0Pw069av1dm0aZOef/55vfvuuyosLJQkb8Vk+/btNWnSJJ166qmy2+165ZVX9M0338hisejnn3+m9SuOStEu/wYAAAAAAAAAAPUr2tf+j9qg0iM/P1+vv/66XnrpJW3btk2SgrZ4NQyDoBJHtWh/swIAAAAAAAAAAPUr2tf+j4rWr9VJTk7WrbfeqoyMDH3++ecaO3asty2s5x0AAAAAAAAAAABA/Trqg0pf5557rhYsWKA1a9ZowoQJkoJXVwIAAAAAAAAAAACoG4LKII4//njNnz9fS5YsUe/evamqBAAAAAAAAAAAAOoZQWU1Tj31VK1du1YXX3xxtJcCAAAAAAAAAAAANCsElSHExcVp9uzZOu6446K9FAAAAAAAAAAAAKDZIKisAavVqhtuuCHaywAAAAAAAAAAAACaDXu0F9BUnH322exVCQTIzc2t8djU1NQGXAkAAAAAAAAAAPCVk5MTckxtrvM3BILKGurevbsefPBBpaWlRXspQKPRv3//Go8l6AcAAAAAAAAAIHKaQqZlMUgPANRATk5Onb6p8a0GAAAAAAAAAIDIsVgsYT0vOzs7Yl0S2aMSAAAAAAAAAAAAQMQRVAIAAAAAAAAAAACIOPaoBBC2TZs2KSUlJdrLAAAAAAAAAAAAAbKzs0OOyc3NVf/+/SOwmuAIKgGELSUlJWJ9qgEAAAAAAAAAQM01hev3tH4FAAAAAAAAAAAAEHEElQAAAAAAAAAAAAAijqASAAAAAAAAAAAAQMQRVAIAAAAAAAAAAACIOIJKAAAAAAAAAAAAABFHUAkAAAAAAAAAAAAg4ggqAQAAAAAAAAAAAEQcQSUAAAAAAAAAAACAiCOoBAAAAAAAAAAAABBxBJUAAAAAAAAAAAAAIo6gEgAAAAAAAAAAAEDEEVQCAAAAAAAAAAAAiDiCSgAAAAAAAAAAAAARR1AJAAAAAAAAAAAAIOIIKgEAAAAAAAAAAABEHEElAAAAAAAAAAAAgIgjqAQAAAAAAAAAAAAQcQSVAAAAAAAAAAAAACKOoBIAAAAAAAAAAABAxBFUAgAAAAAAAAAAAIg4gkoAAAAAAAAAAAAAEUdQCQAAAAAAAAAAACDiCCoBAAAAAAAAAAAARBxBJQAAAAAAAAAAAICII6gEAAAAAAAAAAAAEHEElQAAAAAAAAAAAAAijqASAAAAAAAAAAAAQMQRVAIAAAAAAAAAAACIOIJKAAAAAAAAAAAAABFHUAkAAAAAAAAAAAAg4ggqAQAAAAAAAAAAAEScPdoLANB05ebm1nhsampqA64EAAAAAAAAAAD4ysnJCTmmNtf5GwJBJYCw9e/fv8ZjDcNowJUAAAAAAAAAAABfaWlp0V5CSLR+BQAAAAAAAAAAABBxBJUAAAAAAAAAAAAAIo6gEgAAAAAAAAAAAEDEsUclgLBt2rRJKSkp0V4GAAAAAAAAAAAIkJ2dHXJMbm6u+vfvH4HVBEdQCSBsKSkpSk1NjfYyAAAAAAAAAABAgKZw/Z7WrwAAAAAAAAAAAAAijqASAAAAAAAAAAAAQMQRVAIAAAAAAAAAAACIOIJKAAAAAAAAAAAAABFHUAkAAAAAAAAAAAAg4ggqAQAAAAAAAAAAAEQcQSUAAAAAAAAAAACAiCOoBAAAAAAAAAAAABBxBJUAAAAAAAAAAAAAIo6gEgAAAAAAAAAAAEDEEVQCAAAAAAAAAAAAiDiCSgAAAAAAAAAAAAARR1AJAAAAAAAAAAAAIOIIKgEAAAAAAAAAAABEHEElAAAAAAAAAAAAgIgjqAQAAAAAAAAAAAAQcQSVAAAAAAAAAAAAACKOoBIAAAAAAAAAAABAxBFUAgAAAAAAAAAAAIg4gkoAAAAAAAAAAAAAEUdQCQAAAAAAAAAAACDiCCoBAAAAAAAAAAAARBxBJQAAAAAAAAAAAICII6gEAAAAAAAAAAAAEHEElQAAAAAAAAAAAAAijqASAAAAAAAAAAAAQMQRVAIAAAAAAAAAAACIOIJKAAAAAAAAAAAAABFHUAkAAAAAAAAAAAAg4ggqAQAAAAAAAAAAAEScPdoLAAAAAAAAAICj0d6Cvco4kKH80nyVOcsUa4tVclyy+rTro45JHaO9PAAAGhxBJQAAAAAAAABEQGZ+pmb/PFtLdy3Vqr2rlFWQVeXYTkmdNKzjMI3qOkpTBk1RenJ6BFcKAEBkWAzDMKK9CACNX05OjtLS0vyObdq0SSkpKTV6fmpqakMsCwAAAAAAoFEzDENf7/haM1fO1CcZn8hluGo9h81i08Q+EzV9+HSN7TFWFoulAVYKAGhucnJyQo7Jzc1V//79/Y5lZ2dH7Jo+QSWAGgkWVNYG32oAAAAAAMDRZkP2Bk37dJpWZK6otzlHpI/QKxNe0cC0gfU2JwCgeQr3hS2RDCqtETkLAAAAAAAAABwlHC6HHl7ysIbOGlqvIaUkrchcoaGzhurhJQ/L4XLU69wAAEQaFZUAaoSKSgAAAAAAgNByCnM0ac4kLc9c3uDnGpk+UvMvna/URLbcAQBURkUlAAAAAAAAABwlMvMzNeqNUREJKSVpeeZyjX5ztDLzMyNyPgAA6ps92gsA0HRt2rRJKSkp0V4GAAAAAABA1GUXZmvc2+OUcSAjoufdkrtF494ep6VXL6WyEgDgJzs7O+SY3Nxc9e/fPwKrCY6gEkDYUlJSIlb+DQAAAAAA0FiVO8s1ec7kiIeUHhkHMjRpziQtuXqJ7FYu+QIATE3h+j3/awEAAAAAAABAHTz2/WMRa/daleWZy/XY94/pnlH3RHUdANBY7S3Yq4wDGcovzVeZs0yxtlglxyWrT7s+6pjUMdrLO2oRVAIAAAAAAABAmDZkb9AD3z4Q7WVIkmYsnqGJfSZqYNrAaC8FAKIuMz9Ts3+eraW7lmrV3lXKKsiqcmynpE4a1nGYRnUdpSmDpig9OT2CKz26WQzDMKK9CACNX05OjtLS0vyOZWdnN4nScQAAAAAAgIZgGIZGvjZSP2z9IdpLMSVKI9JHaNk1y2SxWKK9GgCIOMMw9PWOrzVz5Ux9kvGJXIar1nPYLDZN7DNR04dP19geY5v999NoX/unohIAAAAAAAAAwrDw14X6Yc8P0uPRXonbDGlF5got/HWhxh0zLtqrAYCI2pC9QdM+naYVmSvqNI/TcGrulrmau2WuRqSP0CsTXqFSvQFZo70AAAAAAAAAAGiKZv40M9pLCOqllS9FewkAEDEOl0MPL3lYQ2cNrXNIGWhF5goNnTVUDy95WA6Xo17nhomgEgAAAAAAAABqKTM/U/Mz5kd7GUHN3zJfmfmZ0V4GADS4nMIcjX5jtO5ddK/KXeUNco5yV7nuXXSvRr8xWjmFOQ1yjqMZQSUAAAAAAAAA1NLsn2eHtfdZJDgNp2b/PDvaywCABpWZn6lRb4zS8szlETnf8szlGv3maF4IUs/YoxIAAAAAAHjtLdirjAMZyi/NV5mzTLG2WCXHJatPuz7qmNQx2ssDgEZj6a6lFXfuqONkr7s/XlPHeXx8t/s73VHnhQFA45RdmK1xb49TxoGMiJ53S+4WjXt7nJZevVSpiakRPXdzRVAJAAAAAMBRLDM/U7N/nq2lu5Zq1d5VyirIqnJsp6ROGtZxmEZ1HaUpg6YoPTk9gisFgOhyGS4VlRfpSNkRHSk74r8PWmIdJ/f0vavrPD4W7liouxbcpVhbrOLscYqzxVV5O87uvl+D23Yrl5QBRFe5s1yT50yOeEjpkXEgQ5PmTNKSq5fwPbEeWAzDMKK9CACNX05OjtLS0vyOZWdnKzWVV40AAAAATY1hGPp6x9eauXKmPsn4JKzWhTaLTRP7TNT04dM1tsdYWSyWBlgpANSeYRgqcZSosLzQGyp63gvLghwLGFfV8wrLCxtu0S+6P97YcKeoL1aLNfyg0xpeOBrsduAa7FY7/xcBR4mHlzysexfdG+1l6OExD+ueUfdEexl1Fu1r/wSVAGok2t+sAAAAANSPDdkbNO3Taf6VQHU0In2EXpnwigamDay3OQEcHcqd5aGDw8BwsTx04NhY946sUhMKKhsriyze4LKm4Wal2+E8pwa3CVCB+rMhe4OGzhqqcld5tJeiGGuMVl+/usn/DBzta//UpAIAAAAAcBRwuBx69LtH9cC3D9T7hZ0VmSs0dNZQ3X/a/brr1LtogQU0Q06X0xsE1qQq0TuuvPpqxsZwobleGJIcksrc9z0tXPdLOuQ+7vueLulY95ivJB12335Hks39fqKkHu7jC9znsMm8ousZM1BSknvObUEet0nqKLO1bLmkkoAxVknNJEMzZKjUWapSZ2m0l1JJjDWmVuGmX1gaRjha06pUq8UaevFAI2IYhqZ+MlXlBY3j/47yxHJN+3Sall2zjBck1AG/OQAAAAAA0MzlFOZo0pxJWp65vMHOUe4q172L7tXn2z7X/EvnKzWR7itANBiGoaLyotBViVWFi1UEjsWO4mh/avXHJalU/sFhuftjT5kB3kFJG4KMiZE02T3PKkmLfR739K07VtJl7tvLJa0NsoYRqggqd8sMOT23ne73vj7jV7iPBeomM6g8IunDKj7f/yczkNwhaXaQx1Mk3eS+/ZOkZaoceHaTNNZnTGaQMd19PqeNqhyK2iR1kJTsHrPfva7AYDVWFXt2NhPlrnKVl5XriI5Eeyl+bBZb+K14G6B9r+c2L3hCVRb+ulA/7PlBejzaK3GbYb5gb+GvCzXumHHRXk2Txb94AAAAAACascz8TI17e5wyDmRE5HzLM5dr9JujteDyBUpPTo/IOYGmyDAMlTnLalaVWItwsbCsUIaayU5PLpnhoCTFuT/uk1Qg/3CxTNIxkjq5x8yXVBhkzMUyKxmPSHqqinPeKamFzArHb4I83srndqz7fmzAe3ufMUNkVkUGjmnpM+ZaSTPdtz2tXw3J74/xFlUEmA6f2+3cjydKuijgcc9Hm8/aTwwyxlP9KffYOPdjpT5jfD/v32SGuIEsqggql8gMIgNdKOk49+1ZMv+MA10vswr0gHtMYNhpl3Sd+/Yu97kCxyRLOsNnvb8FmaO1zHBVkrIlFQUZk+B+l/vrYFWzClGdhlNF5UUqKi+K9lL8WC3Wem3fW9dWvp45YqwxVM1F2cyfZoYeFAUvrXyJoLIOCCoBAAAAAGimsguzIxpSemzJ3aJxb4/T0quXUlmJZsHhctQuOPSMqabtaWF5oRwuR+iTNwW+bU99352qCIL2S9oeZExrSWPcY76VtEYV4aInpDxB0nj37f+TtDPIGs5RRVC5TVKxzEAwxv0xURUtTuMlDVVFaBjjc9tztbSTzMAsNmCcb0g1yP1enW7u9+oEyz0sAceTg4zxFSezDWx1Okg6L8SYoe736lwgaaL8A1OHzK+rxwSZfwaB4arn9SuGpNOCzOGUGRRLZljYJciYclX8ORTKDCEd8g92U1QRVP4qs/I1UD9V/P38VmYVaKDRqvj7+W+ZgaZV/mHmeFVUv74S5HGbpLNk/l0/ImmpKgeinla/Vkl5kvYEeTxOkmcLuRL35+w7phkFqC7DpRJHiUocJWZg3oiEHXRaG6Z9b6wtVrG22KOijW9mfqbmZ8yP9jKCmr9lvjLzM3mRXpgIKgEAAAAAaIbKneWaPGdyxENKj4wDGZo0Z5KWXL2EFm6IGJfhUlF5UciqxGABY3WBY2Pc8y5snmzU889yr8zQIzBA7CupjcxQ6PMgj5dJulpm29FMSa8FOVespHvct/dI+l+QMZ1UEQR5KtiS5R8Q+l73HSGzIi8mYExrnzF/UUUVYTCxMoO26sTLrOpDZb4tWqsS6lq9RWZQWZ3Wki4PMaafzNa2klmd6QkzfUPLEyT1VuVA1LeSdIjMUDRwTFefMcfKDEADx3iqfV0yg9PAYNWlitD0iKQfqvhcTnJ/3C3poyCPp6qi4na5zHDVl0VmWP079/3PZLb7DQw8h0ga7B7zP5mVpIFjBskMRQ1JK30e9x3T1f25l8tslRz4uCdcbWY8+6AWlBVEeyl+Yqwx4QWd1vDC0ZpWq9qs1X0zrp3ZP8+WywhWhh19TsOp2T/P1h2n3BHtpTRJ/KYAAAAAAEAz9Nj3jzXonpQ1sTxzuR77/jHdM+qe0INxVDEMQyWOklq1PK1J29PG1r6wTpzyb1taJjOI8IRnmTLDv8DwsJOk4e4xX6pyFaNL0jhJp7rHfCDpUJDzt3G/W1Sxx2JgOOjZM7GlzPAwsL2pb0jRW2aL08AxvlcnT3G/V6dviMel6kPKhlJYx+d7rr3XdR6f8C3GGqOBaQNV5iwzwxVHqd/tUmdpo73oHxZPW9aYgOMt5d9qN5hjVdG2tipn1eD8twY57lJFdWyqpL8qeCWpZ0y6zLDRqaorVjvL/HceOEcHnzEx7nenzBcjeMb6fpvcIjNkDNRJZlDplPlChWBukvlv/ICkl4M8bpF0v/v2BkmfqnKYmSbpEveYNZI2BRnTRWa46pnnUJAxHVXRcnm3zK+57+N2mf82YmWGr56WyM2oi2u5q1zlrnIVltf1m0j98uyDWh+tfD/a5JPg1zUPfN398Zo6zuPju93f6Y46L+zoRFAJAAAAAEAzsyF7gx749oFoL0OSNGPxDE3sM1ED00L1JERj5dlHsUZViTVoeep5XrMJSDyfhlXmBfD9Cl59OFBmS8t8mZVQgY+XS7pB5oXzDQpdUbVNlSuqJLNNoieo9AQkSfIPB1N8xo92nzswQPSMsUu6W5XbnvpqI3PvwerUJCyKEKvFqpaxLdUytqUSYxK9t1vGtlRirPt+TJBjvuNiEnXX13dp0c5F5qSP19Pi6jrPjIqb5/Y6V/Mvrb5NotPlDBpiVhduljnLan+7ls9vNm2RJf9/N579M6vTWv4VwsH0dr9X5+wQj0vm95PAPU2dqvi3apV0hSoHog6fMYmSTg8yh29Va4LMcDVwjO9/A4dktukN/KN3qCKoXCfze1+gsaoIKv8rc4/ZQJfKfKGDU9JDPp+fb5h5jczvZzmS5qpyIBqriorVPZJ+VuUq0mRVtITeJzMIDmz1m+g+j2QGx66AMc2oi2uD7YOaGHpItTxf47rO42Nl1sr6m+woQ1AJAAAAAEAzYhiGpn4yVeUF5aEHR0B5YrmmfTpNy65ZJoulGZUuNEJOl7Pq4LAWVYmBzyt3NY6/S3UWbB9Fu6R27sd/k3lxOjBAPEZSf/eYj1U5iCyXeeHac2F6lvwv0Ht0kRlUlkta5T5mVeUKRbvMkGKAKoeHST7zHS+pR5AxvtVk54f6oqgiAKhOFNs3tohpETQkDHWsqnCxZWxLxdvj6+X70bnHnlsRVDZCp3Y5NeQYm9WmFtYWahHTIuTYSHIZrvACUfftGgWvYTy/zFkW7S9N/fIEY1WxyvweWJ0kmUFldXq636szRhVtoH2rSX3/qZ4nc+/TwIpU3xdfnFHFGM/3ekPm9+vA0NShirTEIbO6OXCMb5qyX9KKIJ9HJ1X8f7BOZpveQMfL3OtVMv9f+SXgcaukMyWNdN9/zb2ewMBzrCr2cZ2vyqGp3T1Hgsy2w5uDjIlRxZ9NkaSCIHPYVblSGZVkFWRp35F96tCyQ+jB8ENQCQAAgCZhb8FeZRzIUH5pvsqcZYq1xSo5Lll92vVRxyQ2EAIAj4W/LtQPe36ov+qeupohrchcoYW/LtS4Y8ZFezWNgmEYfvso1qTtaU3CxRJHSbQ/tfpjyLw47ZRZjRIYDJbJvNBrkxku/qTKAWO8pD+451smaYEqB4i9JP3RfXu1zIvKgWJUEVQWu88fJ/8qRU+AaJF54dimygFiW/eYNpLuVOW2p77SJV1cxWMebX3mbATibHHVBoU1CRcDn9cipoWslsZbWjRl0BTdvfBuOQ1n6MERZrPYNGXQlGgvI2xWi1Xx9njF2+NDD44gwzBU7ioPPxytSbVqmBWuRtBXSDRRVQWonpbU1Tk+xOMxqqiKrEpHmXvdBvKtAB0oM+ALDDN91328zOAyMBBN9RnTR+bnFDjG9/OMk/n/mufFNp4xntcRlcus7gzmBJlB5UEFb+Pru5fwZpktegOlS5rqvr1A5r6lgWFmf1Xsxfq1zCA3cMwAVQTfy1URDvuOOUbm/6lOmS8gCha+Jrtvu1TR5reRvBZuS+4WgsowEFQCAACgUcrMz9Tsn2dr6a6lWrV3lbIKsqoc2ympk4Z1HKZRXUdpyqApSk9Oj+BKAaBxmfnTzDo9v63aqou6KFGJsssuhxwqVKF2a7cOBt3IqmZeWvlSkwsqDcNQqbO05lWJNWh7WlheqMKywuZzQdkl/30UY1TR1nCHpDz5h4tlkvpJ6uYe877MKo/AEPJKSV1lVpC8WMW5+8m8+Jov6Uef4559FFv5HGsr82JwVe1NJbPqJNQ+i39UaKGK2KwyKyujxGaxKSkuqeqQMKbq4LC6cNFuPfouM6Ynp2tin4mau2VutJdSyaS+k/iZuAFYLBbF2mIVa4tVkl+Jc3QZhiGHy9Go2vd6bjfGID9svq+b8PwfUZ0O8t83NJjhIR6XpMtCPB4v6V4F3/vU09o0VWYb38AxvjrKrI4NbAfc2mdMa5ltfAPH+P5Ys1/mzwCBf/Rpqggqv1PwPXmvkBlUlkp6u4rP968yf9bYLekN9zHfILOFzD1UJXPf0+/k3+LX5j53PbZ99SgoLaj/SY8CR99PEAAAAGi0DMPQ1zu+1syVM/VJxic13rsqqyBLWQVZ+nTrp7p74d2a2Geipg+frrE9xtJmEMBRJTM/U/Mzqt+PLFCKUjRWYzVIg9RbvZXq9zJ/fznK0VZt1c/6WQu1ULnKrfF55m+Zr8z8zAa7cF7uLA/Z9rQmVYmBz2tWF1gl84JivvyDwzKZgeMA95hMSRuDjGmnilai/5MZDgZe5DxB0nj37SWSdgZZQ2tVBJUHVbE/Ykv5B4SSefF1tCq3NvVtcdpV0m0+x4IV4PV1v1enkRVAWGSptn1pTasSA8fF2mL5+ageTR8+3Qwq74j2SvzdcMIN0V4CIshisSjGFqMYW4wSGyJ9qQPPPqgN1srXFV7732bT1lwyqwk9LVqrkqDQbXw7ud+rM1yhw1XPi3oMmT9feMJM3/VdKfP//8CKVM9eo3aZrX4Dg1enKl5AlCCzsjVwjG+b2jKZL4gKHNNAyVips7RhJm7mCCoBAADQKGzI3qBpn07TisxgG33UnNNwau6WuZq7Za5GpI/QKxNe0cC0gfW0SgBo3Gb/PLvGL/IYpmGapEk6WSfLVu0GVRVS3W+n6BRN0zR9r+81X/O1WqtDPtdpODX759m67eTbvEFgTVqeBt0/Mcjzms2+YYbMC2iecDBO5oU4ydzDqliVW5wOkVkZWCrpwyCPl8msLEiWlCXp9SDnjVVFUJkt/z21LO7Hff+atJG5P6InNPS8++bQZ7jXFBswzrea8CZVL1YVe5ZVJUZR3zsrwZ5Qo5CwNnsqJtgTCBSbgLE9xmpE+og6/wxbn0akj9DYHmOjvQxAUuPfB7VO+5zWpFo1jOc0GxZV3cY3LcRzYyWdGGJMmqSLQowZ7H4P9EKI54UpzhbFTZ2bMIJKAAAARJXD5dCj3z2qB759oN5f1boic4WGzhqq+0+7X3edetdR2ZIMwNFl6a6lFXeqqO7pntNdt391uwbsHRB8QA3ZZNNo99vGjhv1xNlPaGfqzmqfc/fCu3Xn13fW6byNjkNSkSoHgzaZe1dJZvuzX4OM6aaKNqEfS9qqiupGj3E+Yz6TdDjIGrrIDCptMvdz8g0OE+Xfmq6VpJNVfXvT/jKrLjzhol2V936qSUVFtxCPR0GsLbb6KsSYmlUl+o5JjEmUzVqzsB/Nj8Vi0SsTXtHQWUPD+lm2bUFbdcntosTSRNmddjlsDhXGFWp3ym4dTKp9u+1YW6xemfAKITcQgt8+qI0oW/LdB7WhWvmGW9XabNrWSw22p2VSXONpCd2UcKUGAAAAUZNTmKNJcyZpeeby0IPDVO4q172L7tXn2z7X/EvnKzWx6paGANDYeC5WlThKVFxerBJHiXnb4XPbfbzYUewfVAZ0frM6rZry/RRdufhKxbjqt/xswN4B+vfb/9Zbp7+l2afMlssWvKozam1UffdRjJMZvrlkBojBqg9Pkvn1OyzpyyCPOyTdLvMi12ZJ/w1yzjRJ0923d0paGvC4Xf5/Rq1k7g0VGCD6tmA7x73uwDGea2J2Sf+v+i+FWkk6K8SYePd7FFkt1nqpSvQdkxibqFhbqA3FgNobmDZQ9592v+5ddG/IsSl5KRq7YawG/TZIvff2VmpBNe22k3K0teNW/dztZy0cuFC5rUK3277/tPvpJgI0Yb77oDY2DpejYdr3em5X85wjpUe09eDWaH8JQuqbEqrPPIKxGIbRjGJwAA0lJydHaWn+NfnZ2dlKTeViLwAgPJn5mRr39jhlHMiI2Dn7pvTVgssXNNj+aACaL6fLWWVAWJPjVY6twXw1beVanVaFrfTQ7Ic0MLPhL15vSN+ge6fcq7zEvPAmcMhsFxoYDsZL6uwekyFpb5Ax/SQd7x7zrs8Y3yKn30kaJLPF6j/cHwNdLzM0zJU0U5WDwVhJl8usYNwraW2QxxMl9XbPd0RSScDjwfZRbKJ8w8LAoLAm4WKw58XZ4qgIQ5PicDk0+o3RwV+AZ0jDdgzTpJ8m6eSMk2Uzal+B67Q49X2f7zV/+HytPmZ10GqgkekjteTqJXQRAdAsdX6qs7IKssw7hXWczNMG/5o6zuPzorNOSZ2056976jhhdET72j//awEAACDisguzIx5SStKW3C0a9/Y4Lb16KZWVQBNkGIZKnaW1DwNDhIQ1eV59t6aOpJS8FD359pPqeqBrvc5brnKVqEQJSpBddpWpTJu0ScWZxZry8hS9e9K7OmI7YoaEp8gM9bIkfafKAWMLSVPdEy+XtDDICXtJ+qP79iZJ6wIet8hsf+rRQlI7VQ4Q2/qMnyjzykjgmNbuMe0k3RfiC9HR/V6dlu73KIu3x1cfElbT9rSq57WIaSGrpRmlrkCY7Fa75l86X6PeGOX3M273/d11+6e3a0BmHdttGzaN3jJao7eM1sb0jXpiwhPa2X6n9/G+KX01/9L5hJQAmq1hHYdVBJWP19OkdZ1nRsXNEzqdUMfJjl78zwUAAICIKneWa/KcyREPKT0yDmRo0pxJvNocCJNhGHK4HLWuLqyP4LDEURLtT79xc8qsRnS47ydKrY+01l1v3KVDhw9pv/arTGUqVanKVKYu6qIBMi+cf6bPtEd7vI953sZrvE6QedHlT/qTDumQit1vDveJXtALGqABylOe/qK/mOcukPS1z9qGS0qQVCwzZPTsfeh5b+EztqOkE1Q5PGzjM+Z0Vd5nMXAfxQtr8DUbEuLxKBX02a320C1Oa1CVGNj2lP/3gIaVmpiqr6/4WuPeHqdt2dsart125gD9e1ZFu+3e7XtrweULeCEegGZtVNdR+nTrp9FeRpVO7XJq6EEIip9QAQAAEFGPff9Yg+5JWRPLM5frse8f0z2j7onqOoC6cBmu8MLAYGNr+bz6aEXa7BXLDAzLVREeOiSlygzsymUGdr6PecaOlhm8ZUtaEmSOGElXuc+zStJX7uO+fyzdJdvlNj0450EtOLxAn+iTSkucpEneoPJrfa11lUoUpcEa7A0q4xSntmqrBPdbvOKVoAQluTdITFay/qw/ex9PUIL2pu7Vs5OflRHr7q/aQ2aFYnUFeMe636vTJsTjEWKRpUYhYW33VGyM+1IBqJn05HQtGr9I/xv3P3Xb3q3BzhPjitHUb6bqzN/O1Flfn6WOyaFKuwGgaZsyaIruXnh39PY8r4bNYtOUQVOivYwmi6ASAAAAEbMhe4NmfDHD/2J6lMxYPEMT+0zUwLSG368NzZdhGCpzltVtj8JgY2sQHJY5y6L96TdehiqqC52q2DumUNIhVQ7+4mW2FZWkbZJ2q3LI2E2Sp5vT5z5jfN/HyqwclKQXFHzvnCskHeOee24V6z9JZlBZImmDzFDP7vPusxeOWkrqEvB4jKR20qXfX6qBmQNVpjJ1VVfFKU6x7rc4xamjT7/Sv+lvcsnlfSxWsYpRjKw+ieKzeraKBZviFKcLdIH/wRwpZ3uO3uv8nnk/ih1CW8S0qFHb0xoHjrGJSrAnsI8iAD8lmSXadc6uBg0pfXXb3k27z92tNgvaKD49PiLnBIBoSE9O18Q+EzV3S1U/REfPpL6TlJ6cHu1lNFkElQAAAIgIwzA09ZOpcjzqCD04AspnlGvap9O07JplXGRuBrytSGsTBoZoP1qT55U4SmTIiPan37iVqyLw8w3+kiQlu8dkqKIC0XfccTL3CCyX9JkqB4wOSX+QGdbtkfSuz3HPH0usJE/x9BZJwbpFdVZFULld0oogY2yqCCpLJJXK/I06QcEDxMHu9XqCQ88Yz/6IcZIuVeWA0a6KNqjpkv7uPndV+rjfA3Tf312TXp6kwzqsY9xvwRzWYUlSvCoubjvl9LZ3rQ9XLr5S3/f53m8vterE2mJrXZUYak/FFjEtZLNW94UEgLoryy7TunHrVJxRP98/a6poS5HWjVunIUuHKDaVimwAzdf04dPNoPKOaK/E3w0n3BDtJTRpBJUAwpabm1vjsamp7JMAAEe7hb8u1A97foj2MvysyFyhhb8u1LhjxkV7Kc2Cy3Cp1FEadhVhuG1Ji8uLG2X7n0bDUEV4Fyezoq1MUq4qh34uSZ4i4/0yg73A8DBZ0hj3mJ8krQ0yTz9J491jPpBZpRhonCTPNi5fSu68zF8nmUGlJG9XUqv8gz/Pax/iJLVX5eDP93ptuqQzA54fGDCeImmYKoeHvhnX74KsNdCZIR63SeobYky41YeGdMcnd+gS45IwJ6hfi1yLdPunt+uma2+SLNLL57+s9OT0KsPFGFv97uUGAJHgKndpw+QNEQ8pPYozirVh0gYNXjJYVnsUy9cBoAGN7TFWI9JHaEVmsFcWRseI9BEa22NstJdRpZycnJBjanOdvyEQVAIIW//+/Ws81jCoNACAo93Mn2ZGewlBvbTypWYVVBqGoXJXee3DwBDVhTUJHEudpdH+9Bs3TyvSwMrCWFVU2e2WGdgF7lvYzf0uSV9Lylfl6sKxkrq7bz8T8JjHzTKDvwOS/h1kjVb5B5WLgoxpr4qgskRSgSpCvTj3x2Sf8ce67wdWFnb3GXO+zJA0MGRs5X7cLrMq0q6qw7sUVezbWJX27vfqJLnfmyCLzOrwITuGqP+emv+sHgkDMgdo6I6h2jd4n64/4fpoLwcA6t3ux3Yrf3l+VNeQvzxfux/brW73RKbtLABEmsVi0SsTXtHQWUNV7iqv9fPbFrRVl9wuSixNlN1pl8PmUGFcoXan7NbBpIO1ni/WFqtXJrzSqLs0paWlRXsJIRFUAgAAoMFl5mdqfsb8aC8jqPlb5iszP7Pe95Nwupx1qyKsRVtS32MljhK5jEawCWhj5ZIZ3Nnc74akHFUODx2Sesrcu7BQ0hpVDhmdkia75/1VZqgXWFnYRtLV7jHfSloSZE0DJF3svr1M0uYgY05XRVC5RWY1pOQf7HlyYpv7vHZVDv48hWpJMsPGwPDQ7v6aWGQGjH9S5cpC398iR7nfq3NSiMelirarVbHIvzKykYuzxSneHq94e7wSYhLMj/aESscqHQ8ypkbPcx+PscZo0pxJOmHOCaEXGQWTVk7SqvNWRXsZAFDvjmw4orUz1jaKdvA7Z+xUu4nt1HJgy2gvBQAaxMC0gbr/tPt176J7Q45NyUvR2A1jNei3Qeq9t7dSC6ru+peTlKOtHbfq524/a+HAhcptFbrK8P7T7tfAtIEhx6F6BJUAAABocLN/nl0RntV1L4nX3R+vqeM8bk7DqXsW3qOzep5VfXvRWgSOJY6SsF7dedQwVFFd6BsOSpLn98ZcSdmqXFnYRpKnUGyVpExVDhgHyWzdKUlvy6wM9Dzm6RB7kSoqB6sq9v2TpA6SimRWMQYzQWYwWCazStE31EuQf2VhR5n7FgYGf74vcB3pXn9gwOhb4TdNZlWhXVKwF+5aJF1bxXo9WkoaHWJMC1XsldgE2a322gWAtpqFgaGCwzh7nKyW6LXcGxM/RoMyBkXt/NU5ZcspSo5LDj0QAJoQwzCUMTVDkx2To70USdKi8kXaOm2rhiwb0qgrfACgLu469S59vu1zLc9cXvlBQxq2Y5gm/TRJJ2ecLJtRs33KUwtSlVqQqlO2nqJpX0/T932+1/zh87X6mNVBf+8amT5Sd55yZx0/E0gElQAAAIiApbuWVtxJrHpcjXiu/9d1Hh/vrH9H76x/p/4mbCqcMkNDz28Fh2VW5QUGfx0ktXaPWRHwuOf2aPeYfEnzgszhkHSL+1wZkuYEWU8b9xjJrCpcGGRMb1UElb9JWu/zmCf46+FzrKX73IHBnycrsUg6Q5X3PbSrou1oa5nhYOAcvm1I+yh0CN/P/V6driEel8z2qk2IJ8CrVQBYiyrCqsbarUfnr7tjN4zVAeOAJGmu5tZprpt1syTpeT1f53VJks2waeyGsdIF9TIdADQKhxYeUsEPBdFehp/8Ffk6tPCQ2o5rG3owADRBdqtd8y+dr1FvjFLGgQzv8e77u+v2T2/XgMwBdZrfZtg0estojd4yWhvTN+qJCU9oZ/ud3sf7pvTV/EvnH7W/c9Q3vooAwrZp0yalpKREexkAgCZg1V5a/VXJpeDVhSkyQ7BCmVWDgaGfTZKnu+MOSZuCzNFB0pnuMf+TtEH+AaMh6WRJZ7nHfCApK8gaJ0ka4r690P3cQENlBnqGpD3yD/3iZAaGno60reRfNegZ61u918c9X2D7Ut+A+nxJ57mP2xS8uvDCIMcCnRbi8RhJnWswTyMWa4utdfvRUAFhTYLDWFss1RyR9lPFzdbeVxiExyZbvczjZ2XNhx765pCcRU5ZrBZZbBbJKr+P8d3iFd81vtZLKD9ULsNh+M1lsVokm/u25z4A1EDWzGA/PEVf1ktZBJUAmrXUxFR9fcXXGvf2OG3L3qYp30/RlYuvVIwrJvSTa2FA5gD9e9a/9dbpb2n2KbPVu31vLbh8gVITq24j25hkZ2eHHJObm6v+/aO3xz1BJYCwpaSkKDW1aXxDBgBEz96CvcoqaJwXcLwMmSGapyNMoaRiVa4KTJbU3j1mk8wKxMDKwoGq2EvwA5ltQwNDxkskdZKUJ+npKtb0N5n7I+6VNDvI4y1VEVTul//Ff09bUN/fz+Jktg8NDP7a+4wZKrNiMXA/wi4+Y66Q+XUKDBk9VX6tJN1dxefk0VHS70KMSZN/S9RgmlhlodViVYI9ofYBYB2Dw3h7fFRbkaLuXOUuOQuccuQ75CxwKnFAYpVBWsGqxlXVE6hgZc3Xt3X6VhVnFFf5ePcHuqv7fd1rvYYNkzYob2lelY93vqmzej0fauPUyrZO36qDXx0MHoBaLWp7dlsd869jaj3v3tf26tA3h/zDVJ95W/RtofQ/136f5bzleSpYWeA3l+/a7W3tShlf+xemlu4rVenu0irntcRYlNAjodbzAo1RSWaJcueH3sMsGnLn56oks0Tx6bV/QQcANBXpyelaNH6R/jfuf+q2vVvoJ4QpxhWjqd9M1Zm/namzvj5LHZM7Nti56ltTuH5PUAkAAIAG5duGpS7aFrRVh90dpEJzL6DyL8tVYinRwfiDKjqlyAzMDkj6UZUrC2MkXeyeaJ2kxaocHnaXdKV7zDcy9z8MNFxmFZ9ktkDdFWRMqiqCykyZexf6hn6+12bjZLYxra6laJqkyaocMMb6zDNM0nE+jwXbguM0ha4cPCHE45J/aNlE1SoArGbfwtoGhzG2+n1lLxovwzDkKnHJllCz/XB85f+Yr4zrMuTMd5rhZIFDRqnhN+aUg6copk3lv0+le0tVllUW9rojoSyrTKX7ShXXoQavNHBW/7DFFl7Vo+E0qh8QZq5ftrdMJTtKqny8RZ/wNn3N/yFf2e9X/Ur41mNbhxVUHvj8gHY9HOw/MlPioMSwgsqc/+Tol1t/qfLx2A6xOnnvybWed//s/dr8x81Bq2stVosssRadsv+UWs+b/1O+frnllyrnlU3qP7u/7Em1u4RWmlWq3U/srpgryLydb+ismHa1+7/BWezUgU8PBA3DPedIGp6kmNa1m9cwDJXuLq12XmuCVVY7L3zxlT0729sxorG125bTXF/XO2rSVx4AmqaSzBLtOmdXg4aUvrpt76bd5+5WmwVteCFIPSKoBAAAQL3KK8nT2n1rtWbfGq3eu1rf/vZt7ScxpDa726j/qv46peAUnZBzglQgXaJLKsb8UHFz1k+zlNM5R98kf6NvVn7jP5dN/u1CbTIDwkT5h4O+1Xu9ZLYhDaws9H0h4nkyw9DAkNH32vtfQ3ye8ZLvpxRUsqTBIcbEyj+4bAJirDG1DwBDhIE1CQ7jbHG0IkW9yP8xX7se3SVngdOv2tETLsopneY8rdYtRA2HocJ1hdWOcRY4gwaVRRlFtTpXoHKVq0hFKlaxClWoEpXIkKGVWqkhGiKbbCpQgXZqp9KVrjZqI0naru2SJKv7zSKLbLL53bbIojjFKUlJKtpSJGeyUw6HQ0lJSbJYLHK5XHK5XLLZbN5/o4arYQJFbxvqKjRYAFr73NqcN8TXIew2tQ0VBDfQn5vhNCTD/DciSYb8z2OJCW+9jkMO5S/PD33uWirLLlPm05nVjkn7fVqtg0rHQYc2/X5TtWOGfDdErU5pVe2YQIbD0IpuK6odM2DuAKVOrn1Vxg99f5DzSNVtnLs/0F1pF4Vqo1DZ1hu3qmx/WZXzpl6Yqnbnt6v1vPve3aeyvWX+4bLP7cSBiWo10vz6+lZnN8Z223nf5YXeQxsAmqiy7DKtG7eu2g4cDaFoS5HWjVunIUuHKDa1if0i3kgRVAIAACBs+4/s1+q9q7Vm3xrzfe8abT+0PbzJNkvaJSXtSJIjx6FDrkP6Xt9rlEYpVakyZGiyJquLuqit2ipWsYpTnGIVq+6F3dV7a28N13Bdp+u0ptcafXXCV1rba23lC6ID3e/V6et+r06H8D7NxsQiixJiEmoeANpqV0VY1dh4e7xs1jCv2AO1VLC6QNmzs+UocAQNFSXppK0n1Xre8txy5X5cfbs/5xGn7Mm1+7XblhT634Yj3yHJrIAqKipSQUGBCgoKtGv1Lv2sn1Xk83a8jlc3d5n303paHdVRl+pSSdIrekWLtMg7tjzoBrTSHbpDX+gLJShBG7VRd+tu3aW7dI7OkSTdpJtUoqorCT1O0kl6RI/IWeDU9OnT9dZbb+nIkSNKTEzUl19+qfHjx1d8HWw2WZwWb/jpG3r+WX/WWI2VxWZR3759NXLkSL3xxhuSpLvvvlvz58+XzWaT1WoN+rFoQ5EMGXpEjyhOcdqiLXpTb+piXaxhGiZZpcsvv1zl5eXe51Q138CBA/WnP/1JkvTVnq+0Rmt0la5SjGKUqUx9o2+860/enKyOT3YMOtfpp5+u3r17S5L+85//qH379jr99NMlSRv3b9RmbfYGvtaAt9Z5rXXk+yOy2WwaPny4bDab8vPz9euvv6pr165q08YdKG/fLovF4j3nvrx9OqiDlQLlGMUoVrGSVXK5XLJYLLV6gUeoUC/cADRUwBx2ABoqWFWYaw4RBEvhhcw1WW84oXhNwthwQ/GyrDLv99tgnHk1+GIFcfD/DlZbxZxwbEJYQWXWi1nKX1F1eJ1+a7o3qGzs7bYPLTiknQ/uVPe/d6/1c0t2lag0s1SWWIuscVZZY62yxFXctsZbZUvk5zkA0eEqd2nD5A0RDyk9ijOKtWHSBg1eMphuA/WAoBIAAAAhGYahnYd3esPI1ftWa83eNdp7ZG/tJnJIypa57+JeSSmSRpgPxS+LV8nuEpWrXD3VU73VW8fqWA12lxNaZNEtuqXa6WMVq/Zqr3O2naNztp2jjekb9cSEJ7Sz/c7arTPC4mxxIQPA2lQW1jQ4tFvtVBei0SjcVKi8pXmVKhM9LVCtCVYN/DjUqwwqK9pSZLZfrIrF/B5X238LNQ0UA4NKp9PpDRYLCgqUn5/vd//Arwe0SZvUTu10rs6VZLYT/E7f6SE9pAQlaPG3i3XZqZepoKBALlf16c1f9BdvULlIi3SsjvUGlTGKUUu1VKpSlahEJShBLXze5mu+LLLoal1tBleSuqmbbtSN6uvzao4rdIUccsgll5xyypAhV5A3zzpcpS6NGjVKNptNMTFmNVnHjh31+9//Xi6XS06nUy6XS7n/lytHiaPSPElKMk9sldLS0tS6dWvvWjx/juXl5d55Aj+WlpTK6ZMi5SlPa7RGYzTGnMNm0UcffaSSktDh6/nnn+8NKr/d960+02e6QldIknZrt97QGxWDV7vfg3jzzTe9QeVVV12lsWPHeoPKtze9rU/0SdWL+FHSqebNwsJCtWjRQkuWLNGECRP05ptv6sorzb7mgwYNUnFx6It5IzRC/9K/ZLFZdPXVV+vtt9/2BspffPGFfve731UbBBuF5p//DbpBp7l7jl+n69RP/fQX/UWySg888IC++OKLaufxfPzwww8VFxendTvW6VE9qkmapON1vCQzfHfKaQatTps+uvmjoPP069dPV1xh/rnMnz9fGzZs0J133qmYmBjt3LNTH+rDoKG4Jxj+7T+/KaZFjEaOHKkePXpIkj777DOlpqbqpJPMFzps3LhR+/bt856zZGuJtmlb0Hm7qZussqqwtFB7d+xVWlqaWrZsKUnav3+/rFZrlSG5o8whQ4Ysqvp7VliBYqggWI2v3XLUqqPd620K7bZdxS7lfpobVlC57+192vn3nVU+ntArIawX+hxccFB7X9kra5zVG4J6w9A4q2zJNnW9vfbtap3FTjnyHGaI6p7TYq/dCy0ANB27H9sdsiNCQ8tfnq/dj+1Wt3si03a2OSOoBAAAgB+ny6mMAxlmpeTeNd5qycMlh2s3UbnMVqiStFHSEkk58r+o1EuyDrdqyvdTNCpzlBKUoM7q7G19VVcDMgfo37P+rbdOf0uzT5ktl63qK1pWi1WJMYk1DgDDDQ4Dj8XaYmW18ApMNB0lu0tUlFHkt4ei7217sl3H/POYWs97ePFhbbtxW5WP21qF930hZKBoSM5Cp+wtq//1OD8/X7m5ud5Acd/afVqv9SpWsbci0XP7el2vRCVq1Q+rdPPEm3X77bfrD3/4gyQzkMvJyQm57oEa6A0qs5SlDGWoWMVKUIJa2Vpp+PDhSkpK8nu37bGp4J0Cb+CYqERvOChJszVb8arYS+cq91tVFmmRJGm8KiodO6qjLtJFfuOmaErIz8eXNc6qa6+9Vtdee6332NChQzVnzhy/ccs6L6s2BLDYLFqyZInfsX/+85/65z//We35Vw5ZqSNrj3jvn6ST9JW+qpjXalFRUZE33Kwq8HQ6nd6gVZL+2uuvujTrUsW4//M7TsfpVb0qQ4accqrtxLbqcneXoPMOGDDAO88HH3yglJSKvSF/f+zvNXDHwEqBrWfeFgNbqP217eVyuRQbawbKvXv31j/+8Q8NHjzYO89tt92msrIy77kPLj6o/LX5lebrqZ7mE6zSiSeeqOLiYu/n2a5dO40ZM6bKr4fT6VRxZrGK84q94bYk7/yeP7fDhw8rKyurynl8PxqG+bx9B/ZpkRZphOcVTpK+1JcVlcAOSS8E/zMfP368N6j86KOP9O677+q2225TTEyMNu/YrJmaWfVfGEmaZn546623vEHlRRddpDPPPFOffvqpJOmRRx7Ru+++W/08bv+n/1Oc4vTtim910bUX6a233vKur1u3biotLQ05x0iN1D9l/l1/Qk9ooRZqnuYpTnFa+ONCXT/++hoFwf/85z81YcIEGU5Dt+gW9VM//Ulm+P6+3tcqrfIGra0eaKX4WfFB53njjTcUGxurtWvX6oUXXtC1116rkSNHSpJmls70BspWWStVB6d9lqZWWa3Up08fXXSR+f3lq6++UkZGhqZPny673a7ffvtNCxYs8Dvn9vztcspZqcq4l3opVamSVVq8eLHatWunQYMGSZJ++eUXHTx4sNqvye7i3SpRidqrvSyyqExlKlKRWqiFYhUri838HpH3c57KVe4XRDdGnnbJtX5eWYjq6NjwPt+ijCLlfFj1/4MxKTFhBZUHPj+gTRcHtEW2yC8IPXnfybUO8ot3FCvr31n+VaWeMNR9O+XCFNniqS4FIuXIhiNaO2NtpTbw0bBzxk61m9hOLQe2jPZSmjSCSgAAgKNYiaNEG7I3mFWS7hau6/evV7Gjlu1TjkjaJ7NK0vOxUNJdMl91bkgqlrn3YwdJHc33ZFuyHn7jYQ3MrH2VVE3FuGI09ZupGrF1hO6dcq/yEvOCjtvz1z3q0LIZ9HMF3BwFDpXnlAcNE50FTtnb2NXxqo61nnf/u/v16z2/Vvl4XLe4sIJKW3L1F/icBc4aVz56gg2LxaKy2DJlKMOvHapnD0ZPsPjmtDdV6CjUH//4R02ePFmSNHLkSLVu3VpffvmlJGnGjBl6+umna/S5TNEUJSpRRrGhw4cP+1Xm/f73v1dxcbGSkpKUnJxcKWxs2aKlto3bpmQle59zo/vNo29qXy1YsKDSeQ8tPqR176yrcl2Jfhv2Rk9NqlGlGrQQDbMNZcjWmTbz746nmq2m2tjb+AUViUqsCP0kdWzfUX1G9Ak5z4QJE/zuD243WJ3UqcrxKcemaOCt/v+P9u7dW3//+9/9jj344IN+97fdsk171u6pcl6LzaIbb7xRN95Y8XfvpJNO0ueff17t+n97+Df9eq//94hX9WrFvFaLnn766Rr/e/IYN3CcvtbXfl/jeZrnDVotSRaduO3EoIFnQkKC9zkPP/ywbrvtNm+oe2LfE/WcnquyEtgll/p92E+G1dCwYcO887z++uvq2LHie+jVV1+tk08+2XvOwu2F2v3c7qABs919Oa5nj5664447/ILq66+/XmVlZVWGt+V55cr5Ike91dv7nC7qouN0nPeFXi0TW6pfv35Vhsme257zSJJcUq5ylaeKn5P2aZ+2aqs3xLast8i5ruL5nu+1nq+HJP3222967bXXdPrpp3uDyo+dH1fZWtocYL5PnDjRG1S+8847eu+993T99dfLbrdr7dq1mjZtWjV/Qyrcrbt1ls6SxWbRWWedpXPOOUeffGJWJc+YMUPvvfdejeb5Sl8pVrH6ST/pXt2re3SPztSZklVq06aNysr8X0gR2JrZIotGaITu1/2SpGf0jJZqqWZrtmIVq1Vapaf0lHfsPu2TJF2v6xUT8HaxLvZ2GXlez6u7umuCzO8V3+t77dKuSs/xvCXlJ+nIoiOKi4vTiBEjZLVaVVhYqOzsbKWlpSkx0fy/oby8XHZ7RbcNV2n1JavWuPBeaNdQAWjQeQ3JVeKSSiSnzRnW/xvFO4q1+9FqOjNIOiX3lFoHlYUbC7Vq+CozRPWpAvX92P8//ZXQPSH0ZD6cRU7tf3d/lRWrlliLEgckyp5ELICmyTAMZUzN0GTH5GgvRZK0qHyRtk7bqiHLhlDBXQd8RwIAADhK5Jfma92+dX57Sm7K2SSHy1HzSQxJeTKDyC6SWko6JOnZgHHtJB0rqUxSvKQBqtgXstD8kFKQoic/eFJdD9b+FdPhGJg5UM++9qxuv+R25Sblyvd6faekToSUiCrDMOQsdHpbnvruo2hLtqnN6W1qPedvD/2m3Y9VfWEt8fjEsILKUCFTdfuQVceaaFWBCmSTTS3UQpK0Xut1SIfMYNFVqKUPLFVhSWGltqnp6el66623JEn33XefHnroIW3btk09e/bU9tzt3uqgKrkL+YYOHeoNKjt16qTk5IqwcMyYMbLb7d5AsYWlhbJuzVILtajUMtXTmnRAxwHasWOH36mef/750F+LOKuM0qov5DoKgn/fbtGnRci5G4MWfWu4zlCtKMMsXmmoADTabShrLVrrDbfoyFCljgue7xWSZLfb1b59+5DTdO3aVV27Vvzs0aZFGw3SoGqfc9oFp1X6eniqpD3GjBmjMWPGeO8fXnpYa59bW+28/fr202NnPOZ37NlnA3+o8leUUaQfv/jR79jv3W8eI4eN1LdXf1vtPIEMp6H35B/g/dX95nHcZ8ep7bi2Fc8xDLlcLrlcLtnt5iXG8847T4cOHfILh9+3vm+OC6je9YTD3R/prtZntVZSUpL3OX//+991/fXXe6t5R44cqS+//NIveN141UaVHy6XU06/eQfIDH4tVouef/55denSxTvvlClTdNxxx1VbxZv5WqbKcsq8f986qIMmaqLSlW7Oa7PosssuU/62fB1aeqhSEB2s5bUktVEbdVZnWd3/aG2yKVGJ3q+FJBkylCezUtMhh8pUJocc3tbUkhnQn6yTvUHlN+63Km2XPE8vKyuT1WrVggULdMEFF+jdd9/VH//4R0lSYmKiysvLFRsbq7i4ONkddtlkU4xiZJfdG3wO1VBdp+tkjbXqmWee0fLly/Xee+/Jbrdr/fr1ev311xUXF6e4uDjvXL4fC34o0GEdVj/1U5rSJEmbtEmt1Mr8+sRZlZub67eWuLg4vxA1mGgFq1J44aqrxCVXsUsqll87cj9h/EhVfrBcW6/fWu2YId8NUatTWtVqXpfDpZXHr6yyqtQaZ1X6belKPiE59GQBDn97WLKqyrntrexh//mh+Tm08JAKfmhc+wPnr8jXoYWH/P6PRO0QVAIAADRD2YXZ3ratnmDyl4O/hDfZZkm7VVEt6Sm2/J2kQZJaSxomKU1mtWQHSXEBc/j+7v641Fqt9aSeVFdFJqT06Hawm558+Un9WX9W3oyKioETOp0Q0XWgeXA5XH6hojXeqhbH1j4o2nbrNu15bo+q6lzU6rRWarO49kFlQwWKwV6Bv0/7VKYydVVXOQucWrdunX788cdK+y8G25Pxyy+/VK9evbTtwDZN1ERdqSu97Uif0lP6Tb9VnOiBgM/RZlNSUpKczorPpW/fvrrgggu8F7e7HdtN0zStUpjo+zZy0Uh1HNXRr3ruv//9r9+5xo8fr/HjK1qgOkucWnrr0mq/Vo78WrwQxIc9ya7y0qqrj5z5wf/s4jrGKbZTrLdd6mEdDuv83vO4r5DWdZ7Wau29HdspVnEdAv+TCG7k7pEynIZZAek0KyENZ8XtmlZmBur7Rl85jzj95vK9HW7g23FaR7U5s405l8sMfnxvJ59U+4u3kpR0QpJcJS6/uXznTxwQXqWsraVNMWkxQddqOA1ZYhqmYjXsIDjEt6ywg9VQFbZSWGFwyMBW4a25JvOGtd4afB0C1xus8jgmJsZv31hJSnGlqDr9u/dX2pA0v2N9+vRRnz4VFchpaWk655xz/OeNTam+UtNmVqj6Ov/883X++edXu54fP/1RRTlF3vs91dPcX9XNYrPotddeU+4nudqwdEO1c/m60v3mMViD9W/923vf83/fm3qz2nk+1sd+lcXTNE0X62KVq9wbbJb7vNmPtavDXzqotLTUGyj37NlTt99+u7ea1zAMXXzxxSotLVVpaanKysp0eMNhFRYXqkxl3rkLVah8mXvCWeIsWrFihT744ANv6+6MjIyQYbvH3/V3jdEYGTJ0o27UaI3WA3pAllizmvuDDz7wG2+xWCoFn3Fxcdq6datsNpuWrl+qh/SQrtJVGqqhkqQH9aBssilWsYp1xGreX+cFDU/79Omjs88+W5L0448/Kjs7W+eff74sFosO5B7QVm31BrV22RWrWG94G6vY8ILKstAbw4Yzb0MFq0apoaJNRdWOaX9Z6BeLBLP+/PVyFVb99ejzah91vLb2L67LuC5D5QfKg1aVWuOsantOW7Ue1brW85ZmlUqG/CtWY63h//+GWsmamRXtJQSV9VIWQWUdEFQCAAA0YYZhaFfeLr8qydV7VyuroJY/vDskZauibWuapOHux36QtFPmfpPt5W3b6s0YLZL8u9RVyyabHtSDEQ8pPbqqqx7SQ7rFeYt3z8pTu5walbUgsgzDkKvUJcNhhNyPMJjtf9uunI9yvC1UXSX+F1TaTWqnQfOqr8oJxhpjrTKklKoOpUIJFii65FKZyhSveDnzndqzZ48yMjJ0wgknKDk5WYcOHdKsWbOqDRbz9ufpsA7rQl2oq3W1JOle3atiFes9vSej3NBnn3yme++7N+i64uPjvVWJycnJcjjMMK9Dlw46X+erl3p5x16ra1WmMm+gOHzecKUNSPM+Nz4+vlJ1xR/+8Ae/Sqf23drrD/KvfAqUaCTWqsWn5N7zym6pdu+vcMPg9NvSzb+nSXbZkm2yJdnM20nm7bj0qoO+pGFJOpB1QJJ0gS4I6/yB6jqPZ69LyQzdaqqhqieSh4cXGIbSfkp4F2hD6XpHV+mO+p/3mH8do2P+Vfs2zaGk35quDld1MINf36DZfdsaG96fa5uz2qjf7H6V53UHzeHOm9ArQZ1v6Rw0tPaEt+G0crMn2ZV0UlKVQbBcksUeRlgQRqBYIzX4dhXORXjf9rBVamLV0Z4gOFTL8obSSv6VcB3cb1Vp06ONjp9+vN+xQYMG6fHHH/fet1gslVribrl2i/a9vq/Kea2xVs2ZM0fvv/++99/I+PHjtXv3bm/Y6Rt8ej7+9tpv2vvxXm/lqyFD0zXd2+LaGmfVueeeq7S0NL/nBZuzvLzc+/93wZECZSpTJTLbrTvl9K80LZNURcfpSy65xBtUPvroo/r444+9bZEXrVwUsjODJcGiuLg4vf/++7rgggvkcrnUu3dvTZgwwdvm+r777tOyZcu84aglz6JCFQZt13ulrpRFFu3I2qHvvvxOZ555pnr06CHDMPTFF18EDVs9Hx17HDqiI2Y467NXsN+fXRj/vzZUsCqp2i4SdZn34JcHVZpZ9Z6/MW1jwgoqf574s46sOlLpuMVukSXWoi63dVGPf/So9bxZs7JU/EtxlRWrLfq2qHUlrKQab53QFJRklih3fm60lxFU7vxclWSWKD49PvRgVEJQCQAA0EQ4XU5tPbDVr0pyzd41OlRyqHYTOVTxU+AGSd/JDCl9f/fso4qg8iyZIWU71foV+se2PVZDOgxRzzY99diyx+QyXJqsyUpXep0rdOoiXema8v0UvTf6PdksNk0ZNCVqa0H9++3h33R4yeFKLVSdBU4ZDkPtL2+vfm/3q/W8jgMOlWwvqfLxcAPFUFVhpfmlOnjwoAoKCpSWlqaEhAQVFRXpiy++UPfu3XXCCWZF8PPPP6/Nmzd7w8UDWw8oV7mV9mZsr/aaozlyFDg0e/Zs3XHHHVq+fLlGjBihI0eO6O677660hpYtW3rDwZS2KUrNTVWKKipkJmqiylSxV9eFZ1+oE048IegejJ5Kx0AdunXQ7brd79gojfK7P6jLICUdW/OgS5LsyaF/7Q0nULRYLEr7Y5osVos3QAwMFlsOa1nreSWp29+6hR5UhVajWunApwfCfn5Da3Vq7S+woWmJaR2jmNbB/53XRYteLdSiV/23N04anKSkZ2r3faVG8w5L0rAVw0IPrKWWA1vqdON0vyA1MLityfe9QPY2dg1dMTR4FbP7HImDwqjeNaRjnzm2+nn7hVcVnHpBqhz5juDVxi5DcV1rVr0dKLZjrJyFzirntSWY/283lXbb9pTwLv+GqszzhF1Wa8UvCAkJCUpPT6/2eb8s/EWZyqyYR1ZdrIv95r3qqqt01VVX1Wq9Z/Y+Ux/rY+99m2z6Wl97K0wtnSw6bsVxQQPPtm0rqqBuueUWTZ482Rvs9O3QV1M11a9K1ffNYXWo1aRWKi0t9bafdjgcSk5OVlxcxd/BX3/9VStXrvSe27s/bAC77N7q2p/W/aTrr79ec+fOVY8ePeRwOPy6O1RnjMbo7zL3Kn5QD2qVVmme5kmSvlr2le6bcl/QCtXAY9OnT9fgwYNVXlSut/SWeqqnTpX5Is+VWqlc5XorTPev3q92lnZB5+vZ09yzuby8XA6HQ3FxcbJareb3g2pe9CWF/8KlUOFqfQerhsP8XGpUqR9E9ofZOrzwcJWPd5zaMaygcvPlm5XzQU5FVamnxa77dptxbXTs08fWet7DSw+rcENhlRWrMe1i1PK48H4Wrkr27GzvdYu5mlunuW7WzZLMfX/rhdNcX9c7ovOC7KaOoBIA6qB0b6mKMorkzHfKVeaSNT7Un1kAAJ/fSURBVNYqW7JNLfq0UFzH8H4pAgBJKnWUakP2Bm8YuWbfGq3bv05F5dW326mkUBVVkr6tW++QWQnpco85VmaVZAf3R9/ffzqFPo3NYtOAtAEa0mGI+d5xiAZ3GKzkuIqqlYwDGVrz7Rr91/0Wbf9b/D993+d7DT19qNKTq7+ggoax58U9KtxQKEeBI2io2P7y9ur5aM9az3tk7REd+l/VAX64VW41baVqGIaKi4v9qhFbtWrlvUAzf/587d27V3/6k/nq/GV7l+lVvVopUCxUoYpUpPLt5eYLBSQtXrxYp512mgoKCnTxxRfrhhtu8AaV//3vf/Xtt+aeZHa7XS3jWipOcUpQgjqog7f1aTv3ZEapoTGnjdGLL76obt3MYKxDhw766aef/ILFxMREv4uQ+T/ka/WI1X6f+0RN9LvfPaW7+p1YuzC4oQJFa4JVLYe2lK1l5cpEe7J5u0X/8C4293uz9oF3Q0ubkqYdd+8Ia1+rBmcz1weg7ixWS722GbTGWsNuT1wdi9Wi9Fsa5uesPq/0CT0oDIMXDq7RuMB2242RJc6iVieH9wKRUHs+hh3yhAhA63Nem/stTnFKaJHgt19pVUaPHu13v1dqL/1Rf6xyvC3RplEf+7+wKjY2VqtX+/+s9M477/jd3z9vv9ZcsMY/9HS/eYw7c5y++uorDR48WJL5Iqk333yzUqWq7+2CXQXa+9+96qu+3nm6qIsKVei977KZe8vm5+cHrVj1rYSeMGGCBg8erNLCUr2pN3WmzvQGlf/Vf7VCKyo+qb8F/xrFxsaqtNSsbJwzZ46uuOIKzZ8/XxMnTlRRfpEmamKllrq+b23+2UYt32mpcePG6ZZbbpEkzZw5U7/88oueeuopSdL69ev9qk3j4uL0a8Gv3n1Wfd+6q7uSlSzFSDt27FCrVq3Urp3587GnStf3Z99AoQLQcCv8G+zfRqkho9x8D9ZiN6FPQpBnhZb9n2xlvVh1J6dWp7bSkKVDaj3vnhf3KPP5zIqqUp8QtGBNxd6UvlsLhMOzD3Fd5/GV911eg3TBOBoQVAJALZRklih7drbyluapYFVBtb+QxHaKVdKwJLUa1UppU9Io/QdQpYLSAq3bv05r9q7R6n2rtWbvGm3M2SiHqxZ7mxmS8mWGkV0kJUrKlfRCwLi2knpIKpcUK3OPyeNqt94Ee4KOa3+chnQYoqEdh2pIxyEamDZQ8fbqv89NP2G6tt62VTfqxtqdsIHEuGJ0+6e3q89tDXORqznJ/jBbpbtK/UJER4HD2wI17Q9p6nxD51rPmzs/V4cWVB0olmdXs+9UNUK1YnMUVP635XQ6deTIkUqtTktLS717WW0u3Kw5mqNzdI66qIuKVKT7dJ83XCxZW6KS1iU6cuSI356JkjR16lS98sorkqQXX3xRK1as8AaVe4v3apEWKU5xaqEW3kAxRSlmw1NbC/W8pqeSk5PVsaO5P0/btm01e/Zs9e1bcRFqzpw5slqtSkpKUnx8vA7975DWn7O+2q/FoJ6DNHT4UO/9mJgYb/BZlZrsCxhOoGhLsvm3OQ1seZpsU0z72ldpWSwWnbDq6NmHNj49XikTU5Q7t/G1xUqZlMLPxACaFd92241xX+C2Z7dV+k3hBcV9Xumjnk/1lFHmbp3v/ui5bW8X3mXlxOMTlXJhit+cvnMnHBNeaNLUglWLw6J491tVOnXtpM49Kn7GttvtuvLKK6scL5lVbmv/u9bvmKdC02Pi+RN18bSLFYxhGHI4HN7QMjHRrHiOMWL0ul5Xgir+fK7SVZqgCd6gNX1GuiwdLJXCT1/du3fXZZddpq5dzaozZ4lTx+pYb+WrZ5/VIzrinXf71u0q31KutLSKFzt98skn+u6777xB5cqVK4N2BQnmX/qXRmiEyqxl6tmzp6688kq9+eabkqRJkybpyy+/lN1uD1oZGhcXp/Kd5WqhFnpK5rlXa7Xma74u02XqpV5y2By65ZZbalSx2rNnTw0bZlbf/3L4Fx3UQfWR+ftpsYq9bXztsqvcVi6Xy1VtiBpM1ILVuPD+bZTtK1NxRnFYz422gpUFoQchKIJKAAjBMAwd+vqQsmZmKfeT3ND7VbiVZZXpQNYBHfj0gHbcvUMpE1PUaXontRnbptn0hgdQezmFOX5Vkqv3rtYvB3+RUd0GdVXZLClTFdWSnp/lL5HUX2YoOUQV+0q2lyr9Hhzi21GruFZmGOmukhzacah6t+stu7X2P0YO3TFU9j2N68fPAZkDdNyO46TaF+01Soe/O6zynPJKlYmeYDH1d6lKmZASeqIAux/frYKfqv6lqzZ7zvkKFXgFCxR9lZWVBd1Hceu+rdqt3RqmYeqgDipXuV7QC+qlXhqv8XIWOHXzzTfrq6++8j63qCh4tXJ8fLyKi81/XL/k/6L39b76q7+6qIvssmuLtniDxbaWtup0Qie/akRP69OhQyvCwMcff1wlJRUtZC8961INfmuw91W9lTil0146zW/PsZiYGF166aV+wzp08N+fqiZ7ZzkLnIppW7vwz/fPzRJj8atM9LyHc9HOnmTXqLxRoQcipE7TOyl3bm6dW2LVt0431KBEHwCaEN92241xX+C6tNu2t7LL3qr+f3bvNLWTOk2t//8POk7tqDbj2shV5pJRashV5g5V3bfDaYksSfa2drUc3NIMUoPM7WkFXFuhQh7ZwttvNuS8qj5ctVgsiomJUUxMjDeklCSVSz3kv++iJ1DzGH7xcCX2r76V86hRozRqVMXPe/G2eG/gV5XjPztebca08Tv2wQcfeH9Gl8yA8bjjjvMLSFeeu1Llhn/FapnK1F3dJZktZe+8805vUCiZFbUtW7asco/V0tJSFTgLvHuhStJe7dUSLdEETZAklVhK9Nxzz1X7OXn4vpjxyZ1PaoM26DN9Jkn6Rt/oCT1RMfh58z0mJqZS4Pn2229r9OjRKiws1FlnnaVJkybpzjvvlCTN2jRLW7RFMYrxq1r13G67ta3Sn0lXy5YtNXXqVElmq+L169fr5JNPVmpqqhwOh9auXesXuu47tE95yvNWqtpll8XnAkO4AWhN9kNtrMqyylS6r1RxHeiyV1uN60oRGjXDMLRr1y5lZ2crLi5O3bt3V3Jy/bcFOZqtXbtW8+bN896fPHmyt70DouPIhiPaOm2r8lfk120ip5Q7N1e5c3OVPCJZvV/prZYD67dPO4DGxTAM7c7f7RdIrtm3Rpn5maGf7MshKUcVbVvbS/L8HrVM0m6ZP9F1UEXbVs+Lbq2SJtX8VB1bdtSQjkMqKiU7DFH31t3r7cUVWS9V3RYmmrJezlLbM9uGHliPSn4rkSPPUaky0dMCte05bZU8vPY/Z2Vcm6HirVW/+jShR0JYQWVdA0UPwzBUVFTkDRS3lG1RpjL9Wp4WqUgd1VGn6TQ5C5x6/PHHtWTJEn366aeSzLapU6dOVX5+fqVXaAeaoRnqoA6yyaZP9IlO02lmUJnvlGEYio+PV2pqql+gGOzdMAxZLBadc9I5SpmTolSlSpJiFeu9kCBJtjibRn0dOmg7/vjj/e7Ht4mvOqR0cxQ4ar3nW1V/btYWVm+loqu89hcC4jrF6eSck2VPsoe9ZxAaVpuxbZQ8Ilm+3diiLXlEstqMbRN6IAA0IbTbbjziu8Yrvmv9V+23n9Je7ae0r/d5k0ckq88bfaqsWA13n0PDMGRLtnnnC/Z62HB+fqtrAFqVUJWwUvD1Jicn+12Xbteunbd9qyS5HC7FGdWHRYlJiXr00Uf9jv3tb1X0r/XxXbvv5DhY8fvP+Tpf5+k874uPWyW30p49e4KGnYG3u3fv7p1nUvIknVhwovd+N3XThbrQG7DGDYpTTJ+YoOGpZz/U0tJS/frrr8rOzvbO82Puj/pJP1X9Ca0y39u0aeMNKr/66ivdcMMNWrBggcaNG6e8vDwNHz485NcmRjEar/H6s/4sa5xVl19+uTIyMvTjjz9KMn+Xe/bZZ4NWl3o+Fn1XpBKV6Bydo07qpDKV6f/0f+qhHhqkQZKkjdqoQhVWausb7M23CjgSirYUEVSGgaASIa1fv17PPvusPv30U+Xk5HiPWywWDR06VFdccYWmTp2qFi2axibijdWRI0d00UUXafv27d5j3bt3J6iMEpfDpd2P7tbOB3bKKA/vh8Oq5K/I16qhq9T9/u7qclcXWe1c4AOaOqfLqW0Ht3lDSU/F5IHiA7WbyKGKn87Wywwis+Vfyd1PFUHlOZJiJKXIDCVr4Zg2x1RUSrqrJTu07BD6iWEqySxR7nyzDWFj2/Q+d36uSjJLgrYjNAxDzkKnf2WiT6Vi8sjksNpTrTpxVbVtTW1JtrCCypCBYn4t2gn7KE0oVbayKwWKnjfLDxa1uLuFCgoK9Nxzz8lqterbb7/VnXfeqQceeEDnnHOODMNQbGysHI7QazhFp5hBZb5T69at0zfffOP9BbxNmzYaMGBApTDRN2gsXVSqI+8fUS/1kiRZZdU8zfP+kuoocOiFFwL7IofWtn1bdVHVexs5jzhluIxa7xkWspWq1Zy7tkFlQs8EDVk+xL/asaWtzj97WGwWxabE1mkONCyLxaLer/TWqqGr6v1n2bDWE2uuh64iAJob2m0jXAnHJITd5rY6bce19XaoMAxDhtPwrwItM2RLrH0VaGz7WHX7e7cqK1ZdpeFVrTZUANpQ80rBw1WL+02S7Al2dezUsdbznhF/hl+l5kD3m0ePS3uo2z3dqp2jbdu2ysryf4HwS/1e0oHlB/yqSj2tdstVrtaXtFb7m9v77U06ZswYvf322xo40Dx/fHy8HnnkEb+Qde/cvcrfnu+3z2q5yr2/L1liLYqLi1NCQsXf89zcXK1du9Y7T3W/Gw7VUHVSJxWqUE/raU3SJG9Q+Ype0TqtC/UlVSu10jzNkyR9qk/1sl7WI3pEgzRITjllre2FlBoIZwsMEFSiGocOHdIdd9yh119/3e8blYdhGFq1apVWrVqlRx99VLNmzdL48eOjsNIKDz74oO67774Gm/+NN97QVVdd1SBz33LLLX4hJaKnLKdMGyZtUP7yOlZRVsMoN/Trvb/qwOcHNHD+QMWmcrEPaCrKnGXamL3Rr0py3b51KiwvrN1ERaqokvR8LJV0m/txh6QjMluSdnS/d5D89nmvwZaANotN/VL7+VVJDu4wWK3iw28DFY7s2dnewLXRbXrvNNfX9Y6ulR5amrhUruKqX+Xb540+YV1gsCXZqg0qw/3lxp5k976S1yKLilWsPdrjDRTj1sYp6dUkvzapntan1113nc444wxJ0sCBAzV06FC9/fbbkqSHNz2sT/Vp1Sfe4H6X9Mgjj6hly5ZyOBzKysrSkSNHzPVYLLrkkktkt9u9wWL5snKVfVvmbZ2aqEQlKEFtZVa4Ogoceuedd/zCjdGjR2vx4sXVfh32OPZo2/vb/I61UsXf+bC/vjW4+OIsdMqeVLtfs1r0baF+7/UL2kLVnmSXtYU1rIDHlmBTqxGR/beOxqPlwJbqfn93/Xrvr9Feirrf351uIgCaLU+77caGdtuwWCyy2C2SXWGFk77iOsepxz96hB5YS/Hd4nXKgVP8q0o9Yaj7dou+4RXHpP0xrcqKVVepSzFtar/3udRw+5YapQ00b5mhWPdbMF26dlHPU/33Qundu7d69+7tvZ+YmKi77rrLb8z6zet1cPvBKs9rjbPq1Vdf9Tt27bXX6tprr/Xed7lclapDN/9ls7I+ylKazIrwRCXqCT2hFFV0BpqiKTpTZ1YKXQPffPeAbaM26q/+aqmKn0ktofbCCUNNqoRRGUElgsrIyND555/vDc4sFoumTZumG264QX379lVRUZGWLFmihx56SKtWrVJWVpYmTpyo++67TzNmzIjKmp1Op2bNmtWg5/Bs9Fzf5s6dq9dff71B5kbtlGSW6P+zd9/xTdX7H8ffSSedtLSlLatsxLIKIiiCylBBUYZevYqCG/e4uEUQB05+XvdVAQcuBETFxQYFFaGgyBaQ1dJBacvoPr8/QkND0jZJ26Tj9eSRBz3fc87nfJKWb0o+5/v9bhi0wWOLNuesztH6/uvVdWFX7nQEaqEjBUe0IXWDzZqSG9M2qrCk/AKTHUNSjiyFyJaSGskySvKNU46LkNRCUqEsoyS7S0qSSwJ9A9W1aVebUZJdYrqokZ9npzpxJHtltrdTqFD2T9nSBPt2c5C5wkJldRW8DBnKU57MMitAASrOLdbKlSuVlZXlcA3GstudO3fWyy9b1nV54Z8X9Jk+05f6UiEK0V/6SxPKPrElJx4O9O/f31qojIqKsplKqX/b/grYFaCgE39OLSxGd4tW79m9FRoaap1lY+DAgdq7d6/NNWbNmmWz/c/Uf7RreflFlOLcYrcKdJUVCouPFFunc3VF0GlBSngywVpA9Ak7WUy0FhfduUM9yl9N/139U4oBLR5socwFmTV6A15lwvqGqcUD5Y9EBoC6rnS67Xm/1J51gZluG3WFycfk8nrpzvAJ8lHnjzpXe1xJ6rGqh90o1bJF0LC+7i2VFtwtWH5N/codseoTVDProdZUYdWZKYbNZrMCAwMVGHjyM9GcgBz56eTPhL/81VM9bc47U2e6mK3U78SfUpUtveEulsZwD4VK2Pn99981ZMgQZWVlSZL8/f312Wef6bLLLrMeExgYqMsuu0wXX3yxrrzySs2ZM0eGYWjy5Mk6cuSIXnzxxXKi15z58+dr//79NRY/JiZGAwYMqPa4KSkpuvnmm6s9LlxXkFbg0SJlqWNbjmnDoA3qsbIHIysBL8o8lmkzSjI5JVnbMrdZR6e5ZLOkfTo5WvLYifZ/S+ogqYkshcimOjlS8tR7FSr53TYsIMxakEyKS1KPuB7qFNVJvuaq/3pXfKxYKdNTVJJXopK8E/85OvF1Sb7l75YPt1TwacFOx8xdm1vlvGpS7u+O8/MN81VRZvnT0RTnFmvfvn0qKiqyri+ybt06/fHHH3aFxbLFxYM7DipXufqv/qtwhWuDNuhe3au7dJdGaISKc4s1evRom7VFHAkODpaf38n/xLWJaqMzd52pkhPDV5urucZpnLXAGJMUo8SnEx1Omervf/I96NQRiyN6jlCvRb3Kz8MIVvv27SvM1ZFKC4puFoIbdWik2LGxdiMTyxYWZUiu3kDbqE0jJTye4FZOgDeYfc1KnJ+o5HOSPf47rmQZLZw4P5GlDgDUa6XTbecm5TLdNtAAhPVyrxBZma7fdK2RuG2ea6PCjMJyR6w2HtDYrbg+IT7yjfQ9ua7qKf1fVUaA1mWVLusBhyhUwsaePXt0ySWXWIuUkvTCCy/YFCnL8vX11UcffaS//vpLW7ZskSS99NJLatGihe6++25PpGz1xhunDk2pXiNHjpSPT/V2NIZhaNy4ccrIqH1ThDQ0JYUl2njZRq98gCNJx7ce18ZLN6r7iu58kAPUMMMwtC9nn80oyXUp67Q3Z2/lJ5dVLCldJ6dtjZOl+ChJK060+0pqKplOM6lRZCMFBQapUXoj+Rf7y7+Xv/yL/OVX5Cf/3f5a03aNCv0cj9RsGtz05HqScZbiZOuI1irYU6DNYzarJK9Ex/OPa23e2pMFxRNFxV5reyn4dOcLipJUcrxEO+7cUeExTa9t6nShMj8lXwUHClzKoSYYMlSkIuvdmWlKU4pSdJpOkw5I//zxj75Y+IVNYfGfQ/8oW9k6ruM2azKO0RiN1EgV5RSpX99+io+P16+//ipJ+vjjj/XSSy85zMHHx0ehoaEKLAxUgAJUIMvrEq1oXaAL1FzNJVmmPH3xxRdlGIbd+oul28HBwXa/m4zpOUYD1wy0bscqVtfqWut2eEi4elzYw+XXrtKCYo57BcWAVgEK7xfucGSib5ivfBu799+VsDPCFDajZj5AAOoa/2h/dVvUzeM35AV1ClLXhV25EQ9Ag8B02wBqqyYXNamRuInzEm22jRLL6M/SgqjZ373PN2P+FaPg04PtRqwWZhUqY3bt/wzd3amKGzoKlbAqKirSZZddptTUVGtb//79deedd1Z4XmBgoF577TUNGjTI2vaf//xHffv2Ve/evWss37K2bdumJUvKmcesmlx++eXVHvPVV1/VDz/8UO1x4br1T6zXntV7vJrD4dWH1eT5JpUujA3AeSVGiXYc2qHklDIjJVOTlXHM8S+3sVmxOmvrWfIvOlFELPaTf5G/fAp81KikkfyL/PVMm2dk/GZYpm8tW5tJ1MlC5VBJAbKMnPSRTt9zul6d/mqFuV5+3+XK8MtQ68at1SOuh5Jik6xFybjQOIfnGEVGpVOqluS5vj6CObDy/1BUNs1LWce2Hqv8oNK4J4qJhSpUwSl/mqu5/OWvEpUoT3nard1KUIIk6XN9rlSl6riO66iO2hUWS/+0VVv9T/+TJM3XfH2sj/WhPlRzNdc/v/2j//znP3Y5+cvfOiIxSEGKUpTCZCmCFecW64477lBIyMkPg8aOHatzzz3XYXExMDBQJpNJm67apLRPT46WbKZmekgPWbeLc4o1ZswYp1+3UpXdveluQdEv2k/+8f7lTnnqH+deISLq4ihFXRxV+YEAqiSweaB6rOxR4+uwlwrrG8Y67AAaHKbbBtCQmcwm+QT62M8W5aLoUdGKHhXtcN+qZqtqxU3Q5fGP91dAbIC306iTKFTC6vnnn1dycrJN28SJE52aKmLgwIHq06ePfvnlF0mWouc111yjDRs2qFGjml8X64033pBhWD4wDQoK0jXXXKMLL7xQnTt3VlxcnBo1amQzLVplCgoKFBMTo+xsy4e/TZs2rfZpXzdt2mRdhLhLly76888/qzU+nHdk4xH1fLZn5Qd6wLJJy9RkeBPufkS9UXysWEWHi+xG+ZV+bfIxKXJIpMtxM7/N1D9P/2MTqyS/RIXHClWcV6wic5Gm/HeK1qeu15GCI07HTUhL0Njvx2q7tmuHdmibtmmHdqhABfpYH0uSnot/TkW5RVIbWaZsLZ26tewSMKd8NlDgU/kv0p9f8rm6n9ldEY2cX0vGmYKiK4VKwzBUUFCgY3nHlKUslahETWS5+zJd6UpVqtqpnRqpkQ5nHtZ3H32n/Px85eXlWR9lt0u/HhA7QG3URpL0rJ5VkYr0uB6XJM3WbH2mz2wKkuVNtztd09VarVWkIqUrXUu1VOM0TpL0nb7Tbu22HttIjazrJ0YoQs3UTI3UyDpiUZL6qI8iFalQhUqSEhonaNWqVTbFxV1X7VLuj+VPW1ucW2x9Py+VmJioxMTEcs6wqLSg6OaUp6VxTb4mm5GJpV8HdXDv7s74m+MVf3O8W+cCqB38o/3VfUV37X1+r3ZP2l0j0xOa/ExKmJSgFg+0YJYQAA0O020DQM0K7RmqzAOZkqTDOlylWMUn7jyvapzGamz9OrRXaJViNWQUKiFJ2r17t6ZMmWLTlpiYqIEDB5Zzhr0bbrjBWqiUpO3bt2vatGl65JFHqi1PR44dO6aZM2dKks455xzNnDlTbdq0qVLMhQsXWouUUvVP+1pQUKB///vfysvLU2BgoD7++GN16dKl2uLDeYZhaOuNW72dhpVRaGjbTdvUY1UP1pOAR2WvzlbOLzk2hb+y6xL6N/NXm6dc71sPvHlAf//n73L3BzQPUN+9fV2OeyTtiHJWOb5T2SyzzGazftrzU8VBDEm5skzb2lJSoHQ457CGa7jNYfGKV3u1V6EK5Sc/NerSSLl9XVxv0Ykb6s6IOkO+Jl/l5+crIMBywq5du5Sfn69OnTpJkv7++29t2rTJWgg8mnFUm7VZBSqwG4F4la5StKK1b98+jRk+RqNGjdJ1110nSRo9erT+/PNPh4XFslqohT7QB5KkH/SD3tN7ekfvqJ3a6WDaQY2Z4NyIv/DLwq2FynSlW6c7laRQhSpOcfKTn/zL/Dl121/+Cle4JMlXvmqiJhqgkzcRTdVU+chHQQpSoAJlrmyRT0ldTvwpFahA9e1r+/OY0jhFuSr/+12UU/76lRXxCbP/vcLcyCyfMMsoRf9m7o1CavGfFmoxoYXMAWbeRwDYMfua1eqRVmoyvIm23bRNOb9U36ifsD5h6vBOB264A9CgMd02ANSc8HPClfm1pVA5QiOqJWZV4yzVUuvX4f3Cq5pOg0WhEpKkqVOnKi8vz6Zt5MiRLsUYPXq0br31VhUXnxwBMHXqVN1yyy1q0qRm5sKWpFmzZik7O1ujR4/WrFmz5O9f9V/KvvjiC5vtK664osoxy3r00Ue1YcMGSdJzzz1X6agL1JysxVnK/dXFgkMNy/klR1mLsxQ5yPVRZqg9Cg8Xqji32HbEX5nin1+Mn8LOcH39tD0v7lHG3IxyRyiG9wtXtx+6uRw3c0Gm9jxd/vTHwYnBbhUqTQEVF0qcGe136Pgh61qSpetJxq6I1RN6otxzfEt8ZS4xq8R8SvzNkvbr5LqSR0+0j5HUVjI1Nqm/+qu92itRiWqndkpTmnKUo2Qlq1CFlhh+kopkmfq16MTDT9JZUqh/qFqltVLRH0W6/t7rdeEZF8p/q78uf+1ym2LiqYXFwi6W9SkffPBBTZ06VZI0atQoHT58WDt37pQkzZ49Ww8//HClr5kkDdEQRStaBccK9P3339vcEGMYhvz9/a1TkQYEBCgwMNDm60MfHFJE0cnRnT3VU43UyDrCsmlwU82bN8963qlxym7n/pCrzV9uliS9rJdt8rzwxB9XmGVWiEKsxU9JaqqmLsVwGDfAvrhZ4chHk2X6XXe0uLeF4sbFWadQ9QnxqZa7330aVe962gDqp5DEEPVY1UNZi7N04I0DypifIbk+U7jkI0VdGqX48fGKGBjBDRIAIKbbBoCaEnNVjHY+vNN2GZ7awseSH9xDoRI6cOCAdURiWZdccolLcRo3bqyePXvqt99+s7bl5ubqf//7n9MfqrrjzTff1Nlnn11tRcrCwkLNnz/fuh0bG6v+/ftXOW6pZcuW6eWXLR/SXnjhhZWuAYqadeCNA95OwaEDbx6gUOkh6fPSlbcrz7bwV6b41/jcxoob53h9wIpsvXGrMuaUv8h39OhonT77dJfj5u3Oq/A/uyXH3PmUsfIpREvyay5uSUmJ8vLy5Ofnp7TjaVqzd40Wr12sjQc2akvqFqUeTj1ZDDxRHMzfn68v9IXaqZ26n1gY8gt9oRzl6Fpdq3/0j/StpB2yFBAbnTj3oE7+Qms+8dCJfZLyivO0QisUq1hr3AmaoC3acjLpBY6fS5OmTfTLJ7+oTUQb/d+0/9P9/3e/+j3VT12adtHOPTu1T/tsRgeGKMRmO/q8aIU2C1X37t2tMW+55RYdP37yTuxhw4apWbNm1gKgv5+/tgzdYjfy0F/+1jUUm4c3V0GB7dSzc+bMqfD7Ikk/zf9JRZknRwueduJPqUAjUJdddlmlcSQpPyK/8oNqAUdFyWbjmylqeJTdFKo+oT7yCfZx+0P5gGYBCmjG2hUAvMdkMilyUKQiB0Uqb1+e0j5JU/ZP2cr9PbfCtX/84/0V2itU4f3CFXNVjAKbV3EhIgCoh5huGwCqX2DzQEUNj1LGvPI/b/OWqEuj+L24CihUQu+8847dVG+NGjVSjx49XI513nnn2RQqJcv6kQ8++KDM5ur/pWn16tXavn27Nm/eXC1FSklavHixsrKyrNujRo2qttwPHz6sa6+9ViUlJYqOjtbMmTO569iL8vblWe4elzRP86oU605ZCs6v6tUq5yVJGfMzlLcvr06+wRWkF6jkWIndSMLS4l/QaUEKauf6Gmmbx27Wsc3H7EYQlo5QbPFAC7We3NrluPtf36/Diw+Xu9/sb3arUFlpgc6FdQM9ETffnG+dktPRqD/jkKFdn+5SXl6eLrroIjVt2lQ5OTmaNm2aevXqpWHDhkmSnn76af3111/W6URzducoS1l2owdDFarpmq6i40UafPtgLXlriRrf1liHYw5LOdIpg+7s7NIuva7XNUIjrAXF+ZqvFKXoU31qGfn4+4mDfWQpVPpICpHlt5/AE3+XPk4MHCwOKtYIjVCiTo50v1yXK1vZ1ulI9922TwldEnRa7GmKj4hXo0aNFBgYqKCgILWLbCdJuuOOO3T77bdb35uaJzTXXM2t8Dl1e6ybIs63XZ/ylltusdnu0qWL3VThgebACkfBuF1kdjC60CauCz9rQR3dWxfR04I62ecZ2jNUoT1ZZwJA/RbYPFAtJ7SUJli281PzdWzLMevsEOYAs2Wd205BCojlJgsAcAbTbQNA9Yu/Lb5WFirjx8d7O4U6jUIl9Omnn9q1denSxa01Gfv06WPXtm/fPq1cuVIDBgxwcEbVxMXFafbs2WrevHm1xazJaV/Hjx+vvXv3SpKmT5+upk2rPk0d3Jf2SZr1w/2yCx+7w0c+1RLHqtiSX8sJLasnngP7X9+v4mPF5Rb+4m6OU+NzGrsc9/cev6tgf/l34bd9qa2C7nO9aHF041EdWXuk3P0lx2vZSMLKijz5JSoqKrKuDehorcDSryVp6NChkqRt2du0QAs0QAMUoxgd0zHN0AxrAbBke4mCRwbbxC2N969//UsTJ06UJF1wwQX666+/tG/fPknS7OTZelyPl59wpqSrLF8uXbpUTZs2VV5eniZNmqTx48dbC5ULFy7U8uXLZTKZLFN/mgPkIx/reoNBClK4whVxojJoKjJpSe4SqZt02HTYcoFASf1lW0j0leXfa66kHCk4NVihKaH6Rb/oLt0lyTLV6RzNUUd1VDu101cXf6UjbY5IjSUnliuUJBUHF1vjlTpf59ts97yhp0KTKi5cnXrzTGU/Z1LVitcVjaR1N25AfIBMZpPMgWaZA80yBZz82hxoVmCC8zdSBMQFyD/ev8IROt7mH+/Ph+8AcEJAbAB9IgBUE6bbBoDqEzEwQmF9wjTvl6oNOqlOYX3CFDEwovIDUS4KlQ3c+vXrtWXLFrv2rl27uhXvtNNOc9j+xRdf1EihMiEhQQkJCdUWr6ioSF9++aV1Oy4uTv369auW2B999JG1KDx+/HhdfPHF1RIX7steme3tFCqU/VO2iu8s1h+D/3C4FmHpI/HLRDUZ6vo6sH8/+LdKjpb/v6PG5zZ2q1BZnaOwbOJW40hCwzBUWFio/Px8HTYdVprS7EYQhitcLdVSJXklWrRokQ4ePKirr75akrR27VrNnz+/3MJiXl6esv7M0hEd0Z26U53USbnK1TiN00AN1HiNV0leiQYPHqxly5ZVmm9ERIQOHTokSVp/cL3e0BtqozaKUYyKVawvVOYGi2zJPN/scM3Asv+R7dWrl6Kjo63bia0TNVIjbaYOLS0u+stfgYGB6j6ruwICAqwj+iIjI/Xnn3/axJnz1RxtztysP9L/0PqD65X3fZ6uf+P6Cp+ff4K/CtqXKWD5SzpDlnUkW0kKkGVdyXdOHnJURxWqULVTOxWrWD7y0b/1b12ja2SS5XkubbNURyLLL25Lkr+Pv7rEdFGP2B7qEddDPYweyn+14mlK3fkZruzfhbtxJanZ7c1kFBsni4gBZpuvw852fS1USeq5pqdb55UntGeoMg9YFr0/rMNVilV8Yv7eqsYpe3NJaC9GTQIAAKBmMN02AFQPk8mkDu90UG5Sbo1Mq+1yPv6WfLh5pGooVDZw33//vcP2Vq1auRWvXbt28vf3t1sLa8mSJW7F87SlS5cqMzPTul1d077+888/uuOOOyRZirkvvfRSlWOi6nLX5no7hQrl/p4rk69J2T9VXFB1u/AXYK6wUFlTaxIWHy8ut8CXkJCgsLAwFRYW6ocfflB8fLySkpIkSctzlmu7tttMH1q2uOizwEd+//jJ19fXuv7enDlz9Oijj+qdd97ROeeco+zsbMXFxSkvL0+GUfEvMxfpIj2gB1SSV6IXXnhBq1evthYq169frylTpjg8z9fXV4GBgfIr8pOPfJQny4hIX/kqVrHWwkhJXokuHHWhWrdubVNMdPR1cHCwNf7gboMV+nWoWssyzW2wgvW5Pj+57mHzEJ2z95xKvkuWKVrL6tOlT4Ujgk3FJg0YaXvDSW5hrtKD0/XD3z8o+edkJacma0vGFpUYJ392euZWXuzyL/JXwY4C6YAsxckUSUdP7BwrKUFSlKQukuIsj5Y+LfX+9Pdt4pSObC7lV+xnsx3iH6Lusd3VI7aHkuKS1CO2h06LPk3+PidHPxZkFGhN0zV2xb6yX/uEuT7jgMnPpO7LutuMSDx1hKLZ3733m7bPt3XrPE8LPydcmV9b3mNHaES1xKxqnKVaav06vF94VdMBAAAAKsV02wBQNSGJIUp4IkG7Htvl7VSU8EQC03BXAwqVDdyqVasctrs7laqPj49atmypHTt22LRv3rxZGRkZioqKciuup9TEtK8lJSW69tprlZ2dLX9/f3388cdq1KhRleOiavJT8mv1FISSVHCgQIUZhZZ19YrLP87VkYSlhcHDfod1VEfVVJYpiLOUpT3aowQlKFzhyj+arw8//NDhaMFT2/r27avbbrtNkvRqxqv6U3/q//R/kqQlWqLX9NrJouJThdJTjvNbsGCBhg4dqoKCAl1yySW67rrrNHPmTEnSvNR5WqmV5T+5nZLfXj+Fh58sNpjNZvn6+lqLkoGBgTrvvPNsCoHHVx9X0ZYiu5GEpYXAkvwSTZ48WTk5J9cTGTFihPr27WtXUAwICJCvr+WtdeejO7XnmT3WcxqpkV7Ta9btkvwSPfjgg05812zFxcSpi06uUWiWWdE6OaLRnO9esauyEX9GoaEFWxYoOS1Z61LWKTk1WbsP7640boHvyX9nxSrWHu3R9hN/EpWoARog/yJ/aZEs08v6SIqR1FGWomTkiZMDJI06GTf3SK7m9p6rAt8Cm0ehT6EKfAsUEBygbl266aq2V1kLk20j28psqvh5+kf56+zUsyt9Xq4ymUxqPKBxtcetS2KuitHOh3dW2J95jY8lPwAAAMDTmG4bAFzX4sEWylyQqZzV1bf+r6vC+oapxQMtvHb9+oRCZQO3evVqh+1VWfOxadOmdoVKwzC0fv16DRo0yO24Na24uNhm2tf4+Phqmfb1ueee04oVKyRZRjB17969yjFRdce2HvP4NUtUokIVypChQFmma0lTmnKUo3ZqJ0lKV7q2aZu1qJf8QrJ2m3crvzjfbgThMA1TO7VT3pE8XXLJJTrnnHP0wAMPSJLuvPNO/fDDD3YFxVNHO/vJTz/qR0nSGq3Rs3pWUzRF/dRPRceLdO211zr13IqLi62FysPGYR3UQeu+EIWouZpbpxENbxuuqD5RDkcOtmtneR0aNWqkmTNnqn379tY493a9V1cuvtJmOtKyhcX40fHqOtt22uoRI0ZoxIiTI64CAgK0YMECm2O23b5NB7YcKPe5leSV2K2/GxkZqcjIyHLOsKjOqWpdiuvmSFifMB/5x/nLHGBWkV+R8nzydMR0RNnKVlZxlo6YjmjyrMkq8i1yLmCJJLO0s+lOXXP2NcrYlqGCQwUyik+OZJ3XZZ6euvQpFfkUSZfIsjZltCQnBixmhWTp1aGvSpJahre0GSXZI66HmoU2Y9qNWiaweaCihkfVykXvoy6NYhotAAAAAADqCLOvWYnzE5V8TrKObz3u8esHdQpS4vxEmX2rPhsjKFQ2aPv371dGhuMPC6tSqIyJcTwiYdOmTbW6ULlixQqlpaVZt0ePHl3lD7nXrVunJ554QpI0cOBA3X///VWKh+pTnFO9Q3oMGTqog7pVt9qtdVj6p0iWAs/5Ol+P63FJ0qt6Vau0Sou0SCaZ9If+0FNlhxu+XP41u6u72qmdzIVmLVy4UE2anFyn0my2rFHYuHFjazHw1GlFs+dky5xlliFDJpnUSZ10p+60jiT0LfLV/PnzK5yStPTrgICTd39OSZyiw0sPW7d7n/hTKm5gnDq+3bHC19NsNuu6666zaesY01ERKn9halOBe/9ea2xNzRqKG9wlWM3ubuZwSlJzoFnmIOd/QSoqKdLm9M1KTk1WspK17pl1Wp+6Xjn5Lt6NlicpVZYpW0v/NkkaLx0NPKqjQUctU7kmyDJKMtbyd3FEsVSabkLllzHJpI5RHS3FyNI1JWN7qEmQ62u0wjvib4uvlYXK+PHx3k4BAAAAAAC4wD/aX90WddOGQRs8WqwM6hSkrgu7yj/av/KD4RQKlQ3Yrl3lz+FclUJldHS0w/bt27e7HdMTZs+ebbNd1Wlfjx8/rquvvlqFhYVq0qSJPvjgA0b31CIlBe4ViSpSpCJlK1t+8lOgAhWmMLvRf37yU2d1tp5zvs5XB3WwFgtP1+l6RI9Yz2v/WHulv5kuU6bJer51LUKdmP+8QMrLy7PJ5ZVXXqk039/X/a4jWUes2y1P/Cll5BsaPny4y6+D10YSuhnXr4mf/Jv52xf+TmwHdQpyK27MVTEK7xduH7PM+oTuCO8TrvA+rq+ld7zwuP5M+9MybWuKZT3JP9P+VF5RXuUnl5UrSzEyQZKfpD2Spp+apKR4WUdVqo+ks2QpXjrJz+ynxJjEkyMl43qoa9OuCvFn3v+6LGJghML6hGneL/O8nYpVWJ8wRQws/yYIAAAAAABQOwU2D1SPlT208dKNHpkGNqxvmBLnJ1KkrGYUKhuw3bt3O2wPDg5WSIj7HwSXHVlVVmpqqtsxa1pJSYnmzTv5oWnz5s111llnVSnm/fffry1btkiS3nnnHcXH17/RGuWNyK0O5RW8q4vZv3qH5ZtkUnM110zNdOm883SezXbsiT+lEnsnasesHcrLLL+YVNtG/NVUQTFiSIR8I3wdjyIMNCughXtrerR6tJVaPdrKrXMrEtgiUIEtvDOV5OG8w1qful7JKclal2opTG7J2KJiw8WRxIakzbIdKVla275BUgtZpmpNlGWkZOloyVNru5VM5RrsF6zusd2toyST4pLUObqz/H34pa++MZlM6vBOB+Um5cooNCo/oabz8bfkw41EAAAAAADUTf7R/uq+orv2Pr9XuyftrpHPG0x+JiVMSlCLB1p4dbrX9PT0Golbk5/zO4NCZQO2b98+h+1BQe6NHipVXqHy4MGDDttrg59++smmkFrVaV+//fZbvfnmm5KkG2+80WaNvPqkc+fOlR/kJsOo2Q+wfcKcWASvFvAJ9amxNQn94/wV0DLA4ShCc6BZwZ2D3Yrb+unWljdtB8VEc4C50gJpeZpe2VRNr2zq1rn1WeqRVEtBMmWdZQrX1GTtzNrpWpASSRk6WYxsJamTLCMgf5R0WJZiY4yk9rIUJEsHdTaSNNr5SzVp1MRSjIxNsk7d2i6ynXzMdePfJKouJDFECU8kaNdj5c/s4CkJTyQoJJFRugAAAAAA1GVmX7NaPdJKTYY30babtinnl+obXRnWJ0wd3ulQKz4/KG/ZvbqOQmUDlpPj+B9rTRUqy7tebVCd076mp6fr+uuvlyR16NBB//d//1eV1FBDgjpW7efcU4I6BSn2ulgVpBeUW/gL6e7em2TinMRqztYi+DT3CpyomGEY2nV4l3Xa1tLCZOoRF0erl07HKklrJa2TdFA6sYSqRYEshUpJGi7LCMkoufxbQ4uwFtZiZOkUrs3DmjN6DWrxYAtlLsj0yLQs5QnrG6YWD7Tw2vUBAAAAAED1CkkMUY9VPZS1OEsH3jigjPkZls/CXOUjRV0apfjx8YoYGMFnWTWMQmUDduzYMYftjRo1qlJcHx/Ho2Ly8/OrFLemGIahuXPnWrdbtGihPn36uB3vxhtv1MGDB+Xn56dZs2YpOJiiTW0UEBcg/3h/FRwo8HYq5fKP91dAbIBaPtiy8oNRrxSVFGlrxlabUZLJKcnKzs92LVCeLEXIlDIPX0k3n9h/VFKWpJY6OW1rnKTIMjHaVH4Zk0xq36T9yfUkT0zhGhUU5Vq+aDDMvmYlzk9U8jnJHl3wvlRQpyAlzk/06nQtAAAAAACg+plMJkUOilTkoEjl7ctT2idpyv4pW7m/51b4WbB/vL9Ce4UqvF+4Yq6KUWBz7yzp1BBRqGzAyitUVnVEZXGx4zXQCgpqZ0Fo1apVOnDggHW7KtO+vv322/rqq68kSZMnT1avXr2qJUfUjNCeoco8kOntNMoV2ivU2ynAA/KK8vTnwT+txch1qev0x8E/lFdU/rqkDh2RZerWBFne3XdJev+UY8IkNZdl7UmTpLMlnXPiayf5mn2VGJNoHSXZI66HujXtptAAfl7hGv9of3Vb1E0bBm3waLEyqFOQui7sysL3AAAAAADUc4HNA9VyQktpgmU7PzVfx7YcU3FusUryS2QOMMsn1EdBnYIUEOt4pkjUPAqVDVh5awBWdURlSYnjsdTlTQnrbdU17ev27dt1//33S5IGDBigBx98sMq51XabNm1SVFTdHTEVfk64Mr+uvYXK8H7hlR+EOiUnP0frU9efHCmZkqxN6ZtUbDi+waNchqQtsoyQLF1XMvfEvpslxUuKlpQo25GSp96HUsmykEF+QerWtNvJkZJxPXR69OkK8K2d/TnqnsDmgeqxsoc2XrrRI9PAhvUNU+L8RIqUAAAAAAA0QAGxAXW6IJmWllYjcTMyMtS5c+caie0MCpUNWEhIzSz+mpfneBRQVUdq1oRTp31t2bKlW9O+FhUV6eqrr9bRo0fVuHFjffjhhzKb6/90clFRUYqOjvZ2Gm6LuSpGOx/eKRVLh3W4SrGKZSk0VTVOYzW2fOFjyQ9118EjB21GSSanJOvvrL9dC1IiKVMnp21tLamDLCMgv5WlOGmWFCOprSzFyNKBjSGSRjt/qYjACJtpW5PiktQ+sr18zJVUM4Eq8o/2V/cV3bX3+b3aPWm3jELHN1JVhcnPpIRJCWrxQAumewUAAAAAAHVSXf4sviIUKhuw0FDH0/SVV2h0VnlrUVZ1pGZN+PXXX7V3717r9uWXX+5WnEmTJmnNmjWSpLfeekstWrSolvxQswKbBypqeJQy5mVohEZUS8yqxlmqpZIsizUzD3rdYBiG/sn+xzJKMsWynuS6lHVKOZLiYiCdnIL1d0nrZVlfsrDMMcWyFCol6VJJwbKMnHTx3bxZaDNLMTLWMkqyR2wPtQxvycLg8Bqzr1mtHmmlJsObaNtN25TzS/WNrgzrE6YO73RQSGLN3KAFAAAAAAAA91GobMBqqlB55MgRh+2NGzeuUtya8MUXX9hsuzPt688//6ypU6dKkq699lr961//qpbc4Bnxt8UrY16Gt9OwEz8+3tspwIHikmJtzdxqU5Bcn7peWXlZrgXKl2XK1tJpW1MkBUi6/sT+XFlGUjaXZZRk6fStTcrEaOfcpdpHtrcWI0tHS8YEM1oXtVNIYoh6rOqhrMVZOvDGAWXMz7CMLHaVj+WGj/jx8YoYGEERHgAAAAAAoJaiUNmARUREOGyvaqEyJ8fxKIhWrVpVKW5NKFuoTEhIUO/evV06Pzc3V2PGjFFxcbHatGmj1157rbpTRA2LGBihsD5h0i/ezuSksD5hihjo+N8nPCe/KF8b0zaeXE8yNVkbUjfoeNFx1wId1clpW30k/S3pw1OOCZNUdrnXcySdq5MjLJ3ga/ZV5+jOJ9eTjO2hbrHdFBYQ5lq+gJeZTCZFDopU5KBI5e3LU9onacr+KVu5v+eq4EBBuef5x/srtFeowvuFK+aqGEalAwAAAAAA1AEUKhuwjh07Omwvb0Sksw4fPuywvWXLllWKW93WrFmjf/75x7rtzrSvTz31lHbt2iVJ2rlzp8LCqrcgMG7cOI0bN86ufcaMGRo7dmy1XquhMplM6vBOB6mLtzOxMPlb8mH0j2fl5OdoQ+oG6yjJ5NRkbUrfpKKSItcClUjappOjJFMlld67MV5SU1mmaj1dJ0dJxskyhWtZlbw7N/JtpG6x3ayjJJPiknR6zOkK9KUwg/olsHmgWk5oKU2wbOen5uvYlmMqzi1WSX6JzAFm+YT6KKhTkAJiA7ybLAAAAAAAAFxGobIBO/300x22p6enq6ioSL6+7v14pKenO2xPSEhwK15NqY5pXw8ePFhd6cCLQhJDtPbhtdrz7B5vp6KEJxJYR62GpR1Ns07dWlqY3HFoh2tBSmSZmrV06ta2Jx4mSV9JOibJLEtRso0sBcmgE+eGSXLhvojGgY1tRkn2iOuhjk06ysfs41rOQD0QEBtAQRIAAAAAAKAeoVDZgEVGRio2Nlapqak27SUlJUpJSVGLFi3cilte8a5nz55uxaspZQuVrVu3Vq9evbyYDbyt+5PdpWVSzmrHUxd7QljfMLV4wL1/d7BnGIb2ZO+xFCRTkrUudZ2SU5K1P3e/i4F0cgrWNZL+kKVAWVjmmBKdLFReJilEUoxcfpeND423WUsyKS5JrcJbMcIWAAAAAAAAQL1EobKB69atm12hUpL27dvnVqEyLy9PGRkZdu3R0dFq27atWznWhHXr1mnnzp3WbXemfUX9YvY1K3F+opLPSdbxrS6uQVgNgjoFKXF+osy+Zo9fuz4oLinWtsxt1qJk6WjJQ8cPuRYoX9JBnZy2NUVSI0nXndifLSldUnOdnLY1TlKTMjE6OHepthFtLcXI2CT1iLMUJ5uGNHUtXwAAAAAAAACowyhUNnAXXXSRfvjhB7v2Xbt2qW/fvi7H2717t8P2Pn36uByrJlXHtK+of/yj/dVtUTdtGLTBo8XKoE5B6rqwq/yj/T12zbosvyhff6X/ZRkleWI9yQ0HN+hY4THXAh2TpRDZWpZpWrdLmnXKMaGSospsD5A0UCdHWDrBx+SjztGdrcXIpLgkdWvaTeGB4a7lCwAAAAAAAAD1DIXKBm748OG655577NrXrVunf//73y7H2759u8P2Sy65xOVYNalsobJt27ZuT0s7c+ZMzZw5s1pycjS144wZMzR27NhqiQ/nBDYPVI+VPbTx0o0emQY2rG+YEucnUqQsR25+rjYc3GAdJbkuZZ02pW9SYUlh5SeXVSJpm06OkkyRVPrtvUOWYmS0pM46OUoyVpYpXMvyq/gygb6B6tq0q82akokxiWrk18i1fAEAAAAAAACgAaBQ2cC1bt1ap59+uv766y+b9rVr17oV748//rBr8/X11ciRI92KVxM2bNhgU1Bl2lecyj/aX91XdNfe5/dq96TdMgqNar+Gyc+khEkJavFAC6Z7PSHjWIZNQTI5NVnbM7fLkAuvf4mkQzpZkGwny4hJk6R5skztapKlKNlaloJk4IlzG0tyYXB1eEC4dZRkaWGyY1RH+Zp5awUAAAAAAAAAZ/BpKjRmzBg99NBDNm3JyckyDMPhKL+KrFu3zq5t8ODBatKkiYOjvYNpX+EMs69ZrR5ppSbDm2jbTduU80v1ja4M6xOmDu90UEjiqcP1GgbDMLQ3Z6/NWpLrUtZpX84+FwPp5BSsv0naKEuBsuCU40oLlSNlGSEZo0pHRp4qNiTWZpRkj7geat24tct9JAAAAAAAAADgJAqV0K233qpnnnlGOTknCzHZ2dn65ZdfXF6n8ueff7ZrczS1rDeVLVS2b99ePXr08GI2qO1CEkPU/efuWvLREu1+bbda/95aPoaPy3GKzcXa1WuXWt/RWt2v7i6zuWGMoiwxSrQ9c7vNKMnklGRlHs90LVCBpIM6OW1rqixFx6tP7M86sT9eJ6dtjZNU9h6Jjs5dqk1EG+soydIRk3Ghca7lCwAAAAAAAACoFIVKKDw8XLfeequef/55m/Z58+a5VKhcu3atDh48aNOWlJSkIUOGVEue1WHjxo3asmWLdZtpX1GZjWkbddPXN+mXfb9Iw6SoflEauHGguuzpog4HOig6N7rcc9ND07Utfpv+bPmnFicuVkZ4hrRT6jOjj9655B0lxiR68JnUvILiAv2V9pe1GJmcmqz1qet1tPCoa4GOyVKILB0JuUXSp6ccEyLLupKlzpc0RCdHWDrBbDLrtKjT1COuh5Jik9Qjroe6x3ZX48DGruULAAAAAAAAAHALhUpIsox6fP3113X06MmCwrx58+yKlxWZO3euXduUKVOqJb/qcuq0rxQqUZ6ikiI999Nzmrx8sgpLCq3tGeEZ+uzsz/TZ2Z9JkiJyI9Qyo6WCCoLkV+SnQt9CHfM/pj1Re5QVmuUw9i/7flHS20l6YsATerDfg3VyTcOjBUe14eAGJaecHCm5MW2jzWvllGJJO3RyTckUSdkn9t0tKUKW9SQ76+QoyVhJoafEqWQq1wCfAHVt2tU6SjIpLkldYrqokV8j1/IFAAAAAAAAAFSbuvfpOGpEXFycJk6cqAcffNDatmPHDi1fvlwDBgyo9Py8vDy9++67Nm2jRo3S0KFDnc7hyy+/1KRJk7R582bFxsbqlltu0UMPPVStU2SWLVR26NBB3bt3r7bYqD/Sj6br0k8v1ep9qys9Nis0q9yCZEUKSwr12NLHtGD7As2/cr6ig8sfmeltmccybUZJrktZp22Z22TIcD5IiSzTs5ZO29peUitZRkB+IanwxNfRkrrKUpD0P3FuE0kuLCUbFhCm7rHdraMke8T2UKeoTvLzcXFhSgAAAAAAAABAjaJQCat7771XX3zxhdasWWNte+qpp5wqVL700ktKS0uzbjdt2lT//e9/nb727NmzdcUVJysRe/bs0aOPPqqUlBS9+uqrTsepyJYtW/TXX39ZtxlNibLS09MlSQdyD2jUZ6P0d9bfHrnu6q2rddarZ+mLK75QfGi8oqO9V7A0DEP7c/fbjJJMTk3Wnuw9LgbSySlYf5X0lyzFyYIyx5hlKVSaJY2QFCapqSodGXmqmOAYJcUlWdeUTIpLUuuI1jKbGsYaoAAAAAAAAABQl1GohJWfn58+//xz9ezZU4cOHZIkLVq0SO+//76uu+66cs9bsWKFzRSvgYGB+vLLLxUfH+/0tZ944gmH7W+88YYee+wxNW3a1OlY5Zk9e7bNdtnCKBATE+O1a+/QDnV/uLskS7HQE0qMEu04tMM6SrJ0pGTGsQzXAhVIOijbqVvDJV15Yn/mif1xZR6xsl1fsrNzl0ponGAtRpZO4RoXEieTyYWFKQEAAAAAAAAAtQaFSthISEjQggULNHjwYB05ckSSdMsttygsLEwjRoywO/6zzz7TjTfeqPz8fElSaGioPv/8c/Xp08el6+7YscNhe0lJiXbu3Fkthcqy07526tRJXbt2rXJMoLoVlRRV+5qVhcWF2pS+yWaU5PrU9TpScMS1QMdlKTqWTtm6SdJsyWYG2GBJZWu+gyRdpJMjLJ1gNpnVKaqTzSjJ7rHdFdEowrV8AQAAAAAAAAC1GoVK2OnTp48WL16syy67TCkpKcrPz9fIkSN12WWXafTo0YqPj9fu3bv1wQcfaNmyZdbzOnbsqM8//9ytAmD79u21adMmu3az2aw2bdpU5elIkrZv364//vjDus20r6itnv/5eT1yziNun3+04Kj+OPiHdU3JdanrtDFtowqKCyo/uaxiSX/r5CjJVEmHT+y7T5apWqMldZJlhGTpaMnQU+L4q0L+Pv7qEtPFZpRk16ZdFeQX5Fq+AAAAAAAAAIA6h0IlHOrdu7eSk5N177336pNPPpEkffnll/ryyy/tjg0LC9N9992nhx56SAEBAW5db/LkyQ6Lh7fddhvTvqLGbUzb6O0UrCYtm6ThHYcrMSax0mOzjmdZp2wtLUxuzdyqEqPE+QsakrJ0siDZUVKLE/s+k6VgaZJlqtaushQlfU7sj5b0L+cvFeIfYh0l2SPOMlLytKjT5Ofj4sKUAAAAAAAAAIB6wWR4akE01FmbN2/WjBkztHTpUv399986cuSIoqKi1L17dw0bNkxjxoxRWFhYla/z5ZdfatKkSdq0aZNiY2N166236qGHHpLZbK5y7KSkJCUnJ0uSTjvtNIejN1Gx9PR0u3Uc09LSFB0d7aWMqodhGOr7Xl/9uu3XqgWafuLv66uYULDUp3kfrbp+lXXtRcMwdCD3gLUYWVqc/Cf7H/ev84ukzbKMlMwv037uiYck/SXLepMxqnRk5Kmig6ItxcjYJPWIsxQn20a2ldlU9X/PAAAAAAAAAIDq4e3P/ilUAnCKtzurmrJo5yIN/nBw1QO9fuLv26seSpIePedRFZcUW9eUTDua5lqAQlnWkyydtjVFUoSk0oHLX0v6U5bpWstO3RqlkyMmndQqvJW1GFk6hWt8aLy10AoAAAAAAAAAqJ28/dk/U78CaNDeWPOGt1Nw6OmVTzt/8HFJaZJandjeKGmOLNO6lgqWZarWUkMkDZPkwgBHk0zqGNXRpiDZPba7mgQ1cT4IAAAAAAAAAAAnUKgE0GDty9mn+VvnezsN1xRJ2qWTa0qmyrLGpCRNkKUgGSXLWpNlR0uGyrLWZKlKlpP1M/upS9Mu1jUlk+KS1LVpVwX7B1fjkwEAAAAAAAAANGQUKgE0WJ/8+YlKjBJvp+GYIUsBsnTa1tMkxZ9o//jE3yZJTSR1kaUYWVqIjJV0pfOXCvYLVvfY7tZRkj3ieqhzdGf5+7i4MCUAAAAAAAAAAC6gUAmgwVq5Z6W3U7C3WtJWWYqT+WXa/WUpVPpJGimpsaSmJ9pdEBUUZR0l2SPOMlKyXWQ7mU0uzAELAAAAAAAAAEA1oFAJoMFam7LW8xctlGU9ybJTt0ZJGnFi/0FJB3RyytbSv6PKxOji3KVahLWwFCNjk9QjzlKcbB7WXCaTqfKTAQAAAAAAAACoYRQqATRIKbkpOpB7oGYvkicpXVKLE9sbJH0py7StpYIkxZTZvkjScEkuDHA0yaQOTTpYi5FJcUnqHttdUUFRlZ8MAAAAAAAAAICXUKgE0CBtzdxavQENWUZLrtTJ0ZJZJ/Y9KKmRLKMiO8gyQrJ0tGSYTq4tKUkBFV/Gz+yn02NOtxYke8T2ULfYbgrxD6nGJwMAAAAAAAAAQM2jUAmgQcrJz6n+oNmSFp/4OkpSoiwFyVLNJF3lWshOUZ00sPVAa2Gyc3RnBfhWUs0EAAAAAAAAAKAOoFAJoEEqKC6o3oAmSaGSLpfUVJWOjHTWlPOmaHTn0dUTDAAAAAAAAACAWoRCJQC3ZWRkOH1sdHR0DWbiOn8f/+oPGiipZfWGDPBh9CQAAAAAAAAAwHXp6emVHuPK5/w1gUIlALd17tzZ6WMNw6jBTFwXFhDm7RScEhoQ6u0UAAAAAAAAAAB1UExMjLdTqJTZ2wkAgDd0bNLR2yk4pVNUJ2+nAAAAAAAAAABAjaBQCaBBiguNU3xovLfTqFB8aLxiQ2K9nQYAAAAAAAAAADWCQiWABqtnXE9vp1ChXvG9vJ0CAAAAAAAAAAA1hjUqAbht06ZNioqK8nYabjun5Tn6etvX3k6jXP1a9PN2CgAAAAAAAACAOiotLa3SYzIyMtS5c2cPZOMYhUoAbouKilJ0dLS303DbVV2u0sOLH1axUeztVOz4mHx0VZervJ0GAAAAAAAAAKCOqguf31OoBNBgNQ9rruEdh2velnnS0SoGKznxd1XjBFv+urTTpWoe1ryKwQAAAAAAAAAAqL0oVAJo0G474zZLofKFagpY1TiTLH+N7zW+qpkAAAAAAAAAAFCrmb2dAAB408DWA9WneR9vp2GjT/M+Gth6oLfTAAAAAAAAAACgRlGoBNCgmUwmvXPJO95Ow8rfx1/vXPKOTCaTt1MBAAAAAAAAAKBGUagE0OAlxiR6OwWrJwY8UavyAQAAAAAAAACgprBGJQBIOpB6QMM/Ga7fD/zutRx6xffSA2c/4LXrAwAAAAAAAADgSRQqAUBSXNM4fXvTtzpnxjnamrnV49fvFNVJ3479Vr5mumUAAAAAAAAAQMPA1K8AcEJ0cLQWXbtIHZt09Oh1O0V10sIxCxUdHO3R6wIAAAAAAAAA4E0UKgGgjOZhzbVy3Er1bd7XI9fr27yvVoxdoeZhzT1yPQAAAAAAAAAAagsKlQBwiujgaK0Yt0JPn/+0/Mx+NXINP7Ofnj7/aa0Yt4KRlAAAAAAAAACABolCJQA44Gv21SPnPKJ1t6xTn+Z9qjV2n+Z9tO6WdXrknEdYkxIAAAAAAAAA0GBRqASACiTGJGrV9au0cMxCjeg0QmaTe92mj8lHI08bqYVjFmrV9auUGJNYzZkCAAAAAAAAAFC3MJQHACphMpk0qM0gDWozSPty9umTPz/RT3t/0u8HfteB3APlnhcfGq9e8b3Ur0U/XdXlKtahBAAAAAAAAACgDJNhGIa3kwBQ+6WnpysmJsamLS0tTdHRDXt9xdQjqdqSsUW5+bnKL85XgE+AQgNC1Smqk2JDYr2dHgAAAAAAAAAA5fL2Z/+MqASAKogNiaUgCQAAAAAAAACAG1ijEgAAAAAAAAAAAIDHUagEAAAAAAAAAAAA4HEUKgEAAAAAAAAAAAB4HIVKAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx1GoBAAAAAAAAAAAAOBxFCoBAAAAAAAAAAAAeByFSgAAAAAAAAAAAAAeR6ESAAAAAAAAAAAAgMdRqAQAAAAAAAAAAADgcRQqAQAAAAAAAAAAAHgchUoAAAAAAAAAAAAAHkehEgAAAAAAAAAAAIDHUagEAAAAAAAAAAAA4HEUKgEAAAAAAAAAAAB4HIVKAAAAAAAAAAAAAB5HoRIAqiA9PV0mk8nmkZ6e7u20AKBeos8FAM+hzwUAz6C/BQDPoc+tnXy9nQCAuisjI8PpY6Ojo2swEwAAAAAAAAAAUJYzhVhXPuevCRQqAbitc+fOTh9rGEYNZgIAAAAAAAAAAMqKiYnxdgqVYupXAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx1GoBAAAAAAAAAAAAOBxrFEJwG2bNm1SVFSUt9MAAAAAAAAAAACnSEtLq/SYjIwMde7c2QPZOEahEoDboqKiFB0d7e00AAAAAAAAAADAKerC5/dM/QoAAAAAAAAAAADA4yhUAgAAAAAAAAAAAPA4CpUAAAAAAAAAAAAAPI5CJQAAAAAAAAAAAACPo1AJAAAAAAAAAAAAwOMoVAJwSkZGhlNtgCSlp6fLZDLZPNLT072dltfxutjjNXGM1wXO4mfFMV4Xx3hdHON1gbP4WXGM18UxXhd7vCZwBT8vjvG62OM1cYzXBa7w9mf/FCoBAAAAAAAAAAAAeByFSgAAAAAAAAAAAAAeR6ESAAAAAAAAAAAAgMdRqAQAAAAAAAAAAADgcRQqAQAAAAAAAAAAAHgchUoAAAAAAAAAAAAAHkehEgAAAAAAAAAAAIDHUagEAAAAAAAAAAAA4HG+3k4AQN1QUlJi13bo0CGlp6d7IZvaIyMjw6m2hobXxTFeF3u8Jo7xujjG62KP18QxXhfHeF0c43VxjNfFHq+JY7wujvG62OM1cYzXxTFeF8d4XezxmjjG6+IYr4tjhw4dsmtzVA+oKSbDMAyPXQ1AnfXzzz+rX79+3k4DAAAAAAAAAADUoJ9++klnn322R67F1K8AAAAAAAAAAAAAPI5CJQCnREZGejsFAAAAAAAAAABQwzxZD6BQCQAAAAAAAAAAAMDjWKMSgFOKioq0fft2m7bIyEiZzdzvAAAAAAAAAABAXVRSUqJDhw7ZtLVv316+vr4euT6FSgAAAAAAAAAAAAAex1AoAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx1GoBAAAAAAAAAAAAOBxFCoBAAAAAAAAAAAAeByFSgAAAAAAAAAAAAAeR6ESAAAAAAAAAAAAgMdRqAQAAAAAAAAAAADgcRQqAQAAAAAAAAAAAHgchUoAAAAAAAAAAAAAHkehEgAAAAAAAAAAAIDHUagEAAAAAAAAAAAA4HEUKgEAAAAAAAAAAAB4HIVKAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx1GoBAAAAAAAAAAAAOBxFCoBAAAAAAAAAAAAeByFSgAAAAAAAAAAAAAeR6ESAAAAAAAAAAAAgMdRqAQAAAAAAAAAAADgcRQqAQAAAAAAAAAAAHgchUoAAAAAAAAAAAAAHkehEgAAAAAAAAAAAIDHUagEAAAAAAAAAAAA4HEUKgEAAAAAAAAAAAB4HIVKAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx/l6OwEAqEmGYWjPnj1KS0tTQECAEhISFBYW5u20AKDeaSj9rWEY2rFjh7Zs2aI9e/YoJydH+fn5aty4se655x5vpweggWgofS4A1Ab1oc89dOiQMjMzlZWVpeDgYEVGRiomJkY+Pj7eTg0AbNSHPvfgwYNKTU1VXl6ewsLC1Lp1awUGBno7rVrNZBiG4e0kAKC6/fHHH3rllVf09ddfKz093dpuMpmUlJSka6+9VjfeeKOCgoK8mGXFdu/erfbt26uoqMit8/v376/ly5dXc1YAYKs+9LeVOXTokL766it99dVXWrFihTIzM232x8bGqm/fvpo7d66XMgTQUDSEPhcAaou63OcWFRVp9uzZ+uqrr7R8+XKlpKTYHRMcHKy+fftq8ODBuvHGGxUZGemFTAHAoi73uZL0ww8/6MMPP9SPP/5ok78kmc1mJSUlafTo0brhhhsUFRXlpSxrLwqVAOqVrKwsTZgwQdOnT1dl3Vt8fLzefvttXXzxxR7KzjV33HGHXn/9dbfPnz17tkaPHl2NGQHASfWpvy3Pxo0b9fLLL+vjjz9Wfn6+tb1r164aPny4BgwYoF69eqlx48beSxJAg1AX+9wpU6Zo4sSJNRZ/xowZGjt2bI3FB9Bw1cU+t6xZs2bp8ccf165du5w+JygoSLfffrumTJmigICAGswOAGzV9T73119/1W233aZ169Y5dXxoaKgmTpyo++67T2YzKzOW4pUAUG9s3bpVZ5xxht577z0ZhiGTyaSbb75ZycnJOn78uDIzMzVv3jz17NlTknTgwAENHz5ckyZN8m7iDqSnp2v69Olun9+8eXNddtll1ZcQAJRRn/pbRzIzM3XLLbeoW7dumjFjhvLz82UymfSvf/1Lv//+uzZs2KApU6Zo0KBBFCkB1Li62OcWFxfr7bffrtFrtGzZskbjA2iY6mKfWyovL0/XX3+9rrnmGmuRMjAwULfccou+/fZbpaSkKD8/X1lZWUpOTtaLL76ohIQESdKxY8f0wgsv6Mwzz9Tff//txWcBoCGpy32uJL388ss6++yzrUXKFi1a6OWXX9b27dt1/Phxpaamavbs2erXr5/1nNzcXE2YMEGDBw/W4cOHvZR5LWQAQD2wZs0aIyIiwpBkSDL8/f2NefPmOTy2sLDQGDVqlPVYScb999/v2YQr8eijj9rk5+rjqaee8vZTAFBP1bf+9lQLFiwwoqKibHLu1KmTsXr1am+nBqABqqt97pw5c6r0u2xlj5iYGKOoqMgrzw1A/VVX+1zDMIyioiLj4osvtsmnd+/exu7duys8r6CgwLjttttszmvZsqXxzz//eChzAA1VXe5zDcMwHn74YZt8Ro4caWRnZ5d7/Msvv2yYzWabc7p27WocOnTIg1nXXhQqAdR5//zzjxEbG2vT0b/yyisVnnP8+HGjU6dONuf83//9n4cyrlhOTo7NG7Wrj4CAACMtLc3bTwNAPVTf+tuyiouLjQkTJhgmk8km12uvvdY4fvy4t9MD0ADV5T534MCBNVqovPXWWz3+nADUb3W5zzUMw7j77rtt8ujTp49x9OhRp88fN26czfmJiYlGQUFBDWYMoCGr633u66+/bpPH8OHDjcLCwkrP++9//2v3e+3ZZ59Nf2sYBmtUAqjTioqK1Lt3byUnJ1vb+vfvr2XLlslkMlV47uLFizVo0CDrtq+vr37++Wf17t27xvJ1xosvvqgJEya4ff6YMWP0wQcfVGNGAFA/+9tSx48f15VXXqmvvvrKpn3KlCl67LHHvJQVgIasLve527ZtU6dOnSpdY6gqFi9erPPPP7/G4gNoWOpynytJ69at0xlnnKGSkhJJUqNGjbRp0ybrtK7OOHLkiFq2bKmsrCxr21NPPaVHH320utMF0MDV9T53/fr16t27twoLCyVJMTEx2rRpk5o0aeLU+aNHj9acOXNs2u677z699NJL1Z5rXcIalQDqtOeff97mjU2SJk6cWOkbmyQNHDhQffr0sW4XFRXpmmuu0fHjx6s9T2cVFBRo2rRpkqTWrVursLBQhmX0u9MPipQAakJ9629LZWVl6bzzzrMrUr700ksUKQF4TV3uc9944w1rkTIoKEg333yz5s6dqy1btig7O1sFBQUu/W6bn5+v8PBwa/ymTZtqwIABHnkuABqGutznStJjjz1mLVJK0lVXXeVSkVKSQkJCdN1119m0/fe//1VxcXF1pAgAVnW5zzUMQ7feequ1SClJDzzwgNNFSkl65ZVXFBAQYNM2bdo0rVq1qtryrIsoVAKos3bv3q0pU6bYtCUmJmrgwIFOx7jhhhtstrdv324tFHrDBx98oAMHDkiyvNH5+vp6LRcAKFUf+1vJsoj9RRddpF9//dWm/a677tJ9993npawANHR1uc89duyYZs6cKUk655xz9Oeff+rtt9/WiBEj1LFjR4WFhcnPz8+lmAsXLlR2drZ1e+TIkfLx8anOtAE0YHW5z5UsN90tWrTIps2V3Ms699xzbbbT0tK0YsUKd1MDADt1vc997733bD4/8PX11ZgxY1yK0axZM1177bU2bYZh6LbbbqvRGUlqOwqVAOqsqVOnKi8vz6Zt5MiRLsUYPXq03QcdU6dOVWZmZpXzc1VJSYleeOEFSVJcXJzGjRvn8RwAwJH61t9KUl5eni6++GK7IuUll1zi9QIqgIatLve5s2bNUnZ2tkaPHq1FixapTZs2VY75xRdf2GxfccUVVY4JAKXqcp8rSStXrrQZ2SPJpZE9ZbVq1cqubfv27W7FAgBH6nqf++KLL9psd+vWTTExMS7HufHGG+3aNmzYoLlz57qdW11HoRJAnXTgwAHr3dplXXLJJS7Fady4sXr27GnTlpubq//9739VSc8tc+fO1bZt2yRZ5iY/dRoAAPCG+tjfStL48ePt7hBv06aNPvnkE5nN/IoMwDvqep/75ptv6uyzz9asWbPk7+9f5XiFhYWaP3++dTs2Nlb9+/evclwAkOp+nytJ+/bts2srnaXJVSEhIXZthw4dcisWAJyqrve5S5Ys0datW23aevTo4Vas3r17O5yi+//+7//cilcf8CkMgDrpnXfeUX5+vk1bo0aN3HqDOO+88+za3njjDZs1HjzhueeekyRFRkbq1ltv9ei1AaA89bG/feuttxz+B+nNN99UcHCwR3MBgLLqcp+7evVqbd++XZ9++mm1FCklafHixcrKyrJujxo1iptJAFSbutznlirbR5Zas2aNW7Fyc3Pt2po2bepWLAA4VV3vcz/++GO7NlfXAy5ryJAhdm0//fSTdRBLQ8Nv+ADqpE8//dSurUuXLm6tV1N2EeZS+/bt08qVK93KzR2LFi3S77//Lkm68847Hd7JCADeUN/6261bt+qee+6xa7/66qsd/kcBADypLve5cXFxmj17tpo3b15tMZn2FUBNqst9bqnGjRvbtX366ad2xQBnOJrmtV+/fu6kBQB26nqf6yh2WFiY2/FOXRe4VNnZRBoSCpUA6pz169dry5Ytdu1du3Z1K95pp53msP3UD0Zq0tSpU61ff/TRRxo7dqzefPNNJScnq6ioyGN5AEBZ9a2/NQxDN998s90HNyEhIaxLCcDr6nqfm5CQoAsvvLDa4hUVFenLL7+0bsfFxfGBOYBqU9f73FKdO3e2a8vKytLzzz/vcqzly5fbbPft21ft27d3OzcAKFXX+9yMjAyHIx2DgoLcjnnq9LWlFi5c6HbMuoxCJYA65/vvv3fY7mjhd2e0a9fO4fRUS5YscSueq9auXavFixdbt//++2+9//77uu2225SUlKTY2FjdfffdSk5O9kg+AFCqvvW3M2fOtFuXUrKsVxkdHe2RHACgPPWtz62qpUuXKjMz07rNtK8AqlN96XPPPPNMh0sXPP3009q4caPTcfLy8vT555/btE2cOLHK+QGAVPf73L///tth+5EjR9yO2b59e4fPoXTGvYaG3/IB1DmrVq1y2O7uNFM+Pj5q2bKlXfvmzZuVkZHhVkxXlB1N6UhmZqb++9//KikpSd27d9ecOXNqPCcAkOpXf1tYWKhJkybZtfv6+jqcChYAPK0+9bnVgWlfAdSk+tLnBgUFafTo0Xbt+fn5Gjp0qPbv3+9UnGnTptnkedVVV1XrKHkADVtd73MPHTrksD0nJ8ftmCaTSS1atLBrz8rKcrrvrk8oVAKoc1avXu2wvSrr4ThaIN4wDK1fv97tmM7Yvn275s6d6/TxGzZs0OjRozVw4ECX7o4EAHfUp/52+vTp2rNnj1378OHDFR8fX6PXBgBn1Kc+t6qKi4ttpn2Nj49n2lcA1ao+9bkPP/ywwzXe9u7dq/PPP187duyo8Px169bpySeftG4nJSXp3XffrfY8ATRcdb3PzcrKcth++PDhKsWNiIhw2O7os4v6jkIlgDpl//795d4ZU5U3t5iYGIftmzZtcjumM55//nmVlJS4fN6SJUvUo0cPPfvsszWQFQDUv/72xRdfdNg+duzYGr0uADijvvW5VbVixQqlpaVZt0ePHi2TyeTFjADUJ/Wtz+3YsaMeeeQRh/u2bdumPn362K0/WWr//v267LLLlJeXJ0k666yztGjRoiqtuwYAZdWHPjcwMNBhu6N1N13RqFEjh+1lfw9uKChUAqhTdu3aVe6+qry5lbc22fbt292OWZmUlBR9+OGHbp9fVFSkRx55RNdff70KCwurMTMAqF/97YoVKxzeSR4REaELLrjAun3o0CHNmjVLN9xwg7p166bY2FgFBAQoPj5eZ555ph5//HFGswOoEfWpz60Os2fPttlm2lcA1ak+9rkTJ07UwIEDHe7LzMzU4MGDNX36dJv2jIwMDR48WHv37pUkXXnllVq4cGG5I3wAwB31oc9t0qSJw/bk5OQqxS3v89xjx45VKW5d5OvtBADAFbt373bYHhwcrJCQELfjBgQEOGxPTU11O2ZlIiMj9ffff+v48eM6duyYDhw4oH379mn79u367bff9Pvvvzu1KPOMGTO0e/duff311woODq6xfAE0LPWpv50xY4bD9mHDhsnf31+bNm3StGnTNGvWLB0/ftzuuJSUFKWkpOi3337TU089pauvvlovvfSSw6lmAMAd9anPraqSkhLNmzfPut28eXOdddZZXswIQH1TH/tcX19fzZ07VwMGDHA47WFhYaFuuOEGbdmyRVOnTlVaWpoGDx6szZs3KyAgQC+++KLuuOOOGs8TQMNTH/rc8v7vn5KSogMHDri9nEx2drbDdsMw3IpXl1GoBFCn7Nu3z2F7VaclKe/N7eDBg1WKW9k1mzVrZt3u2rWrzf78/Hx99913mjlzpr766qsK36SWLl2qf/3rX/rqq69kNjNYHkDV1Zf+tqSkRF999ZXDfWeddZbuuusuvfHGGyouLpZk+c9SkyZNlJWVpdzcXIfnzZo1S99//72+/fZb9e7du0byBtCw1Jc+tzr89NNPNh8wMe0rgOpWX/vcsLAwLVy4UEOGDCl3lM8LL7ygTZs2aevWrdqxY4d69eqlmTNn6vTTT/dIjgAanvrQ53bo0EGNGzd2uCbl559/rnvuucetuIcOHXLY3rhxY7fi1WV8mg2gTsnJyXHYXlNvbuVdzxMCAgJ02WWX6csvv1RycrKGDh1a4fELFizQ008/7aHsANR39aW/TU5OLveX///85z969dVXFRkZqSeeeEIbNmzQkSNH9M8//ygnJ0d//fWX7rrrLvn5+dmdm5mZqYEDB5a73g8AuKK+9LnVgWlfAdS0+tznRkVFacmSJerTp0+5xyxYsEA7duzQgAED9Msvv1CkBFCj6kOfazabdfbZZzvc99FHH7kVs6ioSOnp6Q73UagEgFquvDm6y1t82Fk+Pj4O2/Pz86sUt7p069ZNCxYs0AcffFDhehFTpkypkUWjATQ89aW/XbJkSYX7n3jiCe3atUuTJk2yG9neuXNnvfLKK1qxYoXDNSmOHDmiyy+/XCkpKdWaM4CGp770uVVlGIbmzp1r3W7RokWFH7YDgDvqe5/buHFjLVmyRCNGjKjwuOXLl+v2228vd400AKgO9aXPHTVqlMP2tWvXavHixS7HO3DggEpKShzuo1AJALVceW9uVb0Lp3TKv1MVFBRUKW51GzNmjH799Ve1bt3a4f7CwkI9+OCDHs4KQH1UX/pbR2v0SFLv3r21efNmTZo0qdL1ffv06aMFCxbI39/fbl96errGjBlTHakCaMDqS59bVatWrdKBAwes20z7CqAmNIQ+t1GjRvriiy90ww03VHjc22+/rfPOO09paWkeygxAQ1Nf+tyrr75acXFxDvfdeeedLt/0sWvXLoftvr6+atOmjcv51XUUKgHUKeWt01jVu3DKu4OlvGkEvKl9+/ZatWqV2rdv73D/N998w6hKAFVWX/rbLVu2OGwfPny4WrZs6XScM888U48++qjDfYsXL3brDkoAKFVf+tyqYtpXAJ7QUPrc5cuX65tvvpGvr2+Fo9N//vln9e3bV9u2bfNgdgAaivrS5/r7+5f7mcDmzZtdGjiSk5OjV1991eG+Tp06KTAw0K0c6zIKlQDqlJCQkBqJm5eX57C9qnf31JTY2Fh9/fXX5U4FMGvWLM8mBKDeqS/97fbt2x22JyQkuBzr/vvvV2RkpMN9zz33nMvxAKBUfelzq+LUaV9btmzJtK8AakRD6HNffPFFDR48WFlZWZozZ45+/vnnCj9E37lzp/r27atffvnFg1kCaAjqU5972223adiwYQ73TZs2TY8++mi5Iz0ly0x4H330kbp06aI5c+Y4PCYpKalacq1rKFQCqFNCQ0Mdtpf35uSs8uYvr+rdPTWpY8eOevvttx3u+/777z2cDYD6pj70t4WFhcrNzXW4r1mzZi7HCw4O1u233+5w36JFi3To0CGXYwKAVD/63Kr69ddftXfvXuv25Zdf7sVsANRn9bnPLS4u1vjx4zVhwgSVlJRo+vTpGj58uMxms6ZOnar333/f4XIGknTo0CFdcMEFWr16tcfyBVD/1ac+12Qy6f3331eXLl0c7n/mmWfUt29fffLJJ0pJSVFxcbFSU1O1aNEi/ec//1GbNm00ZswYZWZmltsXN9Qb9ShUAqhTaurN7ciRIw7ba/vixVdccYUuvPBCu/YNGzbU2rWHANQN9aG/La9IKVlGprujvHV+DMPQihUr3IoJAPWhz62qL774wmabaV8B1JT62ucWFxfryiuv1FtvvSVJuvvuu3X11VfbHHPttdfqxx9/LDennJwcXXDBBfrzzz9rOl0ADUR963ObNGmiFStW6JxzznG4f82aNfr3v/+t+Ph4+fr6Ki4uToMHD9ZLL72k/fv36+qrr9by5csdrmlpNps1YsSIGs2/tqJQCaBOiYiIcNhe1Te3nJwch+2tWrWqUlxPePLJJ+3aiouLtXv3bs8nA6DeqA/97bFjx8rd16RJE7ditmrVSl27dnW479dff3UrJgDUhz63qsoWKhMSEtS7d28vZgOgPquPfa5hGLruuuusfWmbNm00depUh8cOGDBAK1euVHx8vMP9ubm5uuSSS5SVlVVj+QJoOOpjn9u4cWMtWbJEL774osLCwio93t/fX9dcc41+//13ffTRR9q4caPDtTv79evn9k3VdR2FSgB1SseOHR22l3cXjbMOHz7ssL1ly5ZViusJZ5xxhs4880y7dqYgBFAV9aG/9fPzK3efM/+ZKM8FF1zgsD01NdXtmAAatvrQ51bFmjVr9M8//1i3mfYVQE2qj33uM888o1mzZlm3n376aQUEBJR7fGJiolauXFnuuu3//POPJkyYUN1pAmiA6mOfK0m+vr66//77tWvXLr3zzjsaNmyY2rZtq6CgIIWFhaljx4664oor9O6772rPnj368MMPretPfvvttw5jNuQZRXy9nQAAuOL000932J6enq6ioiL5+rrXraWnpztsL++X9tpm+PDhdiN5SkpKvJQNgPqgPvS3wcHB5e4rbz0IZ5S3HkVmZqbbMQE0bPWhz60Kpn0F4En1rc/99ddfNXHiROt2s2bNNHr06ErPa9OmjZYuXaoBAwZoz549dvvfe+89jR8/Xj179qzWfAE0LPWtzz1VZGSkbrzxRt14441OHZ+VlaWvvvrKYZzrrruuutOrMxhRCaBOiYyMdDgEvqSkRCkpKW7HPXjwoMP2uvILef/+/e3aypsDHgCcUR/625CQkHKLlfn5+W7HLe8/WqwNDMBd9aHPrYqyhcrWrVurV69eXswGQH1X3/rcO++80+ZG5ZEjRzr9wX9CQoJ+/PFHRUVFOdz/4osvVkuOABqu+tbnVtWsWbMcTnt79913KyQkxAsZ1Q4UKgHUOd26dXPYvm/fPrfi5eXlKSMjw649Ojpabdu2dSump7Vu3dqurbZN6QWg7qkP/W2bNm0ctldleuymTZs6bHd33UsAkOpHn+uOdevWaefOndZtpn0F4An1pc9dtmyZ1qxZY9M2cOBAl2J07NhRc+bMcVjcnDdvno4fP16lHAGgvvS5VVVSUqI33njDrj00NFR33nmnFzKqPShUAqhzLrroIoftu3btcive7t27Hbb36dPHrXjecOrdj82bN1d4eLiXsgFQX9SH/jYxMdFhu7vPQSp/xHp5d6IDgDPqQ5/rDqZ9BeAN9aXPLbsuZanyfv+tSP/+/TVp0iS79vz8fK1atcqd1ADAqr70uVX16aefavPmzXbtEydOVEREhBcyqj0oVAKoc4YPH+6wfd26dW7F2759u8P2Sy65xK143nDqHY6u3kEJAI7Uh/727LPPdti+ceNGt2OWN52sOx8KAUCp+tDnuqNsobJt27a1frouAPVDfelzV65cadfmaIpFZ0yYMEGtWrWya9+xY4db8QCgVH3pc6uiuLhYTz75pF17z549de+993oho9qFQiWAOqd169YO1wdbu3atW/H++OMPuzZfX1+NHDnSrXjecOq87KNGjfJSJgDqk/rQ3w4ePNhh+6+//up2zCNHjjhsP+ecc9yOCQD1oc911YYNG2w+aGLaVwCeUl/6XEfTJgYGBroVy9/fX2PHjrVrr8qSCQAg1Z8+tyr+7//+T1u3brVp8/X11XvvvScfHx8vZVV7UKgEUCeNGTPGri05OVmGYbgcy9HdO4MHD65Ta42V/cC9VatWGjp0qBezAVCf1PX+tkOHDurevbtd+6JFi9yOefjwYbu2+Ph4derUye2YACDV/T7XVUz7CsCb6kOf6yhXR7+rOqt///52bY0bN3Y7HgCUqg99rrt2796tJ554wq596tSp5a7f2dBQqARQJ916660KCwuzacvOztYvv/zicqyff/7Zru2ee+5xNzWvWLBggfXrZ599ljtxAFSb+tDf3njjjXZte/fudXgXpjO2bNni1DUAwFX1oc91RdlCZfv27dWjRw8vZgOgoakPfa6jaV5TU1PdjtesWTO7tri4OLfjAUCp+tDnuqOkpEQ33nijjh49atM+btw43X///V7KqvahUAmgTgoPD9ett95q1z5v3jyX4qxdu9Zu2tSkpCQNGTKkSvl50o4dOzR37lxJ0llnnaWrrrrKyxkBqE/qQ387btw4RUVF2bV/8MEHbsVbs2aNzbavr69uueUWt2IBQFn1oc911saNG21u/GDaVwCeVh/63N69e9u1rV692u14eXl5Nttms1lnnXWW2/EAoFR96HPdMXnyZC1evNimrV+/fnrrrbe8lFHtRKESQJ11zz33KDg42KbN1Te30gJfWVOmTKlSXp42YcIEFRUVKTAwUK+99pq30wFQD9X1/jYoKMjhNCszZ85Ubm6uy/HmzJljsz1+/HjFx8e7nR8AlFXX+1xnnTrtK4VKAN5Q1/vcSy+91K7t66+/djveqeunnX322YqJiXE7HgCUVdf7XFctWLBATz31lE1bv3799M0338jf399LWdVOFCoB1FlxcXGaOHGiTduOHTu0fPlyp87Py8vTu+++a9M2atQol9Z3/PLLL9W9e3cFBASoVatWeuaZZ1RSUuLUuenp6Zo3b56+/vpr5eTkOH3Nsp5//nl9+eWXkqTp06czXRaAGlHX+1vJUkzs2bOnTVtmZqZefvllp2NI0qpVq7R+/Xrrdnx8vN1/PACgKupDn+uMsoXK8tYTBoCaVtf73NGjR6tNmzY2bd988422b9/u9PXL+vzzz222J0yY4FYcAHCkrve5rvj55591xRVX2MQeMmSIfvjhB4WHh1f79eo8AwDqsIKCAuOMM84wJFkfgwYNcurcp556yua8pk2bGvv373f62p9//rnN+aWPO+64o9JzV6xYYYSFhVnPiYiIMN566y2nr20YhjFt2jTDbDYbkozJkye7dC4AuKqu9rdlbd261QgNDbWJERAQYGzcuNGp8/Pz842uXbtazzWZTMb8+fNdygEAnFEf+tyKbN682Sb2o48+Wm2xAcBVdb3PnTNnjt35/fv3N4qKipyOYRiGsXr1asNkMlljDBkyxKXzAcAZdb3PdcbPP/9sNG7c2OYaY8aMMfLz86v1OvUJhUoAdd6uXbuMyMhIm85/5syZFZ6zfPlyIyAgwHp8YGCgsXr1apeue9pppzl8czObzUZqamqF5w4ePNjhuYMGDTJ27NhR4bkHDx40xo4da0gyfHx8jFdffdWlvAHAXXWxvz3VvHnzDB8fH5s4HTt2NNLS0io8r7i42Lj22mttznv88cddujYAuKI+9LnlefLJJ21ib9iwoVriAoC76nqfe9ttt9nFuOmmm4zi4mKnzt+5c6cRHx9vPbd169bV1ucDwKnqep9bkY8//tgmz6CgIOO9996rltj1GYVKAPXC6tWrjZCQEJsRMnPnznV47KeffmpzbGhoqPHdd9+5fE0/Pz+Hb26SjFWrVlV47vDhw8s919/f37juuuuMb7/91khLSzMKCgqMffv2GYsWLTJuv/1260jMmJgY44cffnA5bwCoirrW3zoyY8YMm7vFJRldunQxtm3b5vD49PR0Y8SIETbH33333S5fFwBcVR/6XEfKjk7v1KlTtcQEgKqqy31uYWGhMWbMGLsYF110kbFz585yzyspKTFmz55tNGnSxHpOXFycsXXrVpefCwC4oi73uY6kp6cb11xzjU3Mbt26OT2DU0NnMgzDEADUA7/99psuu+wypaSkWNsuu+wyjR49WvHx8dq9e7c++OADLVu2zLq/Y8eO+vzzz9W1a1eXr3f66adr06ZNdu1ms1kHDhxQ06ZNyz131apVGjBggIqKily+ro+Pj8aPH68pU6aocePGLp8PAFVVl/rb8nz55Ze69tprlZuba23z9/fXVVddpSFDhiguLk6ZmZlauXKlPvzwQ2VlZVmPeemll3THHXe4fE0AcEd96HPL2r59uzp06GDdfvzxx/Xkk09WKSYAVJe63OcahqGHH35YL7zwgs2aaAEBAbrooot04YUXqkWLFgoICFBmZqbWrVunr776Sps3b7Yee9555+mTTz6pcl8PAM6oy31uqZSUFL322mt64403dPjwYUlSTEyMnnzySd10000ym80ux2yQvFwoBYBqlZqaalx11VXl3h1T+ggLCzMmTZpk5OXluX2t2bNnO4zt7Lzm33zzjREVFVVprqWP4OBg4+abbzY2bdrkds4AUF3qUn9bni1bthiXXHKJU32wyWQyhg8fzt3lALyiPvS5pZ5++mmbuH/++We1xAWA6lLX+9z169cbF1xwgdOfNUgyTjvtNGPmzJkur2sJAFVVl/rco0ePGnv37jV+/PFH47nnnjP69+9vs7RMYmKiMW3aNCM7O9vtHBsqRlQCqJc2b96sGTNmaOnSpfr777915MgRRUVFqXv37ho2bJjGjBmjsLCwKl/nyy+/1KRJk7Rp0ybFxsbq1ltv1UMPPeT03TI5OTn66KOP9OOPP2rTpk1KTU3VsWPHFBAQoMaNG6tdu3bq1q2bBg0apEGDBikoKKjKOQNAdaor/W1F1q9frzlz5mjRokXas2ePMjIy5OPjo+joaHXu3FkDBgzQ6NGj1a5duypfCwCqoj70uUlJSUpOTpYknXbaaQ7vageA2qCu97k7duzQd999px9//FG7d+9Wenq6Dh06pODgYDVp0kQtWrRQ//79df7556t///4ymUxVfi4A4K7a3udOnjxZkyZNsmmLjo5W7969ddZZZ2nw4ME644wzqpxfQ0WhEgAAAAAAAAAAAHAgLS1NaWlp8vX1VUREhCIjI+Xn5+fttOoNCpUAAAAAAAAAAAAAPI6VPAEAAAAAAAAAAAB4HIVKAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx1GoBAAAAAAAAAAAAOBxFCoBAAAAAAAAAAAAeByFSgAAAAAAAAAAAAAeR6ESAAAAAAAAAAAAgMdRqAQAAAAAAAAAAADgcRQqAQAAAAAAAAAAAHgchUoAAAAAAAAAAAAAHkehEgAAAAAAAAAAAIDHUagEAAAAAAAAAAAA4HEUKgEAAAAAAAAAAAB4HIVKAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx1GoBAAAAAAAAAAAAOBxFCoBAAAAAAAAAAAAeByFSgAAAAAAAAAAAAAeR6ESAAAAAAAAAAAAgMdRqAQAAAAAAAAAAADgcRQqAQAAAAAAAAAAAHgchUoAAAAAAAAAAAAAHkehEgAAAAAAAAAAAIDHUagEAAAAAAAAAAAA4HEUKgEAAAAAAAAAAAB4HIVKAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx1GoBAAAAAAAAAAAAOBxFCoBAAAAAAAAAAAAeByFSgAAAAAAAAAAAAAeR6ESAAAAAAAAAAAAgMdRqAQAAAAAAAAAAADgcRQqAQAAAAAAAAAAAHgchUoAAAAAAAAAAAAAHkehEgAAAAAAAAAAAIDHUagEAAAAAAAAAAAA4HEUKgEAAAAAAAAAAAB4HIVKAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx1GoBAAAAAAAAAAAAOBxFCoBAAAAAAAAAAAAeByFSgAAAAAAAAAAAAAeR6ESAAAAAAAAAAAAgMdRqAQAAAAAAAAAAADgcRQqAQAAAAAAAAAAAHgchUoAAAAAACTl5eXprrvuUpMmTRQaGqoxY8bo8OHD3k7LbXv27NHw4cMVFBSkuLg4PfnkkyopKfF2WvCQOXPm6LTTTlNAQIB69uypFStWeDslAAAAwI7JMAzD20kAAAAAAOBtN910k959912btgsvvFDfffedlzJyX0FBgZKSkvTXX3/ZtD/77LN66KGHvJQVPOWnn35S//79VfYjn6CgIP35559q06aNFzMDAAAAbFGoBAAAAIBaJC0tTdu2bfN2GjbOOOMMBQQEeDuNGpWZmano6Gg5+i/yunXr1KNHDy9k5b65c+dq1KhRdu3h4eHKysqSyWTyQlbwlOHDh+vrr7+2a7/rrrv0yiuveCEjAAAAwDFfbycAAAAAADjp22+/1bhx47ydho1du3YpISHB22nUqF27djksUkrS33//XecKlTt37nTYnp2drczMTEVFRXk4I3hSed//v//+28OZAAAAABVjjUoAAAAAQIPXtm1bmc2O/4vcoUMHD2dTde3bt3fYHhERQZGyASjv+18Xf5YBAABQv1GoBAAAAIBabsSIEfriiy+0detWHT58WAUFBTIMw+4xY8YMh+e3atXK4fGGYaiwsFBpaWlauXKlJk6cqLi4OA8/u9ohIiJC48ePt2u/+OKL1bVrVy9kVDXDhg1Tt27d7NofffRRL2QDT3vooYfsCu/BwcG6++67vZQRAAAA4BiFSgAAAACopQICAjR37lzreoMdOnRQeHi4/Pz8qu0avr6+io6OVr9+/TR58mRt2rRJl1xySbXFr0tefvll3XPPPYqMjFRISIiuueYaffTRR95Oyy2+vr5asGCBLr30UjVq1EhNmzbVk08+qfvuu8/bqcEDzjzzTM2dO1ennXaa/Pz8lJSUpO+//16tWrXydmoAAACADZNR3iIcAAAAAACPmzlzpnWNyk8++URXXnmlW+eW1apVK+3evdvpOIZh6OKLL9a3334rqWGsUQkAAAAA8DxGVAIAAABALXTxxRe7VKSsTiaTSe+9954iIyO9cn0AAAAAQMNAoRIAAAAAaqF77rnHq9ePjY3VDTfc4NUcAAAAAAD1G4VKAAAAAKhlQkJCdO6553o7DQ0dOtTbKQAAAAAA6jEKlQAAAABQy3Tv3l0+Pj7eTkM9e/aUyWTydhoAAAAAgHqKQiUAAAAA1CLR0dE677zzvJ2GJCk0NFRDhw5VQECAt1MBAAAAANRDvt5OAAAAAABw0rBhwzRs2DBvp2H1zTffeDsFAAAAAEA9xYhKAAAAAAAAAAAAAB5HoRIAAAAAAAAAAACAx1GoBAAAAAC45eDBg5o2bZq6d+8uk8mkmTNn2h3z/fffa+jQoYqIiFCjRo3Uu3dvffrpp07FLy4u1jfffKP77rtP/fr1U8uWLRUWFiZfX1+Fh4erbdu2uuiii/Tkk08qOTm52p7XunXrdNNNNyk4OFgJCQluxVi2bJmuvPJKBQQE6Nxzzy33uIULF+qaa65RQkKCAgICFB4erjPPPFPPPPOMDh8+7Na1yyopKdE333yjYcOGycfHR2PHjnU5RkFBgT7++GP1799fJpNJkyZNcnhcXl6e3n//fQ0bNkxNmzaVn5+foqOjNWTIEL3//vsqLi6u2pM5xfr16/XMM89o8ODBateuncLDw+Xv76/o6Gh17dpV1113nWbMmKHs7OxqvW5VlZSUaPbs2br22mvVvn17hYeHKzg4WB06dNCoUaP0v//9T3v27LEev3PnTvn7++unn35y+VqZmZl68cUX1b59e5lMJi1btqwan4lnbdmyRU899ZQuuOACJSQkKCgoSAEBAWrevLnOOOMM3X///VqyZIkMw/B2qgAAAHCFAQAAAACoF2bMmGFIsnu0atWq2q6Rl5dnfP7558awYcMMX19fm+vMmDHDetyxY8eMq6++2mE+kownn3yywuv873//M1q0aFHu+Y4e/fr1M9auXevW8zp27JgxY8YMo3fv3m6/docOHTKmTZtmdOrUySbGgAED7I5dv369cdZZZ1X4fKKjo41ly5a59XxSU1ONp556ymjZsqVNzOuuu87pGDt27DAmTJhgREVF2cR44okn7I794osv7K516iMpKcnYu3evW8+nrNWrVxuDBg2yid2oUSMjISHBaNy4sd11AwICjDvuuMM4ePBgla9dVT///LPdz0d5j549exo333yz0b59e0OSsXLlSqevs2rVKmPMmDFGQECATcylS5dWeu6uXbtc+nfnziM8PNzp57JmzRq773dFjx49ehg//vij0/EBAADgXb7lVjABAAAAADhh9erVev/99/XZZ59VOtLv+PHjuuiii7R8+fJyj5k8ebJuvvlmNW3a1Kb9yJEjuvzyy/X9999b20JDQ3XjjTeqf//+CgsL08GDB7VkyRJ9+OGHys/Ptx73008/6ayzztKcOXM0bNgwp57X1q1b9fbbb2vmzJnKyspy6pxT/frrr3rrrbf02Wef6fjx45Ue//rrr+u+++5TQUFBhcelp6dr6NChWrVqlbp16+ZULsuWLdObb76pefPmqbCw0KlzyioqKtLXX3+tt956SwsXLqx0dFpBQYHGjx+v6dOnVxp73bp1GjJkiH799VeFhoa6nJthGJo6daoef/xx6+jMjh076vnnn9dFF10kPz8/SdKGDRv05JNPau7cuZKk/Px8vfbaa3rttdfKjW02m9W5c2f98ccfMplMLufmjE8++URjx461ft/79eunf/3rX2rfvr18fHx08OBBrV69Wp999pkyMjK0du1arV271un4R44c0axZs/Tmm29qw4YNNfIcqktFo4xLlZSU6LHHHtPzzz+v4uJiRURE6KqrrlL//v0VHR2tjIwMLVmyRLNmzdKRI0es5yUnJ2vIkCF67LHH9OSTT9bY9xMAAADVg0IlAAAAAKBC5557boVFx1Ndc801lR5fXFysvXv32hQqjx8/rgsvvFA///yzta1ly5ZasmSJ2rZta3P+VVddpQkTJuiCCy7Q7t27re35+fm6+uqrtXHjRjVv3rzc6//yyy969NFHtWTJEqef16kWLVqkCRMmaP369U4dbxiG7r33Xr3yyitOX+PYsWO64YYb9Ntvv8lsLn/1lg8++EBTp07V5s2bnY59qv/+97967rnndODAAaeOz87O1iWXXKKVK1c6fY3Nmzdr4sSJmjZtmsv53XzzzXr33Xet22eddZa+//57u6Jnt27dNGfOHE2aNEmTJ092KnZJSYk2btyoY8eOKTg42OXcKvPzzz9bi5Q+Pj56++23dcMNN9gdd/XVV+uFF17QpEmT9MILLzg1jWlubq4eeughffjhh8rNza323M8//3xdeuml1qmX/fz8nCr+PfDAA1q9erVde8uWLTVjxowKz83Pz9fll1+ur7/+WpI0btw4vfzyy2rcuLHNcVdccYUmT56sK6+80m5a26eeekopKSk2PzMAAACofVijEgAAAABQoSlTpmjHjh3Ky8vTmjVrKly3cdq0aZo7d65uvPFGZWZmauHCherQoYPdcU2aNFHnzp1t2h5++GGbIqUkzZgxw65IWapDhw769NNP7Yom2dnZeu655yp8TseOHVNQUJCmTp2ql156SaeddlqFxzsSEBCgrl276n//+5/efvttdezYscLj77jjDr3yyivy9fXVNddco++++07p6enKz8/Xjh07NHnyZPn7+9udt3btWn3zzTcVxk5NTVXv3r01bdo0TZw4URERES4/H5PJpCuvvFIzZ87Us88+q7CwsHKPzc3N1YUXXqiVK1cqIiLCWpTKycnRsWPHtHbtWl1zzTUOz33zzTeVnp7uUm5TpkyxKTiFhITo008/rXBk5qRJkzRkyBCH+wICAmwejRo1Uvfu3RUUFORSXs4oKSnRrbfeah1J+fjjjzssUpZq1KiRnnvuOb300ktOxQ8ODtaOHTt022236dVXX9VVV11VLXlL0n/+8x8tXrxYd911ly677DKdf/75Ouecc9SvX78KHzt37nRYpPTz89Nnn31W6c/n1VdfbS1STpo0SdOnT7crUpZq2rSpfvzxR1122WV2+9577z29/vrrLj9vAAAAeJB3Z54FAAAAAFQXT6xRaRiG8dFHHzm8zsMPP2wEBgbarYN45MgRY/z48dY1LaOjo42FCxfaHLNnzx7DbDbbxIuIiHAqn/79+9vl0rx5c5ee0759++zW3HT1tfvzzz8dvi4DBgwwnnjiCUOScfbZZxtbtmwpN8bnn3/uMMbFF1/s0vP59NNPHcZxZY3KV1991WGMRx55xLpm4I033mhkZWWVG+O2225zGOPFF190Oo8//vjD8PHxsTn/5ptvdurcHTt22P1cSbbrqda0L7/80ubaqampTp970UUXWc9zZY3KCy+80OHr7soalfHx8UZhYaHT1yy1efNmIzg42OH1X3rppUrPf/31163Hjxw50unrpqen262nKsnw9/c3/vnnH5efBwAAADyDEZUAAAAAAJf07t3bYfvLL7+sNm3a6K233rJpDw4O1htvvKGUlBQlJydrz549GjRokM0xs2fPVklJiU1bRSP6yho6dKhd2759+1yaBrNZs2Y644wznD7ekcTERIejTdetW6fJkyfrjjvu0LJlyyoceXn55ZfrzDPPtGtfunSp3etTkUsvvbTCqWKdcckllzhsf+2117R8+XJ98MEHeuedd8od6SZZRkI2atTIrn3RokVO5zFhwgTrmpSlLr74YqfObdu2rQYPHuwwZl5entM5VMWpo2Erer1ONW3aNLfWWBwxYoTL55zq6quvlq+vaysGHT9+XFdccYWOHj1qt2/48OG67777Kjx/8+bNuv/++yVZRl86O6pUkqKionTHHXfYtRcUFFQ6whoAAADeQ6ESAAAAAOCSyMhIh+35+fn63//+p8DAQIf7o6Ki1L17d4f7//77b7s2Zws05U3bmpqa6tT5pSqa0tZZrVq1smvLzc3Vww8/rFdffdWpws/IkSPt2o4ePapdu3Y5nUdgYKDN+p/uaNGihcNi5/HjxzV37lyNGTOm0hiRkZE699xz7do3btzoVA4HDx7UwoUL7dq7devm1PmSZR3DU2VkZGjOnDlOx6iKv/76y2bblXVEO3bsqIsuusjla1bHz3L//v1dPueuu+7Sn3/+adfeqlUrzZw5s9Lzn3nmGWsBeciQIS4/D0dFfkmaPn26jh8/7lIsAAAAeAaFSgAAAACASxyNkJOkf/3rXzr77LPdiulo9GR0dLRT5zZr1sxhe3Z2tks5uLOu46kcPY9evXrpmWeecTpGecWWffv2uZRLVZ+P2WxWcHCwXfvdd9/t9IhGyfHzSUlJcWqE6LfffuvwuCZNmjh9/V69ejlsX7p0qdMxqiIjI8Nmu+xam8649tprXb5mdfwsx8XFuXT8xx9/7PC5ObsuZUpKij7//HPr9rBhw1y6viTFx8c7bM/Ly7Nb/xYAAAC1A4VKAAAAAIBL/Pz8HLZfeOGFbsd0NGps4MCBTp3rqJgmWaZ8dEV5Bdiqxigvv/KUN4osMzOzyrm4qqaeT3FxsQ4fPlzpuTt37nTYHhAQ4PT1O3fu7HB07qkjHWvKqSOI33zzTbvpYCsybNgwl56vVLXvfWxsrBYuXKjOnTs7fc62bdt0yy23ONz33HPPlVt8L+u9996z+TebmJjo9PVLVfSzuWLFCpfjAQAAoOZRqAQAAAAAuMTHx6faY/bv319Tp05VUFCQfHx8NGLECD3yyCNOnVveVLOFhYUu5eBqMciR8oq4rihvtKCrayrWh+eTlpbmsN2V9Ud9fX0VEhJi156VleV0jKro0KGDzXZJSYlGjhypl19+2alRpSEhIcrLy1O/fv2cvmZVvveBgYEaNGiQ08XOvLw8XXHFFTpy5IjdvksvvVT33nuvU3EWL15ss92/f3+ZTCaXHu3atSs3/v79+53KAwAAAJ5FoRIAAAAA4BJn14501YMPPqicnBwdOXJEc+fOVWhoaKXn7N+/X++9957DfYZhuHR9R+sxuqo6irjlFYhcLbzWh+fj7+/vsP3QoUMu5eBoSt7qGHHqjAsuuMCurbCwUPfff7/69OmjZcuWVfs1q+N776x77rlHGzZssGtPSEjQjBkznIpRVFSkNWvWVHdqNk6dghcAAAC1g6+3EwAAAAAA1C01VaiULIWxyopjRUVF+uqrr/Tuu+/qhx9+cGpUmrPXrg3Ky8PVwmt9eD6tW7d22L5x40a1bdvW6RyOHz9u11be2qbV7d///rcmTZqkAwcO2O1bs2aNzjvvPJ133nl6/PHHdd5551XLNT31vf/ss8/09ttv27U7uy5lqT/++ENHjx61afv444/VokWLaslTkho3blxtsQAAAFB9KFQCAAAAAOqEAwcO6K233tK7776rlJQUSZbiw0UXXaRPPvnEy9lZ1GQR1xu8/XzOPvtsh+2//fabLr30UqdiFBYWKicnx669f//+VcrNWcHBwXr//fc1bNiwctdNXbp0qZYuXap+/fpp4sSJGjx4sEdyq4odO3bopptucrjv+eefV+/evZ2OtXfvXru29u3bq1evXm7nBwAAgLqBqV8BAAAAALXan3/+qTFjxighIUFTpkxRSkqKkpKS9N5772n//v165plnvJ0iasiZZ57pcOTkZ5995vQI002bNqmoqMimzWw2a/To0dWSozMGDRqkefPmKTw8vMLjfvrpJw0ZMkR9+vTRkiVLPJSd6/Lz83XFFVc4XCv0sssu0z333ONSPEfrhWZnZ7ubHgAAAOoQCpUAAAAAgFpp06ZNGjlypLp166aPPvpIhYWFuuSSS7Ry5UqtXbtW119/vYKCgrydJmrYY489Ztf2999/69tvv3Xq/Pnz59u13XTTTWrTpk2Vc3PF0KFDtW7dOg0YMKDSY3/99VcNHDhQl156qXX0cG1y//33Kzk52a69devWTq9LWZajQmV6erpbuQEAAKBuoVAJAAAAAKhVjh8/rv/85z/q2rWr5s2bJ8MwlJSUpNWrV+urr75Sv379vJ0iPOi6667TkCFD7NrvuOMOu3UNT5WVlaU333zTpq1169ZeG4Xbpk0bLVu2TDNmzHBqjcyvvvpKiYmJWrZsWc0n56Q5c+bo9ddft2v39/fXZ5995tZakMeOHbNrc1QIBQAAQP1DoRIAAAAAUGv89ddf6t69u1566SUVFxdLkh588EH9+uuv6tOnj5ezgzeYTCZ9+umnSkpKsmnfvXu3RowY4bDIJUlHjx7Vv/71L6WmplrbYmJi9OOPPyoyMrJGc67M2LFjtX37dj333HOV5nLo0CENGTJEP/74o4eyK9+uXbt0ww03ONz3wgsv6IwzznArblhYmF3bb7/95lYsAAAA1C0UKgEAAAAAtcLKlSvVp08fbdu2zdo2bdo0TZ06Vb6+vl7MDN4WERGhZcuW6corr7RpX7hwobp06aLp06dr//79Kigo0P79+zVz5kx1795dCxcutB571llnac2aNWrXrp2n03eoUaNGeuCBB7Rr1y5NnDhRwcHB5R5bWFio0aNH659//vFghrYKCgp0xRVXOFw7cuTIkbrrrrvcju2oWPv777/r+PHjbscEAABA3UChEgAAAADgdVu2bNGwYcN05MgRa9sVV1yhe+65x3tJoVYJDQ3VJ598og8++MCmfefOnbrhhhvUvHlzBQQEqHnz5ho3bpx27NghSerQoYPeeustLV++XC1btvRG6hUKCwvT5MmTtW3bNo0ZM6bc43Jzc/Wf//zHg5nZeuCBB/T777/btbdp00bTp0+vUuyoqCi7tiNHjuizzz6rUtxSe/bsqXSaYAAAAHgHt6QCAAAAALxu3Lhxys3NtWmbPHmyl7JBbfXnn3/q0UcfVUhIiD777DPl5+dr+fLl2rZtm9LT01VYWKiIiAhFR0erV69e6t+/v3r37i2z2Xv3aZ977rm66KKL9OCDD1Z4XHx8vD744AP9+9//1rhx42ymrC01d+5cpaSkKC4urqbSdWj+/Pl65ZVX7Nr9/f31+eefKzw8vErxu3fv7rD97bff1tixY6sUW5Iee+wxSbIrcgMAAMD7KFQCAAAAALxq1apV+uWXX2za2rRpo06dOnkpI9RGq1at0tChQ5Wbm6sff/xRAwcOlCSNGDHCy5lVbsWKFZUWKktdeOGF+u233zRw4EBt377dZl9JSYmWL19uNwVuTdq9e7fGjRvncN+LL76onj17uhTvr7/+UrNmzdS4cWNrW9OmTdW+fXu75/vLL79ozpw5GjVqlMt5l0pNTdXs2bO58QEAAKCWYupXAAAAAIBXffnll3Zt1TFizDCMKsdA7fDbb7/pggsuUHZ2tm655RZrkbKuWLlypY4dO+b08S1atNDcuXPl4+Njt2/Pnj3VmVqFCgsLdeWVVyorK8tu36hRo3TnnXe6HPP222/X+vXr7dr79+/v8PjbbrtNmZmZLl+n1KRJk5SXl1fnfmYAAAAaCgqVAAAAAIBqUVJS4tZ5u3fvtms7fPhw1ZKRVFxcXOUY8L60tDRdeuml1vVLr776ai9n5Lrc3FzNnj3bpXMSExN16aWX2rX7+/tXV1qVeuihh/Trr7/atbdp00bvvfeeWzF37tzpsL28UZtpaWkaNWqUS4XeUitXrtS7776rbt26uTzyEwAAAJ5BoRIAAAAA6on8/HyH7QUFBdV6nfIKgKWFJFdlZ2fbtW3ZsqXKxUpXn3d1jMCsTaM468vzeeqpp2zWa9y7d68Xs3HfK6+84vLredZZZ9m1xcfHV3pedXzfvv76a7388st27QEBAW6vS3n48OFyv39nn322zjzzTIf7li9frosvvtilPmbHjh268sorVVxc7NbITwAAAHgGhUoAAAAAqCeOHj3qUru7yiuIOhoZ6YzIyEi7tuLiYr3xxhuVnnvgwAHddtttDved+rxzcnK0devWcmM5KmwWFhZWmkNZx48ft2srKipyKUZ5XC281ofnU1RUZDdyb/z48Xr++ee1YcMGHTp0SPn5+W6P5vWk5ORkzZgxw6VzgoODbbZNJpP69etX6XnlvbbOfv/37t2rsWPHOtz30ksvuT06cfny5RXuf/zxx8vdt3TpUnXp0kWLFy+u9Do//vijzjnnHB04cEDdunUr97kAAADA+yhUAgAAAEA9kZKS4rA9JyenWouV+/fvd9juTAHBka5duzpsf/LJJ7Vy5UqH+woLC/X6668rMTFR3333ncNj/vnnH+vXhw8f1gUXXKDNmzeXm8ehQ4fs2hytzVeRtLQ0u7bc3FyXYpTHUX6uHu/K8ykuLnYYw5PPZ9++fXZTfh4+fFgPPvigunfvriZNmigwMFA+Pj4ymUwymUwym83y9fVVQECAQkJCFBERofj4eHXq1En9+vXTDTfcoBkzZjgcyVvT7r33Xm3cuNHp40899txzz3VqRGV5r60z3/+ioiJdeeWVDmNcfvnluv322yuN4UhxcbGef/75Co8ZNmyYbrnllnL37969W4MGDdI555yjd999Vxs3blR2drby8vK0a9cuffTRRxo8eLAuuOACpaamytfXV2+88YbDtT4BAABQO1CoBAAAAIB6Yt26deXuW79+fbVd57///a/D9j/++EPvvPOOy/GGDRvmsD0/P19DhgzRlClTtGfPHuXl5WnTpk169tln1bFjR91xxx3Kyckpd1rHDz74QGlpaVq7dq369++vrVu3qkePHuXmsWnTJru248ePl1uYdTbGnj17XJqKs7wCWkWjQU9VWrg51fbt252OsWXLFofT/JYtADujKs+nefPmiouLc+l6hmGouLhYBQUFOnr0qA4fPqyUlBRt3bpVP//8s6ZPn67rr79ecXFxmjhxYrVPjVyRnJwcDR061KliZUpKij788EPrtq+vr8OpWB1x9HMoOff9f/TRR7Vq1Sq79rZt2+rdd9916vqnKigo0B133OEw7qmmTZumLl26VHjMTz/9pJtuukldunRR48aN1ahRI7Vp00ZjxozRokWLrMc9//zzDqfPBQAAQO1hMmrDghMAAAAAgCr5/fffdeaZZ5Y7BeZ1112nmTNnuh3/6NGj+uuvv/Tee+/pf//7X7nHmUwmXX/99bruuut0+umnKyIiQiaTqdL4Q4cOLXdkZHmaN2+ujz/+WElJSQoJCanwWH9/fy1YsECDBg1yuP+vv/5St27dHBbmJk+erIkTJ1aaz+LFi8uN/9lnn+mKK66oNIYkPfvss3rkkUfs2iMjI7Vt2zY1adKk0hhvvfWWxo8f73Df8uXL1b9//0pjPP7443rqqafs2oOCgvTXX38pISGh0hiGYeiiiy7SDz/8YLdvwIABWrZsWaUxli5dqksvvbTaRnI6ymPBggV206xWl3PPPdduytOQkBA9//zzuummm+Tr62t3zv79+3XxxRfb3GDw+uuvlzvNcVmGYejss8/W6tWr7fZ17NhRf/zxh/z9/R2e+91332nYsGEOC+uvvPKKkpKSKr2+ZBk9mZeXp/T0dG3evFlz5syxKUwvXbpU5557brnnp6Sk6LzzznOpOH+qW2+9VW+++abb5wMAAMBDDAAAAABAnXXkyBFj+vTpRpMmTQxJFT6uvfZaY+vWrS5fY+zYsZXGLu8xduxYp66xb98+4//bu7/QKus/DuAf3arlkWUxM61cS8LUhLIwsn9qMCGxMALTYhVB1k1/SArCqK5UgqSLRioUepMSmX9mxRKXdJWMIjYkFnE8tZUGazrZPLntPL+LUOq3/398XPB6wbk453yf9/f7POfcvfk+z9VXXz3k3EceeSRpbW09f/xNN93U79hLL7002b17d5/z/vnnn8nnn3+eVFRU9Ht8cXFxsmHDhiSbzSbd3d19Znz88cfJNddc029GJpNJqqurk2PHjiVdXV29Mrq7u5NsNpts2rQpKSoq6jfn1ltvTQ4ePJi0tbX1yujp6UlaWlqSDz74IJk0aVK/GVOnTk127dqVnDhxIikUCr0yfv3112Tjxo1JcXFxvxmzZs1K9u/fn/zxxx9JT09Pr7Xk8/nkhx9+SKqqqgb8HVetWpV89913SWdn54D/jx9//DG56667Rvw/HOy1Zs2aAecfjfvvv7/feW+44YZk3bp1ya5du5JDhw4lu3fvTl566aWktLT0/JiSkpJk69atg85z5syZpKGhIVmzZs2A57ps2bLkyJEjSUdHx7+OP378eFJWVnbBrvE/X3V1dYOeT2tra7Js2bIR5a9fv36kPxcAACmzoxIAAOA/Zv369bFnz57o6OiI3377bdi3rpw6dWqUlZXFxIkTo7a2dtBn3rW0tAz7WY3nXHnllXHttdcOaWxTU1OsWLEimpqa+h1TVlYWmzdvjieeeOJfn7/77rvxyiuv9Bo/Y8aM2LlzZ9x7773/+jyXy0VFRcWwbsl6zvbt26OqqipyuVzceOON/e5iHcjTTz8dH374YUREPPDAA3Ho0KFhZ0yYMOH83Dt27Ignn3xy2BkRfz/3r7y8PHbs2BFPPfXUqK5JxN+3KO1rZ+pglixZMuB1eP3112PDhg2xfPnymD9/fjQ3N8eJEyeira0tTp48GZ2dnXHmzJnI5/PR3d0dhUJhWOuor6+P22+/fdjrHszixYsjn8/Hiy++GNlsNj777LOor68f8rHvv/9+zJ07d8BxS5cujbq6umGv7Z/X/Ouvv44lS5YMO2MkBttReU6SJPHRRx/Fm2++Gc3NzYOOnz9/frz33nupnQcAAKOnqAQAAPiPGU1x+P9mz54dl1xyyZhkjYWzZ8/Gtm3b4pNPPonGxsY4ffp0TJs2LebMmRMrV66M1atXxxVXXNHruCRJYtOmTVFdXR3Hjx+PWbNmxWOPPRYvv/xylJaW9hrf1dU14ttKXnfddTFlypRRZfyzwM1ms9HR0TGinFtuuSUiIk6ePDmkIqcv5/4Do8k4d00iYkjPX+xLJpOJioqKPr9755134tVXX42FCxfG4cOHo6SkZMi5PT090dXVFfl8PlpbW+P333+Po0ePxpdffhl79uw5X8y+9tprsXHjxhGtfbiOHTsWX3zxRXzzzTfR0NAQv/zyS3R2dsaUKVNi5syZsXjx4li1alUsXLhwSHkj/Q8NdM3Hk66urqipqYn9+/fHkSNHIpfLRT6fj6uuuiqmT58eixYtipUrV8bSpUujqKjoYi8XAIBhUFQCAAAA49a2bdvi2WefjcmTJ0djY2OUl5ePWfaBAwdixYoVkSRJPPTQQ7F3794xywYAAAY38WIvAAAAAKAve/fujeeeey4iIt56660xLSkjIpYvXx733XdfRMSIblcLAACMjqISAAAAGHd+/vnnqKqqikKhEKWlpbF27doLMk9ZWVlERFx//fUXJB8AAOifohIAAAAYVwqFQjz++OPR3t4eERGLFi2KyZMnX5C5GhoaIiLO76wEAADSo6gEAAAAxpWtW7fGt99+e/59aWnpBZnnwIED0dTUFKWlpfHwww9fkDkAAID+KSoBAACAcWXz5s3/ev/VV19Fa2vrmM7R3NwczzzzTEREvP322zFp0qQxzQcAAAY3IUmS5GIvAgAAACAi4q+//oqSkpJen99xxx3x6aefxsyZM0c9x9GjR+PBBx+MXC4Xd999dxw+fDiKiopGnQsAAAyPHZUAAADAuHHZZZf1WUbW19fHnDlzYt26ddHS0jKi7La2tnjjjTdiwYIFkcvlYu7cubFv3z4lJQAAXCR2VAIAAADjys6dO2P16tX9fj9hwoRYsGBBVFZWxrx58+Lmm2+O6dOnRyaTiUwmE4VCIU6fPh3t7e3x008/RWNjY9TV1UVtbW2cPXs2IiJuu+22qKmpiRkzZqR1WgAAwP9RVAIAAADjzpYtW+KFF144XyyOpaqqqqiuro5MJjPm2QAAwNC59SsAAAAw7qxduzbq6+ujsrJyzDJnz54d+/bti+3btyspAQBgHLCjEgAAABjXDh48GFu2bImamprI5/PDOnbixIlxzz33xPPPPx+PPvpoFBcXX6BVAgAAw6WoBAAAAP4T2tvbo7a2Nurr6+P777+PbDYbp06dilOnTkVPT09cfvnlUVZWFuXl5TFv3ry48847o7KyMqZNm3axlw4AAPRBUQkAAAAAAACkzjMqAQAAAAAAgNQpKgEAAAAAAIDUKSoBAAAAAACA1CkqAQAAAAAAgNQpKgEAAAAAAIDUKSoBAAAAAACA1CkqAQAAAAAAgNQpKgEAAAAAAIDUKSoBAAAAAACA1CkqAQAAAAAAgNQpKgEAAAAAAIDUKSoBAAAAAACA1CkqAQAAAAAAgNQpKgEAAAAAAIDUKSoBAAAAAACA1CkqAQAAAAAAgNQpKgEAAAAAAIDUKSoBAAAAAACA1CkqAQAAAAAAgNQpKgEAAAAAAIDUKSoBAAAAAACA1CkqAQAAAAAAgNQpKgEAAAAAAIDUKSoBAAAAAACA1CkqAQAAAAAAgNQpKgEAAAAAAIDUKSoBAAAAAACA1CkqAQAAAAAAgNT9D3HbRT2fJFo9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1980x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_graph(train_sizes, unpickle_df_nn_y1, 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nn_graph_loss(train_sizes,unpickle_df_nn_y1,\u001b[39m'\u001b[39;49m\u001b[39mNN\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\OneDrive - Imperial College London\\Imperial academic work\\University life\\Y4\\MSci project\\Project_Coding\\nlp-physicseducation\\NN_tools.py:297\u001b[0m, in \u001b[0;36mnn_graph_loss\u001b[1;34m(train_size, df, mlmodel)\u001b[0m\n\u001b[0;32m    294\u001b[0m c \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# colour notation\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[0;32m    296\u001b[0m     \u001b[39m# all of the arrays will be of size 4 for training size graphs anyway\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m     plt\u001b[39m.\u001b[39;49mplot(train_size,df[\u001b[39m'\u001b[39;49m\u001b[39mck\u001b[39;49m\u001b[39m'\u001b[39;49m][i], label \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(mlmodel,df[\u001b[39m'\u001b[39;49m\u001b[39mfeature extraction\u001b[39;49m\u001b[39m'\u001b[39;49m][i],df[\u001b[39m'\u001b[39;49m\u001b[39mLabel\u001b[39;49m\u001b[39m'\u001b[39;49m][i], \u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m), color \u001b[39m=\u001b[39;49mc[i],marker\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mo\u001b[39;49m\u001b[39m'\u001b[39;49m, markersize \u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m )\n\u001b[0;32m    299\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39m Training size\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    300\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mCokenKappa\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:2748\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2746\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2747\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2748\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[0;32m   2749\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[0;32m   2750\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1670\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1668\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1669\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[1;32m-> 1670\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_line(line)\n\u001b[0;32m   1671\u001b[0m \u001b[39mif\u001b[39;00m scalex:\n\u001b[0;32m   1672\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request_autoscale_view(\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:2333\u001b[0m, in \u001b[0;36m_AxesBase.add_line\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   2330\u001b[0m \u001b[39mif\u001b[39;00m line\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2331\u001b[0m     line\u001b[39m.\u001b[39mset_clip_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch)\n\u001b[1;32m-> 2333\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_line_limits(line)\n\u001b[0;32m   2334\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mget_label():\n\u001b[0;32m   2335\u001b[0m     line\u001b[39m.\u001b[39mset_label(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_child\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_children)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:2356\u001b[0m, in \u001b[0;36m_AxesBase._update_line_limits\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   2352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_line_limits\u001b[39m(\u001b[39mself\u001b[39m, line):\n\u001b[0;32m   2353\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2354\u001b[0m \u001b[39m    Figures out the data limit of the given line, updating self.dataLim.\u001b[39;00m\n\u001b[0;32m   2355\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2356\u001b[0m     path \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39;49mget_path()\n\u001b[0;32m   2357\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mvertices\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2358\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\matplotlib\\lines.py:1031\u001b[0m, in \u001b[0;36mLine2D.get_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidy \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidx:\n\u001b[1;32m-> 1031\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecache()\n\u001b[0;32m   1032\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\matplotlib\\lines.py:664\u001b[0m, in \u001b[0;36mLine2D.recache\u001b[1;34m(self, always)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[39mif\u001b[39;00m always \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalidy:\n\u001b[0;32m    663\u001b[0m     yconv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_yunits(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_yorig)\n\u001b[1;32m--> 664\u001b[0m     y \u001b[39m=\u001b[39m _to_unmasked_float_array(yconv)\u001b[39m.\u001b[39mravel()\n\u001b[0;32m    665\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1369\u001b[0m, in \u001b[0;36m_to_unmasked_float_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39masarray(x, \u001b[39mfloat\u001b[39m)\u001b[39m.\u001b[39mfilled(np\u001b[39m.\u001b[39mnan)\n\u001b[0;32m   1368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1369\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(x, \u001b[39mfloat\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\EfiaA\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102\u001b[0m, in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m like \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_like(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder, like\u001b[39m=\u001b[39mlike)\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m array(a, dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1980x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_graph_loss(train_sizes,unpickle_df_nn_y1,'NN')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YEAR 2 NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_204 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_68 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 193ms/step - loss: 0.6954 - accuracy: 0.3610 - val_loss: 0.6844 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6827 - accuracy: 0.8000 - val_loss: 0.6755 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6739 - accuracy: 0.8000 - val_loss: 0.6681 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6663 - accuracy: 0.8000 - val_loss: 0.6616 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6595 - accuracy: 0.8000 - val_loss: 0.6554 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6532 - accuracy: 0.8000 - val_loss: 0.6495 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6473 - accuracy: 0.8000 - val_loss: 0.6438 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6413 - accuracy: 0.8000 - val_loss: 0.6382 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6355 - accuracy: 0.8000 - val_loss: 0.6327 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6298 - accuracy: 0.8000 - val_loss: 0.6273 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6242 - accuracy: 0.8000 - val_loss: 0.6217 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6186 - accuracy: 0.8000 - val_loss: 0.6164 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6131 - accuracy: 0.8000 - val_loss: 0.6111 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6077 - accuracy: 0.8000 - val_loss: 0.6058 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6023 - accuracy: 0.8000 - val_loss: 0.6007 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5971 - accuracy: 0.8000 - val_loss: 0.5955 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5919 - accuracy: 0.8000 - val_loss: 0.5905 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5868 - accuracy: 0.8000 - val_loss: 0.5855 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5817 - accuracy: 0.8000 - val_loss: 0.5807 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5768 - accuracy: 0.8000 - val_loss: 0.5759 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [1 2 0 0 4 0 3 2 4 2 2 2 4 4 0 3 1 3 2 0 0 4 0 2 0 4 4 3 0 4 4 4 2 2 4 2 4\n",
      " 2 1 4 4 4]\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_207 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_69 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 196ms/step - loss: 0.6871 - accuracy: 0.7854 - val_loss: 0.6691 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6662 - accuracy: 0.8000 - val_loss: 0.6503 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6473 - accuracy: 0.8000 - val_loss: 0.6352 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6320 - accuracy: 0.8000 - val_loss: 0.6228 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6193 - accuracy: 0.8000 - val_loss: 0.6118 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6081 - accuracy: 0.8000 - val_loss: 0.6018 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5979 - accuracy: 0.8000 - val_loss: 0.5926 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5885 - accuracy: 0.8000 - val_loss: 0.5840 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5798 - accuracy: 0.8000 - val_loss: 0.5761 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5718 - accuracy: 0.8000 - val_loss: 0.5686 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5642 - accuracy: 0.8000 - val_loss: 0.5617 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5573 - accuracy: 0.8000 - val_loss: 0.5552 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5508 - accuracy: 0.8000 - val_loss: 0.5491 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5448 - accuracy: 0.8000 - val_loss: 0.5435 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5392 - accuracy: 0.8000 - val_loss: 0.5383 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5341 - accuracy: 0.8000 - val_loss: 0.5335 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5294 - accuracy: 0.8000 - val_loss: 0.5291 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5252 - accuracy: 0.8000 - val_loss: 0.5251 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.5213 - accuracy: 0.8000 - val_loss: 0.5215 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5179 - accuracy: 0.8000 - val_loss: 0.5183 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [2 0 0 2 3 2 4 2 4 4 4 4 1 3 4 4 1 4 4 2 0 4 0 3 4 2 1 4 3 2 4 0 2 0 4 0 2\n",
      " 4 2 2 1 0]\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_210 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_70 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.6956 - accuracy: 0.3610 - val_loss: 0.6823 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6807 - accuracy: 0.8000 - val_loss: 0.6740 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6725 - accuracy: 0.8000 - val_loss: 0.6678 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6662 - accuracy: 0.8000 - val_loss: 0.6624 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6606 - accuracy: 0.8000 - val_loss: 0.6573 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6554 - accuracy: 0.8000 - val_loss: 0.6525 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6505 - accuracy: 0.8000 - val_loss: 0.6480 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6458 - accuracy: 0.8000 - val_loss: 0.6435 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6412 - accuracy: 0.8000 - val_loss: 0.6392 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6368 - accuracy: 0.8000 - val_loss: 0.6350 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6324 - accuracy: 0.8000 - val_loss: 0.6309 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6282 - accuracy: 0.8000 - val_loss: 0.6268 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6240 - accuracy: 0.8000 - val_loss: 0.6228 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6198 - accuracy: 0.8000 - val_loss: 0.6188 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.6158 - accuracy: 0.8000 - val_loss: 0.6149 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6117 - accuracy: 0.8000 - val_loss: 0.6110 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6078 - accuracy: 0.8000 - val_loss: 0.6072 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6039 - accuracy: 0.8000 - val_loss: 0.6034 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6000 - accuracy: 0.8000 - val_loss: 0.5997 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5962 - accuracy: 0.8000 - val_loss: 0.5960 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [0 2 2 4 2 4 4 4 4 4 4 2 1 4 1 4 0 2 3 1 4 2 1 0 2 2 2 3 1 2 2 3 1 0 0 4 4\n",
      " 1 2 4 0 0]\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_213 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_71 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 749ms/step - loss: 0.6964 - accuracy: 0.3610 - val_loss: 0.6876 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6867 - accuracy: 0.8000 - val_loss: 0.6829 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6819 - accuracy: 0.8000 - val_loss: 0.6788 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6777 - accuracy: 0.8000 - val_loss: 0.6749 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6737 - accuracy: 0.8000 - val_loss: 0.6712 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6699 - accuracy: 0.8000 - val_loss: 0.6676 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6662 - accuracy: 0.8000 - val_loss: 0.6641 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6625 - accuracy: 0.8000 - val_loss: 0.6605 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6588 - accuracy: 0.8000 - val_loss: 0.6571 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6552 - accuracy: 0.8000 - val_loss: 0.6536 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6516 - accuracy: 0.8000 - val_loss: 0.6501 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6480 - accuracy: 0.8000 - val_loss: 0.6467 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6445 - accuracy: 0.8000 - val_loss: 0.6432 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6409 - accuracy: 0.8000 - val_loss: 0.6398 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6374 - accuracy: 0.8000 - val_loss: 0.6364 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6338 - accuracy: 0.8000 - val_loss: 0.6330 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6303 - accuracy: 0.8000 - val_loss: 0.6295 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6267 - accuracy: 0.8000 - val_loss: 0.6261 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6232 - accuracy: 0.8000 - val_loss: 0.6227 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6197 - accuracy: 0.8000 - val_loss: 0.6193 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [0 1 0 3 0 4 1 4 2 2 4 4 0 2 2 0 2 4 2 1 2 4 4 2 3 0 1 0 2 2 2 2 4 2 2 4 3\n",
      " 3 4 2 2 1]\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_216 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_72 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 161ms/step - loss: 0.6840 - accuracy: 0.7854 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6507 - accuracy: 0.8000 - val_loss: 0.6315 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6282 - accuracy: 0.8000 - val_loss: 0.6146 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6114 - accuracy: 0.8000 - val_loss: 0.6007 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5973 - accuracy: 0.8000 - val_loss: 0.5884 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5849 - accuracy: 0.8000 - val_loss: 0.5774 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5740 - accuracy: 0.8000 - val_loss: 0.5675 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5641 - accuracy: 0.8000 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5551 - accuracy: 0.8000 - val_loss: 0.5505 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5471 - accuracy: 0.8000 - val_loss: 0.5432 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5399 - accuracy: 0.8000 - val_loss: 0.5367 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5335 - accuracy: 0.8000 - val_loss: 0.5308 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5278 - accuracy: 0.8000 - val_loss: 0.5256 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5227 - accuracy: 0.8000 - val_loss: 0.5211 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5184 - accuracy: 0.8000 - val_loss: 0.5171 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5147 - accuracy: 0.8000 - val_loss: 0.5138 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5115 - accuracy: 0.8000 - val_loss: 0.5109 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5089 - accuracy: 0.8000 - val_loss: 0.5085 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5067 - accuracy: 0.8000 - val_loss: 0.5066 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5050 - accuracy: 0.8000 - val_loss: 0.5051 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [2 0 1 4 4 1 2 2 4 4 1 4 4 0 2 3 2 2 4 0 0 2 0 4 2 2 1 4 2 2 0 2 0 1 2 0 4\n",
      " 4 4 4 4 4]\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_219 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_73 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 165ms/step - loss: 0.6860 - accuracy: 0.7561 - val_loss: 0.6641 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6613 - accuracy: 0.8000 - val_loss: 0.6485 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6457 - accuracy: 0.8000 - val_loss: 0.6360 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6331 - accuracy: 0.8000 - val_loss: 0.6251 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6220 - accuracy: 0.8000 - val_loss: 0.6153 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6120 - accuracy: 0.8000 - val_loss: 0.6061 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6027 - accuracy: 0.8000 - val_loss: 0.5977 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5941 - accuracy: 0.8000 - val_loss: 0.5898 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5861 - accuracy: 0.8000 - val_loss: 0.5823 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5786 - accuracy: 0.8000 - val_loss: 0.5754 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5715 - accuracy: 0.8000 - val_loss: 0.5687 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5649 - accuracy: 0.8000 - val_loss: 0.5625 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5586 - accuracy: 0.8000 - val_loss: 0.5566 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5528 - accuracy: 0.8000 - val_loss: 0.5511 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5473 - accuracy: 0.8000 - val_loss: 0.5459 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5422 - accuracy: 0.8000 - val_loss: 0.5411 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5374 - accuracy: 0.8000 - val_loss: 0.5366 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5331 - accuracy: 0.8000 - val_loss: 0.5324 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5290 - accuracy: 0.8000 - val_loss: 0.5286 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5252 - accuracy: 0.8000 - val_loss: 0.5250 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [4 4 4 0 3 0 0 4 4 1 0 2 2 4 2 4 0 0 4 0 4 1 3 2 2 2 4 4 0 4 4 4 2 0 4 4 2\n",
      " 4 1 0 4 2]\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_222 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_74 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.6900 - accuracy: 0.5805 - val_loss: 0.6726 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6695 - accuracy: 0.8000 - val_loss: 0.6590 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6555 - accuracy: 0.8000 - val_loss: 0.6481 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6442 - accuracy: 0.8000 - val_loss: 0.6385 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6342 - accuracy: 0.8000 - val_loss: 0.6297 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6251 - accuracy: 0.8000 - val_loss: 0.6215 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6165 - accuracy: 0.8000 - val_loss: 0.6137 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6085 - accuracy: 0.8000 - val_loss: 0.6063 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6008 - accuracy: 0.8000 - val_loss: 0.5992 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5935 - accuracy: 0.8000 - val_loss: 0.5925 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5865 - accuracy: 0.8000 - val_loss: 0.5860 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5798 - accuracy: 0.8000 - val_loss: 0.5797 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5734 - accuracy: 0.8000 - val_loss: 0.5736 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5673 - accuracy: 0.8000 - val_loss: 0.5679 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5615 - accuracy: 0.8000 - val_loss: 0.5624 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5559 - accuracy: 0.8000 - val_loss: 0.5571 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5506 - accuracy: 0.8000 - val_loss: 0.5521 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5456 - accuracy: 0.8000 - val_loss: 0.5473 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5409 - accuracy: 0.8000 - val_loss: 0.5429 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5365 - accuracy: 0.8000 - val_loss: 0.5386 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [2 0 2 1 1 1 4 4 2 0 4 4 1 4 4 4 2 4 4 4 2 4 3 4 2 4 2 2 0 4 4 4 0 2 4 0 1\n",
      " 4 2 0 0 2]\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_225 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_75 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 168ms/step - loss: 0.6921 - accuracy: 0.4780 - val_loss: 0.6816 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6801 - accuracy: 0.8000 - val_loss: 0.6719 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6700 - accuracy: 0.8000 - val_loss: 0.6632 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6609 - accuracy: 0.8000 - val_loss: 0.6549 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6524 - accuracy: 0.8000 - val_loss: 0.6473 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6443 - accuracy: 0.8000 - val_loss: 0.6397 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6365 - accuracy: 0.8000 - val_loss: 0.6325 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6290 - accuracy: 0.8000 - val_loss: 0.6254 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6216 - accuracy: 0.8000 - val_loss: 0.6185 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6146 - accuracy: 0.8000 - val_loss: 0.6118 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6076 - accuracy: 0.8000 - val_loss: 0.6053 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6009 - accuracy: 0.8000 - val_loss: 0.5989 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5943 - accuracy: 0.8000 - val_loss: 0.5927 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5879 - accuracy: 0.8000 - val_loss: 0.5867 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5818 - accuracy: 0.8000 - val_loss: 0.5808 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5758 - accuracy: 0.8000 - val_loss: 0.5752 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5700 - accuracy: 0.8000 - val_loss: 0.5697 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5644 - accuracy: 0.8000 - val_loss: 0.5644 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5591 - accuracy: 0.8000 - val_loss: 0.5593 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5539 - accuracy: 0.8000 - val_loss: 0.5544 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [2 4 0 0 4 3 4 0 0 0 1 3 2 4 2 4 4 1 0 1 3 4 2 4 4 4 2 0 2 0 3 2 1 4 4 2 4\n",
      " 0 2 1 0 0]\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_228 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_76 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.6893 - accuracy: 0.4049 - val_loss: 0.6600 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6553 - accuracy: 0.8000 - val_loss: 0.6387 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6336 - accuracy: 0.8000 - val_loss: 0.6228 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6171 - accuracy: 0.8000 - val_loss: 0.6095 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6034 - accuracy: 0.8000 - val_loss: 0.5979 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5913 - accuracy: 0.8000 - val_loss: 0.5874 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5806 - accuracy: 0.8000 - val_loss: 0.5779 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5709 - accuracy: 0.8000 - val_loss: 0.5693 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5622 - accuracy: 0.8000 - val_loss: 0.5614 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5542 - accuracy: 0.8000 - val_loss: 0.5542 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5470 - accuracy: 0.8000 - val_loss: 0.5476 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5405 - accuracy: 0.8000 - val_loss: 0.5416 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5346 - accuracy: 0.8000 - val_loss: 0.5361 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5294 - accuracy: 0.8000 - val_loss: 0.5312 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5247 - accuracy: 0.8000 - val_loss: 0.5267 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5205 - accuracy: 0.8000 - val_loss: 0.5227 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5169 - accuracy: 0.8000 - val_loss: 0.5192 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5137 - accuracy: 0.8000 - val_loss: 0.5161 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5110 - accuracy: 0.8000 - val_loss: 0.5134 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5088 - accuracy: 0.8000 - val_loss: 0.5111 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [0 1 2 2 4 4 2 2 4 3 4 4 0 1 4 4 4 4 0 2 2 2 4 2 2 3 0 4 4 2 2 0 4 4 1 4 4\n",
      " 0 3 1 4 3]\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_231 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_77 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.6972 - accuracy: 0.2878 - val_loss: 0.6913 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6909 - accuracy: 0.8000 - val_loss: 0.6884 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6879 - accuracy: 0.8000 - val_loss: 0.6835 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6828 - accuracy: 0.8000 - val_loss: 0.6798 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6792 - accuracy: 0.8000 - val_loss: 0.6767 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6761 - accuracy: 0.8000 - val_loss: 0.6739 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6732 - accuracy: 0.8000 - val_loss: 0.6712 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6705 - accuracy: 0.8000 - val_loss: 0.6685 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6677 - accuracy: 0.8000 - val_loss: 0.6655 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6646 - accuracy: 0.8000 - val_loss: 0.6624 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6615 - accuracy: 0.8000 - val_loss: 0.6593 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6583 - accuracy: 0.8000 - val_loss: 0.6561 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6551 - accuracy: 0.8000 - val_loss: 0.6530 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6518 - accuracy: 0.8000 - val_loss: 0.6498 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6486 - accuracy: 0.8000 - val_loss: 0.6466 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6453 - accuracy: 0.8000 - val_loss: 0.6434 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6420 - accuracy: 0.8000 - val_loss: 0.6401 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6387 - accuracy: 0.8000 - val_loss: 0.6369 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6353 - accuracy: 0.8000 - val_loss: 0.6336 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6319 - accuracy: 0.8000 - val_loss: 0.6302 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [4 4 4 2 2 2 4 0 4 2 4 4 0 0 4 0 2 0 4 0 2 4 1 1 4 0 2 0 2 0 2 3 2 4 2 0 1\n",
      " 3 4 4 3 0]\n",
      "[]\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_234 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_78 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 167ms/step - loss: 0.6898 - accuracy: 0.4571 - val_loss: 0.6706 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6671 - accuracy: 0.8000 - val_loss: 0.6563 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6527 - accuracy: 0.8000 - val_loss: 0.6445 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6404 - accuracy: 0.8000 - val_loss: 0.6338 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6294 - accuracy: 0.8000 - val_loss: 0.6220 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6165 - accuracy: 0.8000 - val_loss: 0.6095 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6040 - accuracy: 0.8000 - val_loss: 0.5989 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5933 - accuracy: 0.8000 - val_loss: 0.5894 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5837 - accuracy: 0.8000 - val_loss: 0.5807 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5749 - accuracy: 0.8000 - val_loss: 0.5726 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5667 - accuracy: 0.8000 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5591 - accuracy: 0.8000 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5520 - accuracy: 0.8000 - val_loss: 0.5514 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5455 - accuracy: 0.8000 - val_loss: 0.5453 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5395 - accuracy: 0.8000 - val_loss: 0.5396 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5340 - accuracy: 0.8000 - val_loss: 0.5344 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5290 - accuracy: 0.8000 - val_loss: 0.5297 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5245 - accuracy: 0.8000 - val_loss: 0.5254 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5204 - accuracy: 0.8000 - val_loss: 0.5215 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5168 - accuracy: 0.8000 - val_loss: 0.5180 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 2 2 3 0 2 4 4 2 4 0 0 2 2 2 4 2 4 4 0 4 1 4 4 2 0 3 2 2 4 4 3 1 3]\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_237 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_79 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 167ms/step - loss: 0.6849 - accuracy: 0.8000 - val_loss: 0.6696 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6664 - accuracy: 0.8000 - val_loss: 0.6557 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6528 - accuracy: 0.8000 - val_loss: 0.6449 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6419 - accuracy: 0.8000 - val_loss: 0.6351 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6321 - accuracy: 0.8000 - val_loss: 0.6262 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6230 - accuracy: 0.8000 - val_loss: 0.6179 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6145 - accuracy: 0.8000 - val_loss: 0.6100 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6065 - accuracy: 0.8000 - val_loss: 0.6025 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5989 - accuracy: 0.8000 - val_loss: 0.5953 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5916 - accuracy: 0.8000 - val_loss: 0.5884 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5846 - accuracy: 0.8000 - val_loss: 0.5817 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5778 - accuracy: 0.8000 - val_loss: 0.5752 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5713 - accuracy: 0.8000 - val_loss: 0.5691 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5651 - accuracy: 0.8000 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5592 - accuracy: 0.8000 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5535 - accuracy: 0.8000 - val_loss: 0.5520 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5481 - accuracy: 0.8000 - val_loss: 0.5468 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5430 - accuracy: 0.8000 - val_loss: 0.5419 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5381 - accuracy: 0.8000 - val_loss: 0.5373 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5336 - accuracy: 0.8000 - val_loss: 0.5330 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 0 0 1 3 1 2 2 0 1 4 2 4 4 0 4 4 2 4 1 0 2 4 0 0 4 0 2 4 4 4 4 4]\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_240 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_80 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 165ms/step - loss: 0.6872 - accuracy: 0.7510 - val_loss: 0.6681 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6629 - accuracy: 0.8000 - val_loss: 0.6498 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6445 - accuracy: 0.8000 - val_loss: 0.6349 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6294 - accuracy: 0.8000 - val_loss: 0.6218 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6160 - accuracy: 0.8000 - val_loss: 0.6100 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6038 - accuracy: 0.8000 - val_loss: 0.5990 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5928 - accuracy: 0.8000 - val_loss: 0.5890 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5825 - accuracy: 0.8000 - val_loss: 0.5796 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5731 - accuracy: 0.8000 - val_loss: 0.5709 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5644 - accuracy: 0.8000 - val_loss: 0.5628 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5563 - accuracy: 0.8000 - val_loss: 0.5553 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5489 - accuracy: 0.8000 - val_loss: 0.5485 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5422 - accuracy: 0.8000 - val_loss: 0.5422 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5362 - accuracy: 0.8000 - val_loss: 0.5365 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5306 - accuracy: 0.8000 - val_loss: 0.5313 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5257 - accuracy: 0.8000 - val_loss: 0.5267 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5213 - accuracy: 0.8000 - val_loss: 0.5225 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5174 - accuracy: 0.8000 - val_loss: 0.5188 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5141 - accuracy: 0.8000 - val_loss: 0.5156 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5112 - accuracy: 0.8000 - val_loss: 0.5128 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 2 3 2 2 4 4 2 4 4 1 0 2 2 4 1 3 4 3 1 4 4 4 4 4 2 0 2 2 4 0 1 4]\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_243 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_81 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 166ms/step - loss: 0.6910 - accuracy: 0.4327 - val_loss: 0.6789 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6769 - accuracy: 0.8000 - val_loss: 0.6698 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6674 - accuracy: 0.8000 - val_loss: 0.6610 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6587 - accuracy: 0.8000 - val_loss: 0.6532 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6505 - accuracy: 0.8000 - val_loss: 0.6458 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6429 - accuracy: 0.8000 - val_loss: 0.6387 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6356 - accuracy: 0.8000 - val_loss: 0.6318 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6284 - accuracy: 0.8000 - val_loss: 0.6250 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6214 - accuracy: 0.8000 - val_loss: 0.6184 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6146 - accuracy: 0.8000 - val_loss: 0.6120 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6079 - accuracy: 0.8000 - val_loss: 0.6057 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6014 - accuracy: 0.8000 - val_loss: 0.5997 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5952 - accuracy: 0.8000 - val_loss: 0.5936 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5891 - accuracy: 0.8000 - val_loss: 0.5878 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5832 - accuracy: 0.8000 - val_loss: 0.5823 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5775 - accuracy: 0.8000 - val_loss: 0.5768 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5719 - accuracy: 0.8000 - val_loss: 0.5716 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5666 - accuracy: 0.8000 - val_loss: 0.5665 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5614 - accuracy: 0.8000 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5565 - accuracy: 0.8000 - val_loss: 0.5568 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 1 0 2 4 4 3 2 0 4 4 4 2 4 0 4 2 1 4 2 4 2 2 2 4 2 1 4 4 0 0 4 4 4]\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_246 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_82 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 161ms/step - loss: 0.6953 - accuracy: 0.4327 - val_loss: 0.6883 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6875 - accuracy: 0.8000 - val_loss: 0.6846 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6840 - accuracy: 0.8000 - val_loss: 0.6815 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6808 - accuracy: 0.8000 - val_loss: 0.6786 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6778 - accuracy: 0.8000 - val_loss: 0.6755 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6747 - accuracy: 0.8000 - val_loss: 0.6724 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6715 - accuracy: 0.8000 - val_loss: 0.6687 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6674 - accuracy: 0.8000 - val_loss: 0.6641 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6626 - accuracy: 0.8000 - val_loss: 0.6596 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6578 - accuracy: 0.8000 - val_loss: 0.6549 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6530 - accuracy: 0.8000 - val_loss: 0.6503 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6482 - accuracy: 0.8000 - val_loss: 0.6458 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6437 - accuracy: 0.8000 - val_loss: 0.6411 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6387 - accuracy: 0.8000 - val_loss: 0.6365 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6340 - accuracy: 0.8000 - val_loss: 0.6319 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6292 - accuracy: 0.8000 - val_loss: 0.6274 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6245 - accuracy: 0.8000 - val_loss: 0.6227 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6197 - accuracy: 0.8000 - val_loss: 0.6183 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6151 - accuracy: 0.8000 - val_loss: 0.6137 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6104 - accuracy: 0.8000 - val_loss: 0.6092 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 2 2 1 3 0 4 4 2 0 4 0 0 0 3 3 4 3 4 0 2 4 1 4 4 4 2 2 2 4 0 4 2 4]\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_249 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_83 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 0.6855 - accuracy: 0.7755 - val_loss: 0.6677 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6641 - accuracy: 0.8000 - val_loss: 0.6530 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6494 - accuracy: 0.8000 - val_loss: 0.6412 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6373 - accuracy: 0.8000 - val_loss: 0.6309 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6268 - accuracy: 0.8000 - val_loss: 0.6215 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6172 - accuracy: 0.8000 - val_loss: 0.6129 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6083 - accuracy: 0.8000 - val_loss: 0.6047 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5999 - accuracy: 0.8000 - val_loss: 0.5970 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5921 - accuracy: 0.8000 - val_loss: 0.5898 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5846 - accuracy: 0.8000 - val_loss: 0.5828 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5776 - accuracy: 0.8000 - val_loss: 0.5762 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5709 - accuracy: 0.8000 - val_loss: 0.5700 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5645 - accuracy: 0.8000 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5585 - accuracy: 0.8000 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5529 - accuracy: 0.8000 - val_loss: 0.5530 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5475 - accuracy: 0.8000 - val_loss: 0.5479 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5425 - accuracy: 0.8000 - val_loss: 0.5431 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5378 - accuracy: 0.8000 - val_loss: 0.5386 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5335 - accuracy: 0.8000 - val_loss: 0.5344 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5294 - accuracy: 0.8000 - val_loss: 0.5305 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 3 2 2 0 2 2 0 3 4 4 1 4 3 0 4 0 4 2 4 1 2 4 2 0 2 1 4 3 1 2 2 4 4]\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_252 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_84 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 166ms/step - loss: 0.6896 - accuracy: 0.7510 - val_loss: 0.6770 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6732 - accuracy: 0.8000 - val_loss: 0.6607 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6564 - accuracy: 0.8000 - val_loss: 0.6431 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6395 - accuracy: 0.8000 - val_loss: 0.6305 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6272 - accuracy: 0.8000 - val_loss: 0.6201 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6168 - accuracy: 0.8000 - val_loss: 0.6107 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6072 - accuracy: 0.8000 - val_loss: 0.6015 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5979 - accuracy: 0.8000 - val_loss: 0.5929 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5892 - accuracy: 0.8000 - val_loss: 0.5847 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5810 - accuracy: 0.8000 - val_loss: 0.5770 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5733 - accuracy: 0.8000 - val_loss: 0.5697 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5660 - accuracy: 0.8000 - val_loss: 0.5627 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5590 - accuracy: 0.8000 - val_loss: 0.5561 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5525 - accuracy: 0.8000 - val_loss: 0.5498 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5463 - accuracy: 0.8000 - val_loss: 0.5440 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5405 - accuracy: 0.8000 - val_loss: 0.5385 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5351 - accuracy: 0.8000 - val_loss: 0.5334 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5302 - accuracy: 0.8000 - val_loss: 0.5287 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5256 - accuracy: 0.8000 - val_loss: 0.5244 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5215 - accuracy: 0.8000 - val_loss: 0.5206 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 2 2 4 2 2 4 2 3 2 2 1 4 4 4 2 1 1 2 4 4 4 3 4 1 4 4 0 4 4 3 1 2]\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_255 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_85 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.6962 - accuracy: 0.4327 - val_loss: 0.6875 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6861 - accuracy: 0.8000 - val_loss: 0.6816 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6805 - accuracy: 0.8000 - val_loss: 0.6775 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6761 - accuracy: 0.8000 - val_loss: 0.6734 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6720 - accuracy: 0.8000 - val_loss: 0.6696 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6680 - accuracy: 0.8000 - val_loss: 0.6661 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6643 - accuracy: 0.8000 - val_loss: 0.6627 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6607 - accuracy: 0.8000 - val_loss: 0.6591 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6570 - accuracy: 0.8000 - val_loss: 0.6559 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6535 - accuracy: 0.8000 - val_loss: 0.6523 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6498 - accuracy: 0.8000 - val_loss: 0.6488 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6462 - accuracy: 0.8000 - val_loss: 0.6455 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6427 - accuracy: 0.8000 - val_loss: 0.6421 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6392 - accuracy: 0.8000 - val_loss: 0.6386 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6355 - accuracy: 0.8000 - val_loss: 0.6351 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6318 - accuracy: 0.8000 - val_loss: 0.6316 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6282 - accuracy: 0.8000 - val_loss: 0.6281 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6245 - accuracy: 0.8000 - val_loss: 0.6246 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6209 - accuracy: 0.8000 - val_loss: 0.6214 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6175 - accuracy: 0.8000 - val_loss: 0.6176 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 2 4 4 4 2 4 2 2 0 0 3 1 4 4 4 1 4 4 1 2 2 3 1 4 4 0 0 1 2 1 4 0 2]\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_258 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_86 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 166ms/step - loss: 0.6952 - accuracy: 0.4327 - val_loss: 0.6873 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6867 - accuracy: 0.8000 - val_loss: 0.6839 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6831 - accuracy: 0.8000 - val_loss: 0.6809 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6802 - accuracy: 0.8000 - val_loss: 0.6780 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6772 - accuracy: 0.8000 - val_loss: 0.6752 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6744 - accuracy: 0.8000 - val_loss: 0.6724 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6714 - accuracy: 0.8000 - val_loss: 0.6697 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6687 - accuracy: 0.8000 - val_loss: 0.6670 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6658 - accuracy: 0.8000 - val_loss: 0.6642 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6629 - accuracy: 0.8000 - val_loss: 0.6614 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6600 - accuracy: 0.8000 - val_loss: 0.6585 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6571 - accuracy: 0.8000 - val_loss: 0.6558 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6542 - accuracy: 0.8000 - val_loss: 0.6528 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6511 - accuracy: 0.8000 - val_loss: 0.6499 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6481 - accuracy: 0.8000 - val_loss: 0.6470 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6452 - accuracy: 0.8000 - val_loss: 0.6441 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6423 - accuracy: 0.8000 - val_loss: 0.6411 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6391 - accuracy: 0.8000 - val_loss: 0.6381 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6360 - accuracy: 0.8000 - val_loss: 0.6351 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6329 - accuracy: 0.8000 - val_loss: 0.6321 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 3 0 3 4 4 2 2 4 0 4 2 1 0 0 4 4 4 4 4 2 2 3 4 0 2 4 2 4 0 2 4 2]\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_261 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_87 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 170ms/step - loss: 0.6955 - accuracy: 0.3224 - val_loss: 0.6913 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6902 - accuracy: 0.8000 - val_loss: 0.6865 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6856 - accuracy: 0.8000 - val_loss: 0.6815 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6806 - accuracy: 0.8000 - val_loss: 0.6780 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6769 - accuracy: 0.8000 - val_loss: 0.6744 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6733 - accuracy: 0.8000 - val_loss: 0.6709 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6697 - accuracy: 0.8000 - val_loss: 0.6678 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6663 - accuracy: 0.8000 - val_loss: 0.6642 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6629 - accuracy: 0.8000 - val_loss: 0.6608 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6592 - accuracy: 0.8000 - val_loss: 0.6576 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6559 - accuracy: 0.8000 - val_loss: 0.6540 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6521 - accuracy: 0.8000 - val_loss: 0.6505 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6484 - accuracy: 0.8000 - val_loss: 0.6471 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6449 - accuracy: 0.8000 - val_loss: 0.6436 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6413 - accuracy: 0.8000 - val_loss: 0.6399 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6374 - accuracy: 0.8000 - val_loss: 0.6363 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6338 - accuracy: 0.8000 - val_loss: 0.6329 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6302 - accuracy: 0.8000 - val_loss: 0.6292 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6262 - accuracy: 0.8000 - val_loss: 0.6254 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6225 - accuracy: 0.8000 - val_loss: 0.6220 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 2 4 2 2 2 0 2 4 2 2 4 2 1 3 4 2 3 4 2 2 2 0 2 2 2 1 0 1 4 2 3 4]\n",
      "[]\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_264 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_265 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_88 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 157ms/step - loss: 0.6896 - accuracy: 0.7793 - val_loss: 0.6801 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6765 - accuracy: 0.8000 - val_loss: 0.6670 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6636 - accuracy: 0.8000 - val_loss: 0.6565 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6531 - accuracy: 0.8000 - val_loss: 0.6476 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6440 - accuracy: 0.8000 - val_loss: 0.6388 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6351 - accuracy: 0.8000 - val_loss: 0.6305 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6266 - accuracy: 0.8000 - val_loss: 0.6227 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6187 - accuracy: 0.8000 - val_loss: 0.6150 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6108 - accuracy: 0.8000 - val_loss: 0.6076 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6033 - accuracy: 0.8000 - val_loss: 0.6004 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5960 - accuracy: 0.8000 - val_loss: 0.5934 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5889 - accuracy: 0.8000 - val_loss: 0.5866 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5820 - accuracy: 0.8000 - val_loss: 0.5800 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5753 - accuracy: 0.8000 - val_loss: 0.5736 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5689 - accuracy: 0.8000 - val_loss: 0.5675 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5627 - accuracy: 0.8000 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5568 - accuracy: 0.8000 - val_loss: 0.5559 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5512 - accuracy: 0.8000 - val_loss: 0.5505 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5458 - accuracy: 0.8000 - val_loss: 0.5454 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5408 - accuracy: 0.8000 - val_loss: 0.5405 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 4 0 2 4 0 4 4 0 2 0 0 4 0 4 1 2 3 3 3 2 4 2 4]\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_267 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_89 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.6836 - accuracy: 0.7897 - val_loss: 0.6639 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6566 - accuracy: 0.8000 - val_loss: 0.6427 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6359 - accuracy: 0.8000 - val_loss: 0.6273 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6204 - accuracy: 0.8000 - val_loss: 0.6142 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6072 - accuracy: 0.8000 - val_loss: 0.6025 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5953 - accuracy: 0.8000 - val_loss: 0.5919 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5846 - accuracy: 0.8000 - val_loss: 0.5822 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5747 - accuracy: 0.8000 - val_loss: 0.5724 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5649 - accuracy: 0.8000 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5561 - accuracy: 0.8000 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5482 - accuracy: 0.8000 - val_loss: 0.5483 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5411 - accuracy: 0.8000 - val_loss: 0.5417 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5348 - accuracy: 0.8000 - val_loss: 0.5358 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5292 - accuracy: 0.8000 - val_loss: 0.5305 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5242 - accuracy: 0.8000 - val_loss: 0.5258 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5199 - accuracy: 0.8000 - val_loss: 0.5216 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5161 - accuracy: 0.8000 - val_loss: 0.5180 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5128 - accuracy: 0.8000 - val_loss: 0.5148 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5101 - accuracy: 0.8000 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5078 - accuracy: 0.8000 - val_loss: 0.5098 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 3 4 4 0 4 4 3 4 2 4 4 2 2 4 1 2 0 1 2 0 2 2 2 0]\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_270 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_90 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 240ms/step - loss: 0.6911 - accuracy: 0.5310 - val_loss: 0.6826 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6802 - accuracy: 0.8000 - val_loss: 0.6739 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6717 - accuracy: 0.8000 - val_loss: 0.6666 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6642 - accuracy: 0.8000 - val_loss: 0.6592 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6567 - accuracy: 0.8000 - val_loss: 0.6525 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6499 - accuracy: 0.8000 - val_loss: 0.6463 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6434 - accuracy: 0.8000 - val_loss: 0.6402 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6373 - accuracy: 0.8000 - val_loss: 0.6344 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6313 - accuracy: 0.8000 - val_loss: 0.6287 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6254 - accuracy: 0.8000 - val_loss: 0.6231 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6197 - accuracy: 0.8000 - val_loss: 0.6176 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6141 - accuracy: 0.8000 - val_loss: 0.6122 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6086 - accuracy: 0.8000 - val_loss: 0.6069 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6032 - accuracy: 0.8000 - val_loss: 0.6017 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5979 - accuracy: 0.8000 - val_loss: 0.5966 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5927 - accuracy: 0.8000 - val_loss: 0.5916 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5875 - accuracy: 0.8000 - val_loss: 0.5866 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5825 - accuracy: 0.8000 - val_loss: 0.5818 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5777 - accuracy: 0.8000 - val_loss: 0.5771 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5729 - accuracy: 0.8000 - val_loss: 0.5725 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 3 4 1 4 3 4 4 4 4 4 0 4 2 0 2 1 2 4 0 4 2 0 4]\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_273 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_91 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 187ms/step - loss: 0.6939 - accuracy: 0.2724 - val_loss: 0.6899 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6884 - accuracy: 0.8000 - val_loss: 0.6841 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6828 - accuracy: 0.8000 - val_loss: 0.6791 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6777 - accuracy: 0.8000 - val_loss: 0.6746 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6730 - accuracy: 0.8000 - val_loss: 0.6703 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6686 - accuracy: 0.8000 - val_loss: 0.6661 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6643 - accuracy: 0.8000 - val_loss: 0.6620 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6601 - accuracy: 0.8000 - val_loss: 0.6579 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6559 - accuracy: 0.8000 - val_loss: 0.6540 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6518 - accuracy: 0.8000 - val_loss: 0.6499 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6476 - accuracy: 0.8000 - val_loss: 0.6460 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6435 - accuracy: 0.8000 - val_loss: 0.6420 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6394 - accuracy: 0.8000 - val_loss: 0.6380 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6352 - accuracy: 0.8000 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6311 - accuracy: 0.8000 - val_loss: 0.6300 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6269 - accuracy: 0.8000 - val_loss: 0.6260 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6228 - accuracy: 0.8000 - val_loss: 0.6220 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6187 - accuracy: 0.8000 - val_loss: 0.6180 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6145 - accuracy: 0.8000 - val_loss: 0.6140 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6104 - accuracy: 0.8000 - val_loss: 0.6099 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 0 4 1 4 1 4 0 2 4 0 4 2 4 3 2 2 2 2 2 4 0 4 3 0]\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_276 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_92 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.6885 - accuracy: 0.5103 - val_loss: 0.6718 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6674 - accuracy: 0.8000 - val_loss: 0.6586 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6540 - accuracy: 0.8000 - val_loss: 0.6469 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6420 - accuracy: 0.8000 - val_loss: 0.6364 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6310 - accuracy: 0.8000 - val_loss: 0.6265 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6208 - accuracy: 0.8000 - val_loss: 0.6171 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6111 - accuracy: 0.8000 - val_loss: 0.6081 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6018 - accuracy: 0.8000 - val_loss: 0.5994 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5928 - accuracy: 0.8000 - val_loss: 0.5911 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.5842 - accuracy: 0.8000 - val_loss: 0.5830 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.5760 - accuracy: 0.8000 - val_loss: 0.5753 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.5682 - accuracy: 0.8000 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5607 - accuracy: 0.8000 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5537 - accuracy: 0.8000 - val_loss: 0.5544 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5471 - accuracy: 0.8000 - val_loss: 0.5481 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5410 - accuracy: 0.8000 - val_loss: 0.5423 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5354 - accuracy: 0.8000 - val_loss: 0.5370 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5302 - accuracy: 0.8000 - val_loss: 0.5320 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5255 - accuracy: 0.8000 - val_loss: 0.5275 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5213 - accuracy: 0.8000 - val_loss: 0.5235 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 3 4 0 3 3 0 0 2 2 3 2 4 2 4 2 1 2 4 4 2 4 2 0 0]\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_279 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_280 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_93 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 276ms/step - loss: 0.6696 - accuracy: 0.8000 - val_loss: 0.6351 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6244 - accuracy: 0.8000 - val_loss: 0.6015 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5931 - accuracy: 0.8000 - val_loss: 0.5782 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5710 - accuracy: 0.8000 - val_loss: 0.5606 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5542 - accuracy: 0.8000 - val_loss: 0.5468 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5412 - accuracy: 0.8000 - val_loss: 0.5358 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5309 - accuracy: 0.8000 - val_loss: 0.5271 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5228 - accuracy: 0.8000 - val_loss: 0.5202 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5166 - accuracy: 0.8000 - val_loss: 0.5148 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5118 - accuracy: 0.8000 - val_loss: 0.5107 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5082 - accuracy: 0.8000 - val_loss: 0.5077 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.5056 - accuracy: 0.8000 - val_loss: 0.5054 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5038 - accuracy: 0.8000 - val_loss: 0.5038 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5026 - accuracy: 0.8000 - val_loss: 0.5028 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.5018 - accuracy: 0.8000 - val_loss: 0.5020 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5013 - accuracy: 0.8000 - val_loss: 0.5016 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5013 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 4 0 1 2 3 4 2 3 4 0 4 2 4 2 2 4 0 0 4 2 4 2 0]\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_282 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_94 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 200ms/step - loss: 0.6877 - accuracy: 0.7069 - val_loss: 0.6719 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6665 - accuracy: 0.8000 - val_loss: 0.6542 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6495 - accuracy: 0.8000 - val_loss: 0.6410 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6362 - accuracy: 0.8000 - val_loss: 0.6297 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6247 - accuracy: 0.8000 - val_loss: 0.6195 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6143 - accuracy: 0.8000 - val_loss: 0.6101 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6046 - accuracy: 0.8000 - val_loss: 0.6013 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5957 - accuracy: 0.8000 - val_loss: 0.5931 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5873 - accuracy: 0.8000 - val_loss: 0.5853 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5795 - accuracy: 0.8000 - val_loss: 0.5780 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5720 - accuracy: 0.8000 - val_loss: 0.5711 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5651 - accuracy: 0.8000 - val_loss: 0.5646 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5585 - accuracy: 0.8000 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.5524 - accuracy: 0.8000 - val_loss: 0.5527 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5467 - accuracy: 0.8000 - val_loss: 0.5473 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5413 - accuracy: 0.8000 - val_loss: 0.5422 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5364 - accuracy: 0.8000 - val_loss: 0.5375 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5318 - accuracy: 0.8000 - val_loss: 0.5331 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5276 - accuracy: 0.8000 - val_loss: 0.5290 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5238 - accuracy: 0.8000 - val_loss: 0.5253 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 2 0 1 4 4 4 0 1 1 1 4 4 4 2 2 3 0 0 2 4 0 1 4]\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_285 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_95 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 187ms/step - loss: 0.6993 - accuracy: 0.4276 - val_loss: 0.6893 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6886 - accuracy: 0.8000 - val_loss: 0.6861 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6860 - accuracy: 0.8000 - val_loss: 0.6828 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6821 - accuracy: 0.8000 - val_loss: 0.6789 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6780 - accuracy: 0.8000 - val_loss: 0.6749 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6744 - accuracy: 0.8000 - val_loss: 0.6714 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6702 - accuracy: 0.8000 - val_loss: 0.6672 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6659 - accuracy: 0.8000 - val_loss: 0.6629 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6615 - accuracy: 0.8000 - val_loss: 0.6586 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6570 - accuracy: 0.8000 - val_loss: 0.6541 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6523 - accuracy: 0.8000 - val_loss: 0.6493 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6475 - accuracy: 0.8000 - val_loss: 0.6445 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6425 - accuracy: 0.8000 - val_loss: 0.6401 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6380 - accuracy: 0.8000 - val_loss: 0.6352 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6331 - accuracy: 0.8000 - val_loss: 0.6304 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6281 - accuracy: 0.8000 - val_loss: 0.6255 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6230 - accuracy: 0.8000 - val_loss: 0.6205 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6179 - accuracy: 0.8000 - val_loss: 0.6156 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6129 - accuracy: 0.8000 - val_loss: 0.6105 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6077 - accuracy: 0.8000 - val_loss: 0.6056 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 2 1 4 4 2 4 1 2 0 2 4 1 2 2 0 1 0 0 2 3 2 4 2 4]\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_288 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_96 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.6937 - accuracy: 0.4379 - val_loss: 0.6889 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6882 - accuracy: 0.8000 - val_loss: 0.6857 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6851 - accuracy: 0.8000 - val_loss: 0.6830 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6822 - accuracy: 0.8000 - val_loss: 0.6804 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6796 - accuracy: 0.8000 - val_loss: 0.6778 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6769 - accuracy: 0.8000 - val_loss: 0.6751 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6740 - accuracy: 0.8000 - val_loss: 0.6723 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6709 - accuracy: 0.8000 - val_loss: 0.6695 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6684 - accuracy: 0.8000 - val_loss: 0.6662 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6647 - accuracy: 0.8000 - val_loss: 0.6627 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6611 - accuracy: 0.8000 - val_loss: 0.6592 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6574 - accuracy: 0.8000 - val_loss: 0.6555 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6534 - accuracy: 0.8000 - val_loss: 0.6519 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6498 - accuracy: 0.8000 - val_loss: 0.6481 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6458 - accuracy: 0.8000 - val_loss: 0.6443 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6419 - accuracy: 0.8000 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6381 - accuracy: 0.8000 - val_loss: 0.6368 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6340 - accuracy: 0.8000 - val_loss: 0.6330 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6301 - accuracy: 0.8000 - val_loss: 0.6292 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6261 - accuracy: 0.8000 - val_loss: 0.6253 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 2 2 0 3 4 2 4 4 2 1 4 2 0 4 4 4 2 4 4 4 4 3 2 1]\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_291 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_97 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 170ms/step - loss: 0.6872 - accuracy: 0.6759 - val_loss: 0.6708 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6663 - accuracy: 0.8000 - val_loss: 0.6557 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6512 - accuracy: 0.8000 - val_loss: 0.6430 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6383 - accuracy: 0.8000 - val_loss: 0.6316 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6267 - accuracy: 0.8000 - val_loss: 0.6213 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6162 - accuracy: 0.8000 - val_loss: 0.6117 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6064 - accuracy: 0.8000 - val_loss: 0.6028 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5973 - accuracy: 0.8000 - val_loss: 0.5944 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5887 - accuracy: 0.8000 - val_loss: 0.5864 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5806 - accuracy: 0.8000 - val_loss: 0.5788 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5730 - accuracy: 0.8000 - val_loss: 0.5717 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5658 - accuracy: 0.8000 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5590 - accuracy: 0.8000 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5527 - accuracy: 0.8000 - val_loss: 0.5526 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5468 - accuracy: 0.8000 - val_loss: 0.5470 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5412 - accuracy: 0.8000 - val_loss: 0.5417 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5361 - accuracy: 0.8000 - val_loss: 0.5368 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5314 - accuracy: 0.8000 - val_loss: 0.5323 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5270 - accuracy: 0.8000 - val_loss: 0.5281 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5231 - accuracy: 0.8000 - val_loss: 0.5243 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 2 0 2 0 2 4 4 3 4 0 4 2 2 2 4 4 4 0 4 2 4 1 1]\n",
      "[]\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_294 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_98 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 85ms/step - loss: 0.6779 - accuracy: 0.8000 - val_loss: 0.6528 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6469 - accuracy: 0.8000 - val_loss: 0.6283 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6238 - accuracy: 0.8000 - val_loss: 0.6088 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6048 - accuracy: 0.8000 - val_loss: 0.5925 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5890 - accuracy: 0.8000 - val_loss: 0.5782 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5747 - accuracy: 0.8000 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5623 - accuracy: 0.8000 - val_loss: 0.5543 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5513 - accuracy: 0.8000 - val_loss: 0.5442 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5414 - accuracy: 0.8000 - val_loss: 0.5353 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5328 - accuracy: 0.8000 - val_loss: 0.5277 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5255 - accuracy: 0.8000 - val_loss: 0.5212 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5192 - accuracy: 0.8000 - val_loss: 0.5159 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5142 - accuracy: 0.8000 - val_loss: 0.5115 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5101 - accuracy: 0.8000 - val_loss: 0.5082 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5070 - accuracy: 0.8000 - val_loss: 0.5056 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5047 - accuracy: 0.8000 - val_loss: 0.5037 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5031 - accuracy: 0.8000 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5020 - accuracy: 0.8000 - val_loss: 0.5017 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5014 - accuracy: 0.8000 - val_loss: 0.5013 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5010 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 4 1 1 2 2 2 3 0 4 3 4 4 4 4 4]\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_297 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_99 (Flatten)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 88ms/step - loss: 0.6932 - accuracy: 0.5273 - val_loss: 0.6868 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6857 - accuracy: 0.8000 - val_loss: 0.6826 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6816 - accuracy: 0.8000 - val_loss: 0.6787 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6776 - accuracy: 0.8000 - val_loss: 0.6748 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6736 - accuracy: 0.8000 - val_loss: 0.6708 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6695 - accuracy: 0.8000 - val_loss: 0.6666 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6652 - accuracy: 0.8000 - val_loss: 0.6623 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6607 - accuracy: 0.8000 - val_loss: 0.6581 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6564 - accuracy: 0.8000 - val_loss: 0.6539 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6522 - accuracy: 0.8000 - val_loss: 0.6498 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6479 - accuracy: 0.8000 - val_loss: 0.6456 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6437 - accuracy: 0.8000 - val_loss: 0.6415 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6394 - accuracy: 0.8000 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6352 - accuracy: 0.8000 - val_loss: 0.6334 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6310 - accuracy: 0.8000 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6267 - accuracy: 0.8000 - val_loss: 0.6250 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6225 - accuracy: 0.8000 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6184 - accuracy: 0.8000 - val_loss: 0.6169 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6142 - accuracy: 0.8000 - val_loss: 0.6127 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6100 - accuracy: 0.8000 - val_loss: 0.6086 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 4 0 2 2 4 2 4 2 1 2 2 4 2 4 4]\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_300 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_100 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 83ms/step - loss: 0.6909 - accuracy: 0.5273 - val_loss: 0.6780 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6755 - accuracy: 0.8000 - val_loss: 0.6681 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6657 - accuracy: 0.8000 - val_loss: 0.6600 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6574 - accuracy: 0.8000 - val_loss: 0.6516 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6493 - accuracy: 0.8000 - val_loss: 0.6436 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6414 - accuracy: 0.8000 - val_loss: 0.6362 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6338 - accuracy: 0.8000 - val_loss: 0.6290 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6264 - accuracy: 0.8000 - val_loss: 0.6221 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6195 - accuracy: 0.8000 - val_loss: 0.6154 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6131 - accuracy: 0.8000 - val_loss: 0.6083 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6058 - accuracy: 0.8000 - val_loss: 0.6016 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5990 - accuracy: 0.8000 - val_loss: 0.5949 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5921 - accuracy: 0.8000 - val_loss: 0.5883 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5856 - accuracy: 0.8000 - val_loss: 0.5816 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5787 - accuracy: 0.8000 - val_loss: 0.5754 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5726 - accuracy: 0.8000 - val_loss: 0.5688 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5661 - accuracy: 0.8000 - val_loss: 0.5627 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5600 - accuracy: 0.8000 - val_loss: 0.5568 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5541 - accuracy: 0.8000 - val_loss: 0.5511 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5484 - accuracy: 0.8000 - val_loss: 0.5456 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 3 1 2 3 0 4 0 2 2 2 0 4 4 2 4 4]\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_303 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_101 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 84ms/step - loss: 0.6904 - accuracy: 0.7909 - val_loss: 0.6826 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6805 - accuracy: 0.8000 - val_loss: 0.6739 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6716 - accuracy: 0.8000 - val_loss: 0.6652 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6627 - accuracy: 0.8000 - val_loss: 0.6566 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6540 - accuracy: 0.8000 - val_loss: 0.6482 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6453 - accuracy: 0.8000 - val_loss: 0.6397 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6367 - accuracy: 0.8000 - val_loss: 0.6314 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6281 - accuracy: 0.8000 - val_loss: 0.6230 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6196 - accuracy: 0.8000 - val_loss: 0.6147 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6111 - accuracy: 0.8000 - val_loss: 0.6065 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6027 - accuracy: 0.8000 - val_loss: 0.5983 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5945 - accuracy: 0.8000 - val_loss: 0.5904 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5864 - accuracy: 0.8000 - val_loss: 0.5826 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5786 - accuracy: 0.8000 - val_loss: 0.5751 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5710 - accuracy: 0.8000 - val_loss: 0.5678 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5637 - accuracy: 0.8000 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5567 - accuracy: 0.8000 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5501 - accuracy: 0.8000 - val_loss: 0.5478 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5438 - accuracy: 0.8000 - val_loss: 0.5418 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5380 - accuracy: 0.8000 - val_loss: 0.5362 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 4 1 1 2 2 0 4 0 2 2 0 2 2 4 0 0]\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_306 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_102 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 84ms/step - loss: 0.6928 - accuracy: 0.5273 - val_loss: 0.6839 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6821 - accuracy: 0.8000 - val_loss: 0.6761 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6747 - accuracy: 0.8000 - val_loss: 0.6695 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6680 - accuracy: 0.8000 - val_loss: 0.6625 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6612 - accuracy: 0.8000 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6544 - accuracy: 0.8000 - val_loss: 0.6492 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6475 - accuracy: 0.8000 - val_loss: 0.6426 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6409 - accuracy: 0.8000 - val_loss: 0.6362 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6344 - accuracy: 0.8000 - val_loss: 0.6297 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6279 - accuracy: 0.8000 - val_loss: 0.6234 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6215 - accuracy: 0.8000 - val_loss: 0.6170 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6150 - accuracy: 0.8000 - val_loss: 0.6109 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6087 - accuracy: 0.8000 - val_loss: 0.6047 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6024 - accuracy: 0.8000 - val_loss: 0.5983 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5961 - accuracy: 0.8000 - val_loss: 0.5921 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5900 - accuracy: 0.8000 - val_loss: 0.5860 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5840 - accuracy: 0.8000 - val_loss: 0.5800 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5778 - accuracy: 0.8000 - val_loss: 0.5743 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5720 - accuracy: 0.8000 - val_loss: 0.5687 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5664 - accuracy: 0.8000 - val_loss: 0.5630 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 2 2 2 4 0 4 0 0 0 0 1 4 0 2 4 4]\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_309 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_310 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_103 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 84ms/step - loss: 0.6789 - accuracy: 0.8000 - val_loss: 0.6550 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6489 - accuracy: 0.8000 - val_loss: 0.6344 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6287 - accuracy: 0.8000 - val_loss: 0.6175 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6120 - accuracy: 0.8000 - val_loss: 0.6027 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5972 - accuracy: 0.8000 - val_loss: 0.5894 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5839 - accuracy: 0.8000 - val_loss: 0.5773 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5719 - accuracy: 0.8000 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5611 - accuracy: 0.8000 - val_loss: 0.5564 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5513 - accuracy: 0.8000 - val_loss: 0.5474 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5426 - accuracy: 0.8000 - val_loss: 0.5394 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5348 - accuracy: 0.8000 - val_loss: 0.5323 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5280 - accuracy: 0.8000 - val_loss: 0.5260 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5220 - accuracy: 0.8000 - val_loss: 0.5207 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5170 - accuracy: 0.8000 - val_loss: 0.5161 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5128 - accuracy: 0.8000 - val_loss: 0.5123 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5094 - accuracy: 0.8000 - val_loss: 0.5092 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5067 - accuracy: 0.8000 - val_loss: 0.5067 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5047 - accuracy: 0.8000 - val_loss: 0.5048 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5031 - accuracy: 0.8000 - val_loss: 0.5034 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5021 - accuracy: 0.8000 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 4 0 4 2 2 4 4 2 3 4 2 2 2 0 0 4]\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_312 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_104 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 84ms/step - loss: 0.6912 - accuracy: 0.5273 - val_loss: 0.6742 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6702 - accuracy: 0.8000 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6526 - accuracy: 0.8000 - val_loss: 0.6420 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6393 - accuracy: 0.8000 - val_loss: 0.6306 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6280 - accuracy: 0.8000 - val_loss: 0.6201 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6174 - accuracy: 0.8000 - val_loss: 0.6100 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6074 - accuracy: 0.8000 - val_loss: 0.6004 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5978 - accuracy: 0.8000 - val_loss: 0.5911 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5884 - accuracy: 0.8000 - val_loss: 0.5821 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5792 - accuracy: 0.8000 - val_loss: 0.5733 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5705 - accuracy: 0.8000 - val_loss: 0.5649 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5622 - accuracy: 0.8000 - val_loss: 0.5570 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5543 - accuracy: 0.8000 - val_loss: 0.5496 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5469 - accuracy: 0.8000 - val_loss: 0.5427 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5401 - accuracy: 0.8000 - val_loss: 0.5363 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.8000 - val_loss: 0.5306 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5283 - accuracy: 0.8000 - val_loss: 0.5253 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5233 - accuracy: 0.8000 - val_loss: 0.5208 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5188 - accuracy: 0.8000 - val_loss: 0.5167 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5150 - accuracy: 0.8000 - val_loss: 0.5132 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 2 0 4 3 4 3 2 0 0 4 2 0 4 2 2]\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_315 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_105 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 82ms/step - loss: 0.6870 - accuracy: 0.5364 - val_loss: 0.6659 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6622 - accuracy: 0.8000 - val_loss: 0.6496 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6462 - accuracy: 0.8000 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6321 - accuracy: 0.8000 - val_loss: 0.6228 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6190 - accuracy: 0.8000 - val_loss: 0.6107 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6069 - accuracy: 0.8000 - val_loss: 0.5995 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5955 - accuracy: 0.8000 - val_loss: 0.5889 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5849 - accuracy: 0.8000 - val_loss: 0.5790 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5749 - accuracy: 0.8000 - val_loss: 0.5698 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5656 - accuracy: 0.8000 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5570 - accuracy: 0.8000 - val_loss: 0.5530 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5490 - accuracy: 0.8000 - val_loss: 0.5456 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5417 - accuracy: 0.8000 - val_loss: 0.5388 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5351 - accuracy: 0.8000 - val_loss: 0.5326 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5290 - accuracy: 0.8000 - val_loss: 0.5271 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5237 - accuracy: 0.8000 - val_loss: 0.5222 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5190 - accuracy: 0.8000 - val_loss: 0.5179 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5149 - accuracy: 0.8000 - val_loss: 0.5141 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5114 - accuracy: 0.8000 - val_loss: 0.5109 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5085 - accuracy: 0.8000 - val_loss: 0.5084 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 2 2 3 4 3 2 2 2 0 2 2 0 4 2 4 4]\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_318 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_106 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 88ms/step - loss: 0.6944 - accuracy: 0.3455 - val_loss: 0.6913 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6905 - accuracy: 0.7909 - val_loss: 0.6877 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6870 - accuracy: 0.8000 - val_loss: 0.6850 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6846 - accuracy: 0.8000 - val_loss: 0.6828 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6823 - accuracy: 0.8000 - val_loss: 0.6807 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6802 - accuracy: 0.8000 - val_loss: 0.6787 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6781 - accuracy: 0.8000 - val_loss: 0.6767 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6764 - accuracy: 0.8000 - val_loss: 0.6746 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6740 - accuracy: 0.8000 - val_loss: 0.6725 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6719 - accuracy: 0.8000 - val_loss: 0.6703 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6698 - accuracy: 0.8000 - val_loss: 0.6681 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6676 - accuracy: 0.8000 - val_loss: 0.6658 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6651 - accuracy: 0.8000 - val_loss: 0.6633 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6626 - accuracy: 0.8000 - val_loss: 0.6609 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6600 - accuracy: 0.8000 - val_loss: 0.6583 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6576 - accuracy: 0.8000 - val_loss: 0.6557 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6548 - accuracy: 0.8000 - val_loss: 0.6529 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6521 - accuracy: 0.8000 - val_loss: 0.6503 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6493 - accuracy: 0.8000 - val_loss: 0.6473 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6462 - accuracy: 0.8000 - val_loss: 0.6443 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 1 2 1 3 1 4 2 4 0 4 2 4 3 0 2]\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_321 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_107 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 81ms/step - loss: 0.6928 - accuracy: 0.5455 - val_loss: 0.6867 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6853 - accuracy: 0.8000 - val_loss: 0.6815 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6805 - accuracy: 0.8000 - val_loss: 0.6777 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6767 - accuracy: 0.8000 - val_loss: 0.6742 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6732 - accuracy: 0.8000 - val_loss: 0.6709 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6699 - accuracy: 0.8000 - val_loss: 0.6677 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6667 - accuracy: 0.8000 - val_loss: 0.6646 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6635 - accuracy: 0.8000 - val_loss: 0.6615 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6604 - accuracy: 0.8000 - val_loss: 0.6585 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6573 - accuracy: 0.8000 - val_loss: 0.6555 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6542 - accuracy: 0.8000 - val_loss: 0.6525 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6511 - accuracy: 0.8000 - val_loss: 0.6494 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6480 - accuracy: 0.8000 - val_loss: 0.6464 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6449 - accuracy: 0.8000 - val_loss: 0.6434 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6418 - accuracy: 0.8000 - val_loss: 0.6404 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6387 - accuracy: 0.8000 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6356 - accuracy: 0.8000 - val_loss: 0.6343 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6326 - accuracy: 0.8000 - val_loss: 0.6313 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6295 - accuracy: 0.8000 - val_loss: 0.6283 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6264 - accuracy: 0.8000 - val_loss: 0.6253 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 2 2 0 0 4 4 0 4 0 2 0 1 0 4 4]\n",
      "[]\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_324 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_108 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 92ms/step - loss: 0.6874 - accuracy: 0.6216 - val_loss: 0.6769 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6733 - accuracy: 0.8000 - val_loss: 0.6674 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6639 - accuracy: 0.8000 - val_loss: 0.6593 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6557 - accuracy: 0.8000 - val_loss: 0.6517 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6480 - accuracy: 0.8000 - val_loss: 0.6434 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6387 - accuracy: 0.8000 - val_loss: 0.6337 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6294 - accuracy: 0.8000 - val_loss: 0.6257 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6213 - accuracy: 0.8000 - val_loss: 0.6181 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6137 - accuracy: 0.8000 - val_loss: 0.6108 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6064 - accuracy: 0.8000 - val_loss: 0.6038 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5992 - accuracy: 0.8000 - val_loss: 0.5970 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5923 - accuracy: 0.8000 - val_loss: 0.5903 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5856 - accuracy: 0.8000 - val_loss: 0.5837 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5790 - accuracy: 0.8000 - val_loss: 0.5774 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5726 - accuracy: 0.8000 - val_loss: 0.5712 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5664 - accuracy: 0.8000 - val_loss: 0.5652 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5605 - accuracy: 0.8000 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5548 - accuracy: 0.8000 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5493 - accuracy: 0.8000 - val_loss: 0.5487 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5441 - accuracy: 0.8000 - val_loss: 0.5436 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 0 4 2 1 1 4 0]\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_327 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_109 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 81ms/step - loss: 0.6812 - accuracy: 0.8000 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6384 - accuracy: 0.8000 - val_loss: 0.6192 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6110 - accuracy: 0.8000 - val_loss: 0.5974 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5898 - accuracy: 0.8000 - val_loss: 0.5798 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5726 - accuracy: 0.8000 - val_loss: 0.5650 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5581 - accuracy: 0.8000 - val_loss: 0.5523 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5459 - accuracy: 0.8000 - val_loss: 0.5415 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5355 - accuracy: 0.8000 - val_loss: 0.5324 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5269 - accuracy: 0.8000 - val_loss: 0.5247 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5199 - accuracy: 0.8000 - val_loss: 0.5184 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5142 - accuracy: 0.8000 - val_loss: 0.5135 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5099 - accuracy: 0.8000 - val_loss: 0.5096 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5066 - accuracy: 0.8000 - val_loss: 0.5067 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5043 - accuracy: 0.8000 - val_loss: 0.5047 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5028 - accuracy: 0.8000 - val_loss: 0.5032 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5018 - accuracy: 0.8000 - val_loss: 0.5023 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5012 - accuracy: 0.8000 - val_loss: 0.5018 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5010 - accuracy: 0.8000 - val_loss: 0.5015 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5013 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5012 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 3 4 4 2 0 2 0 2]\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_330 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_110 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 82ms/step - loss: 0.6761 - accuracy: 0.8000 - val_loss: 0.6433 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6337 - accuracy: 0.8000 - val_loss: 0.6133 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6058 - accuracy: 0.8000 - val_loss: 0.5921 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5850 - accuracy: 0.8000 - val_loss: 0.5738 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5672 - accuracy: 0.8000 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5530 - accuracy: 0.8000 - val_loss: 0.5469 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5414 - accuracy: 0.8000 - val_loss: 0.5369 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5319 - accuracy: 0.8000 - val_loss: 0.5286 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5240 - accuracy: 0.8000 - val_loss: 0.5216 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5177 - accuracy: 0.8000 - val_loss: 0.5161 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5126 - accuracy: 0.8000 - val_loss: 0.5116 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5087 - accuracy: 0.8000 - val_loss: 0.5082 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5058 - accuracy: 0.8000 - val_loss: 0.5057 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5038 - accuracy: 0.8000 - val_loss: 0.5039 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5024 - accuracy: 0.8000 - val_loss: 0.5027 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5016 - accuracy: 0.8000 - val_loss: 0.5020 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5015 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.5013 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 0 4 1 2 4 2 4 4]\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_333 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_111 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 81ms/step - loss: 0.6805 - accuracy: 0.6378 - val_loss: 0.6540 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6469 - accuracy: 0.8000 - val_loss: 0.6334 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6271 - accuracy: 0.8000 - val_loss: 0.6170 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6110 - accuracy: 0.8000 - val_loss: 0.6030 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5972 - accuracy: 0.8000 - val_loss: 0.5905 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5848 - accuracy: 0.8000 - val_loss: 0.5792 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5736 - accuracy: 0.8000 - val_loss: 0.5688 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5635 - accuracy: 0.8000 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5542 - accuracy: 0.8000 - val_loss: 0.5508 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5457 - accuracy: 0.8000 - val_loss: 0.5429 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5381 - accuracy: 0.8000 - val_loss: 0.5358 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5313 - accuracy: 0.8000 - val_loss: 0.5294 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5253 - accuracy: 0.8000 - val_loss: 0.5238 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5200 - accuracy: 0.8000 - val_loss: 0.5190 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5156 - accuracy: 0.8000 - val_loss: 0.5148 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5118 - accuracy: 0.8000 - val_loss: 0.5114 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5088 - accuracy: 0.8000 - val_loss: 0.5085 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5063 - accuracy: 0.8000 - val_loss: 0.5062 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5044 - accuracy: 0.8000 - val_loss: 0.5045 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5031 - accuracy: 0.8000 - val_loss: 0.5032 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 4 4 2 2 2 3 2 4]\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_336 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_112 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 82ms/step - loss: 0.6712 - accuracy: 0.8000 - val_loss: 0.6430 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6339 - accuracy: 0.8000 - val_loss: 0.6166 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6085 - accuracy: 0.8000 - val_loss: 0.5967 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5891 - accuracy: 0.8000 - val_loss: 0.5806 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5733 - accuracy: 0.8000 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5600 - accuracy: 0.8000 - val_loss: 0.5551 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5485 - accuracy: 0.8000 - val_loss: 0.5450 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5388 - accuracy: 0.8000 - val_loss: 0.5363 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5305 - accuracy: 0.8000 - val_loss: 0.5288 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5235 - accuracy: 0.8000 - val_loss: 0.5225 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5178 - accuracy: 0.8000 - val_loss: 0.5173 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5131 - accuracy: 0.8000 - val_loss: 0.5130 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5094 - accuracy: 0.8000 - val_loss: 0.5096 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5066 - accuracy: 0.8000 - val_loss: 0.5069 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5045 - accuracy: 0.8000 - val_loss: 0.5050 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5030 - accuracy: 0.8000 - val_loss: 0.5035 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5020 - accuracy: 0.8000 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5014 - accuracy: 0.8000 - val_loss: 0.5019 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5015 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.5013 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 0 4 0 0 2 4 2 2]\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_339 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_113 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 81ms/step - loss: 0.6845 - accuracy: 0.5649 - val_loss: 0.6561 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6480 - accuracy: 0.8000 - val_loss: 0.6218 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6140 - accuracy: 0.8000 - val_loss: 0.5946 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5882 - accuracy: 0.8000 - val_loss: 0.5740 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5684 - accuracy: 0.8000 - val_loss: 0.5572 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5522 - accuracy: 0.8000 - val_loss: 0.5434 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5391 - accuracy: 0.8000 - val_loss: 0.5321 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5284 - accuracy: 0.8000 - val_loss: 0.5230 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5199 - accuracy: 0.8000 - val_loss: 0.5159 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5134 - accuracy: 0.8000 - val_loss: 0.5107 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5087 - accuracy: 0.8000 - val_loss: 0.5068 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5054 - accuracy: 0.8000 - val_loss: 0.5042 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5032 - accuracy: 0.8000 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5019 - accuracy: 0.8000 - val_loss: 0.5016 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5013 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.5008 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5007 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5007 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5007 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5006 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 2 4 2 4 4 2 4]\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_342 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_114 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 359ms/step - loss: 0.6909 - accuracy: 0.5730 - val_loss: 0.6842 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6824 - accuracy: 0.8000 - val_loss: 0.6780 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6760 - accuracy: 0.8000 - val_loss: 0.6708 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6696 - accuracy: 0.8000 - val_loss: 0.6645 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6631 - accuracy: 0.8000 - val_loss: 0.6588 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6568 - accuracy: 0.8000 - val_loss: 0.6518 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6508 - accuracy: 0.8000 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6445 - accuracy: 0.8000 - val_loss: 0.6396 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6380 - accuracy: 0.8000 - val_loss: 0.6331 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6315 - accuracy: 0.8000 - val_loss: 0.6267 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6249 - accuracy: 0.8000 - val_loss: 0.6196 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6180 - accuracy: 0.8000 - val_loss: 0.6124 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6110 - accuracy: 0.8000 - val_loss: 0.6056 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6042 - accuracy: 0.8000 - val_loss: 0.5987 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5973 - accuracy: 0.8000 - val_loss: 0.5919 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5903 - accuracy: 0.8000 - val_loss: 0.5854 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5840 - accuracy: 0.8000 - val_loss: 0.5788 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5774 - accuracy: 0.8000 - val_loss: 0.5721 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5708 - accuracy: 0.8000 - val_loss: 0.5661 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5646 - accuracy: 0.8000 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 2 4 1 2 4 3 0]\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_345 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_115 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 82ms/step - loss: 0.6860 - accuracy: 0.5649 - val_loss: 0.6654 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6600 - accuracy: 0.8000 - val_loss: 0.6471 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6421 - accuracy: 0.8000 - val_loss: 0.6321 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6272 - accuracy: 0.8000 - val_loss: 0.6187 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6138 - accuracy: 0.8000 - val_loss: 0.6065 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6015 - accuracy: 0.8000 - val_loss: 0.5952 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5902 - accuracy: 0.8000 - val_loss: 0.5847 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5797 - accuracy: 0.8000 - val_loss: 0.5748 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5699 - accuracy: 0.8000 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5608 - accuracy: 0.8000 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5525 - accuracy: 0.8000 - val_loss: 0.5494 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5448 - accuracy: 0.8000 - val_loss: 0.5423 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5378 - accuracy: 0.8000 - val_loss: 0.5357 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5315 - accuracy: 0.8000 - val_loss: 0.5298 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5258 - accuracy: 0.8000 - val_loss: 0.5246 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5209 - accuracy: 0.8000 - val_loss: 0.5199 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5165 - accuracy: 0.8000 - val_loss: 0.5159 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5128 - accuracy: 0.8000 - val_loss: 0.5124 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5097 - accuracy: 0.8000 - val_loss: 0.5095 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5072 - accuracy: 0.8000 - val_loss: 0.5071 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 4 2 0 4 3 3 4]\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_348 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_350 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_116 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 85ms/step - loss: 0.6666 - accuracy: 0.8000 - val_loss: 0.6314 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6192 - accuracy: 0.8000 - val_loss: 0.6011 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5909 - accuracy: 0.8000 - val_loss: 0.5791 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5697 - accuracy: 0.8000 - val_loss: 0.5619 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5531 - accuracy: 0.8000 - val_loss: 0.5478 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5398 - accuracy: 0.8000 - val_loss: 0.5364 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5293 - accuracy: 0.8000 - val_loss: 0.5273 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5210 - accuracy: 0.8000 - val_loss: 0.5200 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5147 - accuracy: 0.8000 - val_loss: 0.5144 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5099 - accuracy: 0.8000 - val_loss: 0.5101 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5065 - accuracy: 0.8000 - val_loss: 0.5069 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5041 - accuracy: 0.8000 - val_loss: 0.5047 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5026 - accuracy: 0.8000 - val_loss: 0.5033 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5017 - accuracy: 0.8000 - val_loss: 0.5023 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5012 - accuracy: 0.8000 - val_loss: 0.5017 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.5014 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5012 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 2 4 4 4 2 2 2 2]\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_351 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_117 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 89ms/step - loss: 0.6965 - accuracy: 0.3135 - val_loss: 0.6846 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6822 - accuracy: 0.8000 - val_loss: 0.6760 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6738 - accuracy: 0.8000 - val_loss: 0.6684 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6663 - accuracy: 0.8000 - val_loss: 0.6613 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6590 - accuracy: 0.8000 - val_loss: 0.6544 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6519 - accuracy: 0.8000 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6448 - accuracy: 0.8000 - val_loss: 0.6404 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6377 - accuracy: 0.8000 - val_loss: 0.6335 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6306 - accuracy: 0.8000 - val_loss: 0.6266 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6236 - accuracy: 0.8000 - val_loss: 0.6198 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6166 - accuracy: 0.8000 - val_loss: 0.6130 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6097 - accuracy: 0.8000 - val_loss: 0.6062 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6028 - accuracy: 0.8000 - val_loss: 0.5996 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5961 - accuracy: 0.8000 - val_loss: 0.5932 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5897 - accuracy: 0.8000 - val_loss: 0.5870 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5834 - accuracy: 0.8000 - val_loss: 0.5811 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5774 - accuracy: 0.8000 - val_loss: 0.5752 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5715 - accuracy: 0.8000 - val_loss: 0.5697 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5659 - accuracy: 0.8000 - val_loss: 0.5642 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5605 - accuracy: 0.8000 - val_loss: 0.5590 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 2 2 4 2 2 0 2 0]\n",
      "[]\n",
      "seconds value in hours: 0.0\n",
      "seconds value in minutes: 0.0\n",
      "tfidf\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_354 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_118 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 193ms/step - loss: 0.6843 - accuracy: 0.8000 - val_loss: 0.6565 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6507 - accuracy: 0.8000 - val_loss: 0.6319 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6259 - accuracy: 0.8000 - val_loss: 0.6143 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6079 - accuracy: 0.8000 - val_loss: 0.6000 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5932 - accuracy: 0.8000 - val_loss: 0.5876 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5806 - accuracy: 0.8000 - val_loss: 0.5767 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5696 - accuracy: 0.8000 - val_loss: 0.5670 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5598 - accuracy: 0.8000 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5510 - accuracy: 0.8000 - val_loss: 0.5504 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5433 - accuracy: 0.8000 - val_loss: 0.5433 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5363 - accuracy: 0.8000 - val_loss: 0.5369 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5302 - accuracy: 0.8000 - val_loss: 0.5313 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5249 - accuracy: 0.8000 - val_loss: 0.5264 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5203 - accuracy: 0.8000 - val_loss: 0.5220 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5163 - accuracy: 0.8000 - val_loss: 0.5182 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5129 - accuracy: 0.8000 - val_loss: 0.5149 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5101 - accuracy: 0.8000 - val_loss: 0.5122 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5077 - accuracy: 0.8000 - val_loss: 0.5098 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5058 - accuracy: 0.8000 - val_loss: 0.5079 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5043 - accuracy: 0.8000 - val_loss: 0.5063 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [4 2 1 4 2 4 1 2 0 4 4 1 2 4 4 3 0 0 0 2 4 4 4 1 1 4 4 0 4 4 2 2 3 0 2 0 2\n",
      " 4 0 3 0 3]\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_357 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_119 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.6926 - accuracy: 0.4780 - val_loss: 0.6872 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6865 - accuracy: 0.8000 - val_loss: 0.6831 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6823 - accuracy: 0.8000 - val_loss: 0.6795 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6787 - accuracy: 0.8000 - val_loss: 0.6761 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6752 - accuracy: 0.8000 - val_loss: 0.6729 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6718 - accuracy: 0.8000 - val_loss: 0.6696 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6686 - accuracy: 0.8000 - val_loss: 0.6665 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6653 - accuracy: 0.8000 - val_loss: 0.6634 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6621 - accuracy: 0.8000 - val_loss: 0.6603 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6589 - accuracy: 0.8000 - val_loss: 0.6571 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6557 - accuracy: 0.8000 - val_loss: 0.6540 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6524 - accuracy: 0.8000 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6491 - accuracy: 0.8000 - val_loss: 0.6476 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6459 - accuracy: 0.8000 - val_loss: 0.6444 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6426 - accuracy: 0.8000 - val_loss: 0.6411 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6392 - accuracy: 0.8000 - val_loss: 0.6379 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6358 - accuracy: 0.8000 - val_loss: 0.6346 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6324 - accuracy: 0.8000 - val_loss: 0.6313 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6290 - accuracy: 0.8000 - val_loss: 0.6279 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6255 - accuracy: 0.8000 - val_loss: 0.6245 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 2 1 4 2 2 4 0 4 2 4 0 0 3 4 2 4 2 1 4 2 1 0 1 1 1 3 3 0 4 4 4 1 0 0 4 2\n",
      " 1 4 4 4 2]\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_360 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_120 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.6891 - accuracy: 0.6976 - val_loss: 0.6734 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6710 - accuracy: 0.8000 - val_loss: 0.6614 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6589 - accuracy: 0.8000 - val_loss: 0.6515 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6488 - accuracy: 0.8000 - val_loss: 0.6428 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6399 - accuracy: 0.8000 - val_loss: 0.6348 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6317 - accuracy: 0.8000 - val_loss: 0.6272 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6239 - accuracy: 0.8000 - val_loss: 0.6200 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6165 - accuracy: 0.8000 - val_loss: 0.6131 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6095 - accuracy: 0.8000 - val_loss: 0.6065 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6027 - accuracy: 0.8000 - val_loss: 0.6001 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5962 - accuracy: 0.8000 - val_loss: 0.5940 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5899 - accuracy: 0.8000 - val_loss: 0.5880 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5838 - accuracy: 0.8000 - val_loss: 0.5823 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5780 - accuracy: 0.8000 - val_loss: 0.5767 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5723 - accuracy: 0.8000 - val_loss: 0.5714 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5669 - accuracy: 0.8000 - val_loss: 0.5662 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5617 - accuracy: 0.8000 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5567 - accuracy: 0.8000 - val_loss: 0.5564 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5519 - accuracy: 0.8000 - val_loss: 0.5519 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5474 - accuracy: 0.8000 - val_loss: 0.5475 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [0 2 4 0 2 4 4 4 2 4 0 4 4 4 2 2 0 4 2 2 2 2 1 4 0 0 4 0 4 4 2 4 3 2 4 1 4\n",
      " 2 3 0 3 1]\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_363 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_121 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.6938 - accuracy: 0.3610 - val_loss: 0.6884 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6877 - accuracy: 0.8000 - val_loss: 0.6846 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6839 - accuracy: 0.8000 - val_loss: 0.6812 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6804 - accuracy: 0.8000 - val_loss: 0.6771 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6760 - accuracy: 0.8000 - val_loss: 0.6718 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6706 - accuracy: 0.8000 - val_loss: 0.6671 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6657 - accuracy: 0.8000 - val_loss: 0.6625 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6610 - accuracy: 0.8000 - val_loss: 0.6581 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6564 - accuracy: 0.8000 - val_loss: 0.6537 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6519 - accuracy: 0.8000 - val_loss: 0.6494 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6474 - accuracy: 0.8000 - val_loss: 0.6450 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6429 - accuracy: 0.8000 - val_loss: 0.6408 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6385 - accuracy: 0.8000 - val_loss: 0.6365 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6341 - accuracy: 0.8000 - val_loss: 0.6322 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6296 - accuracy: 0.8000 - val_loss: 0.6279 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6252 - accuracy: 0.8000 - val_loss: 0.6236 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6208 - accuracy: 0.8000 - val_loss: 0.6194 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.6164 - accuracy: 0.8000 - val_loss: 0.6152 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6120 - accuracy: 0.8000 - val_loss: 0.6109 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6077 - accuracy: 0.8000 - val_loss: 0.6067 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [4 0 4 2 2 4 1 4 0 3 2 4 2 4 1 0 2 3 0 2 3 4 2 2 0 2 3 2 4 4 4 2 0 4 2 4 0\n",
      " 0 4 4 2 1]\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_366 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_122 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.6942 - accuracy: 0.3610 - val_loss: 0.6902 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6897 - accuracy: 0.8000 - val_loss: 0.6874 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6868 - accuracy: 0.8000 - val_loss: 0.6845 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6842 - accuracy: 0.8000 - val_loss: 0.6828 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6819 - accuracy: 0.8000 - val_loss: 0.6796 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6792 - accuracy: 0.8000 - val_loss: 0.6773 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6771 - accuracy: 0.8000 - val_loss: 0.6753 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6749 - accuracy: 0.8000 - val_loss: 0.6733 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6730 - accuracy: 0.8000 - val_loss: 0.6711 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6707 - accuracy: 0.8000 - val_loss: 0.6691 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6686 - accuracy: 0.8000 - val_loss: 0.6670 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6664 - accuracy: 0.8000 - val_loss: 0.6648 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6642 - accuracy: 0.8000 - val_loss: 0.6627 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6620 - accuracy: 0.8000 - val_loss: 0.6604 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6596 - accuracy: 0.8000 - val_loss: 0.6582 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6572 - accuracy: 0.8000 - val_loss: 0.6558 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6551 - accuracy: 0.8000 - val_loss: 0.6535 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6527 - accuracy: 0.8000 - val_loss: 0.6511 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6501 - accuracy: 0.8000 - val_loss: 0.6487 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6475 - accuracy: 0.8000 - val_loss: 0.6462 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [0 4 4 2 0 2 3 0 4 2 4 0 0 4 4 2 4 4 2 3 1 2 2 4 4 2 4 4 2 2 2 4 2 2 2 3 1\n",
      " 4 2 2 1 4]\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_369 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_370 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_123 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.6896 - accuracy: 0.6244 - val_loss: 0.6701 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6677 - accuracy: 0.8000 - val_loss: 0.6551 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6529 - accuracy: 0.8000 - val_loss: 0.6432 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6410 - accuracy: 0.8000 - val_loss: 0.6331 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6306 - accuracy: 0.8000 - val_loss: 0.6238 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6212 - accuracy: 0.8000 - val_loss: 0.6153 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6124 - accuracy: 0.8000 - val_loss: 0.6071 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6042 - accuracy: 0.8000 - val_loss: 0.5995 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5964 - accuracy: 0.8000 - val_loss: 0.5922 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5890 - accuracy: 0.8000 - val_loss: 0.5852 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5820 - accuracy: 0.8000 - val_loss: 0.5786 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5753 - accuracy: 0.8000 - val_loss: 0.5723 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5688 - accuracy: 0.8000 - val_loss: 0.5662 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5628 - accuracy: 0.8000 - val_loss: 0.5605 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5571 - accuracy: 0.8000 - val_loss: 0.5550 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5516 - accuracy: 0.8000 - val_loss: 0.5499 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5465 - accuracy: 0.8000 - val_loss: 0.5450 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5416 - accuracy: 0.8000 - val_loss: 0.5405 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5371 - accuracy: 0.8000 - val_loss: 0.5362 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5329 - accuracy: 0.8000 - val_loss: 0.5322 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 4 2 4 4 4 2 2 0 2 2 0 2 3 4 2 2 4 4 4 4 2 0 0 4 1 4 4 2 2 0 0 1 2 4 4 3\n",
      " 4 3 2 2 4]\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_372 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_374 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_124 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 168ms/step - loss: 0.6838 - accuracy: 0.8000 - val_loss: 0.6608 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6575 - accuracy: 0.8000 - val_loss: 0.6399 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6370 - accuracy: 0.8000 - val_loss: 0.6241 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6211 - accuracy: 0.8000 - val_loss: 0.6105 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6075 - accuracy: 0.8000 - val_loss: 0.5985 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5955 - accuracy: 0.8000 - val_loss: 0.5878 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5846 - accuracy: 0.8000 - val_loss: 0.5780 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5748 - accuracy: 0.8000 - val_loss: 0.5690 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5658 - accuracy: 0.8000 - val_loss: 0.5607 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5576 - accuracy: 0.8000 - val_loss: 0.5532 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5501 - accuracy: 0.8000 - val_loss: 0.5463 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5432 - accuracy: 0.8000 - val_loss: 0.5400 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5370 - accuracy: 0.8000 - val_loss: 0.5342 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5314 - accuracy: 0.8000 - val_loss: 0.5291 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5264 - accuracy: 0.8000 - val_loss: 0.5245 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5220 - accuracy: 0.8000 - val_loss: 0.5205 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5181 - accuracy: 0.8000 - val_loss: 0.5169 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5147 - accuracy: 0.8000 - val_loss: 0.5138 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5118 - accuracy: 0.8000 - val_loss: 0.5111 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5093 - accuracy: 0.8000 - val_loss: 0.5089 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [2 4 2 4 2 4 0 3 0 2 4 4 4 3 4 0 4 2 3 2 2 3 4 2 0 2 2 1 4 0 1 0 0 2 3 4 2\n",
      " 2 2 1 1 4]\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_375 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_125 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 159ms/step - loss: 0.6958 - accuracy: 0.3610 - val_loss: 0.6900 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6896 - accuracy: 0.8000 - val_loss: 0.6878 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6876 - accuracy: 0.8000 - val_loss: 0.6861 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6859 - accuracy: 0.8000 - val_loss: 0.6845 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6843 - accuracy: 0.8000 - val_loss: 0.6831 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6829 - accuracy: 0.8000 - val_loss: 0.6817 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6816 - accuracy: 0.8000 - val_loss: 0.6804 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6803 - accuracy: 0.8000 - val_loss: 0.6792 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6790 - accuracy: 0.8000 - val_loss: 0.6779 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6778 - accuracy: 0.8000 - val_loss: 0.6767 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6765 - accuracy: 0.8000 - val_loss: 0.6755 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6753 - accuracy: 0.8000 - val_loss: 0.6743 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6741 - accuracy: 0.8000 - val_loss: 0.6731 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6730 - accuracy: 0.8000 - val_loss: 0.6720 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6718 - accuracy: 0.8000 - val_loss: 0.6708 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6706 - accuracy: 0.8000 - val_loss: 0.6696 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6695 - accuracy: 0.8000 - val_loss: 0.6685 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6683 - accuracy: 0.8000 - val_loss: 0.6673 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6671 - accuracy: 0.8000 - val_loss: 0.6656 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6655 - accuracy: 0.8000 - val_loss: 0.6643 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [4 2 2 2 2 2 4 4 2 4 0 2 0 3 4 2 4 2 4 0 1 4 4 4 4 4 1 2 1 2 3 3 0 4 0 2 1\n",
      " 4 4 4 0 0]\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_378 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_380 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_126 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 165ms/step - loss: 0.6956 - accuracy: 0.3610 - val_loss: 0.6853 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6825 - accuracy: 0.8000 - val_loss: 0.6713 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6687 - accuracy: 0.8000 - val_loss: 0.6629 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6601 - accuracy: 0.8000 - val_loss: 0.6557 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6526 - accuracy: 0.8000 - val_loss: 0.6490 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6457 - accuracy: 0.8000 - val_loss: 0.6428 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6392 - accuracy: 0.8000 - val_loss: 0.6369 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6331 - accuracy: 0.8000 - val_loss: 0.6312 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6272 - accuracy: 0.8000 - val_loss: 0.6257 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6215 - accuracy: 0.8000 - val_loss: 0.6204 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6160 - accuracy: 0.8000 - val_loss: 0.6152 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6106 - accuracy: 0.8000 - val_loss: 0.6101 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6054 - accuracy: 0.8000 - val_loss: 0.6052 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6003 - accuracy: 0.8000 - val_loss: 0.6003 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5953 - accuracy: 0.8000 - val_loss: 0.5956 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5904 - accuracy: 0.8000 - val_loss: 0.5909 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5856 - accuracy: 0.8000 - val_loss: 0.5864 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5810 - accuracy: 0.8000 - val_loss: 0.5820 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5765 - accuracy: 0.8000 - val_loss: 0.5776 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5720 - accuracy: 0.8000 - val_loss: 0.5734 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [4 4 2 2 1 2 1 4 0 0 4 2 4 4 4 2 2 4 2 3 4 4 3 2 4 4 2 4 2 3 2 0 0 4 4 0 1\n",
      " 2 4 4 2 1]\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_381 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_382 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_127 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 0.6902 - accuracy: 0.6537 - val_loss: 0.6727 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6700 - accuracy: 0.8000 - val_loss: 0.6564 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6531 - accuracy: 0.8000 - val_loss: 0.6417 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6382 - accuracy: 0.8000 - val_loss: 0.6295 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6257 - accuracy: 0.8000 - val_loss: 0.6186 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6146 - accuracy: 0.8000 - val_loss: 0.6086 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6044 - accuracy: 0.8000 - val_loss: 0.5994 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5949 - accuracy: 0.8000 - val_loss: 0.5907 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5861 - accuracy: 0.8000 - val_loss: 0.5826 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5779 - accuracy: 0.8000 - val_loss: 0.5750 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5702 - accuracy: 0.8000 - val_loss: 0.5678 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5630 - accuracy: 0.8000 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5562 - accuracy: 0.8000 - val_loss: 0.5548 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5499 - accuracy: 0.8000 - val_loss: 0.5488 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5441 - accuracy: 0.8000 - val_loss: 0.5433 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5386 - accuracy: 0.8000 - val_loss: 0.5382 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5336 - accuracy: 0.8000 - val_loss: 0.5335 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5291 - accuracy: 0.8000 - val_loss: 0.5292 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5249 - accuracy: 0.8000 - val_loss: 0.5252 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5211 - accuracy: 0.8000 - val_loss: 0.5216 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [2 2 4 2 2 3 4 4 4 1 4 4 2 0 4 4 4 0 4 1 4 0 4 0 2 3 2 4 0 0 2 2 2 2 0 0 4\n",
      " 2 4 2 4 0]\n",
      "[]\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_384 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_385 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_386 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_128 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 166ms/step - loss: 0.6898 - accuracy: 0.5673 - val_loss: 0.6788 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6768 - accuracy: 0.8000 - val_loss: 0.6697 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6677 - accuracy: 0.8000 - val_loss: 0.6615 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6594 - accuracy: 0.8000 - val_loss: 0.6545 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6524 - accuracy: 0.8000 - val_loss: 0.6482 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6459 - accuracy: 0.8000 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6400 - accuracy: 0.8000 - val_loss: 0.6369 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6344 - accuracy: 0.8000 - val_loss: 0.6316 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6288 - accuracy: 0.8000 - val_loss: 0.6263 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6235 - accuracy: 0.8000 - val_loss: 0.6213 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6183 - accuracy: 0.8000 - val_loss: 0.6163 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6131 - accuracy: 0.8000 - val_loss: 0.6113 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6080 - accuracy: 0.8000 - val_loss: 0.6064 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6030 - accuracy: 0.8000 - val_loss: 0.6015 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5980 - accuracy: 0.8000 - val_loss: 0.5968 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5931 - accuracy: 0.8000 - val_loss: 0.5920 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5882 - accuracy: 0.8000 - val_loss: 0.5873 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5834 - accuracy: 0.8000 - val_loss: 0.5826 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5787 - accuracy: 0.8000 - val_loss: 0.5781 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5741 - accuracy: 0.8000 - val_loss: 0.5737 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 0 2 1 2 2 3 0 4 0 0 3 4 1 4 4 4 2 0 4 4 0 4 3 2 0 3 2 1 2 4 2 4 4]\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_387 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_129 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.6983 - accuracy: 0.4327 - val_loss: 0.6816 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6797 - accuracy: 0.8000 - val_loss: 0.6745 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6726 - accuracy: 0.8000 - val_loss: 0.6684 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6663 - accuracy: 0.8000 - val_loss: 0.6627 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6604 - accuracy: 0.8000 - val_loss: 0.6572 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6547 - accuracy: 0.8000 - val_loss: 0.6519 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6493 - accuracy: 0.8000 - val_loss: 0.6468 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6439 - accuracy: 0.8000 - val_loss: 0.6416 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6386 - accuracy: 0.8000 - val_loss: 0.6366 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6334 - accuracy: 0.8000 - val_loss: 0.6316 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6282 - accuracy: 0.8000 - val_loss: 0.6267 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6232 - accuracy: 0.8000 - val_loss: 0.6219 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6182 - accuracy: 0.8000 - val_loss: 0.6169 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6132 - accuracy: 0.8000 - val_loss: 0.6122 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6082 - accuracy: 0.8000 - val_loss: 0.6074 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6033 - accuracy: 0.8000 - val_loss: 0.6027 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5985 - accuracy: 0.8000 - val_loss: 0.5981 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5938 - accuracy: 0.8000 - val_loss: 0.5934 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5890 - accuracy: 0.8000 - val_loss: 0.5889 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5844 - accuracy: 0.8000 - val_loss: 0.5845 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 1 0 4 4 1 4 2 2 4 1 4 4 4 2 4 4 3 3 2 0 4 4 2 0 2 2 4 4 0 4 2 0 4]\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_390 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_392 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_130 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 159ms/step - loss: 0.6802 - accuracy: 0.8000 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6418 - accuracy: 0.8000 - val_loss: 0.6230 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6163 - accuracy: 0.8000 - val_loss: 0.6038 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5969 - accuracy: 0.8000 - val_loss: 0.5879 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5810 - accuracy: 0.8000 - val_loss: 0.5732 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5661 - accuracy: 0.8000 - val_loss: 0.5602 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5533 - accuracy: 0.8000 - val_loss: 0.5493 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5428 - accuracy: 0.8000 - val_loss: 0.5402 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5340 - accuracy: 0.8000 - val_loss: 0.5325 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5267 - accuracy: 0.8000 - val_loss: 0.5260 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5206 - accuracy: 0.8000 - val_loss: 0.5206 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5157 - accuracy: 0.8000 - val_loss: 0.5161 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5117 - accuracy: 0.8000 - val_loss: 0.5125 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5086 - accuracy: 0.8000 - val_loss: 0.5095 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5062 - accuracy: 0.8000 - val_loss: 0.5072 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5044 - accuracy: 0.8000 - val_loss: 0.5055 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5031 - accuracy: 0.8000 - val_loss: 0.5042 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5021 - accuracy: 0.8000 - val_loss: 0.5031 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5015 - accuracy: 0.8000 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5020 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 1 2 4 4 2 2 2 2 1 0 3 3 4 2 0 0 4 4 0 0 4 3 0 2 4 4 1 2 4 4 4 4 2]\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_393 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_394 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_131 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 0.6872 - accuracy: 0.6531 - val_loss: 0.6662 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6612 - accuracy: 0.8000 - val_loss: 0.6480 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6431 - accuracy: 0.8000 - val_loss: 0.6335 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6283 - accuracy: 0.8000 - val_loss: 0.6208 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.6154 - accuracy: 0.8000 - val_loss: 0.6093 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6038 - accuracy: 0.8000 - val_loss: 0.5988 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.5931 - accuracy: 0.8000 - val_loss: 0.5891 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5833 - accuracy: 0.8000 - val_loss: 0.5801 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5742 - accuracy: 0.8000 - val_loss: 0.5717 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.5658 - accuracy: 0.8000 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5580 - accuracy: 0.8000 - val_loss: 0.5566 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5508 - accuracy: 0.8000 - val_loss: 0.5499 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.5442 - accuracy: 0.8000 - val_loss: 0.5437 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5382 - accuracy: 0.8000 - val_loss: 0.5381 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.5327 - accuracy: 0.8000 - val_loss: 0.5329 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.5277 - accuracy: 0.8000 - val_loss: 0.5282 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5233 - accuracy: 0.8000 - val_loss: 0.5240 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5194 - accuracy: 0.8000 - val_loss: 0.5202 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5159 - accuracy: 0.8000 - val_loss: 0.5168 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5128 - accuracy: 0.8000 - val_loss: 0.5139 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 3 2 4 4 2 4 3 2 1 2 4 1 2 2 4 4 2 2 0 4 1 3 4 4 0 2 0 4 4 1 4 2 2]\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_396 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_398 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_132 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 193ms/step - loss: 0.6916 - accuracy: 0.4571 - val_loss: 0.6797 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6772 - accuracy: 0.8000 - val_loss: 0.6697 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6672 - accuracy: 0.8000 - val_loss: 0.6614 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6589 - accuracy: 0.8000 - val_loss: 0.6539 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6510 - accuracy: 0.8000 - val_loss: 0.6466 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6436 - accuracy: 0.8000 - val_loss: 0.6396 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6364 - accuracy: 0.8000 - val_loss: 0.6327 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6294 - accuracy: 0.8000 - val_loss: 0.6260 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6225 - accuracy: 0.8000 - val_loss: 0.6195 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6157 - accuracy: 0.8000 - val_loss: 0.6130 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6091 - accuracy: 0.8000 - val_loss: 0.6067 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6027 - accuracy: 0.8000 - val_loss: 0.6005 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5963 - accuracy: 0.8000 - val_loss: 0.5945 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5901 - accuracy: 0.8000 - val_loss: 0.5885 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5841 - accuracy: 0.8000 - val_loss: 0.5827 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5782 - accuracy: 0.8000 - val_loss: 0.5771 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5724 - accuracy: 0.8000 - val_loss: 0.5716 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5669 - accuracy: 0.8000 - val_loss: 0.5662 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5615 - accuracy: 0.8000 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5563 - accuracy: 0.8000 - val_loss: 0.5561 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 2 4 4 2 0 4 2 2 2 2 2 4 4 1 3 0 4 4 2 0 4 0 2 1 1 2 4 4 3 1 2 0]\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_399 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_400 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_133 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 227ms/step - loss: 0.6921 - accuracy: 0.7265 - val_loss: 0.6882 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6875 - accuracy: 0.8000 - val_loss: 0.6851 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6843 - accuracy: 0.8000 - val_loss: 0.6819 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6811 - accuracy: 0.8000 - val_loss: 0.6791 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6782 - accuracy: 0.8000 - val_loss: 0.6762 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6753 - accuracy: 0.8000 - val_loss: 0.6735 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6724 - accuracy: 0.8000 - val_loss: 0.6707 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6694 - accuracy: 0.8000 - val_loss: 0.6670 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6656 - accuracy: 0.8000 - val_loss: 0.6636 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6621 - accuracy: 0.8000 - val_loss: 0.6604 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6588 - accuracy: 0.8000 - val_loss: 0.6570 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6551 - accuracy: 0.8000 - val_loss: 0.6537 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6517 - accuracy: 0.8000 - val_loss: 0.6502 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.6480 - accuracy: 0.8000 - val_loss: 0.6470 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6446 - accuracy: 0.8000 - val_loss: 0.6433 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6409 - accuracy: 0.8000 - val_loss: 0.6400 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6375 - accuracy: 0.8000 - val_loss: 0.6366 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6338 - accuracy: 0.8000 - val_loss: 0.6329 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6301 - accuracy: 0.8000 - val_loss: 0.6294 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6264 - accuracy: 0.8000 - val_loss: 0.6260 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 1 0 0 2 4 3 4 2 1 3 4 0 1 4 1 4 2 2 2 0 0 4 2 2 2 4 2 4 2 0 3 0 2]\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_402 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_134 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.6948 - accuracy: 0.4327 - val_loss: 0.6863 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6848 - accuracy: 0.8000 - val_loss: 0.6806 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6793 - accuracy: 0.8000 - val_loss: 0.6757 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6743 - accuracy: 0.8000 - val_loss: 0.6718 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6702 - accuracy: 0.8000 - val_loss: 0.6673 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6658 - accuracy: 0.8000 - val_loss: 0.6634 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6616 - accuracy: 0.8000 - val_loss: 0.6594 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6576 - accuracy: 0.8000 - val_loss: 0.6553 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6533 - accuracy: 0.8000 - val_loss: 0.6514 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6491 - accuracy: 0.8000 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6451 - accuracy: 0.8000 - val_loss: 0.6435 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6410 - accuracy: 0.8000 - val_loss: 0.6396 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6369 - accuracy: 0.8000 - val_loss: 0.6356 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6328 - accuracy: 0.8000 - val_loss: 0.6317 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6287 - accuracy: 0.8000 - val_loss: 0.6279 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6248 - accuracy: 0.8000 - val_loss: 0.6240 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6208 - accuracy: 0.8000 - val_loss: 0.6203 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6169 - accuracy: 0.8000 - val_loss: 0.6165 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6130 - accuracy: 0.8000 - val_loss: 0.6127 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6091 - accuracy: 0.8000 - val_loss: 0.6091 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 2 4 2 4 4 2 0 3 4 0 2 2 4 2 0 4 3 4 4 2 1 4 0 4 4 0 0 0 4 0 4 4]\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_405 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_406 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_135 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 232ms/step - loss: 0.6912 - accuracy: 0.4939 - val_loss: 0.6806 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6781 - accuracy: 0.8000 - val_loss: 0.6699 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6673 - accuracy: 0.8000 - val_loss: 0.6613 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6586 - accuracy: 0.8000 - val_loss: 0.6538 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6508 - accuracy: 0.8000 - val_loss: 0.6468 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6436 - accuracy: 0.8000 - val_loss: 0.6402 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6367 - accuracy: 0.8000 - val_loss: 0.6338 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6302 - accuracy: 0.8000 - val_loss: 0.6278 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6239 - accuracy: 0.8000 - val_loss: 0.6219 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6178 - accuracy: 0.8000 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6118 - accuracy: 0.8000 - val_loss: 0.6106 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6061 - accuracy: 0.8000 - val_loss: 0.6051 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6005 - accuracy: 0.8000 - val_loss: 0.5998 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5949 - accuracy: 0.8000 - val_loss: 0.5945 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5895 - accuracy: 0.8000 - val_loss: 0.5893 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5842 - accuracy: 0.8000 - val_loss: 0.5843 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5791 - accuracy: 0.8000 - val_loss: 0.5793 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5740 - accuracy: 0.8000 - val_loss: 0.5745 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5691 - accuracy: 0.8000 - val_loss: 0.5698 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5643 - accuracy: 0.8000 - val_loss: 0.5652 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 4 3 2 0 4 4 4 0 2 4 4 2 2 4 4 4 0 3 3 4 3 2 2 2 1 3 0 1 2 4 2 2]\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_408 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_410 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_136 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 207ms/step - loss: 0.6955 - accuracy: 0.4327 - val_loss: 0.6831 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6804 - accuracy: 0.8000 - val_loss: 0.6691 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6660 - accuracy: 0.8000 - val_loss: 0.6566 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6534 - accuracy: 0.8000 - val_loss: 0.6459 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6426 - accuracy: 0.8000 - val_loss: 0.6363 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6327 - accuracy: 0.8000 - val_loss: 0.6272 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6233 - accuracy: 0.8000 - val_loss: 0.6185 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6145 - accuracy: 0.8000 - val_loss: 0.6103 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6060 - accuracy: 0.8000 - val_loss: 0.6024 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.5980 - accuracy: 0.8000 - val_loss: 0.5949 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5902 - accuracy: 0.8000 - val_loss: 0.5876 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5829 - accuracy: 0.8000 - val_loss: 0.5807 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5758 - accuracy: 0.8000 - val_loss: 0.5740 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5690 - accuracy: 0.8000 - val_loss: 0.5677 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5626 - accuracy: 0.8000 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5565 - accuracy: 0.8000 - val_loss: 0.5559 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5508 - accuracy: 0.8000 - val_loss: 0.5504 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5454 - accuracy: 0.8000 - val_loss: 0.5453 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5403 - accuracy: 0.8000 - val_loss: 0.5405 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.5356 - accuracy: 0.8000 - val_loss: 0.5360 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 2 2 4 4 3 2 4 1 4 4 4 2 4 0 2 4 4 4 4 4 4 4 1 4 2 1 3 2 3 2 0 4 0]\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_411 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_137 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 251ms/step - loss: 0.6892 - accuracy: 0.5673 - val_loss: 0.6671 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6629 - accuracy: 0.8000 - val_loss: 0.6460 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6422 - accuracy: 0.8000 - val_loss: 0.6294 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6255 - accuracy: 0.8000 - val_loss: 0.6149 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6107 - accuracy: 0.8000 - val_loss: 0.6015 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5971 - accuracy: 0.8000 - val_loss: 0.5893 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5848 - accuracy: 0.8000 - val_loss: 0.5781 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5735 - accuracy: 0.8000 - val_loss: 0.5678 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5633 - accuracy: 0.8000 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5540 - accuracy: 0.8000 - val_loss: 0.5500 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5456 - accuracy: 0.8000 - val_loss: 0.5424 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5381 - accuracy: 0.8000 - val_loss: 0.5356 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.5315 - accuracy: 0.8000 - val_loss: 0.5296 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5257 - accuracy: 0.8000 - val_loss: 0.5243 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5206 - accuracy: 0.8000 - val_loss: 0.5198 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5164 - accuracy: 0.8000 - val_loss: 0.5159 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5128 - accuracy: 0.8000 - val_loss: 0.5127 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5098 - accuracy: 0.8000 - val_loss: 0.5100 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5075 - accuracy: 0.8000 - val_loss: 0.5078 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5056 - accuracy: 0.8000 - val_loss: 0.5061 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 0 2 4 4 4 0 2 4 4 2 4 2 1 2 2 2 0 4 4 4 0 0 4 3 3 2 4 4 2 4 4 0]\n",
      "[]\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_414 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_138 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 225ms/step - loss: 0.6812 - accuracy: 0.7897 - val_loss: 0.6574 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6506 - accuracy: 0.8000 - val_loss: 0.6354 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6285 - accuracy: 0.8000 - val_loss: 0.6167 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6103 - accuracy: 0.8000 - val_loss: 0.6018 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5956 - accuracy: 0.8000 - val_loss: 0.5890 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5829 - accuracy: 0.8000 - val_loss: 0.5777 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5717 - accuracy: 0.8000 - val_loss: 0.5676 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5618 - accuracy: 0.8000 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5529 - accuracy: 0.8000 - val_loss: 0.5503 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5449 - accuracy: 0.8000 - val_loss: 0.5430 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5378 - accuracy: 0.8000 - val_loss: 0.5364 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5315 - accuracy: 0.8000 - val_loss: 0.5306 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5259 - accuracy: 0.8000 - val_loss: 0.5254 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5211 - accuracy: 0.8000 - val_loss: 0.5209 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5169 - accuracy: 0.8000 - val_loss: 0.5170 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.5134 - accuracy: 0.8000 - val_loss: 0.5137 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5104 - accuracy: 0.8000 - val_loss: 0.5108 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5080 - accuracy: 0.8000 - val_loss: 0.5085 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5060 - accuracy: 0.8000 - val_loss: 0.5066 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5045 - accuracy: 0.8000 - val_loss: 0.5051 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 4 0 4 1 0 4 0 2 3 4 4 0 2 4 2 2 2 0 1 1 1 4 2]\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_417 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_418 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_139 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.6898 - accuracy: 0.5000 - val_loss: 0.6737 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6692 - accuracy: 0.8000 - val_loss: 0.6595 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6554 - accuracy: 0.8000 - val_loss: 0.6482 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6441 - accuracy: 0.8000 - val_loss: 0.6383 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6341 - accuracy: 0.8000 - val_loss: 0.6292 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6248 - accuracy: 0.8000 - val_loss: 0.6207 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6162 - accuracy: 0.8000 - val_loss: 0.6126 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6080 - accuracy: 0.8000 - val_loss: 0.6050 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6002 - accuracy: 0.8000 - val_loss: 0.5977 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5928 - accuracy: 0.8000 - val_loss: 0.5907 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5857 - accuracy: 0.8000 - val_loss: 0.5840 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5790 - accuracy: 0.8000 - val_loss: 0.5776 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5725 - accuracy: 0.8000 - val_loss: 0.5715 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5664 - accuracy: 0.8000 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5605 - accuracy: 0.8000 - val_loss: 0.5600 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5549 - accuracy: 0.8000 - val_loss: 0.5547 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5497 - accuracy: 0.8000 - val_loss: 0.5496 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5447 - accuracy: 0.8000 - val_loss: 0.5449 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5400 - accuracy: 0.8000 - val_loss: 0.5404 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5357 - accuracy: 0.8000 - val_loss: 0.5362 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 0 2 1 4 4 2 2 2 3 2 4 2 4 3 0 0 1 0 4 1 4 4 2]\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_420 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_422 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_140 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 227ms/step - loss: 0.6798 - accuracy: 0.8000 - val_loss: 0.6557 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6489 - accuracy: 0.8000 - val_loss: 0.6334 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6271 - accuracy: 0.8000 - val_loss: 0.6158 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6096 - accuracy: 0.8000 - val_loss: 0.6007 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5945 - accuracy: 0.8000 - val_loss: 0.5874 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5812 - accuracy: 0.8000 - val_loss: 0.5756 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5694 - accuracy: 0.8000 - val_loss: 0.5649 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5588 - accuracy: 0.8000 - val_loss: 0.5553 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5494 - accuracy: 0.8000 - val_loss: 0.5467 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5410 - accuracy: 0.8000 - val_loss: 0.5390 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5336 - accuracy: 0.8000 - val_loss: 0.5322 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5272 - accuracy: 0.8000 - val_loss: 0.5263 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5217 - accuracy: 0.8000 - val_loss: 0.5213 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5170 - accuracy: 0.8000 - val_loss: 0.5169 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5131 - accuracy: 0.8000 - val_loss: 0.5133 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5099 - accuracy: 0.8000 - val_loss: 0.5103 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5073 - accuracy: 0.8000 - val_loss: 0.5079 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5054 - accuracy: 0.8000 - val_loss: 0.5060 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5039 - accuracy: 0.8000 - val_loss: 0.5045 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5028 - accuracy: 0.8000 - val_loss: 0.5034 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 4 4 1 3 4 1 2 2 2 2 0 2 3 0 2 2 4 0 4 4 4 3 0 4]\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_423 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_424 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_425 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_141 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.6883 - accuracy: 0.6966 - val_loss: 0.6780 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6755 - accuracy: 0.8000 - val_loss: 0.6688 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6664 - accuracy: 0.8000 - val_loss: 0.6604 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6579 - accuracy: 0.8000 - val_loss: 0.6527 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6500 - accuracy: 0.8000 - val_loss: 0.6453 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6425 - accuracy: 0.8000 - val_loss: 0.6382 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6354 - accuracy: 0.8000 - val_loss: 0.6314 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6284 - accuracy: 0.8000 - val_loss: 0.6248 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6216 - accuracy: 0.8000 - val_loss: 0.6183 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6150 - accuracy: 0.8000 - val_loss: 0.6119 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6085 - accuracy: 0.8000 - val_loss: 0.6057 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6022 - accuracy: 0.8000 - val_loss: 0.5997 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5960 - accuracy: 0.8000 - val_loss: 0.5937 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5900 - accuracy: 0.8000 - val_loss: 0.5879 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5841 - accuracy: 0.8000 - val_loss: 0.5823 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5784 - accuracy: 0.8000 - val_loss: 0.5768 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5728 - accuracy: 0.8000 - val_loss: 0.5714 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5675 - accuracy: 0.8000 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5623 - accuracy: 0.8000 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5573 - accuracy: 0.8000 - val_loss: 0.5564 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 4 1 4 4 1 2 1 2 2 4 0 4 2 0 0 0 0 4 2 1 0 1 2]\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_426 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_427 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_142 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.6934 - accuracy: 0.4897 - val_loss: 0.6801 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6765 - accuracy: 0.8000 - val_loss: 0.6665 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6634 - accuracy: 0.8000 - val_loss: 0.6561 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6531 - accuracy: 0.8000 - val_loss: 0.6470 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6438 - accuracy: 0.8000 - val_loss: 0.6386 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6353 - accuracy: 0.8000 - val_loss: 0.6306 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6272 - accuracy: 0.8000 - val_loss: 0.6231 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6195 - accuracy: 0.8000 - val_loss: 0.6158 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6121 - accuracy: 0.8000 - val_loss: 0.6087 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6050 - accuracy: 0.8000 - val_loss: 0.6019 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5980 - accuracy: 0.8000 - val_loss: 0.5953 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5914 - accuracy: 0.8000 - val_loss: 0.5889 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5849 - accuracy: 0.8000 - val_loss: 0.5828 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5786 - accuracy: 0.8000 - val_loss: 0.5768 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5726 - accuracy: 0.8000 - val_loss: 0.5710 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5668 - accuracy: 0.8000 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5612 - accuracy: 0.8000 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5559 - accuracy: 0.8000 - val_loss: 0.5549 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5508 - accuracy: 0.8000 - val_loss: 0.5500 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.5459 - accuracy: 0.8000 - val_loss: 0.5454 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 4 2 4 4 0 2 4 4 4 0 2 4 2 2 0 4 0 1 2 0 2 4 4]\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_429 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_430 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_143 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 225ms/step - loss: 0.6922 - accuracy: 0.4897 - val_loss: 0.6832 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6794 - accuracy: 0.8000 - val_loss: 0.6701 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6675 - accuracy: 0.8000 - val_loss: 0.6618 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6592 - accuracy: 0.8000 - val_loss: 0.6547 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6520 - accuracy: 0.8000 - val_loss: 0.6483 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6455 - accuracy: 0.8000 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6394 - accuracy: 0.8000 - val_loss: 0.6367 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6336 - accuracy: 0.8000 - val_loss: 0.6312 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6280 - accuracy: 0.8000 - val_loss: 0.6260 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6226 - accuracy: 0.8000 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6173 - accuracy: 0.8000 - val_loss: 0.6159 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6122 - accuracy: 0.8000 - val_loss: 0.6110 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6072 - accuracy: 0.8000 - val_loss: 0.6062 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6023 - accuracy: 0.8000 - val_loss: 0.6016 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5975 - accuracy: 0.8000 - val_loss: 0.5970 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5928 - accuracy: 0.8000 - val_loss: 0.5925 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5883 - accuracy: 0.8000 - val_loss: 0.5881 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5838 - accuracy: 0.8000 - val_loss: 0.5838 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5794 - accuracy: 0.8000 - val_loss: 0.5796 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5751 - accuracy: 0.8000 - val_loss: 0.5755 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 0 4 4 2 2 4 4 1 2 4 1 3 0 2 4 0 4 2 2 2 4 1 0 2]\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_432 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_144 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 0.6832 - accuracy: 0.8000 - val_loss: 0.6641 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6596 - accuracy: 0.8000 - val_loss: 0.6472 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6431 - accuracy: 0.8000 - val_loss: 0.6338 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6298 - accuracy: 0.8000 - val_loss: 0.6222 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6177 - accuracy: 0.8000 - val_loss: 0.6098 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6050 - accuracy: 0.8000 - val_loss: 0.5984 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5937 - accuracy: 0.8000 - val_loss: 0.5884 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5838 - accuracy: 0.8000 - val_loss: 0.5794 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5748 - accuracy: 0.8000 - val_loss: 0.5712 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5667 - accuracy: 0.8000 - val_loss: 0.5636 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5591 - accuracy: 0.8000 - val_loss: 0.5566 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5522 - accuracy: 0.8000 - val_loss: 0.5501 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5458 - accuracy: 0.8000 - val_loss: 0.5441 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5399 - accuracy: 0.8000 - val_loss: 0.5386 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5345 - accuracy: 0.8000 - val_loss: 0.5335 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5296 - accuracy: 0.8000 - val_loss: 0.5289 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5252 - accuracy: 0.8000 - val_loss: 0.5248 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5213 - accuracy: 0.8000 - val_loss: 0.5210 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5177 - accuracy: 0.8000 - val_loss: 0.5177 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5146 - accuracy: 0.8000 - val_loss: 0.5147 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 2 4 4 4 0 1 2 2 2 2 0 2 0 4 4 0 0 1 2 4 4 3 4 1]\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_435 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_436 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_145 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.6859 - accuracy: 0.8000 - val_loss: 0.6674 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6615 - accuracy: 0.8000 - val_loss: 0.6488 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6431 - accuracy: 0.8000 - val_loss: 0.6342 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6285 - accuracy: 0.8000 - val_loss: 0.6217 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6158 - accuracy: 0.8000 - val_loss: 0.6105 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6044 - accuracy: 0.8000 - val_loss: 0.6003 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5940 - accuracy: 0.8000 - val_loss: 0.5908 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5844 - accuracy: 0.8000 - val_loss: 0.5820 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5755 - accuracy: 0.8000 - val_loss: 0.5738 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5673 - accuracy: 0.8000 - val_loss: 0.5662 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5596 - accuracy: 0.8000 - val_loss: 0.5591 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5525 - accuracy: 0.8000 - val_loss: 0.5525 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5460 - accuracy: 0.8000 - val_loss: 0.5463 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5400 - accuracy: 0.8000 - val_loss: 0.5407 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5345 - accuracy: 0.8000 - val_loss: 0.5355 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.5295 - accuracy: 0.8000 - val_loss: 0.5307 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5250 - accuracy: 0.8000 - val_loss: 0.5264 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5210 - accuracy: 0.8000 - val_loss: 0.5225 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5174 - accuracy: 0.8000 - val_loss: 0.5191 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5143 - accuracy: 0.8000 - val_loss: 0.5160 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 3 2 4 2 3 0 0 1 4 2 4 4 2 3 4 1 1 4 0 2 0 1 0]\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_438 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_440 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_146 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 245ms/step - loss: 0.6865 - accuracy: 0.7586 - val_loss: 0.6727 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6683 - accuracy: 0.8000 - val_loss: 0.6578 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6538 - accuracy: 0.8000 - val_loss: 0.6461 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6420 - accuracy: 0.8000 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6316 - accuracy: 0.8000 - val_loss: 0.6263 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6220 - accuracy: 0.8000 - val_loss: 0.6175 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6131 - accuracy: 0.8000 - val_loss: 0.6091 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6047 - accuracy: 0.8000 - val_loss: 0.6013 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5967 - accuracy: 0.8000 - val_loss: 0.5937 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5891 - accuracy: 0.8000 - val_loss: 0.5865 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5818 - accuracy: 0.8000 - val_loss: 0.5797 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5750 - accuracy: 0.8000 - val_loss: 0.5732 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5685 - accuracy: 0.8000 - val_loss: 0.5670 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5623 - accuracy: 0.8000 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5564 - accuracy: 0.8000 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5508 - accuracy: 0.8000 - val_loss: 0.5501 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5455 - accuracy: 0.8000 - val_loss: 0.5451 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5406 - accuracy: 0.8000 - val_loss: 0.5404 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5360 - accuracy: 0.8000 - val_loss: 0.5360 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5317 - accuracy: 0.8000 - val_loss: 0.5319 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 0 4 2 4 4 4 0 2 4 1 0 4 0 3 0 4 4 2 4 1 0 0 1]\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_441 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_442 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_147 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.6777 - accuracy: 0.8000 - val_loss: 0.6614 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6568 - accuracy: 0.8000 - val_loss: 0.6433 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6391 - accuracy: 0.8000 - val_loss: 0.6292 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6249 - accuracy: 0.8000 - val_loss: 0.6164 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6122 - accuracy: 0.8000 - val_loss: 0.6052 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6009 - accuracy: 0.8000 - val_loss: 0.5951 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5908 - accuracy: 0.8000 - val_loss: 0.5858 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5814 - accuracy: 0.8000 - val_loss: 0.5771 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5727 - accuracy: 0.8000 - val_loss: 0.5690 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5646 - accuracy: 0.8000 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5571 - accuracy: 0.8000 - val_loss: 0.5545 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5501 - accuracy: 0.8000 - val_loss: 0.5480 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5437 - accuracy: 0.8000 - val_loss: 0.5419 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5378 - accuracy: 0.8000 - val_loss: 0.5364 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5324 - accuracy: 0.8000 - val_loss: 0.5313 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5275 - accuracy: 0.8000 - val_loss: 0.5268 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5231 - accuracy: 0.8000 - val_loss: 0.5226 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5192 - accuracy: 0.8000 - val_loss: 0.5190 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5157 - accuracy: 0.8000 - val_loss: 0.5157 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5127 - accuracy: 0.8000 - val_loss: 0.5129 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 4 0 4 2 0 1 2 4 2 4 3 4 3 2 2 1 2 4 1 2 0 4 4 2]\n",
      "[]\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_444 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_445 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_446 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_148 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.6869 - accuracy: 0.7818 - val_loss: 0.6718 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6682 - accuracy: 0.8000 - val_loss: 0.6580 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6545 - accuracy: 0.8000 - val_loss: 0.6459 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6423 - accuracy: 0.8000 - val_loss: 0.6347 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6309 - accuracy: 0.8000 - val_loss: 0.6241 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6201 - accuracy: 0.8000 - val_loss: 0.6138 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6097 - accuracy: 0.8000 - val_loss: 0.6040 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5997 - accuracy: 0.8000 - val_loss: 0.5946 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5902 - accuracy: 0.8000 - val_loss: 0.5854 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5810 - accuracy: 0.8000 - val_loss: 0.5767 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5722 - accuracy: 0.8000 - val_loss: 0.5683 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5638 - accuracy: 0.8000 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5560 - accuracy: 0.8000 - val_loss: 0.5529 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5486 - accuracy: 0.8000 - val_loss: 0.5459 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5417 - accuracy: 0.8000 - val_loss: 0.5394 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5354 - accuracy: 0.8000 - val_loss: 0.5335 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5296 - accuracy: 0.8000 - val_loss: 0.5280 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5244 - accuracy: 0.8000 - val_loss: 0.5231 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5197 - accuracy: 0.8000 - val_loss: 0.5187 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5157 - accuracy: 0.8000 - val_loss: 0.5149 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 3 4 2 0 2 4 1 4 3 0 0 3 2 4 0 1]\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_447 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_448 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_149 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 119ms/step - loss: 0.6944 - accuracy: 0.5273 - val_loss: 0.6832 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6811 - accuracy: 0.8000 - val_loss: 0.6731 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6702 - accuracy: 0.8000 - val_loss: 0.6619 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6594 - accuracy: 0.8000 - val_loss: 0.6524 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6499 - accuracy: 0.8000 - val_loss: 0.6433 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6408 - accuracy: 0.8000 - val_loss: 0.6347 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6321 - accuracy: 0.8000 - val_loss: 0.6263 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6236 - accuracy: 0.8000 - val_loss: 0.6181 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6154 - accuracy: 0.8000 - val_loss: 0.6099 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6073 - accuracy: 0.8000 - val_loss: 0.6022 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5996 - accuracy: 0.8000 - val_loss: 0.5945 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5919 - accuracy: 0.8000 - val_loss: 0.5871 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5844 - accuracy: 0.8000 - val_loss: 0.5798 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5772 - accuracy: 0.8000 - val_loss: 0.5729 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5703 - accuracy: 0.8000 - val_loss: 0.5661 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5635 - accuracy: 0.8000 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5571 - accuracy: 0.8000 - val_loss: 0.5535 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5510 - accuracy: 0.8000 - val_loss: 0.5476 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5452 - accuracy: 0.8000 - val_loss: 0.5421 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5398 - accuracy: 0.8000 - val_loss: 0.5368 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 0 2 0 2 2 0 1 2 2 1 0 0 2 4 2 2]\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_450 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_451 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_452 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_150 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 103ms/step - loss: 0.6963 - accuracy: 0.2545 - val_loss: 0.6880 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6864 - accuracy: 0.8000 - val_loss: 0.6826 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6811 - accuracy: 0.8000 - val_loss: 0.6769 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6756 - accuracy: 0.8000 - val_loss: 0.6717 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6703 - accuracy: 0.8000 - val_loss: 0.6665 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6650 - accuracy: 0.8000 - val_loss: 0.6611 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6595 - accuracy: 0.8000 - val_loss: 0.6557 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6540 - accuracy: 0.8000 - val_loss: 0.6501 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6483 - accuracy: 0.8000 - val_loss: 0.6445 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6426 - accuracy: 0.8000 - val_loss: 0.6389 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6369 - accuracy: 0.8000 - val_loss: 0.6332 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6312 - accuracy: 0.8000 - val_loss: 0.6274 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6254 - accuracy: 0.8000 - val_loss: 0.6217 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6195 - accuracy: 0.8000 - val_loss: 0.6159 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6137 - accuracy: 0.8000 - val_loss: 0.6102 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6080 - accuracy: 0.8000 - val_loss: 0.6046 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6023 - accuracy: 0.8000 - val_loss: 0.5990 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5967 - accuracy: 0.8000 - val_loss: 0.5935 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5911 - accuracy: 0.8000 - val_loss: 0.5880 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5857 - accuracy: 0.8000 - val_loss: 0.5826 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 2 1 4 2 4 4 3 2 2 4 0 2 4 3 0]\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_453 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_454 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_455 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_151 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 114ms/step - loss: 0.6826 - accuracy: 0.6818 - val_loss: 0.6588 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6534 - accuracy: 0.8000 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6339 - accuracy: 0.8000 - val_loss: 0.6225 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6176 - accuracy: 0.8000 - val_loss: 0.6081 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6032 - accuracy: 0.8000 - val_loss: 0.5950 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5901 - accuracy: 0.8000 - val_loss: 0.5832 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5785 - accuracy: 0.8000 - val_loss: 0.5723 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5676 - accuracy: 0.8000 - val_loss: 0.5624 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5579 - accuracy: 0.8000 - val_loss: 0.5534 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5490 - accuracy: 0.8000 - val_loss: 0.5452 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5411 - accuracy: 0.8000 - val_loss: 0.5378 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5339 - accuracy: 0.8000 - val_loss: 0.5313 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5276 - accuracy: 0.8000 - val_loss: 0.5255 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5221 - accuracy: 0.8000 - val_loss: 0.5204 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5174 - accuracy: 0.8000 - val_loss: 0.5161 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.5134 - accuracy: 0.8000 - val_loss: 0.5124 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5100 - accuracy: 0.8000 - val_loss: 0.5093 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5073 - accuracy: 0.8000 - val_loss: 0.5070 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5053 - accuracy: 0.8000 - val_loss: 0.5051 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5037 - accuracy: 0.8000 - val_loss: 0.5037 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 4 4 0 4 4 0 0 0 2 0 2 0 4 2 2 0]\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_456 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_457 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_458 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_152 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 118ms/step - loss: 0.6871 - accuracy: 0.8000 - val_loss: 0.6690 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6633 - accuracy: 0.8000 - val_loss: 0.6495 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6443 - accuracy: 0.8000 - val_loss: 0.6345 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6293 - accuracy: 0.8000 - val_loss: 0.6214 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6160 - accuracy: 0.8000 - val_loss: 0.6094 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6039 - accuracy: 0.8000 - val_loss: 0.5982 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5925 - accuracy: 0.8000 - val_loss: 0.5877 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5819 - accuracy: 0.8000 - val_loss: 0.5777 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5718 - accuracy: 0.8000 - val_loss: 0.5684 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5624 - accuracy: 0.8000 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5537 - accuracy: 0.8000 - val_loss: 0.5514 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5456 - accuracy: 0.8000 - val_loss: 0.5438 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5381 - accuracy: 0.8000 - val_loss: 0.5369 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5315 - accuracy: 0.8000 - val_loss: 0.5307 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5256 - accuracy: 0.8000 - val_loss: 0.5251 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5203 - accuracy: 0.8000 - val_loss: 0.5202 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5158 - accuracy: 0.8000 - val_loss: 0.5160 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5120 - accuracy: 0.8000 - val_loss: 0.5125 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5089 - accuracy: 0.8000 - val_loss: 0.5096 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5065 - accuracy: 0.8000 - val_loss: 0.5072 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 2 2 0 0 2 4 4 4 3 2 0 4 2 4 2 2]\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_459 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_460 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_461 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_153 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 142ms/step - loss: 0.6893 - accuracy: 0.6545 - val_loss: 0.6798 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6780 - accuracy: 0.8000 - val_loss: 0.6725 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6709 - accuracy: 0.8000 - val_loss: 0.6661 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6642 - accuracy: 0.8000 - val_loss: 0.6598 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6578 - accuracy: 0.8000 - val_loss: 0.6538 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6516 - accuracy: 0.8000 - val_loss: 0.6477 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6454 - accuracy: 0.8000 - val_loss: 0.6416 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6392 - accuracy: 0.8000 - val_loss: 0.6356 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6330 - accuracy: 0.8000 - val_loss: 0.6294 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6267 - accuracy: 0.8000 - val_loss: 0.6232 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6204 - accuracy: 0.8000 - val_loss: 0.6171 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6141 - accuracy: 0.8000 - val_loss: 0.6109 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6078 - accuracy: 0.8000 - val_loss: 0.6047 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6015 - accuracy: 0.8000 - val_loss: 0.5986 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5953 - accuracy: 0.8000 - val_loss: 0.5926 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5891 - accuracy: 0.8000 - val_loss: 0.5866 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5830 - accuracy: 0.8000 - val_loss: 0.5806 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5771 - accuracy: 0.8000 - val_loss: 0.5749 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5712 - accuracy: 0.8000 - val_loss: 0.5692 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5655 - accuracy: 0.8000 - val_loss: 0.5637 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 2 4 0 0 2 3 4 4 2 2 4 1 2 0 1]\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_462 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_463 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_464 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_154 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 118ms/step - loss: 0.6862 - accuracy: 0.7455 - val_loss: 0.6627 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6582 - accuracy: 0.8000 - val_loss: 0.6403 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6362 - accuracy: 0.8000 - val_loss: 0.6214 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6179 - accuracy: 0.8000 - val_loss: 0.6046 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6012 - accuracy: 0.8000 - val_loss: 0.5894 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5863 - accuracy: 0.8000 - val_loss: 0.5758 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5728 - accuracy: 0.8000 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5609 - accuracy: 0.8000 - val_loss: 0.5526 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5502 - accuracy: 0.8000 - val_loss: 0.5428 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5406 - accuracy: 0.8000 - val_loss: 0.5343 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5323 - accuracy: 0.8000 - val_loss: 0.5269 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5253 - accuracy: 0.8000 - val_loss: 0.5207 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5193 - accuracy: 0.8000 - val_loss: 0.5155 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5144 - accuracy: 0.8000 - val_loss: 0.5114 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5104 - accuracy: 0.8000 - val_loss: 0.5080 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5073 - accuracy: 0.8000 - val_loss: 0.5055 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5050 - accuracy: 0.8000 - val_loss: 0.5036 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5033 - accuracy: 0.8000 - val_loss: 0.5024 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5022 - accuracy: 0.8000 - val_loss: 0.5015 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5015 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 4 2 0 2 2 2 2 3 0 0 1 4 1 0 2]\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_465 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_466 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_467 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_155 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.6895 - accuracy: 0.7727 - val_loss: 0.6828 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6812 - accuracy: 0.8000 - val_loss: 0.6762 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6746 - accuracy: 0.8000 - val_loss: 0.6694 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6675 - accuracy: 0.8000 - val_loss: 0.6624 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6604 - accuracy: 0.8000 - val_loss: 0.6555 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6533 - accuracy: 0.8000 - val_loss: 0.6486 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6462 - accuracy: 0.8000 - val_loss: 0.6417 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6391 - accuracy: 0.8000 - val_loss: 0.6348 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6320 - accuracy: 0.8000 - val_loss: 0.6277 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6248 - accuracy: 0.8000 - val_loss: 0.6207 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6177 - accuracy: 0.8000 - val_loss: 0.6137 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6105 - accuracy: 0.8000 - val_loss: 0.6067 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6033 - accuracy: 0.8000 - val_loss: 0.5997 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5962 - accuracy: 0.8000 - val_loss: 0.5927 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5892 - accuracy: 0.8000 - val_loss: 0.5859 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5822 - accuracy: 0.8000 - val_loss: 0.5791 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5754 - accuracy: 0.8000 - val_loss: 0.5725 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5688 - accuracy: 0.8000 - val_loss: 0.5661 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5623 - accuracy: 0.8000 - val_loss: 0.5599 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5561 - accuracy: 0.8000 - val_loss: 0.5538 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 4 3 0 0 4 0 2 4 4 4 1 2 0 4 2]\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_468 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_469 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_470 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_156 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 120ms/step - loss: 0.6714 - accuracy: 0.8000 - val_loss: 0.6254 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6147 - accuracy: 0.8000 - val_loss: 0.5918 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5828 - accuracy: 0.8000 - val_loss: 0.5684 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5606 - accuracy: 0.8000 - val_loss: 0.5510 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5439 - accuracy: 0.8000 - val_loss: 0.5375 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5312 - accuracy: 0.8000 - val_loss: 0.5270 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5216 - accuracy: 0.8000 - val_loss: 0.5191 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5145 - accuracy: 0.8000 - val_loss: 0.5131 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5094 - accuracy: 0.8000 - val_loss: 0.5088 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5058 - accuracy: 0.8000 - val_loss: 0.5057 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5035 - accuracy: 0.8000 - val_loss: 0.5039 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5022 - accuracy: 0.8000 - val_loss: 0.5026 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5014 - accuracy: 0.8000 - val_loss: 0.5019 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5010 - accuracy: 0.8000 - val_loss: 0.5014 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5006 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 4 2 2 4 4 2 3 0 4 4 2 3 4 4 2]\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_471 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_472 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_473 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_157 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 119ms/step - loss: 0.6851 - accuracy: 0.8000 - val_loss: 0.6702 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6673 - accuracy: 0.8000 - val_loss: 0.6568 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6542 - accuracy: 0.8000 - val_loss: 0.6454 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6429 - accuracy: 0.8000 - val_loss: 0.6351 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6325 - accuracy: 0.8000 - val_loss: 0.6250 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6225 - accuracy: 0.8000 - val_loss: 0.6155 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6130 - accuracy: 0.8000 - val_loss: 0.6063 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6037 - accuracy: 0.8000 - val_loss: 0.5974 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5948 - accuracy: 0.8000 - val_loss: 0.5887 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5861 - accuracy: 0.8000 - val_loss: 0.5803 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5777 - accuracy: 0.8000 - val_loss: 0.5722 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5696 - accuracy: 0.8000 - val_loss: 0.5644 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5619 - accuracy: 0.8000 - val_loss: 0.5570 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5544 - accuracy: 0.8000 - val_loss: 0.5499 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5474 - accuracy: 0.8000 - val_loss: 0.5431 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5408 - accuracy: 0.8000 - val_loss: 0.5369 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5347 - accuracy: 0.8000 - val_loss: 0.5312 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5291 - accuracy: 0.8000 - val_loss: 0.5259 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5240 - accuracy: 0.8000 - val_loss: 0.5212 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5194 - accuracy: 0.8000 - val_loss: 0.5170 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 1s 877ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 2 4 1 2 1 4 4 4 0 4 2 2 0 4 3]\n",
      "[]\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_474 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_475 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_476 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_158 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 0.6802 - accuracy: 0.7595 - val_loss: 0.6549 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6463 - accuracy: 0.8000 - val_loss: 0.6341 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6257 - accuracy: 0.8000 - val_loss: 0.6175 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6091 - accuracy: 0.8000 - val_loss: 0.6033 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5947 - accuracy: 0.8000 - val_loss: 0.5905 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5818 - accuracy: 0.8000 - val_loss: 0.5789 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5702 - accuracy: 0.8000 - val_loss: 0.5684 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5597 - accuracy: 0.8000 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5503 - accuracy: 0.8000 - val_loss: 0.5500 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5418 - accuracy: 0.8000 - val_loss: 0.5422 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5343 - accuracy: 0.8000 - val_loss: 0.5351 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5277 - accuracy: 0.8000 - val_loss: 0.5289 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5219 - accuracy: 0.8000 - val_loss: 0.5234 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5170 - accuracy: 0.8000 - val_loss: 0.5186 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5128 - accuracy: 0.8000 - val_loss: 0.5146 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5095 - accuracy: 0.8000 - val_loss: 0.5113 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5068 - accuracy: 0.8000 - val_loss: 0.5086 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5048 - accuracy: 0.8000 - val_loss: 0.5064 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5032 - accuracy: 0.8000 - val_loss: 0.5048 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5022 - accuracy: 0.8000 - val_loss: 0.5037 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 4 1 4 1 0 4 4]\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_477 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_478 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_479 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_159 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 138ms/step - loss: 0.6829 - accuracy: 0.7838 - val_loss: 0.6468 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6330 - accuracy: 0.8000 - val_loss: 0.6074 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5976 - accuracy: 0.8000 - val_loss: 0.5819 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5736 - accuracy: 0.8000 - val_loss: 0.5630 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5556 - accuracy: 0.8000 - val_loss: 0.5481 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5415 - accuracy: 0.8000 - val_loss: 0.5361 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5303 - accuracy: 0.8000 - val_loss: 0.5266 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5216 - accuracy: 0.8000 - val_loss: 0.5190 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5148 - accuracy: 0.8000 - val_loss: 0.5133 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5098 - accuracy: 0.8000 - val_loss: 0.5090 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5063 - accuracy: 0.8000 - val_loss: 0.5059 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5039 - accuracy: 0.8000 - val_loss: 0.5038 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5024 - accuracy: 0.8000 - val_loss: 0.5025 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5015 - accuracy: 0.8000 - val_loss: 0.5017 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5013 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5008 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 0 4 4 3 2 0 4]\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_480 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_481 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_482 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_160 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 111ms/step - loss: 0.6829 - accuracy: 0.8000 - val_loss: 0.6685 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6640 - accuracy: 0.8000 - val_loss: 0.6534 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6489 - accuracy: 0.8000 - val_loss: 0.6397 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6351 - accuracy: 0.8000 - val_loss: 0.6270 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6222 - accuracy: 0.8000 - val_loss: 0.6149 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6099 - accuracy: 0.8000 - val_loss: 0.6033 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5982 - accuracy: 0.8000 - val_loss: 0.5921 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5870 - accuracy: 0.8000 - val_loss: 0.5815 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5763 - accuracy: 0.8000 - val_loss: 0.5715 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5662 - accuracy: 0.8000 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5569 - accuracy: 0.8000 - val_loss: 0.5532 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5482 - accuracy: 0.8000 - val_loss: 0.5450 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5402 - accuracy: 0.8000 - val_loss: 0.5376 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5330 - accuracy: 0.8000 - val_loss: 0.5309 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5266 - accuracy: 0.8000 - val_loss: 0.5249 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5210 - accuracy: 0.8000 - val_loss: 0.5197 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5162 - accuracy: 0.8000 - val_loss: 0.5153 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.5122 - accuracy: 0.8000 - val_loss: 0.5116 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5089 - accuracy: 0.8000 - val_loss: 0.5085 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5063 - accuracy: 0.8000 - val_loss: 0.5061 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 4 0 4 4 4 0 4 4]\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_483 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_484 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_485 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_161 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 131ms/step - loss: 0.6929 - accuracy: 0.5568 - val_loss: 0.6782 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6741 - accuracy: 0.8000 - val_loss: 0.6622 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6575 - accuracy: 0.8000 - val_loss: 0.6470 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6424 - accuracy: 0.8000 - val_loss: 0.6335 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6289 - accuracy: 0.8000 - val_loss: 0.6211 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6163 - accuracy: 0.8000 - val_loss: 0.6094 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6044 - accuracy: 0.8000 - val_loss: 0.5983 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5933 - accuracy: 0.8000 - val_loss: 0.5879 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5829 - accuracy: 0.8000 - val_loss: 0.5781 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5730 - accuracy: 0.8000 - val_loss: 0.5688 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5638 - accuracy: 0.8000 - val_loss: 0.5601 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5552 - accuracy: 0.8000 - val_loss: 0.5521 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5472 - accuracy: 0.8000 - val_loss: 0.5446 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5399 - accuracy: 0.8000 - val_loss: 0.5377 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5332 - accuracy: 0.8000 - val_loss: 0.5315 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5272 - accuracy: 0.8000 - val_loss: 0.5259 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5219 - accuracy: 0.8000 - val_loss: 0.5209 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5173 - accuracy: 0.8000 - val_loss: 0.5166 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5134 - accuracy: 0.8000 - val_loss: 0.5130 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5101 - accuracy: 0.8000 - val_loss: 0.5099 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 1 0 2 2 4 2 3]\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_486 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_487 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_488 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_162 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 144ms/step - loss: 0.6787 - accuracy: 0.7595 - val_loss: 0.6455 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6336 - accuracy: 0.8000 - val_loss: 0.6112 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6007 - accuracy: 0.8000 - val_loss: 0.5863 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5770 - accuracy: 0.8000 - val_loss: 0.5670 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5583 - accuracy: 0.8000 - val_loss: 0.5511 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5432 - accuracy: 0.8000 - val_loss: 0.5383 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5314 - accuracy: 0.8000 - val_loss: 0.5283 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5223 - accuracy: 0.8000 - val_loss: 0.5205 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5153 - accuracy: 0.8000 - val_loss: 0.5144 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5101 - accuracy: 0.8000 - val_loss: 0.5098 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5064 - accuracy: 0.8000 - val_loss: 0.5065 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5039 - accuracy: 0.8000 - val_loss: 0.5043 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5024 - accuracy: 0.8000 - val_loss: 0.5029 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5015 - accuracy: 0.8000 - val_loss: 0.5021 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5016 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.5013 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5012 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 0 2 1 4 4 0 0 0]\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_489 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_490 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_491 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_163 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 130ms/step - loss: 0.6945 - accuracy: 0.4757 - val_loss: 0.6860 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6844 - accuracy: 0.8000 - val_loss: 0.6807 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6792 - accuracy: 0.8000 - val_loss: 0.6760 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6744 - accuracy: 0.8000 - val_loss: 0.6715 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6698 - accuracy: 0.8000 - val_loss: 0.6670 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6652 - accuracy: 0.8000 - val_loss: 0.6624 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6605 - accuracy: 0.8000 - val_loss: 0.6568 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6537 - accuracy: 0.8000 - val_loss: 0.6490 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6463 - accuracy: 0.8000 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6396 - accuracy: 0.8000 - val_loss: 0.6362 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6333 - accuracy: 0.8000 - val_loss: 0.6306 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6276 - accuracy: 0.8000 - val_loss: 0.6251 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6220 - accuracy: 0.8000 - val_loss: 0.6196 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6164 - accuracy: 0.8000 - val_loss: 0.6142 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.6108 - accuracy: 0.8000 - val_loss: 0.6091 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6055 - accuracy: 0.8000 - val_loss: 0.6038 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6002 - accuracy: 0.8000 - val_loss: 0.5985 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5948 - accuracy: 0.8000 - val_loss: 0.5932 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5895 - accuracy: 0.8000 - val_loss: 0.5881 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5843 - accuracy: 0.8000 - val_loss: 0.5830 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 4 1 0 2 0 4 2]\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_492 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_493 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_494 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_164 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.6764 - accuracy: 0.8000 - val_loss: 0.6499 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6432 - accuracy: 0.8000 - val_loss: 0.6294 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6235 - accuracy: 0.8000 - val_loss: 0.6133 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6075 - accuracy: 0.8000 - val_loss: 0.5993 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5934 - accuracy: 0.8000 - val_loss: 0.5865 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5805 - accuracy: 0.8000 - val_loss: 0.5746 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5687 - accuracy: 0.8000 - val_loss: 0.5638 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5580 - accuracy: 0.8000 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5484 - accuracy: 0.8000 - val_loss: 0.5453 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5399 - accuracy: 0.8000 - val_loss: 0.5376 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5324 - accuracy: 0.8000 - val_loss: 0.5307 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5258 - accuracy: 0.8000 - val_loss: 0.5247 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5202 - accuracy: 0.8000 - val_loss: 0.5195 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5154 - accuracy: 0.8000 - val_loss: 0.5151 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5115 - accuracy: 0.8000 - val_loss: 0.5111 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5076 - accuracy: 0.8000 - val_loss: 0.5069 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5044 - accuracy: 0.8000 - val_loss: 0.5045 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5026 - accuracy: 0.8000 - val_loss: 0.5029 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5016 - accuracy: 0.8000 - val_loss: 0.5021 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5015 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 0 3 0 3 2 2 4 4]\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_495 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_496 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_497 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_165 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 151ms/step - loss: 0.6719 - accuracy: 0.8000 - val_loss: 0.6442 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6352 - accuracy: 0.8000 - val_loss: 0.6184 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6101 - accuracy: 0.8000 - val_loss: 0.5978 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5899 - accuracy: 0.8000 - val_loss: 0.5803 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5728 - accuracy: 0.8000 - val_loss: 0.5654 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5583 - accuracy: 0.8000 - val_loss: 0.5526 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5459 - accuracy: 0.8000 - val_loss: 0.5416 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5354 - accuracy: 0.8000 - val_loss: 0.5323 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5267 - accuracy: 0.8000 - val_loss: 0.5245 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5195 - accuracy: 0.8000 - val_loss: 0.5182 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5138 - accuracy: 0.8000 - val_loss: 0.5131 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5095 - accuracy: 0.8000 - val_loss: 0.5092 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5063 - accuracy: 0.8000 - val_loss: 0.5064 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5040 - accuracy: 0.8000 - val_loss: 0.5043 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5025 - accuracy: 0.8000 - val_loss: 0.5029 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5016 - accuracy: 0.8000 - val_loss: 0.5020 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5015 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.5012 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 1 4 1 3 2 2 4 2]\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_498 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_499 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_500 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_166 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 125ms/step - loss: 0.6697 - accuracy: 0.8000 - val_loss: 0.6343 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6260 - accuracy: 0.8000 - val_loss: 0.6061 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5997 - accuracy: 0.8000 - val_loss: 0.5849 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5795 - accuracy: 0.8000 - val_loss: 0.5677 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5629 - accuracy: 0.8000 - val_loss: 0.5535 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5492 - accuracy: 0.8000 - val_loss: 0.5415 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5378 - accuracy: 0.8000 - val_loss: 0.5317 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5284 - accuracy: 0.8000 - val_loss: 0.5235 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5207 - accuracy: 0.8000 - val_loss: 0.5170 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5147 - accuracy: 0.8000 - val_loss: 0.5120 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5100 - accuracy: 0.8000 - val_loss: 0.5082 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5066 - accuracy: 0.8000 - val_loss: 0.5054 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5042 - accuracy: 0.8000 - val_loss: 0.5036 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5027 - accuracy: 0.8000 - val_loss: 0.5024 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5017 - accuracy: 0.8000 - val_loss: 0.5016 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.5012 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5009 - accuracy: 0.8000 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5006 - accuracy: 0.8000 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 4 0 3 3 2 1 2 4]\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_501 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_502 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_503 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_167 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 99ms/step - loss: 0.6669 - accuracy: 0.8000 - val_loss: 0.6313 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6174 - accuracy: 0.8000 - val_loss: 0.5976 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5861 - accuracy: 0.8000 - val_loss: 0.5748 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5641 - accuracy: 0.8000 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.5473 - accuracy: 0.8000 - val_loss: 0.5434 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5343 - accuracy: 0.8000 - val_loss: 0.5323 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5242 - accuracy: 0.8000 - val_loss: 0.5237 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5166 - accuracy: 0.8000 - val_loss: 0.5170 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5109 - accuracy: 0.8000 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5070 - accuracy: 0.8000 - val_loss: 0.5085 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5043 - accuracy: 0.8000 - val_loss: 0.5059 - val_accuracy: 0.8000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5026 - accuracy: 0.8000 - val_loss: 0.5042 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5016 - accuracy: 0.8000 - val_loss: 0.5031 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5010 - accuracy: 0.8000 - val_loss: 0.5024 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5008 - accuracy: 0.8000 - val_loss: 0.5021 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5019 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5018 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5006 - accuracy: 0.8000 - val_loss: 0.5017 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5006 - accuracy: 0.8000 - val_loss: 0.5017 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5006 - accuracy: 0.8000 - val_loss: 0.5017 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [4 2 4 3 0 4 2 2 4]\n",
      "[]\n",
      "seconds value in hours: 0.0\n",
      "seconds value in minutes: 2.0\n",
      "tfidf\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_504 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_505 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_506 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_168 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 248ms/step - loss: 0.6912 - accuracy: 0.7500 - val_loss: 0.6861 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6849 - accuracy: 0.7500 - val_loss: 0.6807 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6795 - accuracy: 0.7500 - val_loss: 0.6764 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6750 - accuracy: 0.7500 - val_loss: 0.6726 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6710 - accuracy: 0.7500 - val_loss: 0.6685 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6667 - accuracy: 0.7500 - val_loss: 0.6644 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6624 - accuracy: 0.7500 - val_loss: 0.6606 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6584 - accuracy: 0.7500 - val_loss: 0.6570 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6547 - accuracy: 0.7500 - val_loss: 0.6534 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6509 - accuracy: 0.7500 - val_loss: 0.6500 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6472 - accuracy: 0.7500 - val_loss: 0.6457 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6425 - accuracy: 0.7500 - val_loss: 0.6411 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6379 - accuracy: 0.7500 - val_loss: 0.6369 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6335 - accuracy: 0.7500 - val_loss: 0.6328 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6293 - accuracy: 0.7500 - val_loss: 0.6289 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6253 - accuracy: 0.7500 - val_loss: 0.6250 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6212 - accuracy: 0.7500 - val_loss: 0.6212 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6173 - accuracy: 0.7500 - val_loss: 0.6174 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6135 - accuracy: 0.7500 - val_loss: 0.6137 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6097 - accuracy: 0.7500 - val_loss: 0.6101 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [1 3 0 1 2 3 0 3 0 1 0 1 2 3 0 2 0 3 3 0 1 3 3 0 0 0 3 0 3 3 3 1 3 0 1 0 0\n",
      " 1 0 3 0 3]\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_507 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_508 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_509 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_169 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 3s 553ms/step - loss: 0.6880 - accuracy: 0.6890 - val_loss: 0.6708 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6681 - accuracy: 0.7500 - val_loss: 0.6585 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6555 - accuracy: 0.7500 - val_loss: 0.6484 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6451 - accuracy: 0.7500 - val_loss: 0.6395 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.6360 - accuracy: 0.7500 - val_loss: 0.6316 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.6279 - accuracy: 0.7500 - val_loss: 0.6244 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6205 - accuracy: 0.7500 - val_loss: 0.6178 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.6137 - accuracy: 0.7500 - val_loss: 0.6117 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.6075 - accuracy: 0.7500 - val_loss: 0.6060 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6018 - accuracy: 0.7500 - val_loss: 0.6008 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.5966 - accuracy: 0.7500 - val_loss: 0.5961 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.5919 - accuracy: 0.7500 - val_loss: 0.5917 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5877 - accuracy: 0.7500 - val_loss: 0.5877 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.5838 - accuracy: 0.7500 - val_loss: 0.5841 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5803 - accuracy: 0.7500 - val_loss: 0.5808 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5772 - accuracy: 0.7500 - val_loss: 0.5779 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.5744 - accuracy: 0.7500 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.5721 - accuracy: 0.7500 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.5701 - accuracy: 0.7500 - val_loss: 0.5711 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5684 - accuracy: 0.7500 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [0 3 3 0 0 0 3 3 2 3 3 0 1 3 2 1 0 1 3 3 3 0 3 3 1 1 2 3 3 1 3 2 3 0 3 0 3\n",
      " 3 1 2 0 3]\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_510 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_511 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_512 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_170 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 450ms/step - loss: 0.6874 - accuracy: 0.7500 - val_loss: 0.6698 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6674 - accuracy: 0.7500 - val_loss: 0.6575 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6547 - accuracy: 0.7500 - val_loss: 0.6475 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6445 - accuracy: 0.7500 - val_loss: 0.6388 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6354 - accuracy: 0.7500 - val_loss: 0.6310 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6274 - accuracy: 0.7500 - val_loss: 0.6240 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6202 - accuracy: 0.7500 - val_loss: 0.6175 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6136 - accuracy: 0.7500 - val_loss: 0.6116 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6076 - accuracy: 0.7500 - val_loss: 0.6062 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6021 - accuracy: 0.7500 - val_loss: 0.6012 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 0.5971 - accuracy: 0.7500 - val_loss: 0.5966 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5925 - accuracy: 0.7500 - val_loss: 0.5923 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5883 - accuracy: 0.7500 - val_loss: 0.5885 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5845 - accuracy: 0.7500 - val_loss: 0.5849 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5811 - accuracy: 0.7500 - val_loss: 0.5817 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5780 - accuracy: 0.7500 - val_loss: 0.5788 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.5753 - accuracy: 0.7500 - val_loss: 0.5762 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5730 - accuracy: 0.7500 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5709 - accuracy: 0.7500 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5691 - accuracy: 0.7500 - val_loss: 0.5702 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 2 3 0 2 3 0 0 2 0 1 3 0 1 1 0 3 0 3 3 1 0 1 2 3 3 3 0 0 2 0 1 2 3 3 3 0\n",
      " 0 0 0 0 0]\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_513 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_514 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_515 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_171 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.7008 - accuracy: 0.3476 - val_loss: 0.6842 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6826 - accuracy: 0.7500 - val_loss: 0.6758 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6744 - accuracy: 0.7500 - val_loss: 0.6698 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6682 - accuracy: 0.7500 - val_loss: 0.6642 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6623 - accuracy: 0.7500 - val_loss: 0.6588 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6566 - accuracy: 0.7500 - val_loss: 0.6535 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6510 - accuracy: 0.7500 - val_loss: 0.6475 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6448 - accuracy: 0.7500 - val_loss: 0.6418 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6389 - accuracy: 0.7500 - val_loss: 0.6363 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6332 - accuracy: 0.7500 - val_loss: 0.6310 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.6278 - accuracy: 0.7500 - val_loss: 0.6260 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6226 - accuracy: 0.7500 - val_loss: 0.6211 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.6176 - accuracy: 0.7500 - val_loss: 0.6163 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.6128 - accuracy: 0.7500 - val_loss: 0.6118 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6081 - accuracy: 0.7500 - val_loss: 0.6074 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.6038 - accuracy: 0.7500 - val_loss: 0.6033 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.5996 - accuracy: 0.7500 - val_loss: 0.5993 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.5956 - accuracy: 0.7500 - val_loss: 0.5956 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.5919 - accuracy: 0.7500 - val_loss: 0.5921 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5884 - accuracy: 0.7500 - val_loss: 0.5888 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [1 0 3 0 2 2 2 1 3 1 0 0 0 0 0 3 3 0 0 2 0 1 3 1 3 2 3 0 1 1 3 0 0 0 1 0 3\n",
      " 0 2 3 3 3]\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_516 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_517 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_518 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_172 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.6838 - accuracy: 0.7500 - val_loss: 0.6607 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6569 - accuracy: 0.7500 - val_loss: 0.6448 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6410 - accuracy: 0.7500 - val_loss: 0.6328 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6292 - accuracy: 0.7500 - val_loss: 0.6230 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6194 - accuracy: 0.7500 - val_loss: 0.6148 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6111 - accuracy: 0.7500 - val_loss: 0.6076 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6039 - accuracy: 0.7500 - val_loss: 0.6012 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5976 - accuracy: 0.7500 - val_loss: 0.5956 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5921 - accuracy: 0.7500 - val_loss: 0.5906 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5872 - accuracy: 0.7500 - val_loss: 0.5863 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5830 - accuracy: 0.7500 - val_loss: 0.5824 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5792 - accuracy: 0.7500 - val_loss: 0.5790 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5760 - accuracy: 0.7500 - val_loss: 0.5760 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.5732 - accuracy: 0.7500 - val_loss: 0.5735 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.5709 - accuracy: 0.7500 - val_loss: 0.5713 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5689 - accuracy: 0.7500 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5673 - accuracy: 0.7500 - val_loss: 0.5679 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5660 - accuracy: 0.7500 - val_loss: 0.5667 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5650 - accuracy: 0.7500 - val_loss: 0.5657 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5642 - accuracy: 0.7500 - val_loss: 0.5650 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 3 3 1 3 3 3 2 3 0 0 2 3 1 0 3 3 2 3 0 0 3 0 0 3 2 0 1 2 3 3 3 1 3 0 0 1\n",
      " 0 1 1 1 3]\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_519 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_520 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_521 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_173 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 549ms/step - loss: 0.6891 - accuracy: 0.7256 - val_loss: 0.6736 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6712 - accuracy: 0.7500 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.6586 - accuracy: 0.7500 - val_loss: 0.6509 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6485 - accuracy: 0.7500 - val_loss: 0.6422 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.6397 - accuracy: 0.7500 - val_loss: 0.6343 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6318 - accuracy: 0.7500 - val_loss: 0.6271 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6245 - accuracy: 0.7500 - val_loss: 0.6204 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.6178 - accuracy: 0.7500 - val_loss: 0.6142 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6116 - accuracy: 0.7500 - val_loss: 0.6085 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6058 - accuracy: 0.7500 - val_loss: 0.6031 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6004 - accuracy: 0.7500 - val_loss: 0.5981 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.5955 - accuracy: 0.7500 - val_loss: 0.5935 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.5910 - accuracy: 0.7500 - val_loss: 0.5893 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.5868 - accuracy: 0.7500 - val_loss: 0.5855 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5831 - accuracy: 0.7500 - val_loss: 0.5820 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.5797 - accuracy: 0.7500 - val_loss: 0.5788 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5767 - accuracy: 0.7500 - val_loss: 0.5760 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5740 - accuracy: 0.7500 - val_loss: 0.5736 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5717 - accuracy: 0.7500 - val_loss: 0.5714 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5697 - accuracy: 0.7500 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 0 3 3 0 1 1 3 0 1 0 3 0 0 2 0 3 0 3 0 0 1 0 0 0 3 3 3 0 2 2 1 3 0 1 3 2\n",
      " 1 0 0 1 0]\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_522 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_523 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_524 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_174 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 324ms/step - loss: 0.6862 - accuracy: 0.7256 - val_loss: 0.6654 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6623 - accuracy: 0.7500 - val_loss: 0.6519 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6488 - accuracy: 0.7500 - val_loss: 0.6414 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6383 - accuracy: 0.7500 - val_loss: 0.6326 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6293 - accuracy: 0.7500 - val_loss: 0.6248 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6215 - accuracy: 0.7500 - val_loss: 0.6178 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6144 - accuracy: 0.7500 - val_loss: 0.6115 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6081 - accuracy: 0.7500 - val_loss: 0.6057 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6024 - accuracy: 0.7500 - val_loss: 0.6005 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5972 - accuracy: 0.7500 - val_loss: 0.5957 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5924 - accuracy: 0.7500 - val_loss: 0.5914 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5882 - accuracy: 0.7500 - val_loss: 0.5874 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.5843 - accuracy: 0.7500 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5809 - accuracy: 0.7500 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.5778 - accuracy: 0.7500 - val_loss: 0.5778 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5751 - accuracy: 0.7500 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.5727 - accuracy: 0.7500 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.5707 - accuracy: 0.7500 - val_loss: 0.5711 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.5690 - accuracy: 0.7500 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5675 - accuracy: 0.7500 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 0 3 0 0 3 0 0 3 3 3 3 0 0 2 1 0 3 0 1 0 3 1 3 3 2 0 3 0 0 3 0 1 0 0 2 0\n",
      " 3 3 0 3 3]\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_525 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_526 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_527 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_175 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 302ms/step - loss: 0.6908 - accuracy: 0.5305 - val_loss: 0.6757 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6732 - accuracy: 0.7500 - val_loss: 0.6616 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6592 - accuracy: 0.7500 - val_loss: 0.6508 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6482 - accuracy: 0.7500 - val_loss: 0.6417 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6388 - accuracy: 0.7500 - val_loss: 0.6336 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6306 - accuracy: 0.7500 - val_loss: 0.6262 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6231 - accuracy: 0.7500 - val_loss: 0.6194 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6162 - accuracy: 0.7500 - val_loss: 0.6132 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6099 - accuracy: 0.7500 - val_loss: 0.6074 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6041 - accuracy: 0.7500 - val_loss: 0.6021 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5987 - accuracy: 0.7500 - val_loss: 0.5971 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5938 - accuracy: 0.7500 - val_loss: 0.5926 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5894 - accuracy: 0.7500 - val_loss: 0.5885 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5853 - accuracy: 0.7500 - val_loss: 0.5847 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5817 - accuracy: 0.7500 - val_loss: 0.5813 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5784 - accuracy: 0.7500 - val_loss: 0.5782 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5755 - accuracy: 0.7500 - val_loss: 0.5755 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5730 - accuracy: 0.7500 - val_loss: 0.5731 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5708 - accuracy: 0.7500 - val_loss: 0.5711 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5689 - accuracy: 0.7500 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 1 3 0 0 1 1 0 0 0 0 2 2 0 1 0 0 2 3 0 3 0 3 0 3 3 3 0 0 2 2 3 3 0 1 3 0\n",
      " 0 2 3 3 1]\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_528 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_529 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_530 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_176 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 217ms/step - loss: 0.6820 - accuracy: 0.7500 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6579 - accuracy: 0.7500 - val_loss: 0.6462 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6429 - accuracy: 0.7500 - val_loss: 0.6344 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6311 - accuracy: 0.7500 - val_loss: 0.6245 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6211 - accuracy: 0.7500 - val_loss: 0.6159 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6125 - accuracy: 0.7500 - val_loss: 0.6084 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6049 - accuracy: 0.7500 - val_loss: 0.6017 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5982 - accuracy: 0.7500 - val_loss: 0.5957 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5924 - accuracy: 0.7500 - val_loss: 0.5904 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5872 - accuracy: 0.7500 - val_loss: 0.5858 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5827 - accuracy: 0.7500 - val_loss: 0.5817 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5788 - accuracy: 0.7500 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.5754 - accuracy: 0.7500 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5725 - accuracy: 0.7500 - val_loss: 0.5725 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5702 - accuracy: 0.7500 - val_loss: 0.5704 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5683 - accuracy: 0.7500 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5667 - accuracy: 0.7500 - val_loss: 0.5671 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5655 - accuracy: 0.7500 - val_loss: 0.5659 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5645 - accuracy: 0.7500 - val_loss: 0.5650 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5639 - accuracy: 0.7500 - val_loss: 0.5644 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 0 0 3 0 3 0 3 3 3 0 3 1 0 1 2 1 3 3 3 3 3 0 0 1 1 3 3 2 0 3 1 1 0 3 3 1\n",
      " 1 0 2 3 3]\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_531 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_532 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_533 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_177 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 170ms/step - loss: 0.6921 - accuracy: 0.4695 - val_loss: 0.6834 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6821 - accuracy: 0.7500 - val_loss: 0.6744 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6731 - accuracy: 0.7500 - val_loss: 0.6672 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6658 - accuracy: 0.7500 - val_loss: 0.6608 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6592 - accuracy: 0.7500 - val_loss: 0.6547 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6531 - accuracy: 0.7500 - val_loss: 0.6490 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6472 - accuracy: 0.7500 - val_loss: 0.6435 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6416 - accuracy: 0.7500 - val_loss: 0.6382 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6362 - accuracy: 0.7500 - val_loss: 0.6331 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6310 - accuracy: 0.7500 - val_loss: 0.6282 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6260 - accuracy: 0.7500 - val_loss: 0.6234 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6211 - accuracy: 0.7500 - val_loss: 0.6188 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6164 - accuracy: 0.7500 - val_loss: 0.6143 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6119 - accuracy: 0.7500 - val_loss: 0.6100 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6076 - accuracy: 0.7500 - val_loss: 0.6059 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6034 - accuracy: 0.7500 - val_loss: 0.6020 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5995 - accuracy: 0.7500 - val_loss: 0.5982 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.5957 - accuracy: 0.7500 - val_loss: 0.5947 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5921 - accuracy: 0.7500 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5888 - accuracy: 0.7500 - val_loss: 0.5881 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 0 0 0 0 3 1 0 1 1 3 3 3 1 1 3 0 3 0 0 3 3 0 0 1 3 1 3 3 2 0 3 1 2 0 0 1\n",
      " 2 2 3 0 3]\n",
      "[]\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_534 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_535 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_536 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_178 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 249ms/step - loss: 0.6942 - accuracy: 0.4541 - val_loss: 0.6885 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6874 - accuracy: 0.7500 - val_loss: 0.6820 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6808 - accuracy: 0.7500 - val_loss: 0.6762 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6747 - accuracy: 0.7500 - val_loss: 0.6701 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6686 - accuracy: 0.7500 - val_loss: 0.6648 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6631 - accuracy: 0.7500 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6580 - accuracy: 0.7500 - val_loss: 0.6549 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6530 - accuracy: 0.7500 - val_loss: 0.6503 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6482 - accuracy: 0.7500 - val_loss: 0.6457 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6435 - accuracy: 0.7500 - val_loss: 0.6413 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6391 - accuracy: 0.7500 - val_loss: 0.6370 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6346 - accuracy: 0.7500 - val_loss: 0.6328 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6303 - accuracy: 0.7500 - val_loss: 0.6286 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6261 - accuracy: 0.7500 - val_loss: 0.6246 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.6220 - accuracy: 0.7500 - val_loss: 0.6207 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6180 - accuracy: 0.7500 - val_loss: 0.6168 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6141 - accuracy: 0.7500 - val_loss: 0.6131 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6103 - accuracy: 0.7500 - val_loss: 0.6094 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6066 - accuracy: 0.7500 - val_loss: 0.6058 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6030 - accuracy: 0.7500 - val_loss: 0.6025 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 0 1 3 0 0 1 0 3 0 0 0 3 3 3 3 1 0 3 2 2 3 0 0 1 2 3 0 3 3 3 0 3 0]\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_537 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_538 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_539 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_179 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 286ms/step - loss: 0.6980 - accuracy: 0.3418 - val_loss: 0.6888 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6878 - accuracy: 0.7500 - val_loss: 0.6853 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6843 - accuracy: 0.7500 - val_loss: 0.6822 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6811 - accuracy: 0.7500 - val_loss: 0.6793 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6780 - accuracy: 0.7500 - val_loss: 0.6766 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6752 - accuracy: 0.7500 - val_loss: 0.6740 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6725 - accuracy: 0.7500 - val_loss: 0.6715 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6699 - accuracy: 0.7500 - val_loss: 0.6690 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6673 - accuracy: 0.7500 - val_loss: 0.6666 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6647 - accuracy: 0.7500 - val_loss: 0.6641 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.6622 - accuracy: 0.7500 - val_loss: 0.6617 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6596 - accuracy: 0.7500 - val_loss: 0.6592 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6570 - accuracy: 0.7500 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.6544 - accuracy: 0.7500 - val_loss: 0.6543 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6518 - accuracy: 0.7500 - val_loss: 0.6518 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6492 - accuracy: 0.7500 - val_loss: 0.6493 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.6466 - accuracy: 0.7500 - val_loss: 0.6468 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6440 - accuracy: 0.7500 - val_loss: 0.6443 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6414 - accuracy: 0.7500 - val_loss: 0.6418 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6388 - accuracy: 0.7500 - val_loss: 0.6393 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 3 3 3 1 0 2 0 0 3 3 3 1 0 0 1 3 0 1 0 3 2 1 3 3 1 2 0 2 3 3 3 1]\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_540 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_541 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_542 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_180 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 255ms/step - loss: 0.6823 - accuracy: 0.7500 - val_loss: 0.6684 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6648 - accuracy: 0.7500 - val_loss: 0.6558 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6523 - accuracy: 0.7500 - val_loss: 0.6458 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6421 - accuracy: 0.7500 - val_loss: 0.6371 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6333 - accuracy: 0.7500 - val_loss: 0.6294 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6255 - accuracy: 0.7500 - val_loss: 0.6223 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6183 - accuracy: 0.7500 - val_loss: 0.6159 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6118 - accuracy: 0.7500 - val_loss: 0.6099 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6058 - accuracy: 0.7500 - val_loss: 0.6044 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6003 - accuracy: 0.7500 - val_loss: 0.5993 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5953 - accuracy: 0.7500 - val_loss: 0.5947 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5907 - accuracy: 0.7500 - val_loss: 0.5904 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.5865 - accuracy: 0.7500 - val_loss: 0.5865 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5827 - accuracy: 0.7500 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5793 - accuracy: 0.7500 - val_loss: 0.5798 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5764 - accuracy: 0.7500 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5737 - accuracy: 0.7500 - val_loss: 0.5744 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5714 - accuracy: 0.7500 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5695 - accuracy: 0.7500 - val_loss: 0.5704 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5679 - accuracy: 0.7500 - val_loss: 0.5688 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 3 2 0 1 2 3 0 1 1 3 2 3 3 3 0 3 3 1 3 2 3 3 0 2 3 0 0 0 1 0 3 2]\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_543 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_544 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_545 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_181 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 215ms/step - loss: 0.6898 - accuracy: 0.6990 - val_loss: 0.6798 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6767 - accuracy: 0.7500 - val_loss: 0.6674 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6643 - accuracy: 0.7500 - val_loss: 0.6583 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6550 - accuracy: 0.7500 - val_loss: 0.6506 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6470 - accuracy: 0.7500 - val_loss: 0.6436 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6399 - accuracy: 0.7500 - val_loss: 0.6373 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6333 - accuracy: 0.7500 - val_loss: 0.6313 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6272 - accuracy: 0.7500 - val_loss: 0.6256 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6214 - accuracy: 0.7500 - val_loss: 0.6203 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6159 - accuracy: 0.7500 - val_loss: 0.6152 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6107 - accuracy: 0.7500 - val_loss: 0.6103 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6058 - accuracy: 0.7500 - val_loss: 0.6057 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6011 - accuracy: 0.7500 - val_loss: 0.6013 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5968 - accuracy: 0.7500 - val_loss: 0.5972 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5927 - accuracy: 0.7500 - val_loss: 0.5933 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.5888 - accuracy: 0.7500 - val_loss: 0.5897 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5853 - accuracy: 0.7500 - val_loss: 0.5863 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5820 - accuracy: 0.7500 - val_loss: 0.5831 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5790 - accuracy: 0.7500 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5763 - accuracy: 0.7500 - val_loss: 0.5776 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 3 2 3 1 1 1 0 1 1 0 0 0 0 3 3 0 0 3 0 0 3 3 0 3 0 0 3 3 2 3 3 3 3]\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_546 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_547 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_548 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_182 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 194ms/step - loss: 0.6909 - accuracy: 0.7500 - val_loss: 0.6849 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6840 - accuracy: 0.7500 - val_loss: 0.6798 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6784 - accuracy: 0.7500 - val_loss: 0.6749 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6733 - accuracy: 0.7500 - val_loss: 0.6706 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6688 - accuracy: 0.7500 - val_loss: 0.6664 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6644 - accuracy: 0.7500 - val_loss: 0.6623 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6602 - accuracy: 0.7500 - val_loss: 0.6583 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6560 - accuracy: 0.7500 - val_loss: 0.6543 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6518 - accuracy: 0.7500 - val_loss: 0.6504 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6478 - accuracy: 0.7500 - val_loss: 0.6466 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6436 - accuracy: 0.7500 - val_loss: 0.6426 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6395 - accuracy: 0.7500 - val_loss: 0.6387 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6354 - accuracy: 0.7500 - val_loss: 0.6348 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6313 - accuracy: 0.7500 - val_loss: 0.6307 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6272 - accuracy: 0.7500 - val_loss: 0.6261 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6225 - accuracy: 0.7500 - val_loss: 0.6219 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6181 - accuracy: 0.7500 - val_loss: 0.6178 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6139 - accuracy: 0.7500 - val_loss: 0.6138 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6097 - accuracy: 0.7500 - val_loss: 0.6099 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6057 - accuracy: 0.7500 - val_loss: 0.6061 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 1 0 2 0 3 0 1 0 1 1 0 0 3 0 3 3 3 1 3 3 1 3 3 2 3 0 3 0 2 3 0 3 2]\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_549 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_550 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_551 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_183 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.6862 - accuracy: 0.7500 - val_loss: 0.6698 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6654 - accuracy: 0.7500 - val_loss: 0.6516 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6469 - accuracy: 0.7500 - val_loss: 0.6378 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6332 - accuracy: 0.7500 - val_loss: 0.6271 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6225 - accuracy: 0.7500 - val_loss: 0.6183 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6136 - accuracy: 0.7500 - val_loss: 0.6106 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6059 - accuracy: 0.7500 - val_loss: 0.6036 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5988 - accuracy: 0.7500 - val_loss: 0.5967 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5921 - accuracy: 0.7500 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5865 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5817 - accuracy: 0.7500 - val_loss: 0.5817 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5777 - accuracy: 0.7500 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5744 - accuracy: 0.7500 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5716 - accuracy: 0.7500 - val_loss: 0.5724 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5693 - accuracy: 0.7500 - val_loss: 0.5702 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5674 - accuracy: 0.7500 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5660 - accuracy: 0.7500 - val_loss: 0.5671 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5649 - accuracy: 0.7500 - val_loss: 0.5660 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5641 - accuracy: 0.7500 - val_loss: 0.5651 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5645 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 1 0 2 3 3 0 3 0 3 3 0 0 1 0 3 1 3 0 1 1 1 2 0 3 3 2 3 2 3 3 3 0 1]\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_552 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_553 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_554 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_184 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 188ms/step - loss: 0.6922 - accuracy: 0.4847 - val_loss: 0.6789 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6762 - accuracy: 0.7500 - val_loss: 0.6667 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6640 - accuracy: 0.7500 - val_loss: 0.6570 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6541 - accuracy: 0.7500 - val_loss: 0.6486 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6456 - accuracy: 0.7500 - val_loss: 0.6410 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6378 - accuracy: 0.7500 - val_loss: 0.6340 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6306 - accuracy: 0.7500 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6239 - accuracy: 0.7500 - val_loss: 0.6211 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6176 - accuracy: 0.7500 - val_loss: 0.6153 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6116 - accuracy: 0.7500 - val_loss: 0.6097 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6060 - accuracy: 0.7500 - val_loss: 0.6046 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6008 - accuracy: 0.7500 - val_loss: 0.5997 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5960 - accuracy: 0.7500 - val_loss: 0.5952 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5915 - accuracy: 0.7500 - val_loss: 0.5910 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5874 - accuracy: 0.7500 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5837 - accuracy: 0.7500 - val_loss: 0.5836 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5803 - accuracy: 0.7500 - val_loss: 0.5804 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5773 - accuracy: 0.7500 - val_loss: 0.5776 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5746 - accuracy: 0.7500 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5723 - accuracy: 0.7500 - val_loss: 0.5728 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 1 3 0 0 0 3 3 2 3 1 0 2 3 1 0 0 0 3 1 0 2 3 0 1 1 1 3 3 0 0 0 1]\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_555 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_556 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_557 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_185 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 176ms/step - loss: 0.6770 - accuracy: 0.7500 - val_loss: 0.6475 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6411 - accuracy: 0.7500 - val_loss: 0.6253 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6195 - accuracy: 0.7500 - val_loss: 0.6100 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6045 - accuracy: 0.7500 - val_loss: 0.5985 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5934 - accuracy: 0.7500 - val_loss: 0.5896 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5849 - accuracy: 0.7500 - val_loss: 0.5826 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5783 - accuracy: 0.7500 - val_loss: 0.5771 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5734 - accuracy: 0.7500 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5698 - accuracy: 0.7500 - val_loss: 0.5699 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5672 - accuracy: 0.7500 - val_loss: 0.5676 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5654 - accuracy: 0.7500 - val_loss: 0.5660 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5642 - accuracy: 0.7500 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5642 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.5631 - accuracy: 0.7500 - val_loss: 0.5637 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5634 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 1 3 2 0 1 0 2 2 3 3 0 1 1 0 3 3 0 0 0 3 3 1 1 3 0 1 0 2 3 0 1 0]\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_558 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_559 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_560 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_186 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 214ms/step - loss: 0.6953 - accuracy: 0.4439 - val_loss: 0.6910 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6907 - accuracy: 0.7500 - val_loss: 0.6894 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6892 - accuracy: 0.7500 - val_loss: 0.6881 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6877 - accuracy: 0.7500 - val_loss: 0.6857 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6852 - accuracy: 0.7500 - val_loss: 0.6837 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6833 - accuracy: 0.7500 - val_loss: 0.6819 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6816 - accuracy: 0.7500 - val_loss: 0.6804 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6800 - accuracy: 0.7500 - val_loss: 0.6790 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6786 - accuracy: 0.7500 - val_loss: 0.6774 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6771 - accuracy: 0.7500 - val_loss: 0.6764 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6760 - accuracy: 0.7500 - val_loss: 0.6746 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6743 - accuracy: 0.7500 - val_loss: 0.6733 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6729 - accuracy: 0.7500 - val_loss: 0.6719 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6715 - accuracy: 0.7500 - val_loss: 0.6705 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6702 - accuracy: 0.7500 - val_loss: 0.6691 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6688 - accuracy: 0.7500 - val_loss: 0.6678 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6676 - accuracy: 0.7500 - val_loss: 0.6664 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6661 - accuracy: 0.7500 - val_loss: 0.6652 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.6648 - accuracy: 0.7500 - val_loss: 0.6637 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6632 - accuracy: 0.7500 - val_loss: 0.6623 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 1 2 3 3 1 1 3 3 0 3 3 0 1 3 1 0 3 1 3 0 0 0 0 0 2 2 3 2 0 2 0 1 0]\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_561 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_562 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_563 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_187 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 166ms/step - loss: 0.6954 - accuracy: 0.2500 - val_loss: 0.6924 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6918 - accuracy: 0.7296 - val_loss: 0.6891 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6886 - accuracy: 0.7500 - val_loss: 0.6863 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6856 - accuracy: 0.7500 - val_loss: 0.6827 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6821 - accuracy: 0.7500 - val_loss: 0.6792 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6786 - accuracy: 0.7500 - val_loss: 0.6760 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6753 - accuracy: 0.7500 - val_loss: 0.6728 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6721 - accuracy: 0.7500 - val_loss: 0.6697 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6690 - accuracy: 0.7500 - val_loss: 0.6667 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6659 - accuracy: 0.7500 - val_loss: 0.6638 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6629 - accuracy: 0.7500 - val_loss: 0.6608 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6599 - accuracy: 0.7500 - val_loss: 0.6579 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6569 - accuracy: 0.7500 - val_loss: 0.6550 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6540 - accuracy: 0.7500 - val_loss: 0.6521 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6511 - accuracy: 0.7500 - val_loss: 0.6493 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6482 - accuracy: 0.7500 - val_loss: 0.6465 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6453 - accuracy: 0.7500 - val_loss: 0.6437 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6425 - accuracy: 0.7500 - val_loss: 0.6409 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6397 - accuracy: 0.7500 - val_loss: 0.6381 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6369 - accuracy: 0.7500 - val_loss: 0.6354 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 1 2 0 0 3 0 1 1 0 1 3 1 1 0 3 0 3 3 0 3 0 0 2 3 2 3 3 3 0 0 2 1]\n",
      "[]\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_564 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_565 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_566 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_188 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 181ms/step - loss: 0.6859 - accuracy: 0.7414 - val_loss: 0.6715 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6672 - accuracy: 0.7500 - val_loss: 0.6559 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6520 - accuracy: 0.7500 - val_loss: 0.6435 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6397 - accuracy: 0.7500 - val_loss: 0.6332 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6294 - accuracy: 0.7500 - val_loss: 0.6241 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6204 - accuracy: 0.7500 - val_loss: 0.6160 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6123 - accuracy: 0.7500 - val_loss: 0.6087 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6051 - accuracy: 0.7500 - val_loss: 0.6021 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5986 - accuracy: 0.7500 - val_loss: 0.5962 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5928 - accuracy: 0.7500 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5877 - accuracy: 0.7500 - val_loss: 0.5862 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5832 - accuracy: 0.7500 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5793 - accuracy: 0.7500 - val_loss: 0.5785 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5759 - accuracy: 0.7500 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5730 - accuracy: 0.7500 - val_loss: 0.5727 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5705 - accuracy: 0.7500 - val_loss: 0.5704 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5685 - accuracy: 0.7500 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5669 - accuracy: 0.7500 - val_loss: 0.5671 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5656 - accuracy: 0.7500 - val_loss: 0.5659 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5647 - accuracy: 0.7500 - val_loss: 0.5650 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 1 3 3 3 0 0 1 0 1 1 3 3 0 0 1 0 0 1 3 3 3 3 3 0]\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_567 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_568 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_569 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_189 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 168ms/step - loss: 0.6800 - accuracy: 0.7500 - val_loss: 0.6586 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6528 - accuracy: 0.7500 - val_loss: 0.6386 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6341 - accuracy: 0.7500 - val_loss: 0.6246 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6205 - accuracy: 0.7500 - val_loss: 0.6130 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6089 - accuracy: 0.7500 - val_loss: 0.6035 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5997 - accuracy: 0.7500 - val_loss: 0.5954 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5918 - accuracy: 0.7500 - val_loss: 0.5886 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5853 - accuracy: 0.7500 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5798 - accuracy: 0.7500 - val_loss: 0.5782 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5755 - accuracy: 0.7500 - val_loss: 0.5744 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5720 - accuracy: 0.7500 - val_loss: 0.5712 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5691 - accuracy: 0.7500 - val_loss: 0.5688 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5670 - accuracy: 0.7500 - val_loss: 0.5669 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5655 - accuracy: 0.7500 - val_loss: 0.5656 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5644 - accuracy: 0.7500 - val_loss: 0.5646 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5636 - accuracy: 0.7500 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5631 - accuracy: 0.7500 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 2 3 0 1 0 3 2 3 3 0 0 0 3 0 3 0 1 0 0 0 0 2 3 0]\n",
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_570 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_571 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_572 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_190 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 166ms/step - loss: 0.6893 - accuracy: 0.5086 - val_loss: 0.6738 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6689 - accuracy: 0.7500 - val_loss: 0.6542 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6489 - accuracy: 0.7500 - val_loss: 0.6406 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6363 - accuracy: 0.7500 - val_loss: 0.6310 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6267 - accuracy: 0.7500 - val_loss: 0.6229 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6187 - accuracy: 0.7500 - val_loss: 0.6159 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6117 - accuracy: 0.7500 - val_loss: 0.6097 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6055 - accuracy: 0.7500 - val_loss: 0.6041 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5999 - accuracy: 0.7500 - val_loss: 0.5990 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.5949 - accuracy: 0.7500 - val_loss: 0.5944 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5904 - accuracy: 0.7500 - val_loss: 0.5903 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5864 - accuracy: 0.7500 - val_loss: 0.5865 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5828 - accuracy: 0.7500 - val_loss: 0.5832 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5796 - accuracy: 0.7500 - val_loss: 0.5801 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5767 - accuracy: 0.7500 - val_loss: 0.5774 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5742 - accuracy: 0.7500 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5720 - accuracy: 0.7500 - val_loss: 0.5729 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5701 - accuracy: 0.7500 - val_loss: 0.5710 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5685 - accuracy: 0.7500 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5671 - accuracy: 0.7500 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 1 0 0 1 1 0 0 0 0 1 3 1 2 0 1 0 3 0 1 3 0 0 3 3]\n",
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_573 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_574 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_575 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_191 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.6948 - accuracy: 0.4138 - val_loss: 0.6916 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6914 - accuracy: 0.7500 - val_loss: 0.6903 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6899 - accuracy: 0.7500 - val_loss: 0.6887 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6884 - accuracy: 0.7500 - val_loss: 0.6875 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6873 - accuracy: 0.7500 - val_loss: 0.6865 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6862 - accuracy: 0.7500 - val_loss: 0.6854 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6852 - accuracy: 0.7500 - val_loss: 0.6845 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6842 - accuracy: 0.7500 - val_loss: 0.6835 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6833 - accuracy: 0.7500 - val_loss: 0.6826 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6824 - accuracy: 0.7500 - val_loss: 0.6817 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6815 - accuracy: 0.7500 - val_loss: 0.6808 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6805 - accuracy: 0.7500 - val_loss: 0.6798 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6795 - accuracy: 0.7500 - val_loss: 0.6786 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6784 - accuracy: 0.7500 - val_loss: 0.6776 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6773 - accuracy: 0.7500 - val_loss: 0.6765 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6762 - accuracy: 0.7500 - val_loss: 0.6755 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6753 - accuracy: 0.7500 - val_loss: 0.6746 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6742 - accuracy: 0.7500 - val_loss: 0.6734 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6732 - accuracy: 0.7500 - val_loss: 0.6724 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6721 - accuracy: 0.7500 - val_loss: 0.6714 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 1 1 3 3 3 1 3 2 2 3 0 0 3 0 3 3 1 0 0 0 0 0 0]\n",
      "Model: \"sequential_192\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_576 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_577 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_578 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_192 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 416ms/step - loss: 0.6934 - accuracy: 0.4914 - val_loss: 0.6883 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6863 - accuracy: 0.7500 - val_loss: 0.6812 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6794 - accuracy: 0.7500 - val_loss: 0.6760 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.6742 - accuracy: 0.7500 - val_loss: 0.6714 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6696 - accuracy: 0.7500 - val_loss: 0.6672 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6653 - accuracy: 0.7500 - val_loss: 0.6631 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6612 - accuracy: 0.7500 - val_loss: 0.6593 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6572 - accuracy: 0.7500 - val_loss: 0.6555 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6533 - accuracy: 0.7500 - val_loss: 0.6519 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6495 - accuracy: 0.7500 - val_loss: 0.6483 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6457 - accuracy: 0.7500 - val_loss: 0.6447 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6421 - accuracy: 0.7500 - val_loss: 0.6412 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.6385 - accuracy: 0.7500 - val_loss: 0.6378 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6350 - accuracy: 0.7500 - val_loss: 0.6345 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.6315 - accuracy: 0.7500 - val_loss: 0.6311 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6281 - accuracy: 0.7500 - val_loss: 0.6279 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6247 - accuracy: 0.7500 - val_loss: 0.6247 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6215 - accuracy: 0.7500 - val_loss: 0.6215 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6182 - accuracy: 0.7500 - val_loss: 0.6184 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6151 - accuracy: 0.7500 - val_loss: 0.6154 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 0 3 0 2 3 0 1 0 1 3 0 1 0 3 0 0 3 2 3 0 2 3 1 3]\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_579 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_580 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_581 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_193 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.6863 - accuracy: 0.6983 - val_loss: 0.6679 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6630 - accuracy: 0.7500 - val_loss: 0.6520 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6475 - accuracy: 0.7500 - val_loss: 0.6398 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6354 - accuracy: 0.7500 - val_loss: 0.6297 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6253 - accuracy: 0.7500 - val_loss: 0.6209 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6165 - accuracy: 0.7500 - val_loss: 0.6131 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6087 - accuracy: 0.7500 - val_loss: 0.6061 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6019 - accuracy: 0.7500 - val_loss: 0.5999 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5957 - accuracy: 0.7500 - val_loss: 0.5944 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5903 - accuracy: 0.7500 - val_loss: 0.5894 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5855 - accuracy: 0.7500 - val_loss: 0.5850 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5813 - accuracy: 0.7500 - val_loss: 0.5811 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5776 - accuracy: 0.7500 - val_loss: 0.5777 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5745 - accuracy: 0.7500 - val_loss: 0.5748 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5718 - accuracy: 0.7500 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5696 - accuracy: 0.7500 - val_loss: 0.5702 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5678 - accuracy: 0.7500 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5663 - accuracy: 0.7500 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5652 - accuracy: 0.7500 - val_loss: 0.5659 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5644 - accuracy: 0.7500 - val_loss: 0.5650 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 3 1 1 1 0 3 2 0 2 1 2 0 0 0 0 3 0 0 2 3 2 0 0]\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_582 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_583 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_584 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_194 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 179ms/step - loss: 0.6870 - accuracy: 0.7069 - val_loss: 0.6720 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6687 - accuracy: 0.7500 - val_loss: 0.6586 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6555 - accuracy: 0.7500 - val_loss: 0.6478 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6447 - accuracy: 0.7500 - val_loss: 0.6388 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6354 - accuracy: 0.7500 - val_loss: 0.6300 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6268 - accuracy: 0.7500 - val_loss: 0.6223 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6191 - accuracy: 0.7500 - val_loss: 0.6153 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6120 - accuracy: 0.7500 - val_loss: 0.6089 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6056 - accuracy: 0.7500 - val_loss: 0.6028 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5997 - accuracy: 0.7500 - val_loss: 0.5973 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5942 - accuracy: 0.7500 - val_loss: 0.5923 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5892 - accuracy: 0.7500 - val_loss: 0.5877 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5848 - accuracy: 0.7500 - val_loss: 0.5836 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5808 - accuracy: 0.7500 - val_loss: 0.5799 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.5773 - accuracy: 0.7500 - val_loss: 0.5767 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5743 - accuracy: 0.7500 - val_loss: 0.5739 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5717 - accuracy: 0.7500 - val_loss: 0.5715 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5695 - accuracy: 0.7500 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.5676 - accuracy: 0.7500 - val_loss: 0.5678 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5662 - accuracy: 0.7500 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 0 0 3 1 0 3 3 1 1 1 3 0 3 0 1 3 3 0 3 0 3 0 1 0]\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_585 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_586 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_587 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_195 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.6872 - accuracy: 0.6638 - val_loss: 0.6735 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6679 - accuracy: 0.7500 - val_loss: 0.6544 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6498 - accuracy: 0.7500 - val_loss: 0.6422 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6375 - accuracy: 0.7500 - val_loss: 0.6321 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6274 - accuracy: 0.7500 - val_loss: 0.6236 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6188 - accuracy: 0.7500 - val_loss: 0.6161 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6113 - accuracy: 0.7500 - val_loss: 0.6094 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6046 - accuracy: 0.7500 - val_loss: 0.6034 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5986 - accuracy: 0.7500 - val_loss: 0.5980 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5933 - accuracy: 0.7500 - val_loss: 0.5931 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5885 - accuracy: 0.7500 - val_loss: 0.5887 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5843 - accuracy: 0.7500 - val_loss: 0.5848 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5805 - accuracy: 0.7500 - val_loss: 0.5813 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5772 - accuracy: 0.7500 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5743 - accuracy: 0.7500 - val_loss: 0.5754 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5719 - accuracy: 0.7500 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5698 - accuracy: 0.7500 - val_loss: 0.5710 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5680 - accuracy: 0.7500 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5666 - accuracy: 0.7500 - val_loss: 0.5678 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5655 - accuracy: 0.7500 - val_loss: 0.5667 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 3 3 1 3 2 0 1 0 1 0 2 2 0 0 0 1 1 0 0 3 0 0 0]\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_588 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_589 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_590 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_196 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.6902 - accuracy: 0.5948 - val_loss: 0.6788 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6753 - accuracy: 0.7500 - val_loss: 0.6669 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6638 - accuracy: 0.7500 - val_loss: 0.6579 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6548 - accuracy: 0.7500 - val_loss: 0.6503 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6473 - accuracy: 0.7500 - val_loss: 0.6438 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6407 - accuracy: 0.7500 - val_loss: 0.6377 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6345 - accuracy: 0.7500 - val_loss: 0.6322 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6291 - accuracy: 0.7500 - val_loss: 0.6271 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6239 - accuracy: 0.7500 - val_loss: 0.6223 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6191 - accuracy: 0.7500 - val_loss: 0.6177 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6144 - accuracy: 0.7500 - val_loss: 0.6134 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6101 - accuracy: 0.7500 - val_loss: 0.6093 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6060 - accuracy: 0.7500 - val_loss: 0.6054 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6022 - accuracy: 0.7500 - val_loss: 0.6018 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.5985 - accuracy: 0.7500 - val_loss: 0.5983 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5951 - accuracy: 0.7500 - val_loss: 0.5950 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5918 - accuracy: 0.7500 - val_loss: 0.5920 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5888 - accuracy: 0.7500 - val_loss: 0.5891 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5860 - accuracy: 0.7500 - val_loss: 0.5864 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5833 - accuracy: 0.7500 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 0 0 1 3 1 3 1 3 1 3 0 3 2 3 3 3 2 0 0 0 0 0 0]\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_591 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_592 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_593 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_197 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 212ms/step - loss: 0.6782 - accuracy: 0.7500 - val_loss: 0.6574 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6508 - accuracy: 0.7500 - val_loss: 0.6359 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6303 - accuracy: 0.7500 - val_loss: 0.6212 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6161 - accuracy: 0.7500 - val_loss: 0.6098 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6050 - accuracy: 0.7500 - val_loss: 0.6006 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5962 - accuracy: 0.7500 - val_loss: 0.5931 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5889 - accuracy: 0.7500 - val_loss: 0.5868 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5829 - accuracy: 0.7500 - val_loss: 0.5816 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5781 - accuracy: 0.7500 - val_loss: 0.5773 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5742 - accuracy: 0.7500 - val_loss: 0.5738 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5710 - accuracy: 0.7500 - val_loss: 0.5710 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5686 - accuracy: 0.7500 - val_loss: 0.5688 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5667 - accuracy: 0.7500 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5653 - accuracy: 0.7500 - val_loss: 0.5658 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5644 - accuracy: 0.7500 - val_loss: 0.5648 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5637 - accuracy: 0.7500 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5632 - accuracy: 0.7500 - val_loss: 0.5637 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 3 0 3 0 1 0 3 0 3 3 0 3 0 0 3 3 0 0 3 1 0 3 3 0]\n",
      "[]\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_594 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_595 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_596 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_198 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 105ms/step - loss: 0.6916 - accuracy: 0.5227 - val_loss: 0.6813 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6796 - accuracy: 0.7500 - val_loss: 0.6731 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6715 - accuracy: 0.7500 - val_loss: 0.6659 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6642 - accuracy: 0.7500 - val_loss: 0.6591 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6573 - accuracy: 0.7500 - val_loss: 0.6525 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6506 - accuracy: 0.7500 - val_loss: 0.6461 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6440 - accuracy: 0.7500 - val_loss: 0.6397 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6375 - accuracy: 0.7500 - val_loss: 0.6335 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6312 - accuracy: 0.7500 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6250 - accuracy: 0.7500 - val_loss: 0.6216 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6191 - accuracy: 0.7500 - val_loss: 0.6159 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6133 - accuracy: 0.7500 - val_loss: 0.6104 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6078 - accuracy: 0.7500 - val_loss: 0.6052 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6025 - accuracy: 0.7500 - val_loss: 0.6002 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5975 - accuracy: 0.7500 - val_loss: 0.5955 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5929 - accuracy: 0.7500 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5885 - accuracy: 0.7500 - val_loss: 0.5870 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5845 - accuracy: 0.7500 - val_loss: 0.5832 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5808 - accuracy: 0.7500 - val_loss: 0.5798 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5775 - accuracy: 0.7500 - val_loss: 0.5767 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 0 0 1 0 3 3 3 0 3 3 3 2 3 0 1]\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_597 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_598 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_599 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_199 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 87ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6882 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6874 - accuracy: 0.7500 - val_loss: 0.6848 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6842 - accuracy: 0.7500 - val_loss: 0.6819 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6813 - accuracy: 0.7500 - val_loss: 0.6792 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6786 - accuracy: 0.7500 - val_loss: 0.6766 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6760 - accuracy: 0.7500 - val_loss: 0.6738 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6728 - accuracy: 0.7500 - val_loss: 0.6698 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6689 - accuracy: 0.7500 - val_loss: 0.6663 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6653 - accuracy: 0.7500 - val_loss: 0.6627 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6617 - accuracy: 0.7500 - val_loss: 0.6591 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6582 - accuracy: 0.7500 - val_loss: 0.6557 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6546 - accuracy: 0.7500 - val_loss: 0.6522 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6511 - accuracy: 0.7500 - val_loss: 0.6487 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6476 - accuracy: 0.7500 - val_loss: 0.6453 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6443 - accuracy: 0.7500 - val_loss: 0.6418 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6407 - accuracy: 0.7500 - val_loss: 0.6384 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6373 - accuracy: 0.7500 - val_loss: 0.6350 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6338 - accuracy: 0.7500 - val_loss: 0.6316 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6304 - accuracy: 0.7500 - val_loss: 0.6282 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6270 - accuracy: 0.7500 - val_loss: 0.6248 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 3 0 1 0 2 3 3 3 0 0 3 0 3 3 2]\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_600 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_601 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_602 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_200 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 141ms/step - loss: 0.6970 - accuracy: 0.5227 - val_loss: 0.6892 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6886 - accuracy: 0.7500 - val_loss: 0.6866 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6859 - accuracy: 0.7500 - val_loss: 0.6842 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6835 - accuracy: 0.7500 - val_loss: 0.6818 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6811 - accuracy: 0.7500 - val_loss: 0.6795 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6788 - accuracy: 0.7500 - val_loss: 0.6771 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6764 - accuracy: 0.7500 - val_loss: 0.6747 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6739 - accuracy: 0.7500 - val_loss: 0.6723 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6714 - accuracy: 0.7500 - val_loss: 0.6697 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6688 - accuracy: 0.7500 - val_loss: 0.6671 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6661 - accuracy: 0.7500 - val_loss: 0.6644 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6633 - accuracy: 0.7500 - val_loss: 0.6615 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6604 - accuracy: 0.7500 - val_loss: 0.6585 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6573 - accuracy: 0.7500 - val_loss: 0.6553 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6540 - accuracy: 0.7500 - val_loss: 0.6521 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6507 - accuracy: 0.7500 - val_loss: 0.6487 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6472 - accuracy: 0.7500 - val_loss: 0.6453 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6437 - accuracy: 0.7500 - val_loss: 0.6418 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6402 - accuracy: 0.7500 - val_loss: 0.6383 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6366 - accuracy: 0.7500 - val_loss: 0.6347 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 2 3 0 0 3 1 2 3 2 3 0 2 0 0 0]\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_603 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_604 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_605 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_201 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 2s 191ms/step - loss: 0.6820 - accuracy: 0.7424 - val_loss: 0.6552 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.6497 - accuracy: 0.7500 - val_loss: 0.6353 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.6308 - accuracy: 0.7500 - val_loss: 0.6207 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6167 - accuracy: 0.7500 - val_loss: 0.6090 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6053 - accuracy: 0.7500 - val_loss: 0.5992 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5958 - accuracy: 0.7500 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.5880 - accuracy: 0.7500 - val_loss: 0.5843 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5816 - accuracy: 0.7500 - val_loss: 0.5787 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5763 - accuracy: 0.7500 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.5722 - accuracy: 0.7500 - val_loss: 0.5707 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5690 - accuracy: 0.7500 - val_loss: 0.5680 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.5666 - accuracy: 0.7500 - val_loss: 0.5660 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5649 - accuracy: 0.7500 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5639 - accuracy: 0.7500 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5632 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 0 0 3 3 3 2 0 1 3 0 0 2 0 0 1]\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_606 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_607 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_608 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_202 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 141ms/step - loss: 0.6826 - accuracy: 0.7273 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6554 - accuracy: 0.7500 - val_loss: 0.6427 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6390 - accuracy: 0.7500 - val_loss: 0.6298 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6264 - accuracy: 0.7500 - val_loss: 0.6190 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6160 - accuracy: 0.7500 - val_loss: 0.6099 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6070 - accuracy: 0.7500 - val_loss: 0.6019 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5993 - accuracy: 0.7500 - val_loss: 0.5949 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5925 - accuracy: 0.7500 - val_loss: 0.5888 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5866 - accuracy: 0.7500 - val_loss: 0.5836 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5816 - accuracy: 0.7500 - val_loss: 0.5790 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5772 - accuracy: 0.7500 - val_loss: 0.5752 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5736 - accuracy: 0.7500 - val_loss: 0.5720 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5707 - accuracy: 0.7500 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5683 - accuracy: 0.7500 - val_loss: 0.5673 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5665 - accuracy: 0.7500 - val_loss: 0.5657 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5650 - accuracy: 0.7500 - val_loss: 0.5646 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5641 - accuracy: 0.7500 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5634 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 3 1 1 3 1 1 3 0 3 0 3 1 0 0 3]\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_609 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_610 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_611 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_203 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 82ms/step - loss: 0.6889 - accuracy: 0.5227 - val_loss: 0.6655 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6610 - accuracy: 0.7500 - val_loss: 0.6482 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6442 - accuracy: 0.7500 - val_loss: 0.6341 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6303 - accuracy: 0.7500 - val_loss: 0.6220 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6183 - accuracy: 0.7500 - val_loss: 0.6114 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6079 - accuracy: 0.7500 - val_loss: 0.6021 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5988 - accuracy: 0.7500 - val_loss: 0.5940 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5909 - accuracy: 0.7500 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5843 - accuracy: 0.7500 - val_loss: 0.5812 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5787 - accuracy: 0.7500 - val_loss: 0.5764 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5741 - accuracy: 0.7500 - val_loss: 0.5725 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5705 - accuracy: 0.7500 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5677 - accuracy: 0.7500 - val_loss: 0.5671 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5657 - accuracy: 0.7500 - val_loss: 0.5654 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5644 - accuracy: 0.7500 - val_loss: 0.5643 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 2 3 3 3 0 0 1 3 0 0 0 0 3 3 3 3]\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_612 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_613 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_614 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_204 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 88ms/step - loss: 0.6771 - accuracy: 0.7500 - val_loss: 0.6457 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6388 - accuracy: 0.7500 - val_loss: 0.6226 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6167 - accuracy: 0.7500 - val_loss: 0.6064 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6011 - accuracy: 0.7500 - val_loss: 0.5941 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5894 - accuracy: 0.7500 - val_loss: 0.5848 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5807 - accuracy: 0.7500 - val_loss: 0.5777 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5742 - accuracy: 0.7500 - val_loss: 0.5726 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5697 - accuracy: 0.7500 - val_loss: 0.5688 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5666 - accuracy: 0.7500 - val_loss: 0.5662 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5646 - accuracy: 0.7500 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 2 3 3 0 1 0 0 3 3 3 0 1 3 0 3]\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_615 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_616 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_617 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_205 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 113ms/step - loss: 0.6921 - accuracy: 0.5682 - val_loss: 0.6882 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6874 - accuracy: 0.7500 - val_loss: 0.6842 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6839 - accuracy: 0.7500 - val_loss: 0.6810 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6802 - accuracy: 0.7500 - val_loss: 0.6761 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.6750 - accuracy: 0.7500 - val_loss: 0.6704 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6692 - accuracy: 0.7500 - val_loss: 0.6653 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6640 - accuracy: 0.7500 - val_loss: 0.6596 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6583 - accuracy: 0.7500 - val_loss: 0.6545 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6531 - accuracy: 0.7500 - val_loss: 0.6492 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6476 - accuracy: 0.7500 - val_loss: 0.6438 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6420 - accuracy: 0.7500 - val_loss: 0.6383 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6364 - accuracy: 0.7500 - val_loss: 0.6329 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6310 - accuracy: 0.7500 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6254 - accuracy: 0.7500 - val_loss: 0.6212 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6188 - accuracy: 0.7500 - val_loss: 0.6142 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6118 - accuracy: 0.7500 - val_loss: 0.6076 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6051 - accuracy: 0.7500 - val_loss: 0.6013 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5988 - accuracy: 0.7500 - val_loss: 0.5954 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5929 - accuracy: 0.7500 - val_loss: 0.5899 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5875 - accuracy: 0.7500 - val_loss: 0.5849 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 3 3 1 0 1 3 3 0 3 3 0 3 3 0 3 3]\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_618 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_619 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_620 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_206 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 98ms/step - loss: 0.6919 - accuracy: 0.5379 - val_loss: 0.6844 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6831 - accuracy: 0.7500 - val_loss: 0.6786 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6776 - accuracy: 0.7500 - val_loss: 0.6738 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6728 - accuracy: 0.7500 - val_loss: 0.6693 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6684 - accuracy: 0.7500 - val_loss: 0.6650 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6641 - accuracy: 0.7500 - val_loss: 0.6608 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6600 - accuracy: 0.7500 - val_loss: 0.6568 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6560 - accuracy: 0.7500 - val_loss: 0.6528 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6520 - accuracy: 0.7500 - val_loss: 0.6489 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6481 - accuracy: 0.7500 - val_loss: 0.6451 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6443 - accuracy: 0.7500 - val_loss: 0.6413 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6405 - accuracy: 0.7500 - val_loss: 0.6375 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6367 - accuracy: 0.7500 - val_loss: 0.6338 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6330 - accuracy: 0.7500 - val_loss: 0.6301 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6293 - accuracy: 0.7500 - val_loss: 0.6264 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6257 - accuracy: 0.7500 - val_loss: 0.6229 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6221 - accuracy: 0.7500 - val_loss: 0.6193 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6186 - accuracy: 0.7500 - val_loss: 0.6159 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6151 - accuracy: 0.7500 - val_loss: 0.6125 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6118 - accuracy: 0.7500 - val_loss: 0.6092 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 0 2 3 1 0 0 3 0 0 0 2 3 0 3 3]\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_621 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_622 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_623 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_207 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 118ms/step - loss: 0.6826 - accuracy: 0.7500 - val_loss: 0.6590 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6537 - accuracy: 0.7500 - val_loss: 0.6396 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6350 - accuracy: 0.7500 - val_loss: 0.6246 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6204 - accuracy: 0.7500 - val_loss: 0.6123 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6084 - accuracy: 0.7500 - val_loss: 0.6020 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5984 - accuracy: 0.7500 - val_loss: 0.5932 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5900 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5830 - accuracy: 0.7500 - val_loss: 0.5800 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5773 - accuracy: 0.7500 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5728 - accuracy: 0.7500 - val_loss: 0.5713 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5693 - accuracy: 0.7500 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5668 - accuracy: 0.7500 - val_loss: 0.5663 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5650 - accuracy: 0.7500 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5638 - accuracy: 0.7500 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5632 - accuracy: 0.7500 - val_loss: 0.5634 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 2 3 3 0 0 3 0 3 1 3 3 0 3 1 0 2]\n",
      "[]\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_624 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_625 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_626 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_208 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 2s 219ms/step - loss: 0.6927 - accuracy: 0.5473 - val_loss: 0.6866 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6851 - accuracy: 0.7500 - val_loss: 0.6812 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6798 - accuracy: 0.7500 - val_loss: 0.6761 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6747 - accuracy: 0.7500 - val_loss: 0.6711 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6693 - accuracy: 0.7500 - val_loss: 0.6652 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6633 - accuracy: 0.7500 - val_loss: 0.6593 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6574 - accuracy: 0.7500 - val_loss: 0.6536 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6516 - accuracy: 0.7500 - val_loss: 0.6480 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6461 - accuracy: 0.7500 - val_loss: 0.6427 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6408 - accuracy: 0.7500 - val_loss: 0.6376 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6356 - accuracy: 0.7500 - val_loss: 0.6326 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6306 - accuracy: 0.7500 - val_loss: 0.6276 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6256 - accuracy: 0.7500 - val_loss: 0.6228 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.6208 - accuracy: 0.7500 - val_loss: 0.6180 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6161 - accuracy: 0.7500 - val_loss: 0.6136 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6115 - accuracy: 0.7500 - val_loss: 0.6090 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.6070 - accuracy: 0.7500 - val_loss: 0.6047 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6028 - accuracy: 0.7500 - val_loss: 0.6005 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5986 - accuracy: 0.7500 - val_loss: 0.5966 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5947 - accuracy: 0.7500 - val_loss: 0.5928 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 3 0 2 1 3 0 0]\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_627 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_628 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_629 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_209 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 86ms/step - loss: 0.6794 - accuracy: 0.7500 - val_loss: 0.6586 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6524 - accuracy: 0.7500 - val_loss: 0.6385 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6333 - accuracy: 0.7500 - val_loss: 0.6234 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6185 - accuracy: 0.7500 - val_loss: 0.6109 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6063 - accuracy: 0.7500 - val_loss: 0.6004 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5961 - accuracy: 0.7500 - val_loss: 0.5917 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5877 - accuracy: 0.7500 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5808 - accuracy: 0.7500 - val_loss: 0.5784 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5753 - accuracy: 0.7500 - val_loss: 0.5737 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5711 - accuracy: 0.7500 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5679 - accuracy: 0.7500 - val_loss: 0.5674 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5657 - accuracy: 0.7500 - val_loss: 0.5655 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5643 - accuracy: 0.7500 - val_loss: 0.5642 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5634 - accuracy: 0.7500 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 3 2 0 0 3 3 3]\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_630 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_631 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_632 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_210 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 98ms/step - loss: 0.6936 - accuracy: 0.5473 - val_loss: 0.6906 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6901 - accuracy: 0.7500 - val_loss: 0.6889 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6886 - accuracy: 0.7500 - val_loss: 0.6876 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6872 - accuracy: 0.7500 - val_loss: 0.6863 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6860 - accuracy: 0.7500 - val_loss: 0.6848 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6844 - accuracy: 0.7500 - val_loss: 0.6832 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6826 - accuracy: 0.7500 - val_loss: 0.6814 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6810 - accuracy: 0.7500 - val_loss: 0.6799 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6795 - accuracy: 0.7500 - val_loss: 0.6783 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6779 - accuracy: 0.7500 - val_loss: 0.6768 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6763 - accuracy: 0.7500 - val_loss: 0.6753 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6749 - accuracy: 0.7500 - val_loss: 0.6737 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6733 - accuracy: 0.7500 - val_loss: 0.6722 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6718 - accuracy: 0.7500 - val_loss: 0.6707 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6703 - accuracy: 0.7500 - val_loss: 0.6691 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6687 - accuracy: 0.7500 - val_loss: 0.6675 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6670 - accuracy: 0.7500 - val_loss: 0.6660 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6655 - accuracy: 0.7500 - val_loss: 0.6642 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6638 - accuracy: 0.7500 - val_loss: 0.6625 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6621 - accuracy: 0.7500 - val_loss: 0.6608 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 2 1 0 3 1 0 0]\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_633 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_634 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_635 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_211 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 0.6911 - accuracy: 0.6486 - val_loss: 0.6841 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6826 - accuracy: 0.7500 - val_loss: 0.6776 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6764 - accuracy: 0.7500 - val_loss: 0.6721 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6709 - accuracy: 0.7500 - val_loss: 0.6669 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6657 - accuracy: 0.7500 - val_loss: 0.6619 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6607 - accuracy: 0.7500 - val_loss: 0.6570 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6557 - accuracy: 0.7500 - val_loss: 0.6521 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6509 - accuracy: 0.7500 - val_loss: 0.6473 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6460 - accuracy: 0.7500 - val_loss: 0.6425 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6412 - accuracy: 0.7500 - val_loss: 0.6377 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.6364 - accuracy: 0.7500 - val_loss: 0.6330 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6316 - accuracy: 0.7500 - val_loss: 0.6283 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6270 - accuracy: 0.7500 - val_loss: 0.6237 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.6223 - accuracy: 0.7500 - val_loss: 0.6192 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.6178 - accuracy: 0.7500 - val_loss: 0.6147 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6134 - accuracy: 0.7500 - val_loss: 0.6104 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6090 - accuracy: 0.7500 - val_loss: 0.6062 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6048 - accuracy: 0.7500 - val_loss: 0.6021 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6007 - accuracy: 0.7500 - val_loss: 0.5981 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5968 - accuracy: 0.7500 - val_loss: 0.5943 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 1 0 0 3 3 3 0 3]\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_636 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_637 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_638 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_212 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 101ms/step - loss: 0.6857 - accuracy: 0.7230 - val_loss: 0.6704 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6662 - accuracy: 0.7500 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6529 - accuracy: 0.7500 - val_loss: 0.6451 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6414 - accuracy: 0.7500 - val_loss: 0.6347 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6310 - accuracy: 0.7500 - val_loss: 0.6251 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6215 - accuracy: 0.7500 - val_loss: 0.6163 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6127 - accuracy: 0.7500 - val_loss: 0.6081 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6047 - accuracy: 0.7500 - val_loss: 0.6007 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5974 - accuracy: 0.7500 - val_loss: 0.5939 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5908 - accuracy: 0.7500 - val_loss: 0.5879 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5850 - accuracy: 0.7500 - val_loss: 0.5827 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5800 - accuracy: 0.7500 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5757 - accuracy: 0.7500 - val_loss: 0.5742 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5721 - accuracy: 0.7500 - val_loss: 0.5709 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5691 - accuracy: 0.7500 - val_loss: 0.5683 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5669 - accuracy: 0.7500 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5652 - accuracy: 0.7500 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5641 - accuracy: 0.7500 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5634 - accuracy: 0.7500 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 1 3 0 1 3 0 0 0]\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_639 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_640 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_641 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_213 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 136ms/step - loss: 0.6850 - accuracy: 0.7500 - val_loss: 0.6684 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6627 - accuracy: 0.7500 - val_loss: 0.6479 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6427 - accuracy: 0.7500 - val_loss: 0.6338 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6293 - accuracy: 0.7500 - val_loss: 0.6228 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6185 - accuracy: 0.7500 - val_loss: 0.6134 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6092 - accuracy: 0.7500 - val_loss: 0.6052 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6011 - accuracy: 0.7500 - val_loss: 0.5980 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5940 - accuracy: 0.7500 - val_loss: 0.5916 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5878 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5824 - accuracy: 0.7500 - val_loss: 0.5812 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5779 - accuracy: 0.7500 - val_loss: 0.5770 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5740 - accuracy: 0.7500 - val_loss: 0.5735 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5709 - accuracy: 0.7500 - val_loss: 0.5707 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5683 - accuracy: 0.7500 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5664 - accuracy: 0.7500 - val_loss: 0.5666 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5650 - accuracy: 0.7500 - val_loss: 0.5653 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.5640 - accuracy: 0.7500 - val_loss: 0.5643 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.5633 - accuracy: 0.7500 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 1 3 0 0 0 0 3 3]\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_642 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_643 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_644 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_214 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 125ms/step - loss: 0.6897 - accuracy: 0.5473 - val_loss: 0.6741 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6705 - accuracy: 0.7500 - val_loss: 0.6623 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6587 - accuracy: 0.7500 - val_loss: 0.6522 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6488 - accuracy: 0.7500 - val_loss: 0.6426 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6394 - accuracy: 0.7500 - val_loss: 0.6337 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6305 - accuracy: 0.7500 - val_loss: 0.6260 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6227 - accuracy: 0.7500 - val_loss: 0.6184 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6153 - accuracy: 0.7500 - val_loss: 0.6116 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6084 - accuracy: 0.7500 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6020 - accuracy: 0.7500 - val_loss: 0.5990 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5962 - accuracy: 0.7500 - val_loss: 0.5935 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5908 - accuracy: 0.7500 - val_loss: 0.5885 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5859 - accuracy: 0.7500 - val_loss: 0.5841 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5816 - accuracy: 0.7500 - val_loss: 0.5803 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5779 - accuracy: 0.7500 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5747 - accuracy: 0.7500 - val_loss: 0.5738 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5719 - accuracy: 0.7500 - val_loss: 0.5712 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.5695 - accuracy: 0.7500 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5676 - accuracy: 0.7500 - val_loss: 0.5674 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5661 - accuracy: 0.7500 - val_loss: 0.5660 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 3 3 2 2 0 0 0]\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_645 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_646 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_647 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_215 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 91ms/step - loss: 0.6878 - accuracy: 0.7230 - val_loss: 0.6758 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6715 - accuracy: 0.7500 - val_loss: 0.6630 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6588 - accuracy: 0.7500 - val_loss: 0.6526 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6482 - accuracy: 0.7500 - val_loss: 0.6432 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6387 - accuracy: 0.7500 - val_loss: 0.6346 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6299 - accuracy: 0.7500 - val_loss: 0.6265 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6217 - accuracy: 0.7500 - val_loss: 0.6190 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6141 - accuracy: 0.7500 - val_loss: 0.6120 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6070 - accuracy: 0.7500 - val_loss: 0.6054 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6004 - accuracy: 0.7500 - val_loss: 0.5993 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5944 - accuracy: 0.7500 - val_loss: 0.5937 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5890 - accuracy: 0.7500 - val_loss: 0.5885 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5840 - accuracy: 0.7500 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5797 - accuracy: 0.7500 - val_loss: 0.5798 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5759 - accuracy: 0.7500 - val_loss: 0.5763 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5727 - accuracy: 0.7500 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.5700 - accuracy: 0.7500 - val_loss: 0.5706 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.5678 - accuracy: 0.7500 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5661 - accuracy: 0.7500 - val_loss: 0.5669 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5649 - accuracy: 0.7500 - val_loss: 0.5656 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 3 0 1 3 0 3 3]\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_648 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_649 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_650 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_216 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 2s 159ms/step - loss: 0.6869 - accuracy: 0.7162 - val_loss: 0.6687 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6626 - accuracy: 0.7500 - val_loss: 0.6498 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6453 - accuracy: 0.7500 - val_loss: 0.6359 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6317 - accuracy: 0.7500 - val_loss: 0.6240 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6199 - accuracy: 0.7500 - val_loss: 0.6135 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6097 - accuracy: 0.7500 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6007 - accuracy: 0.7500 - val_loss: 0.5962 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5928 - accuracy: 0.7500 - val_loss: 0.5891 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5861 - accuracy: 0.7500 - val_loss: 0.5831 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5804 - accuracy: 0.7500 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5756 - accuracy: 0.7500 - val_loss: 0.5739 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5718 - accuracy: 0.7500 - val_loss: 0.5705 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5688 - accuracy: 0.7500 - val_loss: 0.5680 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5665 - accuracy: 0.7500 - val_loss: 0.5661 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5649 - accuracy: 0.7500 - val_loss: 0.5648 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5639 - accuracy: 0.7500 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5632 - accuracy: 0.7500 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 3 1 3 0 1 2 0]\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_651 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_652 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_653 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_217 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 2s 145ms/step - loss: 0.6838 - accuracy: 0.7500 - val_loss: 0.6600 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6562 - accuracy: 0.7500 - val_loss: 0.6419 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6396 - accuracy: 0.7500 - val_loss: 0.6284 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6268 - accuracy: 0.7500 - val_loss: 0.6172 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.6160 - accuracy: 0.7500 - val_loss: 0.6077 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6067 - accuracy: 0.7500 - val_loss: 0.5992 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5986 - accuracy: 0.7500 - val_loss: 0.5919 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5914 - accuracy: 0.7500 - val_loss: 0.5855 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5852 - accuracy: 0.7500 - val_loss: 0.5801 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5799 - accuracy: 0.7500 - val_loss: 0.5755 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5755 - accuracy: 0.7500 - val_loss: 0.5718 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5719 - accuracy: 0.7500 - val_loss: 0.5688 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.5690 - accuracy: 0.7500 - val_loss: 0.5666 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.5667 - accuracy: 0.7500 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5651 - accuracy: 0.7500 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.5640 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.5633 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5625 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5625 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5625 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 0 0 0 1 2 0 0]\n",
      "[]\n",
      "seconds value in hours: 0.0\n",
      "seconds value in minutes: 0.0\n",
      "tfidf\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_654 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_655 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_656 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_218 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 348ms/step - loss: 0.6949 - accuracy: 0.3110 - val_loss: 0.6889 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6879 - accuracy: 0.7500 - val_loss: 0.6844 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6836 - accuracy: 0.7500 - val_loss: 0.6813 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6804 - accuracy: 0.7500 - val_loss: 0.6784 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6775 - accuracy: 0.7500 - val_loss: 0.6758 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6748 - accuracy: 0.7500 - val_loss: 0.6732 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6721 - accuracy: 0.7500 - val_loss: 0.6708 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6696 - accuracy: 0.7500 - val_loss: 0.6683 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6670 - accuracy: 0.7500 - val_loss: 0.6659 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6646 - accuracy: 0.7500 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6621 - accuracy: 0.7500 - val_loss: 0.6612 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6597 - accuracy: 0.7500 - val_loss: 0.6588 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6572 - accuracy: 0.7500 - val_loss: 0.6565 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6548 - accuracy: 0.7500 - val_loss: 0.6541 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6524 - accuracy: 0.7500 - val_loss: 0.6518 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6500 - accuracy: 0.7500 - val_loss: 0.6495 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6476 - accuracy: 0.7500 - val_loss: 0.6472 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6452 - accuracy: 0.7500 - val_loss: 0.6449 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6428 - accuracy: 0.7500 - val_loss: 0.6426 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6404 - accuracy: 0.7500 - val_loss: 0.6403 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [0 0 2 3 1 2 1 0 0 0 1 1 3 2 1 3 3 2 0 3 3 3 1 0 1 3 2 0 1 2 3 3 0 3 0 0 1\n",
      " 2 3 2 1 0]\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_657 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_658 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_659 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_219 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.6904 - accuracy: 0.5671 - val_loss: 0.6764 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6741 - accuracy: 0.7500 - val_loss: 0.6651 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6624 - accuracy: 0.7500 - val_loss: 0.6553 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6524 - accuracy: 0.7500 - val_loss: 0.6469 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6438 - accuracy: 0.7500 - val_loss: 0.6394 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6361 - accuracy: 0.7500 - val_loss: 0.6325 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6290 - accuracy: 0.7500 - val_loss: 0.6261 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6225 - accuracy: 0.7500 - val_loss: 0.6201 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6164 - accuracy: 0.7500 - val_loss: 0.6144 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6106 - accuracy: 0.7500 - val_loss: 0.6091 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6053 - accuracy: 0.7500 - val_loss: 0.6041 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6002 - accuracy: 0.7500 - val_loss: 0.5994 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5956 - accuracy: 0.7500 - val_loss: 0.5951 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5913 - accuracy: 0.7500 - val_loss: 0.5910 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5873 - accuracy: 0.7500 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5837 - accuracy: 0.7500 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5804 - accuracy: 0.7500 - val_loss: 0.5808 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5774 - accuracy: 0.7500 - val_loss: 0.5779 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5748 - accuracy: 0.7500 - val_loss: 0.5754 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5725 - accuracy: 0.7500 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 0 1 3 3 3 3 0 3 0 3 2 0 1 0 3 0 2 0 0 0 1 1 1 0 0 2 2 3 0 2 1 0 3 3 0 3\n",
      " 1 0 3 0 3]\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_660 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_661 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_662 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_220 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.6955 - accuracy: 0.3598 - val_loss: 0.6889 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6885 - accuracy: 0.7500 - val_loss: 0.6859 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6855 - accuracy: 0.7500 - val_loss: 0.6834 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6829 - accuracy: 0.7500 - val_loss: 0.6810 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6805 - accuracy: 0.7500 - val_loss: 0.6787 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6782 - accuracy: 0.7500 - val_loss: 0.6764 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6759 - accuracy: 0.7500 - val_loss: 0.6741 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6735 - accuracy: 0.7500 - val_loss: 0.6719 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6712 - accuracy: 0.7500 - val_loss: 0.6696 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.6689 - accuracy: 0.7500 - val_loss: 0.6673 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6665 - accuracy: 0.7500 - val_loss: 0.6650 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6642 - accuracy: 0.7500 - val_loss: 0.6627 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6618 - accuracy: 0.7500 - val_loss: 0.6603 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6594 - accuracy: 0.7500 - val_loss: 0.6580 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6570 - accuracy: 0.7500 - val_loss: 0.6557 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6546 - accuracy: 0.7500 - val_loss: 0.6534 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6522 - accuracy: 0.7500 - val_loss: 0.6511 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6499 - accuracy: 0.7500 - val_loss: 0.6487 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6474 - accuracy: 0.7500 - val_loss: 0.6465 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6451 - accuracy: 0.7500 - val_loss: 0.6441 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 3 2 1 3 1 0 0 2 3 3 0 3 0 3 0 3 1 0 0 2 0 3 1 2 0 1 3 0 3 3 3 0 3 2 0 2\n",
      " 0 3 1 0 0]\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_663 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_664 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_665 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_221 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.6932 - accuracy: 0.5915 - val_loss: 0.6918 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6917 - accuracy: 0.7500 - val_loss: 0.6909 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6908 - accuracy: 0.7500 - val_loss: 0.6901 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6900 - accuracy: 0.7500 - val_loss: 0.6893 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6893 - accuracy: 0.7500 - val_loss: 0.6887 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6886 - accuracy: 0.7500 - val_loss: 0.6880 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6879 - accuracy: 0.7500 - val_loss: 0.6874 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6873 - accuracy: 0.7500 - val_loss: 0.6867 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6866 - accuracy: 0.7500 - val_loss: 0.6861 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6860 - accuracy: 0.7500 - val_loss: 0.6855 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6854 - accuracy: 0.7500 - val_loss: 0.6848 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6848 - accuracy: 0.7500 - val_loss: 0.6843 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6842 - accuracy: 0.7500 - val_loss: 0.6836 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6835 - accuracy: 0.7500 - val_loss: 0.6829 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6829 - accuracy: 0.7500 - val_loss: 0.6823 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6822 - accuracy: 0.7500 - val_loss: 0.6799 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6791 - accuracy: 0.7500 - val_loss: 0.6752 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6744 - accuracy: 0.7500 - val_loss: 0.6710 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6704 - accuracy: 0.7500 - val_loss: 0.6682 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6676 - accuracy: 0.7500 - val_loss: 0.6658 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 0 3 2 0 0 3 3 3 1 2 1 0 0 1 2 3 0 3 1 3 3 1 1 2 1 3 0 0 0 3 3 1 2 0 0 0\n",
      " 3 0 0 3 2]\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_666 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_667 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_668 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_222 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 167ms/step - loss: 0.6897 - accuracy: 0.7256 - val_loss: 0.6733 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6712 - accuracy: 0.7500 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6587 - accuracy: 0.7500 - val_loss: 0.6514 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6488 - accuracy: 0.7500 - val_loss: 0.6431 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6402 - accuracy: 0.7500 - val_loss: 0.6359 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6327 - accuracy: 0.7500 - val_loss: 0.6291 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6258 - accuracy: 0.7500 - val_loss: 0.6231 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6196 - accuracy: 0.7500 - val_loss: 0.6172 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6136 - accuracy: 0.7500 - val_loss: 0.6119 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6083 - accuracy: 0.7500 - val_loss: 0.6069 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6032 - accuracy: 0.7500 - val_loss: 0.6022 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5985 - accuracy: 0.7500 - val_loss: 0.5979 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5942 - accuracy: 0.7500 - val_loss: 0.5938 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5901 - accuracy: 0.7500 - val_loss: 0.5902 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5865 - accuracy: 0.7500 - val_loss: 0.5867 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5832 - accuracy: 0.7500 - val_loss: 0.5834 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5800 - accuracy: 0.7500 - val_loss: 0.5806 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5772 - accuracy: 0.7500 - val_loss: 0.5779 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5748 - accuracy: 0.7500 - val_loss: 0.5756 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5726 - accuracy: 0.7500 - val_loss: 0.5734 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [3 3 1 3 1 3 3 0 0 3 0 3 0 2 3 2 1 2 1 3 3 0 0 0 0 3 1 1 1 0 0 3 3 0 3 3 3\n",
      " 3 3 0 1 0]\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_669 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_670 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_671 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_223 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 186ms/step - loss: 0.6921 - accuracy: 0.3841 - val_loss: 0.6807 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6791 - accuracy: 0.7500 - val_loss: 0.6737 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6720 - accuracy: 0.7500 - val_loss: 0.6681 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6661 - accuracy: 0.7500 - val_loss: 0.6631 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6609 - accuracy: 0.7500 - val_loss: 0.6584 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6561 - accuracy: 0.7500 - val_loss: 0.6540 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6515 - accuracy: 0.7500 - val_loss: 0.6498 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6472 - accuracy: 0.7500 - val_loss: 0.6458 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6429 - accuracy: 0.7500 - val_loss: 0.6419 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6389 - accuracy: 0.7500 - val_loss: 0.6381 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6349 - accuracy: 0.7500 - val_loss: 0.6344 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6311 - accuracy: 0.7500 - val_loss: 0.6307 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6274 - accuracy: 0.7500 - val_loss: 0.6272 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6237 - accuracy: 0.7500 - val_loss: 0.6238 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6202 - accuracy: 0.7500 - val_loss: 0.6204 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6167 - accuracy: 0.7500 - val_loss: 0.6171 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6133 - accuracy: 0.7500 - val_loss: 0.6139 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6101 - accuracy: 0.7500 - val_loss: 0.6108 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6069 - accuracy: 0.7500 - val_loss: 0.6077 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6038 - accuracy: 0.7500 - val_loss: 0.6048 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [2 3 0 3 3 3 0 0 0 3 3 3 0 1 0 0 0 3 3 3 3 0 3 3 1 0 3 1 3 0 2 3 0 2 1 2 0\n",
      " 0 2 3 2 1]\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_672 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_673 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_674 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_224 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 204ms/step - loss: 0.6976 - accuracy: 0.3232 - val_loss: 0.6921 - val_accuracy: 0.7381\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6919 - accuracy: 0.7256 - val_loss: 0.6903 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6901 - accuracy: 0.7500 - val_loss: 0.6890 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6888 - accuracy: 0.7500 - val_loss: 0.6879 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6878 - accuracy: 0.7500 - val_loss: 0.6870 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6868 - accuracy: 0.7500 - val_loss: 0.6861 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6859 - accuracy: 0.7500 - val_loss: 0.6852 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6851 - accuracy: 0.7500 - val_loss: 0.6843 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6842 - accuracy: 0.7500 - val_loss: 0.6835 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6834 - accuracy: 0.7500 - val_loss: 0.6827 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6826 - accuracy: 0.7500 - val_loss: 0.6819 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6818 - accuracy: 0.7500 - val_loss: 0.6811 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6810 - accuracy: 0.7500 - val_loss: 0.6803 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6802 - accuracy: 0.7500 - val_loss: 0.6795 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6794 - accuracy: 0.7500 - val_loss: 0.6787 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6786 - accuracy: 0.7500 - val_loss: 0.6779 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6778 - accuracy: 0.7500 - val_loss: 0.6772 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6770 - accuracy: 0.7500 - val_loss: 0.6764 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6762 - accuracy: 0.7500 - val_loss: 0.6756 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6755 - accuracy: 0.7500 - val_loss: 0.6748 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [2 1 3 0 1 0 3 0 2 3 1 0 3 1 0 3 0 0 3 0 0 2 3 3 2 1 3 1 3 3 0 0 0 2 3 3 1\n",
      " 0 0 1 0 3]\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_675 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_676 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_677 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_225 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6837 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6824 - accuracy: 0.7500 - val_loss: 0.6773 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6758 - accuracy: 0.7500 - val_loss: 0.6720 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6703 - accuracy: 0.7500 - val_loss: 0.6672 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6653 - accuracy: 0.7500 - val_loss: 0.6626 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6605 - accuracy: 0.7500 - val_loss: 0.6583 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6560 - accuracy: 0.7500 - val_loss: 0.6542 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6517 - accuracy: 0.7500 - val_loss: 0.6501 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6474 - accuracy: 0.7500 - val_loss: 0.6462 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6433 - accuracy: 0.7500 - val_loss: 0.6423 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6393 - accuracy: 0.7500 - val_loss: 0.6386 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6354 - accuracy: 0.7500 - val_loss: 0.6348 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6315 - accuracy: 0.7500 - val_loss: 0.6312 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6278 - accuracy: 0.7500 - val_loss: 0.6276 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6241 - accuracy: 0.7500 - val_loss: 0.6241 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6205 - accuracy: 0.7500 - val_loss: 0.6207 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6169 - accuracy: 0.7500 - val_loss: 0.6173 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6135 - accuracy: 0.7500 - val_loss: 0.6140 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6101 - accuracy: 0.7500 - val_loss: 0.6108 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6069 - accuracy: 0.7500 - val_loss: 0.6077 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [0 3 3 3 1 3 0 0 0 3 3 0 3 0 3 3 0 3 1 0 1 3 3 0 2 1 3 2 1 2 3 0 0 1 0 1 2\n",
      " 3 3 0 0 0]\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_678 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_679 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_680 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_226 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 189ms/step - loss: 0.6979 - accuracy: 0.3841 - val_loss: 0.6871 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6863 - accuracy: 0.7500 - val_loss: 0.6819 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6810 - accuracy: 0.7500 - val_loss: 0.6762 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6756 - accuracy: 0.7500 - val_loss: 0.6713 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6702 - accuracy: 0.7500 - val_loss: 0.6668 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6656 - accuracy: 0.7500 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6603 - accuracy: 0.7500 - val_loss: 0.6570 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6553 - accuracy: 0.7500 - val_loss: 0.6524 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6506 - accuracy: 0.7500 - val_loss: 0.6481 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6460 - accuracy: 0.7500 - val_loss: 0.6431 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6410 - accuracy: 0.7500 - val_loss: 0.6384 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6361 - accuracy: 0.7500 - val_loss: 0.6339 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6316 - accuracy: 0.7500 - val_loss: 0.6297 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6272 - accuracy: 0.7500 - val_loss: 0.6251 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6225 - accuracy: 0.7500 - val_loss: 0.6207 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6180 - accuracy: 0.7500 - val_loss: 0.6166 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6137 - accuracy: 0.7500 - val_loss: 0.6124 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6096 - accuracy: 0.7500 - val_loss: 0.6091 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6061 - accuracy: 0.7500 - val_loss: 0.6048 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6018 - accuracy: 0.7500 - val_loss: 0.6011 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [0 3 3 0 1 3 1 0 0 1 0 3 3 3 0 3 1 3 1 3 0 0 1 0 3 3 3 0 0 0 3 0 3 0 3 3 1\n",
      " 3 0 0 2 0]\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_681 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_682 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_683 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_227 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 187ms/step - loss: 0.6895 - accuracy: 0.7256 - val_loss: 0.6723 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6692 - accuracy: 0.7500 - val_loss: 0.6581 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6551 - accuracy: 0.7500 - val_loss: 0.6473 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6441 - accuracy: 0.7500 - val_loss: 0.6381 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6348 - accuracy: 0.7500 - val_loss: 0.6300 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6266 - accuracy: 0.7500 - val_loss: 0.6227 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6192 - accuracy: 0.7500 - val_loss: 0.6160 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6125 - accuracy: 0.7500 - val_loss: 0.6100 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6064 - accuracy: 0.7500 - val_loss: 0.6044 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6009 - accuracy: 0.7500 - val_loss: 0.5993 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5958 - accuracy: 0.7500 - val_loss: 0.5946 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5912 - accuracy: 0.7500 - val_loss: 0.5903 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5870 - accuracy: 0.7500 - val_loss: 0.5864 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5832 - accuracy: 0.7500 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5798 - accuracy: 0.7500 - val_loss: 0.5797 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5768 - accuracy: 0.7500 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5741 - accuracy: 0.7500 - val_loss: 0.5744 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5718 - accuracy: 0.7500 - val_loss: 0.5722 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5698 - accuracy: 0.7500 - val_loss: 0.5704 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.5682 - accuracy: 0.7500 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "y_test_b [1 2 1 2 3 2 1 3 0 3 3 3 0 0 1 1 0 0 2 2 3 3 3 3 3 1 1 2 0 1 2 0 3 1 3 0 0\n",
      " 0 3 3 0 0]\n",
      "[]\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_684 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_685 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_686 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_228 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.6895 - accuracy: 0.6888 - val_loss: 0.6776 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6745 - accuracy: 0.7500 - val_loss: 0.6651 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6618 - accuracy: 0.7500 - val_loss: 0.6529 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6493 - accuracy: 0.7500 - val_loss: 0.6412 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6379 - accuracy: 0.7500 - val_loss: 0.6319 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6286 - accuracy: 0.7500 - val_loss: 0.6239 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6206 - accuracy: 0.7500 - val_loss: 0.6168 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6135 - accuracy: 0.7500 - val_loss: 0.6104 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6070 - accuracy: 0.7500 - val_loss: 0.6045 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6012 - accuracy: 0.7500 - val_loss: 0.5991 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5958 - accuracy: 0.7500 - val_loss: 0.5942 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.5910 - accuracy: 0.7500 - val_loss: 0.5897 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5867 - accuracy: 0.7500 - val_loss: 0.5857 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5827 - accuracy: 0.7500 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5792 - accuracy: 0.7500 - val_loss: 0.5788 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5761 - accuracy: 0.7500 - val_loss: 0.5759 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5734 - accuracy: 0.7500 - val_loss: 0.5734 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5711 - accuracy: 0.7500 - val_loss: 0.5713 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5692 - accuracy: 0.7500 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5675 - accuracy: 0.7500 - val_loss: 0.5679 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 3 2 3 3 3 1 3 0 3 0 1 0 3 1 0 2 0 3 2 1 2 0 2 0 0 3 2 3 0 3 0 0]\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_687 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_688 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_689 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_229 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.6899 - accuracy: 0.6480 - val_loss: 0.6781 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6757 - accuracy: 0.7500 - val_loss: 0.6678 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6653 - accuracy: 0.7500 - val_loss: 0.6594 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6567 - accuracy: 0.7500 - val_loss: 0.6521 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6491 - accuracy: 0.7500 - val_loss: 0.6454 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6422 - accuracy: 0.7500 - val_loss: 0.6391 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6357 - accuracy: 0.7500 - val_loss: 0.6333 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6296 - accuracy: 0.7500 - val_loss: 0.6277 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6239 - accuracy: 0.7500 - val_loss: 0.6224 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6185 - accuracy: 0.7500 - val_loss: 0.6174 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6134 - accuracy: 0.7500 - val_loss: 0.6127 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6085 - accuracy: 0.7500 - val_loss: 0.6081 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6040 - accuracy: 0.7500 - val_loss: 0.6038 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5996 - accuracy: 0.7500 - val_loss: 0.5998 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.5956 - accuracy: 0.7500 - val_loss: 0.5960 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5918 - accuracy: 0.7500 - val_loss: 0.5924 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5883 - accuracy: 0.7500 - val_loss: 0.5890 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.5850 - accuracy: 0.7500 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5820 - accuracy: 0.7500 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5792 - accuracy: 0.7500 - val_loss: 0.5803 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 1 2 2 3 1 0 3 1 3 3 1 1 3 3 3 3 2 3 2 3 0 1 1 1 0 0 2 0 3 0 3 0 2]\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_690 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_691 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_692 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_230 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 204ms/step - loss: 0.6901 - accuracy: 0.5765 - val_loss: 0.6778 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6748 - accuracy: 0.7500 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6613 - accuracy: 0.7500 - val_loss: 0.6540 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6505 - accuracy: 0.7500 - val_loss: 0.6454 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6417 - accuracy: 0.7500 - val_loss: 0.6379 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6340 - accuracy: 0.7500 - val_loss: 0.6311 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6270 - accuracy: 0.7500 - val_loss: 0.6249 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6206 - accuracy: 0.7500 - val_loss: 0.6191 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6147 - accuracy: 0.7500 - val_loss: 0.6137 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.6092 - accuracy: 0.7500 - val_loss: 0.6088 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6042 - accuracy: 0.7500 - val_loss: 0.6040 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5994 - accuracy: 0.7500 - val_loss: 0.5997 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5951 - accuracy: 0.7500 - val_loss: 0.5957 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.5911 - accuracy: 0.7500 - val_loss: 0.5919 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.5874 - accuracy: 0.7500 - val_loss: 0.5884 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.5840 - accuracy: 0.7500 - val_loss: 0.5852 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5810 - accuracy: 0.7500 - val_loss: 0.5823 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5782 - accuracy: 0.7500 - val_loss: 0.5796 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.5757 - accuracy: 0.7500 - val_loss: 0.5772 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5734 - accuracy: 0.7500 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 3 3 2 0 0 0 2 0 3 0 3 0 1 0 1 3 0 1 0 2 3 0 2 0 0 3 2 2 0 0 0 3]\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_693 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_694 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_695 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_231 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 319ms/step - loss: 0.6847 - accuracy: 0.7500 - val_loss: 0.6682 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6646 - accuracy: 0.7500 - val_loss: 0.6530 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6493 - accuracy: 0.7500 - val_loss: 0.6408 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6371 - accuracy: 0.7500 - val_loss: 0.6304 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.6266 - accuracy: 0.7500 - val_loss: 0.6212 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6175 - accuracy: 0.7500 - val_loss: 0.6130 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6094 - accuracy: 0.7500 - val_loss: 0.6057 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6022 - accuracy: 0.7500 - val_loss: 0.5992 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5958 - accuracy: 0.7500 - val_loss: 0.5933 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5900 - accuracy: 0.7500 - val_loss: 0.5881 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5850 - accuracy: 0.7500 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5806 - accuracy: 0.7500 - val_loss: 0.5795 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5767 - accuracy: 0.7500 - val_loss: 0.5761 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5735 - accuracy: 0.7500 - val_loss: 0.5731 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5709 - accuracy: 0.7500 - val_loss: 0.5707 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5686 - accuracy: 0.7500 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.5669 - accuracy: 0.7500 - val_loss: 0.5671 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5655 - accuracy: 0.7500 - val_loss: 0.5658 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5645 - accuracy: 0.7500 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.5638 - accuracy: 0.7500 - val_loss: 0.5642 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 2 1 1 2 0 3 2 1 3 3 1 1 3 3 1 3 3 0 1 0 0 2 3 0 2 0 2 0 3 1 3 3 0]\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_696 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_697 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_698 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_232 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 257ms/step - loss: 0.6876 - accuracy: 0.6071 - val_loss: 0.6666 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6617 - accuracy: 0.7500 - val_loss: 0.6472 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6429 - accuracy: 0.7500 - val_loss: 0.6336 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6295 - accuracy: 0.7500 - val_loss: 0.6228 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6187 - accuracy: 0.7500 - val_loss: 0.6138 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6098 - accuracy: 0.7500 - val_loss: 0.6060 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6021 - accuracy: 0.7500 - val_loss: 0.5993 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5955 - accuracy: 0.7500 - val_loss: 0.5935 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5898 - accuracy: 0.7500 - val_loss: 0.5884 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5849 - accuracy: 0.7500 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5806 - accuracy: 0.7500 - val_loss: 0.5801 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5770 - accuracy: 0.7500 - val_loss: 0.5768 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5739 - accuracy: 0.7500 - val_loss: 0.5739 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.5714 - accuracy: 0.7500 - val_loss: 0.5716 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5692 - accuracy: 0.7500 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5675 - accuracy: 0.7500 - val_loss: 0.5680 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5662 - accuracy: 0.7500 - val_loss: 0.5667 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5651 - accuracy: 0.7500 - val_loss: 0.5657 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5643 - accuracy: 0.7500 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5637 - accuracy: 0.7500 - val_loss: 0.5642 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 0 0 3 1 3 3 0 0 0 3 2 2 0 0 2 1 3 0 3 0 3 0 2 3 0 0 1 3 2 3 3 2]\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_699 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_700 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_701 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_233 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 356ms/step - loss: 0.6906 - accuracy: 0.5255 - val_loss: 0.6788 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6759 - accuracy: 0.7500 - val_loss: 0.6666 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6641 - accuracy: 0.7500 - val_loss: 0.6572 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6547 - accuracy: 0.7500 - val_loss: 0.6490 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6465 - accuracy: 0.7500 - val_loss: 0.6416 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6390 - accuracy: 0.7500 - val_loss: 0.6348 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6321 - accuracy: 0.7500 - val_loss: 0.6284 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6257 - accuracy: 0.7500 - val_loss: 0.6223 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6196 - accuracy: 0.7500 - val_loss: 0.6166 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6138 - accuracy: 0.7500 - val_loss: 0.6113 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6084 - accuracy: 0.7500 - val_loss: 0.6063 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.6035 - accuracy: 0.7500 - val_loss: 0.6016 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5988 - accuracy: 0.7500 - val_loss: 0.5973 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5945 - accuracy: 0.7500 - val_loss: 0.5932 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.5905 - accuracy: 0.7500 - val_loss: 0.5894 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.5868 - accuracy: 0.7500 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.5834 - accuracy: 0.7500 - val_loss: 0.5826 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.5802 - accuracy: 0.7500 - val_loss: 0.5796 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.5773 - accuracy: 0.7500 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5747 - accuracy: 0.7500 - val_loss: 0.5744 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 0 0 3 0 0 2 3 3 0 0 0 3 0 1 3 1 3 0 0 3 2 2 1 0 1 3 0 1 0 1 3 0 0]\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_702 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_703 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_704 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_234 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 312ms/step - loss: 0.6950 - accuracy: 0.3724 - val_loss: 0.6922 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6918 - accuracy: 0.7500 - val_loss: 0.6909 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6907 - accuracy: 0.7500 - val_loss: 0.6901 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6900 - accuracy: 0.7500 - val_loss: 0.6895 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6894 - accuracy: 0.7500 - val_loss: 0.6889 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6887 - accuracy: 0.7500 - val_loss: 0.6881 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6877 - accuracy: 0.7500 - val_loss: 0.6860 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.6856 - accuracy: 0.7500 - val_loss: 0.6846 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6842 - accuracy: 0.7500 - val_loss: 0.6833 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6829 - accuracy: 0.7500 - val_loss: 0.6820 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6818 - accuracy: 0.7500 - val_loss: 0.6809 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6806 - accuracy: 0.7500 - val_loss: 0.6798 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6795 - accuracy: 0.7500 - val_loss: 0.6787 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6784 - accuracy: 0.7500 - val_loss: 0.6776 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6774 - accuracy: 0.7500 - val_loss: 0.6766 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6763 - accuracy: 0.7500 - val_loss: 0.6755 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.6753 - accuracy: 0.7500 - val_loss: 0.6745 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6742 - accuracy: 0.7500 - val_loss: 0.6734 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6731 - accuracy: 0.7500 - val_loss: 0.6723 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6721 - accuracy: 0.7500 - val_loss: 0.6713 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 2 0 2 3 1 3 3 1 0 1 3 0 3 1 3 1 0 3 1 2 3 0 0 3 0 1 2 0 0 3 3 2]\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_705 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_706 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_707 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_235 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 264ms/step - loss: 0.6854 - accuracy: 0.7500 - val_loss: 0.6599 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6538 - accuracy: 0.7500 - val_loss: 0.6365 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6313 - accuracy: 0.7500 - val_loss: 0.6204 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6155 - accuracy: 0.7500 - val_loss: 0.6080 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6033 - accuracy: 0.7500 - val_loss: 0.5980 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5937 - accuracy: 0.7500 - val_loss: 0.5900 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5860 - accuracy: 0.7500 - val_loss: 0.5836 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.5799 - accuracy: 0.7500 - val_loss: 0.5784 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5751 - accuracy: 0.7500 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5714 - accuracy: 0.7500 - val_loss: 0.5710 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5686 - accuracy: 0.7500 - val_loss: 0.5686 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5666 - accuracy: 0.7500 - val_loss: 0.5668 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5651 - accuracy: 0.7500 - val_loss: 0.5655 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.5641 - accuracy: 0.7500 - val_loss: 0.5645 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5631 - accuracy: 0.7500 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 2 3 3 0 3 3 3 0 1 2 0 2 3 3 0 0 3 1 1 0 1 0 3 2 1 2 2 3 0 0 3 0 0]\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_708 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_709 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_710 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_236 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.6905 - accuracy: 0.4439 - val_loss: 0.6715 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6678 - accuracy: 0.7500 - val_loss: 0.6534 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6490 - accuracy: 0.7500 - val_loss: 0.6375 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6333 - accuracy: 0.7500 - val_loss: 0.6254 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6213 - accuracy: 0.7500 - val_loss: 0.6154 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6113 - accuracy: 0.7500 - val_loss: 0.6069 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6029 - accuracy: 0.7500 - val_loss: 0.5996 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5957 - accuracy: 0.7500 - val_loss: 0.5933 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5895 - accuracy: 0.7500 - val_loss: 0.5878 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5842 - accuracy: 0.7500 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5797 - accuracy: 0.7500 - val_loss: 0.5789 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5759 - accuracy: 0.7500 - val_loss: 0.5755 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5727 - accuracy: 0.7500 - val_loss: 0.5726 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5701 - accuracy: 0.7500 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5681 - accuracy: 0.7500 - val_loss: 0.5683 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.5664 - accuracy: 0.7500 - val_loss: 0.5668 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5652 - accuracy: 0.7500 - val_loss: 0.5657 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5643 - accuracy: 0.7500 - val_loss: 0.5648 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5637 - accuracy: 0.7500 - val_loss: 0.5642 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5633 - accuracy: 0.7500 - val_loss: 0.5637 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 3 3 3 0 0 0 0 0 1 2 1 1 0 3 3 2 0 3 1 1 3 0 3 3 0 0 3 3 3 1 2 0]\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_711 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_712 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_713 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_237 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 248ms/step - loss: 0.6887 - accuracy: 0.6582 - val_loss: 0.6738 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6702 - accuracy: 0.7500 - val_loss: 0.6592 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6556 - accuracy: 0.7500 - val_loss: 0.6470 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.6435 - accuracy: 0.7500 - val_loss: 0.6371 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6335 - accuracy: 0.7500 - val_loss: 0.6284 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6248 - accuracy: 0.7500 - val_loss: 0.6207 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6170 - accuracy: 0.7500 - val_loss: 0.6137 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6100 - accuracy: 0.7500 - val_loss: 0.6074 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6037 - accuracy: 0.7500 - val_loss: 0.6017 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5980 - accuracy: 0.7500 - val_loss: 0.5965 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.5928 - accuracy: 0.7500 - val_loss: 0.5917 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5882 - accuracy: 0.7500 - val_loss: 0.5875 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5841 - accuracy: 0.7500 - val_loss: 0.5837 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5804 - accuracy: 0.7500 - val_loss: 0.5803 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5772 - accuracy: 0.7500 - val_loss: 0.5772 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5743 - accuracy: 0.7500 - val_loss: 0.5746 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5719 - accuracy: 0.7500 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5698 - accuracy: 0.7500 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5681 - accuracy: 0.7500 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5667 - accuracy: 0.7500 - val_loss: 0.5673 - val_accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 0 2 0 3 2 0 1 1 3 0 1 3 0 3 0 3 3 0 2 3 0 3 1 0 0 0 1 0 0 2 0 0 0]\n",
      "[]\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_714 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_715 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_716 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_238 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.6843 - accuracy: 0.7500 - val_loss: 0.6697 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6656 - accuracy: 0.7500 - val_loss: 0.6564 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6524 - accuracy: 0.7500 - val_loss: 0.6457 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6416 - accuracy: 0.7500 - val_loss: 0.6363 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6322 - accuracy: 0.7500 - val_loss: 0.6280 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6237 - accuracy: 0.7500 - val_loss: 0.6204 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6161 - accuracy: 0.7500 - val_loss: 0.6135 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6091 - accuracy: 0.7500 - val_loss: 0.6072 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6028 - accuracy: 0.7500 - val_loss: 0.6014 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5970 - accuracy: 0.7500 - val_loss: 0.5961 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5919 - accuracy: 0.7500 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.5872 - accuracy: 0.7500 - val_loss: 0.5870 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5830 - accuracy: 0.7500 - val_loss: 0.5831 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5793 - accuracy: 0.7500 - val_loss: 0.5797 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5761 - accuracy: 0.7500 - val_loss: 0.5766 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5733 - accuracy: 0.7500 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5709 - accuracy: 0.7500 - val_loss: 0.5717 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5689 - accuracy: 0.7500 - val_loss: 0.5698 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5673 - accuracy: 0.7500 - val_loss: 0.5682 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5660 - accuracy: 0.7500 - val_loss: 0.5669 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 0 1 3 0 0 1 3 3 3 3 0 3 0 3 1 1 2 1 1 2 3 0 0 0]\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_717 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_718 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_719 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_239 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 235ms/step - loss: 0.6871 - accuracy: 0.7500 - val_loss: 0.6742 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6707 - accuracy: 0.7500 - val_loss: 0.6600 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6560 - accuracy: 0.7500 - val_loss: 0.6473 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6436 - accuracy: 0.7500 - val_loss: 0.6370 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6333 - accuracy: 0.7500 - val_loss: 0.6280 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6244 - accuracy: 0.7500 - val_loss: 0.6201 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6165 - accuracy: 0.7500 - val_loss: 0.6130 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6094 - accuracy: 0.7500 - val_loss: 0.6065 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6030 - accuracy: 0.7500 - val_loss: 0.6006 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5972 - accuracy: 0.7500 - val_loss: 0.5953 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5920 - accuracy: 0.7500 - val_loss: 0.5905 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5873 - accuracy: 0.7500 - val_loss: 0.5862 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5831 - accuracy: 0.7500 - val_loss: 0.5823 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5795 - accuracy: 0.7500 - val_loss: 0.5789 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5762 - accuracy: 0.7500 - val_loss: 0.5759 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5735 - accuracy: 0.7500 - val_loss: 0.5733 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5711 - accuracy: 0.7500 - val_loss: 0.5711 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5691 - accuracy: 0.7500 - val_loss: 0.5692 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5674 - accuracy: 0.7500 - val_loss: 0.5677 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5661 - accuracy: 0.7500 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 1 0 3 0 3 3 3 3 1 1 3 3 0 3 1 0 3 0 2 3 3 3 3]\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_720 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_721 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_722 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_240 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 154ms/step - loss: 0.6872 - accuracy: 0.5086 - val_loss: 0.6665 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6614 - accuracy: 0.7500 - val_loss: 0.6502 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6455 - accuracy: 0.7500 - val_loss: 0.6377 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6331 - accuracy: 0.7500 - val_loss: 0.6273 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6227 - accuracy: 0.7500 - val_loss: 0.6183 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6137 - accuracy: 0.7500 - val_loss: 0.6104 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6058 - accuracy: 0.7500 - val_loss: 0.6034 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5989 - accuracy: 0.7500 - val_loss: 0.5972 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5928 - accuracy: 0.7500 - val_loss: 0.5918 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5876 - accuracy: 0.7500 - val_loss: 0.5869 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5829 - accuracy: 0.7500 - val_loss: 0.5827 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5790 - accuracy: 0.7500 - val_loss: 0.5791 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5756 - accuracy: 0.7500 - val_loss: 0.5759 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5727 - accuracy: 0.7500 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5703 - accuracy: 0.7500 - val_loss: 0.5710 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5684 - accuracy: 0.7500 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5668 - accuracy: 0.7500 - val_loss: 0.5676 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5656 - accuracy: 0.7500 - val_loss: 0.5663 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5646 - accuracy: 0.7500 - val_loss: 0.5654 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5640 - accuracy: 0.7500 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 0 0 3 3 1 1 1 0 1 3 3 0 0 3 1 0 3 1 0 0 3 0 3 3]\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_723 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_724 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_725 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_241 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 156ms/step - loss: 0.6748 - accuracy: 0.7500 - val_loss: 0.6517 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6459 - accuracy: 0.7500 - val_loss: 0.6334 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6279 - accuracy: 0.7500 - val_loss: 0.6196 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6143 - accuracy: 0.7500 - val_loss: 0.6086 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6035 - accuracy: 0.7500 - val_loss: 0.5996 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5947 - accuracy: 0.7500 - val_loss: 0.5922 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5875 - accuracy: 0.7500 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5816 - accuracy: 0.7500 - val_loss: 0.5808 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5768 - accuracy: 0.7500 - val_loss: 0.5766 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5729 - accuracy: 0.7500 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5699 - accuracy: 0.7500 - val_loss: 0.5705 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5676 - accuracy: 0.7500 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5659 - accuracy: 0.7500 - val_loss: 0.5668 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5647 - accuracy: 0.7500 - val_loss: 0.5656 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5638 - accuracy: 0.7500 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5633 - accuracy: 0.7500 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5637 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5634 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 2 0 1 1 0 3 0 2 0 1 3 3 1 3 1 2 2 3 1 3 0 0 0]\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_726 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_727 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_728 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_242 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 0.6895 - accuracy: 0.6724 - val_loss: 0.6746 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6699 - accuracy: 0.7500 - val_loss: 0.6590 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6542 - accuracy: 0.7500 - val_loss: 0.6441 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6394 - accuracy: 0.7500 - val_loss: 0.6319 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6273 - accuracy: 0.7500 - val_loss: 0.6215 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6170 - accuracy: 0.7500 - val_loss: 0.6127 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6083 - accuracy: 0.7500 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6007 - accuracy: 0.7500 - val_loss: 0.5983 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5941 - accuracy: 0.7500 - val_loss: 0.5923 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5884 - accuracy: 0.7500 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5834 - accuracy: 0.7500 - val_loss: 0.5826 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5791 - accuracy: 0.7500 - val_loss: 0.5787 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5755 - accuracy: 0.7500 - val_loss: 0.5754 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5725 - accuracy: 0.7500 - val_loss: 0.5726 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5700 - accuracy: 0.7500 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5679 - accuracy: 0.7500 - val_loss: 0.5684 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5664 - accuracy: 0.7500 - val_loss: 0.5669 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5652 - accuracy: 0.7500 - val_loss: 0.5657 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5643 - accuracy: 0.7500 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5637 - accuracy: 0.7500 - val_loss: 0.5642 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 3 3 0 0 0 3 3 2 0 3 0 1 1 3 0 1 3 2 1 3 3 3 0 3]\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_729 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_730 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_731 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_243 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 156ms/step - loss: 0.6888 - accuracy: 0.6810 - val_loss: 0.6794 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6773 - accuracy: 0.7500 - val_loss: 0.6710 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6683 - accuracy: 0.7500 - val_loss: 0.6624 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6601 - accuracy: 0.7500 - val_loss: 0.6554 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6531 - accuracy: 0.7500 - val_loss: 0.6491 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6467 - accuracy: 0.7500 - val_loss: 0.6431 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6406 - accuracy: 0.7500 - val_loss: 0.6374 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6349 - accuracy: 0.7500 - val_loss: 0.6320 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6293 - accuracy: 0.7500 - val_loss: 0.6268 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6240 - accuracy: 0.7500 - val_loss: 0.6217 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6188 - accuracy: 0.7500 - val_loss: 0.6168 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6139 - accuracy: 0.7500 - val_loss: 0.6121 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6091 - accuracy: 0.7500 - val_loss: 0.6075 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6046 - accuracy: 0.7500 - val_loss: 0.6032 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6003 - accuracy: 0.7500 - val_loss: 0.5991 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5961 - accuracy: 0.7500 - val_loss: 0.5951 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5923 - accuracy: 0.7500 - val_loss: 0.5915 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5886 - accuracy: 0.7500 - val_loss: 0.5880 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5852 - accuracy: 0.7500 - val_loss: 0.5847 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.5821 - accuracy: 0.7500 - val_loss: 0.5818 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 1 0 0 2 0 2 0 0 3 0 3 3 3 3 3 3 3 3 0 3 1 3 1 0]\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_732 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_733 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_734 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_244 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 165ms/step - loss: 0.6923 - accuracy: 0.5172 - val_loss: 0.6877 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6866 - accuracy: 0.7500 - val_loss: 0.6829 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6819 - accuracy: 0.7500 - val_loss: 0.6793 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6778 - accuracy: 0.7500 - val_loss: 0.6743 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6732 - accuracy: 0.7500 - val_loss: 0.6705 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6696 - accuracy: 0.7500 - val_loss: 0.6671 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6659 - accuracy: 0.7500 - val_loss: 0.6634 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6623 - accuracy: 0.7500 - val_loss: 0.6603 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6589 - accuracy: 0.7500 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6553 - accuracy: 0.7500 - val_loss: 0.6535 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6521 - accuracy: 0.7500 - val_loss: 0.6501 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6486 - accuracy: 0.7500 - val_loss: 0.6468 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6452 - accuracy: 0.7500 - val_loss: 0.6436 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6420 - accuracy: 0.7500 - val_loss: 0.6404 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6387 - accuracy: 0.7500 - val_loss: 0.6372 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6355 - accuracy: 0.7500 - val_loss: 0.6340 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6322 - accuracy: 0.7500 - val_loss: 0.6308 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6289 - accuracy: 0.7500 - val_loss: 0.6277 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6259 - accuracy: 0.7500 - val_loss: 0.6245 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6226 - accuracy: 0.7500 - val_loss: 0.6215 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 1 3 1 1 3 2 3 3 1 3 1 0 3 2 3 0 2 0 0 0 1 1 3 2]\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_735 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_736 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_737 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_245 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.6824 - accuracy: 0.7500 - val_loss: 0.6655 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6608 - accuracy: 0.7500 - val_loss: 0.6505 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6463 - accuracy: 0.7500 - val_loss: 0.6389 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6350 - accuracy: 0.7500 - val_loss: 0.6293 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6255 - accuracy: 0.7500 - val_loss: 0.6210 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6172 - accuracy: 0.7500 - val_loss: 0.6136 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6099 - accuracy: 0.7500 - val_loss: 0.6070 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6033 - accuracy: 0.7500 - val_loss: 0.6010 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5975 - accuracy: 0.7500 - val_loss: 0.5957 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5923 - accuracy: 0.7500 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5877 - accuracy: 0.7500 - val_loss: 0.5866 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5835 - accuracy: 0.7500 - val_loss: 0.5828 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5799 - accuracy: 0.7500 - val_loss: 0.5794 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5767 - accuracy: 0.7500 - val_loss: 0.5764 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5739 - accuracy: 0.7500 - val_loss: 0.5738 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5716 - accuracy: 0.7500 - val_loss: 0.5716 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5696 - accuracy: 0.7500 - val_loss: 0.5697 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5679 - accuracy: 0.7500 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5665 - accuracy: 0.7500 - val_loss: 0.5668 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5654 - accuracy: 0.7500 - val_loss: 0.5658 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 1 3 0 1 0 3 0 3 0 3 0 1 3 3 0 2 1 0 3 3 1 0 0]\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_738 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_739 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_740 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_246 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 151ms/step - loss: 0.6832 - accuracy: 0.6983 - val_loss: 0.6630 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6571 - accuracy: 0.7500 - val_loss: 0.6448 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6395 - accuracy: 0.7500 - val_loss: 0.6313 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6263 - accuracy: 0.7500 - val_loss: 0.6205 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6156 - accuracy: 0.7500 - val_loss: 0.6113 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6066 - accuracy: 0.7500 - val_loss: 0.6035 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5989 - accuracy: 0.7500 - val_loss: 0.5966 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5923 - accuracy: 0.7500 - val_loss: 0.5908 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5866 - accuracy: 0.7500 - val_loss: 0.5857 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5818 - accuracy: 0.7500 - val_loss: 0.5813 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5777 - accuracy: 0.7500 - val_loss: 0.5775 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5743 - accuracy: 0.7500 - val_loss: 0.5744 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5714 - accuracy: 0.7500 - val_loss: 0.5718 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5691 - accuracy: 0.7500 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5673 - accuracy: 0.7500 - val_loss: 0.5679 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5659 - accuracy: 0.7500 - val_loss: 0.5665 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5648 - accuracy: 0.7500 - val_loss: 0.5654 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5640 - accuracy: 0.7500 - val_loss: 0.5646 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5640 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5631 - accuracy: 0.7500 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 0 3 0 0 0 0 3 0 0 0 3 0 2 1 1 0 3 3 1 3 0 0 1]\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_741 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_742 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_743 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_247 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 151ms/step - loss: 0.6877 - accuracy: 0.7500 - val_loss: 0.6779 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6752 - accuracy: 0.7500 - val_loss: 0.6662 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6632 - accuracy: 0.7500 - val_loss: 0.6552 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6519 - accuracy: 0.7500 - val_loss: 0.6451 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6420 - accuracy: 0.7500 - val_loss: 0.6367 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6335 - accuracy: 0.7500 - val_loss: 0.6292 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6260 - accuracy: 0.7500 - val_loss: 0.6224 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6191 - accuracy: 0.7500 - val_loss: 0.6161 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6128 - accuracy: 0.7500 - val_loss: 0.6103 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6071 - accuracy: 0.7500 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6018 - accuracy: 0.7500 - val_loss: 0.6000 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5968 - accuracy: 0.7500 - val_loss: 0.5954 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5923 - accuracy: 0.7500 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5882 - accuracy: 0.7500 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5844 - accuracy: 0.7500 - val_loss: 0.5838 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5810 - accuracy: 0.7500 - val_loss: 0.5806 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5779 - accuracy: 0.7500 - val_loss: 0.5777 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5752 - accuracy: 0.7500 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5728 - accuracy: 0.7500 - val_loss: 0.5729 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5707 - accuracy: 0.7500 - val_loss: 0.5709 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 3 1 2 0 2 3 1 0 1 3 3 3 3 0 3 0 0 1 3 3 3 3 0 3]\n",
      "[]\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_744 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_745 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_746 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_248 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 75ms/step - loss: 0.6821 - accuracy: 0.7500 - val_loss: 0.6594 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6542 - accuracy: 0.7500 - val_loss: 0.6412 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6364 - accuracy: 0.7500 - val_loss: 0.6269 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6223 - accuracy: 0.7500 - val_loss: 0.6149 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6105 - accuracy: 0.7500 - val_loss: 0.6047 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6003 - accuracy: 0.7500 - val_loss: 0.5959 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5918 - accuracy: 0.7500 - val_loss: 0.5885 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.5846 - accuracy: 0.7500 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5787 - accuracy: 0.7500 - val_loss: 0.5770 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5739 - accuracy: 0.7500 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5702 - accuracy: 0.7500 - val_loss: 0.5697 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5674 - accuracy: 0.7500 - val_loss: 0.5673 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5654 - accuracy: 0.7500 - val_loss: 0.5656 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5641 - accuracy: 0.7500 - val_loss: 0.5644 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5633 - accuracy: 0.7500 - val_loss: 0.5637 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 0 0 3 1 3 1 0 3 0 3 3 0 0 1 0]\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_747 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_748 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_749 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_249 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 77ms/step - loss: 0.6874 - accuracy: 0.6288 - val_loss: 0.6692 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6647 - accuracy: 0.7500 - val_loss: 0.6540 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6497 - accuracy: 0.7500 - val_loss: 0.6420 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6377 - accuracy: 0.7500 - val_loss: 0.6317 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6272 - accuracy: 0.7500 - val_loss: 0.6224 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6179 - accuracy: 0.7500 - val_loss: 0.6140 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6095 - accuracy: 0.7500 - val_loss: 0.6064 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6019 - accuracy: 0.7500 - val_loss: 0.5995 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5951 - accuracy: 0.7500 - val_loss: 0.5932 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5890 - accuracy: 0.7500 - val_loss: 0.5877 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5837 - accuracy: 0.7500 - val_loss: 0.5828 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5790 - accuracy: 0.7500 - val_loss: 0.5785 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5750 - accuracy: 0.7500 - val_loss: 0.5749 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5717 - accuracy: 0.7500 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5691 - accuracy: 0.7500 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5670 - accuracy: 0.7500 - val_loss: 0.5674 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5654 - accuracy: 0.7500 - val_loss: 0.5659 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5642 - accuracy: 0.7500 - val_loss: 0.5648 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 0 3 3 3 0 3 3 3 3 2 3 3 3 0 0 1]\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_750 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_751 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_752 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_250 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 75ms/step - loss: 0.6819 - accuracy: 0.7424 - val_loss: 0.6620 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6588 - accuracy: 0.7500 - val_loss: 0.6460 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6432 - accuracy: 0.7500 - val_loss: 0.6333 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6309 - accuracy: 0.7500 - val_loss: 0.6226 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6204 - accuracy: 0.7500 - val_loss: 0.6133 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6113 - accuracy: 0.7500 - val_loss: 0.6052 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6032 - accuracy: 0.7500 - val_loss: 0.5977 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5959 - accuracy: 0.7500 - val_loss: 0.5911 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5894 - accuracy: 0.7500 - val_loss: 0.5853 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5837 - accuracy: 0.7500 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5788 - accuracy: 0.7500 - val_loss: 0.5759 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5747 - accuracy: 0.7500 - val_loss: 0.5724 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5714 - accuracy: 0.7500 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5686 - accuracy: 0.7500 - val_loss: 0.5673 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5666 - accuracy: 0.7500 - val_loss: 0.5657 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5651 - accuracy: 0.7500 - val_loss: 0.5644 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5640 - accuracy: 0.7500 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5633 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 2 3 0 2 0 0 0 2 0 1 0 1 2 3 2]\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_753 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_754 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_755 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_251 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 75ms/step - loss: 0.6787 - accuracy: 0.7500 - val_loss: 0.6470 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6394 - accuracy: 0.7500 - val_loss: 0.6236 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6171 - accuracy: 0.7500 - val_loss: 0.6073 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6016 - accuracy: 0.7500 - val_loss: 0.5952 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5900 - accuracy: 0.7500 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5814 - accuracy: 0.7500 - val_loss: 0.5789 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5750 - accuracy: 0.7500 - val_loss: 0.5737 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5705 - accuracy: 0.7500 - val_loss: 0.5699 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5673 - accuracy: 0.7500 - val_loss: 0.5673 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5652 - accuracy: 0.7500 - val_loss: 0.5655 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5640 - accuracy: 0.7500 - val_loss: 0.5643 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5632 - accuracy: 0.7500 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 3 1 0 2 0 0 0 2 3 3 3 2 3 0 1]\n",
      "Model: \"sequential_252\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_756 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_757 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_758 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_252 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 78ms/step - loss: 0.6805 - accuracy: 0.7500 - val_loss: 0.6588 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6544 - accuracy: 0.7500 - val_loss: 0.6423 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6383 - accuracy: 0.7500 - val_loss: 0.6291 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6255 - accuracy: 0.7500 - val_loss: 0.6182 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6147 - accuracy: 0.7500 - val_loss: 0.6088 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6054 - accuracy: 0.7500 - val_loss: 0.6006 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5975 - accuracy: 0.7500 - val_loss: 0.5935 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5905 - accuracy: 0.7500 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5846 - accuracy: 0.7500 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5796 - accuracy: 0.7500 - val_loss: 0.5777 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5754 - accuracy: 0.7500 - val_loss: 0.5739 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5720 - accuracy: 0.7500 - val_loss: 0.5709 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5692 - accuracy: 0.7500 - val_loss: 0.5685 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5670 - accuracy: 0.7500 - val_loss: 0.5666 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5654 - accuracy: 0.7500 - val_loss: 0.5652 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5643 - accuracy: 0.7500 - val_loss: 0.5642 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5631 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 0 0 0 1 3 3 3 3 0 3 3 0 0 3 3]\n",
      "Model: \"sequential_253\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_759 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_760 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_761 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_253 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 73ms/step - loss: 0.6950 - accuracy: 0.5227 - val_loss: 0.6889 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6882 - accuracy: 0.7500 - val_loss: 0.6860 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6852 - accuracy: 0.7500 - val_loss: 0.6834 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6827 - accuracy: 0.7500 - val_loss: 0.6809 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6801 - accuracy: 0.7500 - val_loss: 0.6787 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6778 - accuracy: 0.7500 - val_loss: 0.6763 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6754 - accuracy: 0.7500 - val_loss: 0.6740 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6730 - accuracy: 0.7500 - val_loss: 0.6717 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6706 - accuracy: 0.7500 - val_loss: 0.6693 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6682 - accuracy: 0.7500 - val_loss: 0.6669 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6658 - accuracy: 0.7500 - val_loss: 0.6643 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6631 - accuracy: 0.7500 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6605 - accuracy: 0.7500 - val_loss: 0.6591 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6577 - accuracy: 0.7500 - val_loss: 0.6564 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6551 - accuracy: 0.7500 - val_loss: 0.6538 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6523 - accuracy: 0.7500 - val_loss: 0.6511 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6494 - accuracy: 0.7500 - val_loss: 0.6482 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6466 - accuracy: 0.7500 - val_loss: 0.6454 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6437 - accuracy: 0.7500 - val_loss: 0.6426 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6407 - accuracy: 0.7500 - val_loss: 0.6397 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [2 2 1 0 1 0 3 1 3 0 3 3 1 3 3 0 0]\n",
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_762 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_763 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_764 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_254 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 76ms/step - loss: 0.6884 - accuracy: 0.6439 - val_loss: 0.6720 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6673 - accuracy: 0.7500 - val_loss: 0.6548 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6508 - accuracy: 0.7500 - val_loss: 0.6416 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6380 - accuracy: 0.7500 - val_loss: 0.6305 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6271 - accuracy: 0.7500 - val_loss: 0.6207 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6174 - accuracy: 0.7500 - val_loss: 0.6120 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6088 - accuracy: 0.7500 - val_loss: 0.6042 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6011 - accuracy: 0.7500 - val_loss: 0.5971 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5942 - accuracy: 0.7500 - val_loss: 0.5906 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5879 - accuracy: 0.7500 - val_loss: 0.5849 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5824 - accuracy: 0.7500 - val_loss: 0.5798 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5776 - accuracy: 0.7500 - val_loss: 0.5754 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5735 - accuracy: 0.7500 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5702 - accuracy: 0.7500 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5677 - accuracy: 0.7500 - val_loss: 0.5668 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5657 - accuracy: 0.7500 - val_loss: 0.5652 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5644 - accuracy: 0.7500 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5634 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 3 2 3 0 0 3 3 1 3 0 0 3 0 1 1]\n",
      "Model: \"sequential_255\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_765 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_766 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_767 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_255 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 75ms/step - loss: 0.6758 - accuracy: 0.7500 - val_loss: 0.6486 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6432 - accuracy: 0.7500 - val_loss: 0.6277 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6234 - accuracy: 0.7500 - val_loss: 0.6123 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6087 - accuracy: 0.7500 - val_loss: 0.6003 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5971 - accuracy: 0.7500 - val_loss: 0.5907 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5878 - accuracy: 0.7500 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5805 - accuracy: 0.7500 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5749 - accuracy: 0.7500 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5706 - accuracy: 0.7500 - val_loss: 0.5688 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5675 - accuracy: 0.7500 - val_loss: 0.5663 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5654 - accuracy: 0.7500 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5640 - accuracy: 0.7500 - val_loss: 0.5637 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5632 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 0 1 3 1 0 0 1 2 1 3 0 1 3 2 2]\n",
      "Model: \"sequential_256\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_768 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_769 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_770 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_256 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 81ms/step - loss: 0.6905 - accuracy: 0.5303 - val_loss: 0.6784 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6761 - accuracy: 0.7500 - val_loss: 0.6688 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6665 - accuracy: 0.7500 - val_loss: 0.6607 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6584 - accuracy: 0.7500 - val_loss: 0.6535 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6511 - accuracy: 0.7500 - val_loss: 0.6467 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6442 - accuracy: 0.7500 - val_loss: 0.6403 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6375 - accuracy: 0.7500 - val_loss: 0.6339 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6311 - accuracy: 0.7500 - val_loss: 0.6277 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6249 - accuracy: 0.7500 - val_loss: 0.6218 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6188 - accuracy: 0.7500 - val_loss: 0.6161 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6131 - accuracy: 0.7500 - val_loss: 0.6106 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6076 - accuracy: 0.7500 - val_loss: 0.6054 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6024 - accuracy: 0.7500 - val_loss: 0.6004 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5974 - accuracy: 0.7500 - val_loss: 0.5957 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5927 - accuracy: 0.7500 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5884 - accuracy: 0.7500 - val_loss: 0.5872 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5844 - accuracy: 0.7500 - val_loss: 0.5834 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5807 - accuracy: 0.7500 - val_loss: 0.5799 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5774 - accuracy: 0.7500 - val_loss: 0.5768 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5744 - accuracy: 0.7500 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 3 0 3 3 0 2 1 2 3 3 0 0 1 0 3]\n",
      "Model: \"sequential_257\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_771 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_772 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_773 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_257 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 72ms/step - loss: 0.6884 - accuracy: 0.6970 - val_loss: 0.6755 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6721 - accuracy: 0.7500 - val_loss: 0.6629 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6597 - accuracy: 0.7500 - val_loss: 0.6527 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6494 - accuracy: 0.7500 - val_loss: 0.6435 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6402 - accuracy: 0.7500 - val_loss: 0.6351 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6318 - accuracy: 0.7500 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6240 - accuracy: 0.7500 - val_loss: 0.6202 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6167 - accuracy: 0.7500 - val_loss: 0.6133 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6100 - accuracy: 0.7500 - val_loss: 0.6070 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6036 - accuracy: 0.7500 - val_loss: 0.6011 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5978 - accuracy: 0.7500 - val_loss: 0.5956 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5924 - accuracy: 0.7500 - val_loss: 0.5906 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5875 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5831 - accuracy: 0.7500 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5791 - accuracy: 0.7500 - val_loss: 0.5782 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5757 - accuracy: 0.7500 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5727 - accuracy: 0.7500 - val_loss: 0.5722 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5702 - accuracy: 0.7500 - val_loss: 0.5699 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5681 - accuracy: 0.7500 - val_loss: 0.5680 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5664 - accuracy: 0.7500 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [1 3 0 0 2 3 0 3 0 3 1 3 1 0 0 2 2]\n",
      "[]\n",
      "Model: \"sequential_258\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_774 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_775 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_776 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_258 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 90ms/step - loss: 0.6911 - accuracy: 0.6216 - val_loss: 0.6864 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6848 - accuracy: 0.7500 - val_loss: 0.6816 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6801 - accuracy: 0.7500 - val_loss: 0.6773 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6750 - accuracy: 0.7500 - val_loss: 0.6713 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6689 - accuracy: 0.7500 - val_loss: 0.6660 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6635 - accuracy: 0.7500 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6583 - accuracy: 0.7500 - val_loss: 0.6561 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6533 - accuracy: 0.7500 - val_loss: 0.6514 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6483 - accuracy: 0.7500 - val_loss: 0.6466 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6434 - accuracy: 0.7500 - val_loss: 0.6420 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6386 - accuracy: 0.7500 - val_loss: 0.6374 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6338 - accuracy: 0.7500 - val_loss: 0.6328 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6291 - accuracy: 0.7500 - val_loss: 0.6283 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6245 - accuracy: 0.7500 - val_loss: 0.6239 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6200 - accuracy: 0.7500 - val_loss: 0.6196 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6156 - accuracy: 0.7500 - val_loss: 0.6153 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6113 - accuracy: 0.7500 - val_loss: 0.6112 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6071 - accuracy: 0.7500 - val_loss: 0.6071 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6030 - accuracy: 0.7500 - val_loss: 0.6032 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5991 - accuracy: 0.7500 - val_loss: 0.5995 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 3 0 3 1 3 0 1]\n",
      "Model: \"sequential_259\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_777 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_778 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_779 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_259 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 112ms/step - loss: 0.6857 - accuracy: 0.6757 - val_loss: 0.6663 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6619 - accuracy: 0.7500 - val_loss: 0.6511 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6471 - accuracy: 0.7500 - val_loss: 0.6389 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6349 - accuracy: 0.7500 - val_loss: 0.6282 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6243 - accuracy: 0.7500 - val_loss: 0.6187 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6149 - accuracy: 0.7500 - val_loss: 0.6102 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6063 - accuracy: 0.7500 - val_loss: 0.6024 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5987 - accuracy: 0.7500 - val_loss: 0.5955 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5919 - accuracy: 0.7500 - val_loss: 0.5894 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5859 - accuracy: 0.7500 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5807 - accuracy: 0.7500 - val_loss: 0.5792 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5763 - accuracy: 0.7500 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5726 - accuracy: 0.7500 - val_loss: 0.5720 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5696 - accuracy: 0.7500 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5672 - accuracy: 0.7500 - val_loss: 0.5673 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5655 - accuracy: 0.7500 - val_loss: 0.5658 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5643 - accuracy: 0.7500 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5640 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 1 3 2 0 3 0 3]\n",
      "Model: \"sequential_260\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_780 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_781 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_782 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_260 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 78ms/step - loss: 0.6856 - accuracy: 0.7432 - val_loss: 0.6744 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6710 - accuracy: 0.7500 - val_loss: 0.6635 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6607 - accuracy: 0.7500 - val_loss: 0.6549 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6523 - accuracy: 0.7500 - val_loss: 0.6473 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6447 - accuracy: 0.7500 - val_loss: 0.6400 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6376 - accuracy: 0.7500 - val_loss: 0.6333 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6310 - accuracy: 0.7500 - val_loss: 0.6271 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6248 - accuracy: 0.7500 - val_loss: 0.6211 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6189 - accuracy: 0.7500 - val_loss: 0.6154 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6134 - accuracy: 0.7500 - val_loss: 0.6101 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6081 - accuracy: 0.7500 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6031 - accuracy: 0.7500 - val_loss: 0.6002 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5984 - accuracy: 0.7500 - val_loss: 0.5958 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5941 - accuracy: 0.7500 - val_loss: 0.5916 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5900 - accuracy: 0.7500 - val_loss: 0.5878 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5863 - accuracy: 0.7500 - val_loss: 0.5842 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5828 - accuracy: 0.7500 - val_loss: 0.5810 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5797 - accuracy: 0.7500 - val_loss: 0.5780 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5768 - accuracy: 0.7500 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5743 - accuracy: 0.7500 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 2 2 1 3 1 3 3 2]\n",
      "Model: \"sequential_261\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_783 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_784 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_785 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_261 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 109ms/step - loss: 0.6943 - accuracy: 0.3176 - val_loss: 0.6912 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6868 - accuracy: 0.7500 - val_loss: 0.6760 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6724 - accuracy: 0.7500 - val_loss: 0.6644 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6612 - accuracy: 0.7500 - val_loss: 0.6554 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6522 - accuracy: 0.7500 - val_loss: 0.6476 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6444 - accuracy: 0.7500 - val_loss: 0.6405 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6373 - accuracy: 0.7500 - val_loss: 0.6340 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6307 - accuracy: 0.7500 - val_loss: 0.6278 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6245 - accuracy: 0.7500 - val_loss: 0.6220 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6186 - accuracy: 0.7500 - val_loss: 0.6164 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6130 - accuracy: 0.7500 - val_loss: 0.6111 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6077 - accuracy: 0.7500 - val_loss: 0.6060 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6026 - accuracy: 0.7500 - val_loss: 0.6008 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5975 - accuracy: 0.7500 - val_loss: 0.5960 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5928 - accuracy: 0.7500 - val_loss: 0.5916 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5884 - accuracy: 0.7500 - val_loss: 0.5874 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5844 - accuracy: 0.7500 - val_loss: 0.5836 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5808 - accuracy: 0.7500 - val_loss: 0.5801 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5775 - accuracy: 0.7500 - val_loss: 0.5770 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5745 - accuracy: 0.7500 - val_loss: 0.5742 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 0 1 0 0 1 3 3 0]\n",
      "Model: \"sequential_262\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_786 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_787 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_788 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_262 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 113ms/step - loss: 0.6816 - accuracy: 0.7500 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6536 - accuracy: 0.7500 - val_loss: 0.6348 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6280 - accuracy: 0.7500 - val_loss: 0.6166 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6109 - accuracy: 0.7500 - val_loss: 0.6034 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5983 - accuracy: 0.7500 - val_loss: 0.5930 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5885 - accuracy: 0.7500 - val_loss: 0.5848 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5808 - accuracy: 0.7500 - val_loss: 0.5783 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5749 - accuracy: 0.7500 - val_loss: 0.5733 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5704 - accuracy: 0.7500 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5673 - accuracy: 0.7500 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5652 - accuracy: 0.7500 - val_loss: 0.5652 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5639 - accuracy: 0.7500 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5632 - accuracy: 0.7500 - val_loss: 0.5634 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5628 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 3 0 3 3 1 2 0]\n",
      "Model: \"sequential_263\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_789 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_790 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_791 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_263 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 124ms/step - loss: 0.6841 - accuracy: 0.7500 - val_loss: 0.6635 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6593 - accuracy: 0.7500 - val_loss: 0.6446 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6418 - accuracy: 0.7500 - val_loss: 0.6302 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6280 - accuracy: 0.7500 - val_loss: 0.6180 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6163 - accuracy: 0.7500 - val_loss: 0.6077 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6063 - accuracy: 0.7500 - val_loss: 0.5987 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5975 - accuracy: 0.7500 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5900 - accuracy: 0.7500 - val_loss: 0.5843 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5835 - accuracy: 0.7500 - val_loss: 0.5787 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5781 - accuracy: 0.7500 - val_loss: 0.5742 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.5737 - accuracy: 0.7500 - val_loss: 0.5705 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5702 - accuracy: 0.7500 - val_loss: 0.5677 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5675 - accuracy: 0.7500 - val_loss: 0.5657 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5655 - accuracy: 0.7500 - val_loss: 0.5643 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5642 - accuracy: 0.7500 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5634 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 0 3 0 1 3 0 1]\n",
      "Model: \"sequential_264\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_792 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_793 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_794 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_264 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 86ms/step - loss: 0.6889 - accuracy: 0.6419 - val_loss: 0.6760 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6713 - accuracy: 0.7500 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6570 - accuracy: 0.7500 - val_loss: 0.6491 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6454 - accuracy: 0.7500 - val_loss: 0.6386 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6350 - accuracy: 0.7500 - val_loss: 0.6291 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6256 - accuracy: 0.7500 - val_loss: 0.6204 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6170 - accuracy: 0.7500 - val_loss: 0.6124 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6090 - accuracy: 0.7500 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6018 - accuracy: 0.7500 - val_loss: 0.5983 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5952 - accuracy: 0.7500 - val_loss: 0.5922 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5893 - accuracy: 0.7500 - val_loss: 0.5868 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5841 - accuracy: 0.7500 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5795 - accuracy: 0.7500 - val_loss: 0.5777 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5756 - accuracy: 0.7500 - val_loss: 0.5742 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5722 - accuracy: 0.7500 - val_loss: 0.5712 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5695 - accuracy: 0.7500 - val_loss: 0.5687 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5674 - accuracy: 0.7500 - val_loss: 0.5668 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5657 - accuracy: 0.7500 - val_loss: 0.5654 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5645 - accuracy: 0.7500 - val_loss: 0.5643 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5637 - accuracy: 0.7500 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 3 1 0 0 2 1 2]\n",
      "Model: \"sequential_265\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_795 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_796 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_797 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_265 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 2s 357ms/step - loss: 0.6944 - accuracy: 0.3581 - val_loss: 0.6835 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6810 - accuracy: 0.7500 - val_loss: 0.6752 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6731 - accuracy: 0.7500 - val_loss: 0.6681 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6663 - accuracy: 0.7500 - val_loss: 0.6617 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6599 - accuracy: 0.7500 - val_loss: 0.6556 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6537 - accuracy: 0.7500 - val_loss: 0.6497 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6478 - accuracy: 0.7500 - val_loss: 0.6439 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6420 - accuracy: 0.7500 - val_loss: 0.6382 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6364 - accuracy: 0.7500 - val_loss: 0.6327 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6309 - accuracy: 0.7500 - val_loss: 0.6273 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6254 - accuracy: 0.7500 - val_loss: 0.6221 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6202 - accuracy: 0.7500 - val_loss: 0.6170 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6151 - accuracy: 0.7500 - val_loss: 0.6120 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.6102 - accuracy: 0.7500 - val_loss: 0.6073 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6054 - accuracy: 0.7500 - val_loss: 0.6027 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6009 - accuracy: 0.7500 - val_loss: 0.5984 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5966 - accuracy: 0.7500 - val_loss: 0.5943 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5926 - accuracy: 0.7500 - val_loss: 0.5904 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5888 - accuracy: 0.7500 - val_loss: 0.5868 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5853 - accuracy: 0.7500 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 3 2 0 1 0 2 3 3]\n",
      "Model: \"sequential_266\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_798 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_799 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_800 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_266 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 85ms/step - loss: 0.6940 - accuracy: 0.3716 - val_loss: 0.6893 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6886 - accuracy: 0.7500 - val_loss: 0.6870 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6863 - accuracy: 0.7500 - val_loss: 0.6843 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6836 - accuracy: 0.7500 - val_loss: 0.6818 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6811 - accuracy: 0.7500 - val_loss: 0.6795 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6787 - accuracy: 0.7500 - val_loss: 0.6771 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6763 - accuracy: 0.7500 - val_loss: 0.6746 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6737 - accuracy: 0.7500 - val_loss: 0.6721 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6712 - accuracy: 0.7500 - val_loss: 0.6695 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.6685 - accuracy: 0.7500 - val_loss: 0.6668 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6658 - accuracy: 0.7500 - val_loss: 0.6641 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6631 - accuracy: 0.7500 - val_loss: 0.6613 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6603 - accuracy: 0.7500 - val_loss: 0.6586 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6574 - accuracy: 0.7500 - val_loss: 0.6557 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6545 - accuracy: 0.7500 - val_loss: 0.6528 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6516 - accuracy: 0.7500 - val_loss: 0.6499 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6486 - accuracy: 0.7500 - val_loss: 0.6469 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6456 - accuracy: 0.7500 - val_loss: 0.6439 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6425 - accuracy: 0.7500 - val_loss: 0.6409 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6395 - accuracy: 0.7500 - val_loss: 0.6378 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [3 3 0 0 2 2 0 3 1]\n",
      "Model: \"sequential_267\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_801 (Dense)           (None, 12)                65424     \n",
      "                                                                 \n",
      " dense_802 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_803 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      " flatten_267 (Flatten)       (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,537\n",
      "Trainable params: 65,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 88ms/step - loss: 0.6745 - accuracy: 0.7500 - val_loss: 0.6443 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6356 - accuracy: 0.7500 - val_loss: 0.6193 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6121 - accuracy: 0.7500 - val_loss: 0.6018 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5957 - accuracy: 0.7500 - val_loss: 0.5893 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5842 - accuracy: 0.7500 - val_loss: 0.5803 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5761 - accuracy: 0.7500 - val_loss: 0.5739 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5705 - accuracy: 0.7500 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5669 - accuracy: 0.7500 - val_loss: 0.5666 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5647 - accuracy: 0.7500 - val_loss: 0.5648 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5639 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5626 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5624 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5624 - accuracy: 0.7500 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "prediction [0 0 0 0 0 0 0 0 0]\n",
      "y_test_b [0 0 0 3 3 3 0 3 0]\n",
      "[]\n",
      "seconds value in hours: 0.0\n",
      "seconds value in minutes: 2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracies     = []\n",
    "accuracies_sd  = []\n",
    "loss           = []\n",
    "val_loss       = []\n",
    "\n",
    "feature2 = []\n",
    "labels2  = []\n",
    "\n",
    "\n",
    "times = []\n",
    "\n",
    "for label in labels:\n",
    "    for feature in features:\n",
    "        # -- Feature extraction: TF-IDF ---\n",
    "        if feature ==  'tfidf':\n",
    "\n",
    "            starttime = time.time()\n",
    "            wordvec_names, wordvec_counts = np.array(ml_tools.tf_idf(df_y2['Content'].tolist()), dtype = object)\n",
    "            y_tf                          = one_hot_enc_labels_tf(df_y2, label)\n",
    "            print('tfidf')\n",
    "\n",
    "            # NN training \n",
    "            t = NN_data_iteration(NN_optimised_parameters,  wordvec_counts, y_tf, \n",
    "                         train_sizes, num_epochs,num_iter, label, feature, 'y1', dir_name_e )\n",
    "            \n",
    "            # adding results to list\n",
    "            accuracies.append(t['accuracy'])\n",
    "            accuracies_sd.append(t['sem'])\n",
    "            loss.append(t['loss'])\n",
    "            val_loss.append(t['valloss'])\n",
    "\n",
    "            # column titles\n",
    "            feature2.append(feature)\n",
    "            labels2.append(label)\n",
    "\n",
    "            endtime = (time.time() - starttime)/60\n",
    "            times.append(convert_to_preferred_format(endtime))\n",
    "\n",
    "        # -- Feature extraction: Bag of Words ---\n",
    "        elif feature == 'bow':\n",
    "            starttime = time.time()\n",
    "            wordvec_names, wordvec_counts = np.array(ml_tools.tf_idf(df_y2['Content'].tolist()), dtype = object)\n",
    "            y_b                           = one_hot_enc_labels_bow(df_y2, label)\n",
    "            print('tfidf')\n",
    "\n",
    "            # NN training \n",
    "            t = NN_data_iteration(NN_optimised_parameters,  wordvec_counts, y_b, \n",
    "                         train_sizes, num_epochs, num_iter, label, feature, 'y1', dir_name_e )\n",
    "            \n",
    "            # adding results to list\n",
    "            accuracies.append(t['accuracy'])\n",
    "            accuracies_sd.append(t['sem'])\n",
    "            loss.append(t['loss'])\n",
    "            val_loss.append(t['valloss'])\n",
    "\n",
    "            # column titles\n",
    "            feature2.append(feature)\n",
    "            labels2.append(label)\n",
    "\n",
    "            endtime = time.time() - starttime\n",
    "            times.append(convert_to_preferred_format(endtime))\n",
    "\n",
    "df_nn_y2 = pd.DataFrame({ 'Label': labels2, 'feature extraction':feature2, 'accuracy':accuracies, 'sem': accuracies_sd, 'loss': loss, 'val_loss': val_loss, 'time':times})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df_nn_y2  = 'W5_NN_Y2_RESULTS_DF_20ephs_10iterations'\n",
    "pickle_df_nn_y2 = utils.save_as_pickle_file(df_nn_y2, name_df_nn_y2, dir_name_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickle_df_nn_y2 = utils.load_pickle_file_to_df(name_df_nn_y2, dir_name_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1980x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_graph(train_sizes, unpickle_df_nn_y2, 'NN')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. YEAR 1 & 2 NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3,4,5,6,7,7,8,9]\n",
    "print(x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bf9169aea3bf43030d2045b9506020b24091b3061df9b5cfee19d2eac11c6ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
