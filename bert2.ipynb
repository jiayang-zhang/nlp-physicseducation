{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ebp9aVPlje_yA1gfGveLdjmBTCbyT-8d","timestamp":1670259501349}],"collapsed_sections":["XwBJenjTQSO6"],"mount_file_id":"1zl0AkYFg34_0Z5JQHg4nSJD93v_ugfuZ","authorship_tag":"ABX9TyOpPrKzEkM6oLi5pqlmng1T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"b85c317fe402452e85b9df3b81b19784":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59dd899874c943afa60035bf5eeaf188","IPY_MODEL_dff19c516b3c4b11ac8e8933d80fc13f","IPY_MODEL_f59696c287ed44b2adbbd84267fde4d1"],"layout":"IPY_MODEL_9c18d46c9ef84f059cd55dd6763fd1e3"}},"59dd899874c943afa60035bf5eeaf188":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58f7ed221ca04a7c84f28dce11f0bf27","placeholder":"​","style":"IPY_MODEL_dad116ae5e46430b9afdd1f4e2cd08e5","value":"Downloading: 100%"}},"dff19c516b3c4b11ac8e8933d80fc13f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b541252cc7cc47c1bae8ad6b1b8d00dd","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0917e167d5be402c9a787a833b7d879a","value":231508}},"f59696c287ed44b2adbbd84267fde4d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b22f79ff93a4e0bbf8af34c130c944a","placeholder":"​","style":"IPY_MODEL_054f0a1b96af40c795af2fe80dea2301","value":" 232k/232k [00:00&lt;00:00, 238kB/s]"}},"9c18d46c9ef84f059cd55dd6763fd1e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58f7ed221ca04a7c84f28dce11f0bf27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dad116ae5e46430b9afdd1f4e2cd08e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b541252cc7cc47c1bae8ad6b1b8d00dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0917e167d5be402c9a787a833b7d879a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b22f79ff93a4e0bbf8af34c130c944a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"054f0a1b96af40c795af2fe80dea2301":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73b2b69a4e4d4ce49d48a8b10aecfa3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3606309958584011b488f7d49a85441d","IPY_MODEL_c9a356edb10e4815920fb47b338d83b0","IPY_MODEL_e15a77d285e9491c9438409301cb842f"],"layout":"IPY_MODEL_acc52432cfb34105b0d9f838689ac100"}},"3606309958584011b488f7d49a85441d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97dd677673c54b6fbaeb31b11b20bd5d","placeholder":"​","style":"IPY_MODEL_ca297636752442f3933bf5e0da06611b","value":"Downloading: 100%"}},"c9a356edb10e4815920fb47b338d83b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b35720356264d40b2aaa0be08b8dfd6","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1cf6f739402942da95cbf6fff0c81063","value":28}},"e15a77d285e9491c9438409301cb842f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8722d5963bb64a1aaaa1f3d6ede07907","placeholder":"​","style":"IPY_MODEL_4cbeaa48c56d494ab216abf5e44b6a17","value":" 28.0/28.0 [00:00&lt;00:00, 386B/s]"}},"acc52432cfb34105b0d9f838689ac100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97dd677673c54b6fbaeb31b11b20bd5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca297636752442f3933bf5e0da06611b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b35720356264d40b2aaa0be08b8dfd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cf6f739402942da95cbf6fff0c81063":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8722d5963bb64a1aaaa1f3d6ede07907":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cbeaa48c56d494ab216abf5e44b6a17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6468a8453cc42cfa413c01dde89d0b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e59e965396f4533a905b45ff74f4bd1","IPY_MODEL_5379bfc4a3d347f9b2b6113fca6d2a48","IPY_MODEL_c66d55e3d1d44ef880a2c114ad915d1f"],"layout":"IPY_MODEL_dc2ab29050684ee3b29f33887147ee5d"}},"0e59e965396f4533a905b45ff74f4bd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76161b20f5824786b70a09a7df2a7f7f","placeholder":"​","style":"IPY_MODEL_1236083826f34145902310cf696381db","value":"Downloading: 100%"}},"5379bfc4a3d347f9b2b6113fca6d2a48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d69c689372ae464b86544b1d563de816","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c75a01ca9c994920b2615e478a15a2cc","value":570}},"c66d55e3d1d44ef880a2c114ad915d1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fa2705ede7e49a3983065f268b3fabf","placeholder":"​","style":"IPY_MODEL_e98a2cbbf5494273ab2c545eb0d18689","value":" 570/570 [00:00&lt;00:00, 7.11kB/s]"}},"dc2ab29050684ee3b29f33887147ee5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76161b20f5824786b70a09a7df2a7f7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1236083826f34145902310cf696381db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d69c689372ae464b86544b1d563de816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c75a01ca9c994920b2615e478a15a2cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0fa2705ede7e49a3983065f268b3fabf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e98a2cbbf5494273ab2c545eb0d18689":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b112bbeb95141029dedd1c02cc672b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_782daf9cb6e145f9b1dd2396aaf4d049","IPY_MODEL_85976c178e8d4dbb880374cde215eef9","IPY_MODEL_30c8f1145d8348d794efcff2709131c7"],"layout":"IPY_MODEL_c75dd0ec09164b21a222c8f87cf336d3"}},"782daf9cb6e145f9b1dd2396aaf4d049":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a29bf26292c46ff98aadadd68083bc4","placeholder":"​","style":"IPY_MODEL_fba7cbe0d73e414f8f70a5c01395be43","value":"Downloading: 100%"}},"85976c178e8d4dbb880374cde215eef9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5b91c938b854e92a6729ee65bd72929","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0503a1c83804f619cdb03e8ebfaf35c","value":440473133}},"30c8f1145d8348d794efcff2709131c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_991c71a147a548d6b005a02f837ebdf7","placeholder":"​","style":"IPY_MODEL_a5df00d7cc314fa7bf474546500704ae","value":" 440M/440M [00:05&lt;00:00, 68.3MB/s]"}},"c75dd0ec09164b21a222c8f87cf336d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a29bf26292c46ff98aadadd68083bc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fba7cbe0d73e414f8f70a5c01395be43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5b91c938b854e92a6729ee65bd72929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0503a1c83804f619cdb03e8ebfaf35c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"991c71a147a548d6b005a02f837ebdf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5df00d7cc314fa7bf474546500704ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 1. Setup"],"metadata":{"id":"PIZC4JRqGhP5"}},{"cell_type":"markdown","source":["## 1.1 Using Colab GPU for Training\n"],"metadata":{"id":"LNeYfLE7mGul"}},{"cell_type":"markdown","source":["Run the following the cell to confirm the GPU is detected."],"metadata":{"id":"N3upHHQ1m6Zb"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0eZDJWhjmOcC","executionInfo":{"status":"ok","timestamp":1670798578672,"user_tz":0,"elapsed":217,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"986bf765-d0a0-4ef2-bbc9-79a750c15014"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"markdown","source":["In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in out training loop"],"metadata":{"id":"_bgovg_6hNCU"}},{"cell_type":"code","source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3n7WnLmpg_Hj","executionInfo":{"status":"ok","timestamp":1670798578673,"user_tz":0,"elapsed":211,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"ee5f059e-ed93-4097-b309-1fffaf9295ce"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"markdown","source":["## 1.2 Installing Hugging Face Library"],"metadata":{"id":"BH8PQKEhF0YD"}},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6DvZooRmKrn","executionInfo":{"status":"ok","timestamp":1670798551685,"user_tz":0,"elapsed":15156,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"abb51f33-071e-4232-de44-1430fdad0f7b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 30.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 62.6 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 75.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}]},{"cell_type":"markdown","source":["# 2. Retrieve Dataset"],"metadata":{"id":"TxWOmaB9GT4q"}},{"cell_type":"markdown","source":["## 2.1 Mount Google Drive"],"metadata":{"id":"L5UDujTsGY00"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4atrLvNzb0b3","executionInfo":{"status":"ok","timestamp":1670798576783,"user_tz":0,"elapsed":25105,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"93629479-a89a-4443-eaf2-e91c3767b300"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","source":["%cd\n","!pwd\n","%cd /content/gdrive/MyDrive/nlp-physicseducation/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CtXpJC70HM-H","executionInfo":{"status":"ok","timestamp":1670798576785,"user_tz":0,"elapsed":122,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"2ead8a87-fedf-4fbb-cc57-6fff6fbd458f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/root\n","/root\n","/content/gdrive/MyDrive/nlp-physicseducation\n"]}]},{"cell_type":"markdown","source":["## 2.2 Parse Data"],"metadata":{"id":"5pHTEYcyG-D9"}},{"cell_type":"markdown","source":["Specify the directories"],"metadata":{"id":"Ln_QvsjDuynn"}},{"cell_type":"code","source":["dir_csv = 'outputs/sections/labels_cleaned_y1c1c2.csv'"],"metadata":{"id":"s4EMjNyhu3bW","executionInfo":{"status":"ok","timestamp":1670798576787,"user_tz":0,"elapsed":44,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# load the dataset into a pandas dataframe\n","df = pd.read_csv(\n","        dir_csv, \n","        encoding='utf-8', \n","        skiprows = 1, \n","        names=['StudentID', 'Content', 'ArgumentLevel', 'ReasoningLevel']\n",")\n","\n","# Report the number of reports\n","print('Number of reports: {:,}\\n'.format(df.shape[0]))\n","\n","# Display 10 random rows from the data\n","df.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"id":"4-gB9Op4Fts5","executionInfo":{"status":"ok","timestamp":1670798578670,"user_tz":0,"elapsed":1925,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"6ef822df-f85a-44bd-87b2-e87e881b83c9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of reports: 96\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["             StudentID                                            Content  \\\n","80  GS_AAN562_Redacted  a graph of sinθ v m be plot for each light vio...   \n","6   GS_BYH124_Redacted  the wavelength of sodium obtain in this experi...   \n","76  GS_SUY577_Redacted  since the angle θ be measure a a function of o...   \n","33  GS_GKW379_Redacted                                           result 1   \n","67  GS_JWI426_Redacted  through the spectrometer telescope we be able ...   \n","85  GS_OXY643_Redacted  he rydberg constant be one of the most importa...   \n","24  GS_FYO506_Redacted  each measurement of the angle have an overall ...   \n","59  GS_BOD369_Redacted  a spectrometer be use to analyse the emission ...   \n","60  GS_OQP549_Redacted  in the experiment conduct we calculate with an...   \n","51  GS_DHM538_Redacted  have collect the data for a many order of diff...   \n","\n","   ArgumentLevel ReasoningLevel  \n","80   superficial            bal  \n","6    superficial            the  \n","76      extended            bal  \n","33   superficial            bal  \n","67        expert            bal  \n","85   superficial            bal  \n","24        expert            bal  \n","59        expert           none  \n","60   superficial            bal  \n","51          deep            exp  "],"text/html":["\n","  <div id=\"df-8a2816b1-8c80-4ab5-959d-b271d18a691b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>StudentID</th>\n","      <th>Content</th>\n","      <th>ArgumentLevel</th>\n","      <th>ReasoningLevel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>80</th>\n","      <td>GS_AAN562_Redacted</td>\n","      <td>a graph of sinθ v m be plot for each light vio...</td>\n","      <td>superficial</td>\n","      <td>bal</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>GS_BYH124_Redacted</td>\n","      <td>the wavelength of sodium obtain in this experi...</td>\n","      <td>superficial</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>GS_SUY577_Redacted</td>\n","      <td>since the angle θ be measure a a function of o...</td>\n","      <td>extended</td>\n","      <td>bal</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>GS_GKW379_Redacted</td>\n","      <td>result 1</td>\n","      <td>superficial</td>\n","      <td>bal</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>GS_JWI426_Redacted</td>\n","      <td>through the spectrometer telescope we be able ...</td>\n","      <td>expert</td>\n","      <td>bal</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>GS_OXY643_Redacted</td>\n","      <td>he rydberg constant be one of the most importa...</td>\n","      <td>superficial</td>\n","      <td>bal</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>GS_FYO506_Redacted</td>\n","      <td>each measurement of the angle have an overall ...</td>\n","      <td>expert</td>\n","      <td>bal</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>GS_BOD369_Redacted</td>\n","      <td>a spectrometer be use to analyse the emission ...</td>\n","      <td>expert</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>GS_OQP549_Redacted</td>\n","      <td>in the experiment conduct we calculate with an...</td>\n","      <td>superficial</td>\n","      <td>bal</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>GS_DHM538_Redacted</td>\n","      <td>have collect the data for a many order of diff...</td>\n","      <td>deep</td>\n","      <td>exp</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a2816b1-8c80-4ab5-959d-b271d18a691b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8a2816b1-8c80-4ab5-959d-b271d18a691b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8a2816b1-8c80-4ab5-959d-b271d18a691b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["The label 'ArgumentLevel' and 'ReasoningLevel' are mapped to numbers.\n","\n","Argument Level labels {'bal': 0, 'the': 1, 'exp': 2, 'none': 3}\n","\n","Reasoning Level labels {'extended': 0, 'deep': 1, 'expert': 2, 'superficial': 3, 'prediction': 4}"],"metadata":{"id":"ZfT4uprKJsRG"}},{"cell_type":"code","source":["# define dict to code labels to numbers\n","ReasoningLevel_dict = {'bal': 0, 'the': 1, 'exp': 2, 'none': 3}\n","ArgumentLevel_dict = {'extended': 0, 'deep': 1, 'expert': 2, 'superficial': 3, 'prediction': 4}\n","\n","# replace to number labels\n","df['ReasoningLevel'].replace(list(ReasoningLevel_dict.keys()), list(ReasoningLevel_dict.values()),inplace=True) \n","df['ArgumentLevel'].replace(list(ArgumentLevel_dict.keys()), list(ArgumentLevel_dict.values()),inplace=True) \n","\n","\n","# Display 10 random rows from the data\n","df.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":580},"id":"3upygP5AH0NL","executionInfo":{"status":"ok","timestamp":1670798578671,"user_tz":0,"elapsed":221,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"84e87f2e-04a3-4907-896f-fdf4654988c3"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             StudentID                                            Content  \\\n","19  GS_FHJ539_Redacted  only three of the four balmer line of hydrogen...   \n","95  GS_KGR276_Redacted  for each set of measurement for θ the mean val...   \n","21  GS_JWW382_Redacted  the final result obtain forr ∞ from this exper...   \n","82  GS_UGX035_Redacted  troscopy method with a hydrogen lamp the aim b...   \n","59  GS_BOD369_Redacted  a spectrometer be use to analyse the emission ...   \n","35  GS_HDP206_Redacted  the data for the red emission line be show in ...   \n","39  GS_DAR896_Redacted  the main source of random error which be intro...   \n","92  GS_YZI659_Redacted  displayed below in table 1 be the data for the...   \n","25  GS_CZD812_Redacted  for the red and light blue wavelength 6 readin...   \n","64  GS_YMJ516_Redacted  to verify that the data agrees with 1 the sine...   \n","\n","    ArgumentLevel  ReasoningLevel  \n","19              3               0  \n","95              3               0  \n","21              3               1  \n","82              1               0  \n","59              2               3  \n","35              3               0  \n","39              3               1  \n","92              3               1  \n","25              3               2  \n","64              3               1  "],"text/html":["\n","  <div id=\"df-5fa84486-6726-4f99-88e3-cd68b2ac82be\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>StudentID</th>\n","      <th>Content</th>\n","      <th>ArgumentLevel</th>\n","      <th>ReasoningLevel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>19</th>\n","      <td>GS_FHJ539_Redacted</td>\n","      <td>only three of the four balmer line of hydrogen...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>GS_KGR276_Redacted</td>\n","      <td>for each set of measurement for θ the mean val...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>GS_JWW382_Redacted</td>\n","      <td>the final result obtain forr ∞ from this exper...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>GS_UGX035_Redacted</td>\n","      <td>troscopy method with a hydrogen lamp the aim b...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>GS_BOD369_Redacted</td>\n","      <td>a spectrometer be use to analyse the emission ...</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>GS_HDP206_Redacted</td>\n","      <td>the data for the red emission line be show in ...</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>GS_DAR896_Redacted</td>\n","      <td>the main source of random error which be intro...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>GS_YZI659_Redacted</td>\n","      <td>displayed below in table 1 be the data for the...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>GS_CZD812_Redacted</td>\n","      <td>for the red and light blue wavelength 6 readin...</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>GS_YMJ516_Redacted</td>\n","      <td>to verify that the data agrees with 1 the sine...</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fa84486-6726-4f99-88e3-cd68b2ac82be')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5fa84486-6726-4f99-88e3-cd68b2ac82be button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5fa84486-6726-4f99-88e3-cd68b2ac82be');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Let's extract the sentences and labels of our training set as numpy ndarrys."],"metadata":{"id":"OmzBpfb-KMe1"}},{"cell_type":"code","source":["corpus = df.Content.values\n","ArgumentLevels = df.ArgumentLevel.values\n","ReasoningLevels = df.ReasoningLevel.values\n","\n","print('Number of reports: {:,}\\n'.format(len(corpus)))\n","print('First report:    ',corpus[0])\n","print('Second report:   ',corpus[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9U4SpCcQRJ8","executionInfo":{"status":"ok","timestamp":1670798578673,"user_tz":0,"elapsed":207,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"991000f7-2bf8-4cdf-9194-623500d6bf25"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of reports: 96\n","\n","First report:     where z be the atom 's atomic number 𝜀 0 be the vacuum permittivity me be the electron 's mass and e be the charge of the electron if we divide eq 2.2 by eq 2 2.6 where v and t be potential the kinetic energy of electron respectively 5 since the energy of a photon emit by a hydrogen atom be give by the difference of two hydrogen energy level where n and m be positive integer and n be great than m. from the relationship between wavelength and frequency of a photon 𝜈 𝑐 𝜆 2.9 where c be the speed of light eq 6 can be rewrite a for hydrogen atom the atomic number z be 1. therefore the rydberg constant be define a in this experiment we experimentally measure the rydberg constant if hydrogen gas be heat or electrically charge the electron in the atom be excite and the add energy push the electron to high energy orbitals when the electron fall back to their original position the add energy be re-emitted in the form of photon and the wavelength of the photon be determine by the differnece in energy between the orbitals a show in where m can be call the order number we set up the spectrometer a show in fig 3.1 use a collimator a grate and a camera with a crosshair and ensure that they be in parallel the beam of photon from the light source be diffract by the grate so we set the angular position of the camera when they be parallel a an origin and rotate it until a light fringe be observe then we measure the angle of diffraction by measure the change in angle from the origin use a vernier we repeat this with a many other fringe a possible and statisticised the result to find the rydberg constant although the rydberg constant obtain from the experiment be reasonably close to the theoretical value the uncertainty of the constant be unacceptably huge and we found that there be various reason that affected our value since the room be dark and it be hard to read the cramped number on the veriner the angle of diffraction could be measure imprecisely we conclude that this be the major factor that affected the inaccurate rydberg constant we found that the major uncertainty emerge in consequence of the wide slit size since this cause the thicker width of the light fringe this could be improve by use a narrow slit there could be various systematic error that affected the result we try to perfectly align the spectrometer but this could be unsuccessful also the position of the lamp should have be a close to the slit a possible since it be directly related to the intensity of the light this could make u see the cyan colour light the air pressure and humidity be also other source but we decide that they be negligible there be background light which be inevitably require to measure the angle of diffraction we thought this could be the reason why the cyan colour of light and the 3 rd order light fringe of red and violet light be not detect and test without any light but we still could not see the line in the experiment we try to measure the rydberg constant use a hydrogen gas tube and a spectrometer and we get 𝑅 ∞ 10.5 × 10 6 ± 4.4 × 10 6 𝑚 −1 which be only 0.4 unit less than the theoretical value however we fail to obtain the precise value a our uncertainty be over 40 percent of our value and we conclude that the width of the slit be not narrow enough to produce the precise result this could be improve by repeat the experiment in a darker room with a narrower slit width and a clearer vernier a for reference this be the code that have be use for data analysis\n","Second report:    the data that we gather from the method be summarise in table 1 and table 2 we observe the light from the licl to be red and the light from the cuso 4 to be green. this be all do in python\n"]}]},{"cell_type":"markdown","source":["# 3. Tokenization & Input Formatting\n","\n","In this section, we'll transform our dataset into the format that BERT can be trained on."],"metadata":{"id":"PmOSw5EXRmPf"}},{"cell_type":"markdown","source":["## 3.1 Tokenisation"],"metadata":{"id":"kxDtbEM0H186"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer\n","print('loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["b85c317fe402452e85b9df3b81b19784","59dd899874c943afa60035bf5eeaf188","dff19c516b3c4b11ac8e8933d80fc13f","f59696c287ed44b2adbbd84267fde4d1","9c18d46c9ef84f059cd55dd6763fd1e3","58f7ed221ca04a7c84f28dce11f0bf27","dad116ae5e46430b9afdd1f4e2cd08e5","b541252cc7cc47c1bae8ad6b1b8d00dd","0917e167d5be402c9a787a833b7d879a","2b22f79ff93a4e0bbf8af34c130c944a","054f0a1b96af40c795af2fe80dea2301","73b2b69a4e4d4ce49d48a8b10aecfa3b","3606309958584011b488f7d49a85441d","c9a356edb10e4815920fb47b338d83b0","e15a77d285e9491c9438409301cb842f","acc52432cfb34105b0d9f838689ac100","97dd677673c54b6fbaeb31b11b20bd5d","ca297636752442f3933bf5e0da06611b","4b35720356264d40b2aaa0be08b8dfd6","1cf6f739402942da95cbf6fff0c81063","8722d5963bb64a1aaaa1f3d6ede07907","4cbeaa48c56d494ab216abf5e44b6a17","d6468a8453cc42cfa413c01dde89d0b6","0e59e965396f4533a905b45ff74f4bd1","5379bfc4a3d347f9b2b6113fca6d2a48","c66d55e3d1d44ef880a2c114ad915d1f","dc2ab29050684ee3b29f33887147ee5d","76161b20f5824786b70a09a7df2a7f7f","1236083826f34145902310cf696381db","d69c689372ae464b86544b1d563de816","c75a01ca9c994920b2615e478a15a2cc","0fa2705ede7e49a3983065f268b3fabf","e98a2cbbf5494273ab2c545eb0d18689"]},"id":"gx5dgBinVS2N","executionInfo":{"status":"ok","timestamp":1670798587317,"user_tz":0,"elapsed":8847,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"fb4fc409-ea61-4a11-e938-d6dc3d16a6c5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["loading BERT tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b85c317fe402452e85b9df3b81b19784"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b2b69a4e4d4ce49d48a8b10aecfa3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6468a8453cc42cfa413c01dde89d0b6"}},"metadata":{}}]},{"cell_type":"markdown","source":["Now we're ready to perform the real tokenization.\n","\n","The `tokenizer.encode_plus` function combines multiple steps for us:\n","\n","1. Split the sentence into tokens.\n","2. Add the special `[CLS]` and `[SEP]` tokens.\n","3. Map the tokens to their IDs.\n","4. Pad or truncate all sentences to the same length.\n","5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n","\n","The first four features are in `tokenizer.encode`, but I'm using `tokenizer.encode_plus` to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus).\n"],"metadata":{"id":"nfxyOJYug5F1"}},{"cell_type":"code","source":["# Tokenize all of the reports and map the tokens to their word IDs.\n","input_ids, attention_masks = [], []\n","lengths = []\n","\n","# For every report ...\n","for report in corpus:\n","    # 'encode_plus' will:\n","    #   (1) Tokenise the sentence.\n","    #   (2) Prepend the '[CLS]' token to the start\n","    #   (3) Append the '[SEP]' token to the end\n","    #   (4) Map tokens to their IDs\n","    #   (5) Pad or truncate the report to 'max_length'\n","    #   (6) Create attention masks for [PAD] tokens\n","    encoded_dict = tokenizer.encode_plus(\n","                        report,                     # report to encode\n","                        add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,            # Pad & truncate all reports\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks\n","                        return_tensors = 'pt',          # return pytorch tensors\n","\n","    )\n","\n","    # Add the encoded report to the list \n","    input_ids.append(encoded_dict['input_ids'])\n","\n","    # And its attention mask (simply differentiates padding from non-padding)\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","    # lengths.append(len(encoded_dict['input_ids']))\n","    lengths.append(len(encoded_dict['input_ids'][0]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4M7BBNLMg4op","executionInfo":{"status":"ok","timestamp":1670798590126,"user_tz":0,"elapsed":2827,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"191a5a33-840c-486e-e96b-36f2ec7220b2"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["Set which label type to train with; and convert input lists of tensors."],"metadata":{"id":"VRmQt6adGKPW"}},{"cell_type":"code","source":["# Train with ...\n","trainwith = ArgumentLevels #or #ReasoningLevels\n","\n","# Convert the lists into tensors\n","input_ids = torch.cat(input_ids, dim = 0)\n","attention_masks = torch.cat(attention_masks, dim = 0)\n","labels = torch.tensor(trainwith)"],"metadata":{"id":"JxSdH_cxGN98","executionInfo":{"status":"ok","timestamp":1670798590131,"user_tz":0,"elapsed":28,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Print report 0, now as a list of IDs\n","print('Original:', corpus[0])\n","print('Token IDs:', input_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBNaFKj8Hm4J","executionInfo":{"status":"ok","timestamp":1670798590132,"user_tz":0,"elapsed":28,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"51713808-96dd-426b-9c4f-721e0da958e3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Original: where z be the atom 's atomic number 𝜀 0 be the vacuum permittivity me be the electron 's mass and e be the charge of the electron if we divide eq 2.2 by eq 2 2.6 where v and t be potential the kinetic energy of electron respectively 5 since the energy of a photon emit by a hydrogen atom be give by the difference of two hydrogen energy level where n and m be positive integer and n be great than m. from the relationship between wavelength and frequency of a photon 𝜈 𝑐 𝜆 2.9 where c be the speed of light eq 6 can be rewrite a for hydrogen atom the atomic number z be 1. therefore the rydberg constant be define a in this experiment we experimentally measure the rydberg constant if hydrogen gas be heat or electrically charge the electron in the atom be excite and the add energy push the electron to high energy orbitals when the electron fall back to their original position the add energy be re-emitted in the form of photon and the wavelength of the photon be determine by the differnece in energy between the orbitals a show in where m can be call the order number we set up the spectrometer a show in fig 3.1 use a collimator a grate and a camera with a crosshair and ensure that they be in parallel the beam of photon from the light source be diffract by the grate so we set the angular position of the camera when they be parallel a an origin and rotate it until a light fringe be observe then we measure the angle of diffraction by measure the change in angle from the origin use a vernier we repeat this with a many other fringe a possible and statisticised the result to find the rydberg constant although the rydberg constant obtain from the experiment be reasonably close to the theoretical value the uncertainty of the constant be unacceptably huge and we found that there be various reason that affected our value since the room be dark and it be hard to read the cramped number on the veriner the angle of diffraction could be measure imprecisely we conclude that this be the major factor that affected the inaccurate rydberg constant we found that the major uncertainty emerge in consequence of the wide slit size since this cause the thicker width of the light fringe this could be improve by use a narrow slit there could be various systematic error that affected the result we try to perfectly align the spectrometer but this could be unsuccessful also the position of the lamp should have be a close to the slit a possible since it be directly related to the intensity of the light this could make u see the cyan colour light the air pressure and humidity be also other source but we decide that they be negligible there be background light which be inevitably require to measure the angle of diffraction we thought this could be the reason why the cyan colour of light and the 3 rd order light fringe of red and violet light be not detect and test without any light but we still could not see the line in the experiment we try to measure the rydberg constant use a hydrogen gas tube and a spectrometer and we get 𝑅 ∞ 10.5 × 10 6 ± 4.4 × 10 6 𝑚 −1 which be only 0.4 unit less than the theoretical value however we fail to obtain the precise value a our uncertainty be over 40 percent of our value and we conclude that the width of the slit be not narrow enough to produce the precise result this could be improve by repeat the experiment in a darker room with a narrower slit width and a clearer vernier a for reference this be the code that have be use for data analysis\n","Token IDs: tensor([  101,  2073,  1062,  2022,  1996, 13787,  1005,  1055,  9593,  2193,\n","          100,  1014,  2022,  1996, 11641,  9146, 29068,  3012,  2033,  2022,\n","         1996, 10496,  1005,  1055,  3742,  1998,  1041,  2022,  1996,  3715,\n","         1997,  1996, 10496,  2065,  2057, 11443,  1041,  4160,  1016,  1012,\n","         1016,  2011,  1041,  4160,  1016,  1016,  1012,  1020,  2073,  1058,\n","         1998,  1056,  2022,  4022,  1996, 20504,  2943,  1997, 10496,  4414,\n","         1019,  2144,  1996,  2943,  1997,  1037, 26383, 12495,  2102,  2011,\n","         1037,  9732, 13787,  2022,  2507,  2011,  1996,  4489,  1997,  2048,\n","         9732,  2943,  2504,  2073,  1050,  1998,  1049,  2022,  3893, 16109,\n","         1998,  1050,  2022,  2307,  2084,  1049,  1012,  2013,  1996,  3276,\n","         2090, 19934,  1998,  6075,  1997,  1037, 26383,   100,   100,   100,\n","         1016,  1012,  1023,  2073,  1039,  2022,  1996,  3177,  1997,  2422,\n","         1041,  4160,  1020,  2064,  2022,  2128, 26373,  1037,  2005,  9732,\n","        13787,  1996,  9593,  2193,  1062,  2022,  1015,  1012,  3568,  1996,\n","        29431, 25190,  5377,  2022,  9375,  1037,  1999,  2023,  7551,  2057,\n","         6388,  2135,  5468,  1996, 29431, 25190,  5377,  2065,  9732,  3806,\n","         2022,  3684,  2030, 29103,  3715,  1996, 10496,  1999,  1996, 13787,\n","         2022,  4654, 17847,  1998,  1996,  5587,  2943,  5245,  1996, 10496,\n","         2000,  2152,  2943, 13943,  2015,  2043,  1996, 10496,  2991,  2067,\n","         2000,  2037,  2434,  2597,  1996,  5587,  2943,  2022,  2128,  1011,\n","        22627,  1999,  1996,  2433,  1997, 26383,  1998,  1996, 19934,  1997,\n","         1996, 26383,  2022,  5646,  2011,  1996, 11234,  2638,  3401,  1999,\n","         2943,  2090,  1996, 13943,  2015,  1037,  2265,  1999,  2073,  1049,\n","         2064,  2022,  2655,  1996,  2344,  2193,  2057,  2275,  2039,  1996,\n","        28699, 13887, 15141,  1037,  2265,  1999, 20965,  1017,  1012,  1015,\n","         2224,  1037,  8902, 17960,  8844,  1037, 24665,  3686,  1998,  1037,\n","         4950,  2007,  1037,  2892, 26227,  1998,  5676,  2008,  2027,  2022,\n","         1999,  5903,  1996,  7504,  1997, 26383,  2013,  1996,  2422,  3120,\n","         2022,  4487,  4246, 22648,  2102,  2011,  1996, 24665,  3686,  2061,\n","         2057,  2275,  1996, 16108,  2597,  1997,  1996,  4950,  2043,  2027,\n","         2022,  5903,  1037,  2019,  4761,  1998, 24357,  2009,  2127,  1037,\n","         2422, 13548,  2022, 11949,  2059,  2057,  5468,  1996,  6466,  1997,\n","         4487,  4246, 25533,  2011,  5468,  1996,  2689,  1999,  6466,  2013,\n","         1996,  4761,  2224,  1037,  2310, 28484,  2057,  9377,  2023,  2007,\n","         1037,  2116,  2060, 13548,  1037,  2825,  1998, 28093,  6553,  5084,\n","         1996,  2765,  2000,  2424,  1996, 29431, 25190,  5377,  2348,  1996,\n","        29431, 25190,  5377,  6855,  2013,  1996,  7551,  2022, 16286,  2485,\n","         2000,  1996,  9373,  3643,  1996, 12503,  1997,  1996,  5377,  2022,\n","        14477,  9468, 23606,  8231,  4121,  1998,  2057,  2179,  2008,  2045,\n","         2022,  2536,  3114,  2008,  5360,  2256,  3643,  2144,  1996,  2282,\n","         2022,  2601,  1998,  2009,  2022,  2524,  2000,  3191,  1996, 22766,\n","         2193,  2006,  1996,  2310, 11467,  2099,  1996,  6466,  1997,  4487,\n","         4246, 25533,  2071,  2022,  5468, 17727,  2890, 18380,  2135,  2057,\n","        16519,  2008,  2023,  2022,  1996,  2350,  5387,  2008,  5360,  1996,\n","        24949, 29431, 25190,  5377,  2057,  2179,  2008,  1996,  2350, 12503,\n","        12636,  1999,  9509,  1997,  1996,  2898, 18036,  2946,  2144,  2023,\n","         3426,  1996, 19638,  9381,  1997,  1996,  2422, 13548,  2023,  2071,\n","         2022,  5335,  2011,  2224,  1037,  4867, 18036,  2045,  2071,  2022,\n","         2536, 11778,  7561,  2008,  5360,  1996,  2765,  2057,  3046,  2000,\n","         6669, 25705,  1996, 28699, 13887, 15141,  2021,  2023,  2071,  2022,\n","         7736,  2036,  1996,  2597,  1997,  1996, 10437,  2323,  2031,  2022,\n","         1037,   102])\n"]}]},{"cell_type":"markdown","source":["## 3.2 Report Length distribution (Discarded)\n"],"metadata":{"id":"XwBJenjTQSO6"}},{"cell_type":"code","source":["import numpy as np\n","print('Min length: {:,} tokens'.format(min(lengths)))\n","print('Max length: {:,} tokens'.format(max(lengths)))\n","print('Median length: {:,} tokens'.format(np.median(lengths)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaTbhoegXmiF","executionInfo":{"status":"ok","timestamp":1670798590132,"user_tz":0,"elapsed":26,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"ac25838b-d638-4b5d-cd28-c50f0c8f9e87"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Min length: 512 tokens\n","Max length: 512 tokens\n","Median length: 512.0 tokens\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np \n","\n","sns.set(style = 'darkgrid')\n","\n","# Increase the plot size and font size\n","sns.set(font_scale = 1.5)\n","plt.rcParams[\"figure.figsize\"] = (10,5)\n","\n","# Truncate any report lengths greater than 512\n","lengths = [min(l,512) for l in lengths]\n","\n","# Plot the distribution of comment lengths\n","sns.displot(lengths, kde=False, rug=False)\n","\n","plt.title(\"Report Lengths\")\n","plt.xlabel(\"Report Length\")\n","plt.ylabel(\"# of Reports\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"2EXPYdmOQR7l","executionInfo":{"status":"ok","timestamp":1670798591495,"user_tz":0,"elapsed":1378,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"df40e087-6f0e-4787-ea2a-4ac22f53d573"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(10.314999999999998, 0.5, '# of Reports')"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"text/plain":["<Figure size 360x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["How many data (reports) could be faulty? "],"metadata":{"id":"IyD2pukar1QO"}},{"cell_type":"code","source":["# Count the number of suspicious reports that didn't not have full text extracted \n","counter = 0\n","for l in lengths:\n","    if l<20:\n","        counter+=1\n","print('# of possible faulty reports: ', counter)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yLVlc7Er8cI","executionInfo":{"status":"ok","timestamp":1670798591958,"user_tz":0,"elapsed":481,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"e6399023-0a75-43d8-80d6-4b7557422d26"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["# of possible faulty reports:  0\n"]}]},{"cell_type":"markdown","source":["How many reports run into the 512-token limit?"],"metadata":{"id":"6haaD5vpf-Qy"}},{"cell_type":"code","source":["# Count the number of sentences that had to be truncated to 512 tokens\n","num_truncated = lengths.count(512)\n","\n","# Compare this to the total number of training reports\n","num_reports = len(lengths)\n","prcnt = float(num_truncated)/float(num_reports)\n","\n","print('{:,} of {:,} sentences ({:.1%}) of corpus are longer than 512 tokens'.format(\n","        num_truncated, num_reports, prcnt))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKHvKyv6gExI","executionInfo":{"status":"ok","timestamp":1670798591960,"user_tz":0,"elapsed":72,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"e2bdbe00-37fd-4935-8b07-50c04c3af502"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["96 of 96 sentences (100.0%) of corpus are longer than 512 tokens\n"]}]},{"cell_type":"markdown","source":["## 3.3 Training and Validation Split\n","\n","Divde up our training set to use 90% for training and 10% for validation"],"metadata":{"id":"ytev8umirwoF"}},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# define a function for train-validation data splitting\n","def train_val_split(dataset, ratio):\n","    '''\n","    # Create a ratio:(1-ratio) train-validation split\n","    \n","    dataset: tensor object\n","    ratio: float <1 and >0\n","    '''\n","    # Calculate the number of samples to include in each set\n","    train_size = int(ratio * len(dataset))\n","    val_size = len(dataset) - train_size\n","\n","    # Divide the dataset by randomly selecting samples\n","    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","    print('{:>5,} training samples'.format(train_size))\n","    print('{:>5,} validation samples'.format(val_size))\n","    \n","    return train_dataset, val_dataset\n","\n","\n","# execute the function\n","train_ratios = [0.9] #[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n","for ratio in train_ratios:\n","    train_dataset, val_dataset = train_val_split(dataset, ratio)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U6RH18vaWTkq","executionInfo":{"status":"ok","timestamp":1670799212065,"user_tz":0,"elapsed":390,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"outputId":"f6f6b216-a0bf-4204-a86d-5f4624949904"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["   86 training samples\n","   10 validation samples\n"]}]},{"cell_type":"markdown","source":["We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."],"metadata":{"id":"AUmDEtrFtS2w"}},{"cell_type":"code","source":["from tensorflow.python.ops.variables import validate_synchronization_aggregation_trainable\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n","# size of 16 or 32.\n","batch_size = 16\n","\n","def loader(train_dataset, val_dataset, batch_size):\n","\n","    # Create the DataLoaders for our training and validation sets.\n","    # We'll take training samples in random order\n","    train_dataloader = DataLoader(\n","                        train_dataset,                  # the trainig samples\n","                        sampler = RandomSampler(train_dataset), # select batches randomly\n","                        batch_size = batch_size,        # trains with this batch size\n","    )\n","\n","    # For validation the order doesn't matter, so we'll just read them sequentially\n","    validation_dataloader = DataLoader(\n","                        val_dataset,                # the validation samples\n","                        sampler = SequentialSampler(val_dataset), # Pull out batches sequentially\n","                        batch_size = batch_size     # evaluate with this batch size\n","    )\n","    return train_dataloader, validation_dataloader\n","\n","loader(train_dataset, val_dataset, batch_size)\n"],"metadata":{"id":"dfotlmpFtSgw","executionInfo":{"status":"ok","timestamp":1670799219138,"user_tz":0,"elapsed":653,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"17b5ec43-83e0-42ba-b452-dfc4b45136af"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7f806c4d6a60>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7f806c4d6130>)"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["**what is batch size?**\n","\n","In the neural network terminology:\n","\n","\n","*   one epoch = one forward pass and one backward pass of all the training examples\n","*   batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n","*   number of iterations = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes).\n","\n","\n","Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.\n"],"metadata":{"id":"Sgr1-3dq5tMU"}},{"cell_type":"markdown","source":["4. Train Classification Model\n","\n","Now that the input data is properly formatted, it's time to fine tune the BERT model."],"metadata":{"id":"OLx84Fmq7mnM"}},{"cell_type":"markdown","source":["4.1 BertForSequenceClassification\n","\n","For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until the entire model, end-to-end, is well-suited for our task.\n","\n","Thankfully, the huggingface pytorch implementation included a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.\n","\n","Here the current list of classes provided for fine-tuning:\n","* BertModel\n","* BertForPreTraining\n","* BertForMaskedLM\n","* BertForNextSentencePrediction\n","* **BertForSequenceClassification** - The one we'll use.\n","* BertForTokenClassification\n","* BertForQuestionAnswering\n","\n","The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html).\n","\n","\n","We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n","\n","\n","OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n","\n","The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."],"metadata":{"id":"cr7u0rZbvRL5"}},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification, the pre-trained BERT model with a \n","# single linear classification layer on top.\n","\n","model = BertForSequenceClassification.from_pretrained(\n","        \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab\n","        num_labels = 5, # the number of ourput labels -- 5 for five ArgumentLevel classification labels\n","        output_attentions = False, # whether the model returns attention weights\n","        output_hidden_states = False, # whether the model returns all hidden-states\n",")\n","\n","# Tell pytorch to run this model on the GPU\n","model.cuda()"],"metadata":{"id":"TOUbbujd7coW","executionInfo":{"status":"ok","timestamp":1670799341121,"user_tz":0,"elapsed":9862,"user":{"displayName":"Jiayang Zhang","userId":"01870170909349403002"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7b112bbeb95141029dedd1c02cc672b6","782daf9cb6e145f9b1dd2396aaf4d049","85976c178e8d4dbb880374cde215eef9","30c8f1145d8348d794efcff2709131c7","c75dd0ec09164b21a222c8f87cf336d3","5a29bf26292c46ff98aadadd68083bc4","fba7cbe0d73e414f8f70a5c01395be43","c5b91c938b854e92a6729ee65bd72929","c0503a1c83804f619cdb03e8ebfaf35c","991c71a147a548d6b005a02f837ebdf7","a5df00d7cc314fa7bf474546500704ae"]},"outputId":"f894d1a8-a566-40db-c645-c80ea5df7339"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b112bbeb95141029dedd1c02cc672b6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",")"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["4.2 Optimiser & Learning Rate Scheduler\n","\n","Now that we have our model loaded we need to grab the training hyperparameters from within the stored model. \n","\n","For the purpose of fine-tuning, the authors recommend choosing from following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n","\n",">- **Batch size:** 16, 32  \n","- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n","- **Number of epochs:** 2, 3, 4 \n","\n","We chose:\n","* Batch size: 32 (set when creating our DataLoaders)\n","* Learning rate: 2e-5\n","* Epochs: 4 (we'll see that this is probably too many...)\n","\n","\n","The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n","\n","You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."],"metadata":{"id":"6f-2da6EzT4E"}},{"cell_type":"code","source":["# Note: AdamW is a class from the huggingface library (as opposed to pytroch)\n","# I believe the 'W' stands for 'Weight Decay Fix'\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,  # args.learning rate - default is 5e-5\n","                  eps = 1e-8, # args.adam_epsilon - default is 1e-8\n","                \n",")"],"metadata":{"id":"LJX06bRyzTKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommended between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting \n","# the training data.\n","epochs = 10\n","\n","# Total number of training steps is [number of batches] x [number of epochs]\n","# [Note that this is not the same as the number of training samples]\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps,\n","                                            )\n"],"metadata":{"id":"hpDWpR020kPj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4.3 Training loop\n","\n","Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n","\n","> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n","\n","Training: \n","* Unpack our data inputs and labels \n","* Load data onto GPU for acceleration\n","* Clear out the gradients calculated in the previous pass\n","    * In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out\n","* Forward pass (feed input data through the network)\n","* Backward pass (backpropagation)\n","* Tell the network to update parameters with optimizer.step()\n","* Track variables for minitoring progress\n","\n","Evaluation:\n","* Unpack our data inputs and labels\n","* Load data onto the GPU for acceleration\n","* Forward pass (feed input data through the network)\n","* Compute loss on our validation data and track variables for monitoring process\n","\n","\n","Pytorch hides all the detailed calculations from us, but we've commented the code to print out which of the above steps are happening on each line.\n","\n","> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"],"metadata":{"id":"-arhBqEY4I-r"}},{"cell_type":"markdown","source":["Define a helper function for calculating accuracy."],"metadata":{"id":"Boc5UjsH7EkN"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"tyUfj0324InA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helper function for formatting elapsed times as hh:mm:ss"],"metadata":{"id":"jP3rJQq4F-zN"}},{"cell_type":"code","source":["import time \n","import datetime\n","def format_time(elapsed):\n","    '''\n","    Taks a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second\n","    elapsed_rounded = int(round(elapsed))\n","\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds = elapsed_rounded))"],"metadata":{"id":"GCoBT8N50kIm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We're ready to kick off training!"],"metadata":{"id":"hSB875iIGe5c"}},{"cell_type":"code","source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # In PyTorch, calling `model` will in turn call the model's `forward` \n","        # function and pass down the arguments. The `forward` function is \n","        # documented here: \n","        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n","        # The results are returned in a results object, documented here:\n","        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n","        # Specifically, we'll get the loss (because we provided labels) and the\n","        # \"logits\"--the model outputs prior to activation.\n","        result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","        loss = result.loss\n","        logits = result.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"id":"y4euZ-vaGeYz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's view the summary of the training process."],"metadata":{"id":"-eJilZ9_1W7A"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"metadata":{"id":"L52Kumm31Wmx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice that, (If) while the training loss is going down with each epoch, the validation loss is increasing! This suggests that we are training our model too long, and it's over-fitting on the training data. \n","\n","(For reference, we are using 7,695 training samples and 856 validation samples).\n","\n","Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on. \n","\n","If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not.\n","\n","\n"],"metadata":{"id":"W2aDlbLG1o_0"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"rBwtofW32kdt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. Performance on Test Set"],"metadata":{"id":"YsdFtpZ94gPu"}},{"cell_type":"markdown","source":["5.1 Data Preparation"],"metadata":{"id":"rU_BBWgy4lK_"}},{"cell_type":"code","source":["# Create the DataLoader.\n","prediction_data = val_dataset\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = validation_dataloader"],"metadata":{"id":"PRXxjlsM5RZ2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5.2 Evaluate on Test Set"],"metadata":{"id":"DHFs1AkB434s"}},{"cell_type":"code","source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test reports...'.format(len(val_dataset)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions.\n","      result = model(b_input_ids, \n","                     token_type_ids=None, \n","                     attention_mask=b_input_mask,\n","                     return_dict=True)\n","\n","  logits = result.logits\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","print('    DONE.')"],"metadata":{"id":"8KMdiBA9422k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n","\n","We use MCC here because the classes are imbalanced:\n"],"metadata":{"id":"SXlId81P6Kh2"}},{"cell_type":"code","source":["from sklearn.metrics import matthews_corrcoef\n","\n","matthews_set = []\n","\n","# Evaluate each test batch using Matthew's correlation coefficient\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","\n","# For each input batch...\n","for i in range(len(true_labels)):\n","  \n","  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n","  # and one column for \"1\"). Pick the label with the highest value and turn this\n","  # in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  \n","  # Calculate and store the coef for this batch.  \n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n","  matthews_set.append(matthews)"],"metadata":{"id":"jJD1D-g86NUs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The final score will be based on the entire test set, but let's take a look at the scores on the individual batches to get a sense of the variability in the metric between batches. \n","\n","Each batch has 32 sentences in it, except the last batch which has only (516 % 32) = 4 test sentences in it.\n"],"metadata":{"id":"Kx7kqXn6D6VY"}},{"cell_type":"code","source":["# Create a barplot showing the MCC score for each batch of test samples.\n","ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n","\n","plt.title('MCC Score per Batch')\n","plt.ylabel('MCC Score (-1 to +1)')\n","plt.xlabel('Batch #')\n","\n","plt.show()"],"metadata":{"id":"poxIZ-UiD-GZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Combine the results across all batches. \n","flat_predictions = np.concatenate(predictions, axis=0)\n","\n","# For each sample, pick the label (0 or 1) with the higher score.\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n","\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","\n","print('Total MCC: %.3f' % mcc)"],"metadata":{"id":"Nyuwg22cEFWy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["When we actually convert all of our sentences, we'll use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately. \n","\n","Before we can do that, though, we need to talk about some of BERT's formatting requirements."],"metadata":{"id":"dJOEigZaddtC"}},{"cell_type":"code","source":["# Print the original report.\n","print('length:',len(corpus[0]),';  Original: ', corpus[0])\n","\n","# Print the report split into tokens.\n","print('length:',len(tokenizer.tokenize(corpus[0])),';  Tokenized: ', tokenizer.tokenize(corpus[0]))\n","\n","# Print the report mapped to token ids.\n","print('length:',len(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(corpus[0]))) , ';  Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(corpus[0])))"],"metadata":{"id":"aGYv9paXSDm9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's apply the tokenizer to one report just to see the output."],"metadata":{"id":"RgPW9ujVSFLv"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"metadata":{"id":"hrik8ScLRlkd"},"execution_count":null,"outputs":[]}]}