{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a Gridsearch across LDA Parameters\n",
    "\n",
    "In this notebook, we run a \"grid search\" across different LDA parameters to see what effects they have on the resulting LDA models. \n",
    "\n",
    "There are several tunable parameters that one feeds into an LDA model. They include:\n",
    "* The data filtering parameterâ€”essentially, how much of the data you choose to keep, and what you choose to filter out. In practice, this usually involves specifying cutoffs for words that are too rare (i.e., which occur less than 5 times across the dataset) or too frequent (i.e., occur in most papers and so add little value to the analysis).\n",
    "* The number of topics. This one is fairly obvious, but also greatly affects model results and is not obvious a priori. Sometimes a greater number of topics can provide more detailed insights into the data, but greater numbers of topics can also hinder interpretability (for example, imagine trying to distinguish between 50 topics, where many of them are very similar)\n",
    "\n",
    "Going in to the analysis, we weren't sure which of these topics were most meaningful, and how they would affect our model results. So, we decided to try to approach the question quantitatively, by running a lot of different models while tuning the parameters slightly with each run, then comparing the outputs using the \"topic coherence\" scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Importing packages and unpacking our data\n",
    "\n",
    "The first thing we do is import our various packages, and unpack our processed data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print out  all expressions\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" #default 'last_expr'\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning);\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#import nltk\n",
    "#from nltk.corpus import wordnet\n",
    "#from nltk import pos_tag\n",
    "#nltk.download('wordnet',quiet=True)\n",
    "#nltk.download('averaged_perceptron_tagger',quiet=True) #required by pos_tag method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import path_pdf,path_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we unpack here is our lemmatized data. However, we have not created bigrams yet. We do that now, using a machine learning method (the gensim Phraser) to make bi-grams. These are essentially combinations of words that consistently occur together. When the algorithm finds a pair like this (based on thresholds we specify with min_count and threshold), it will associate them together into a single word. We save it as the file \"data_words_bigrams\" which we will use for most of our analysis from here on out.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_words_bigrams = pd.read_pickle(path_pkl+'scied_words_bigrams_V5.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Creating a bag of words on the dataset\n",
    "\n",
    "In order to use LDA, we need to create a [Gensim Dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary), which is a mapping between each of the entries (i.e. normalized words) and its integer id. \n",
    "\n",
    "We also use the \"filter_extremes\" function that gensim provides. This allows us to filter out words that appear too many or too few times. The parameters are:\n",
    "* **no_below**: an integer. Keep tokens which are contained in at least no_below documents.  \n",
    "* **no_above**: a float number between 0 and 1. It filters out tokens which are contained in more than no_above percentage of documents. E.g. with no_above=0.55, tokens in in more than 55% of the documents get cut out. So, the smaller this value, the harsher the filtering.\n",
    "* **keep_n**: an integer. It specifies how many tokens should be kept, starting with the most frequent.\n",
    "\n",
    "This table (hidden) shows how many words are left after filtering. The a no_above parameter of 0.5-1.0 filters out just a hundred words\n",
    "\n",
    "<!--\n",
    "|no_above | unique words, no_below=0 |\n",
    "|: --  | -- |\n",
    "| 1.0  | 27830  |\n",
    "| 0.75 | 27801  |\n",
    "| 0.55 | 27730  |\n",
    "| 0.5  | 27710  |\n",
    "| 0.2  | 27274  |\n",
    "\n",
    "|no_above | unique words, no_below=2 |\n",
    "|: -- | -- |\n",
    "| 1.0 - 0.9  |  3008  |\n",
    "| 0.85 - 0.75  | 3007  |\n",
    "| 0.7 - 0.5   | 3006  |\n",
    "| 0.4      |  3004 | \n",
    "| 0.35 - 0.3  | 3002  |\n",
    "| 0.25      | 2997  |\n",
    "\n",
    "|no_above | unique words, no_below=5 |\n",
    "|: -- | -- |\n",
    "| 0.5-0.25      | 1731  |\n",
    "\n",
    "|no_above | unique words, no_below=10 |\n",
    "|: -- | -- |\n",
    "| 0.5-0.25      | 1040  |\n",
    "-->\n",
    "After the filtering we convert the remaining tokens into a \"bag of words\" (BoW), which is essentially a matrix, shape (number of documents x number of remaining words) with each entry being the number of times that word occurs in that document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search on LDA: find best num_topics, filtering values\n",
    "\n",
    "### A. Defining a function to search across number of topics\n",
    "\n",
    "This is a function to do a gridsearch across a set of topics numbers (for example, 8-12 topics). In addition to the ordinary parameters required to run the LDA model (the dictionary, corpus, texts) it also takes a range of topics, a number of repetitions, and a starting value of a random seed (to make the models reproducible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_topics(dictionary, corpus, texts, range_topics, reps = 1, seedstart=0, iterations=15, passes=25):\n",
    "    \"\"\"\n",
    "    Grid Search on number of topics and the Gensim Dictionary parameters no_below and no_above using c_v coherence\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary for CoherenceModel (id2word)\n",
    "    corpus : Gensim corpus for LdaModel (bow_corpus)\n",
    "    texts : List of input texts for CoherenceModel (data_words_bigrams)\n",
    "    range_topics : range with the number of topics for Gensim LdaModel\n",
    "    reps: repetitions of a particular run. Useful for creating uncertainty intervals\n",
    "    **kw_LDA : parameters to LDA model\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    df: a dataframe containing the number of topics, coherence values, stored models, and the dictionary\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherences = []\n",
    "    model_list = []\n",
    "    df = pd.DataFrame()\n",
    "    import time\n",
    "    counter = 0    \n",
    "    #Iterate on number of topics and run LDA\n",
    "    for num_topics in range_topics:\n",
    "        #Run repetitions\n",
    "        i = 0\n",
    "        seed = seedstart #initialize the random seeds we'll give to the model\n",
    "        t0 = time.time()        \n",
    "        while i < reps:\n",
    "            model = gensim.models.LdaModel(corpus, num_topics, dictionary,\n",
    "                                               alpha='auto', random_state = seed,\n",
    "                                               iterations=iterations, passes=passes)\n",
    "            model_list.append(model)\n",
    "            #Calculate coherence\n",
    "            coherencemodel = gensim.models.CoherenceModel(model=model, \n",
    "                                                          texts=texts, \n",
    "                                                          dictionary=dictionary, \n",
    "                                                          coherence='c_v',\n",
    "                                                          topn=20)\n",
    "            coherence = coherencemodel.get_coherence()\n",
    "            coherences.append(coherence)\n",
    "            #Append to DataFrame\n",
    "            df = df.append(pd.Series([int(num_topics), coherence, model, seed]), ignore_index=True)\n",
    "            seed = seed + 1\n",
    "            i = i + 1\n",
    "            if i%10 == 0: \n",
    "                t2 = round(time.time()-t0)\n",
    "                t2 = \"\"\"%d'%d\" \"\"\" % ((t2-t2%60)/60, t2%60)\n",
    "                msg = \"Finished run %d of %d (k = %d): %s\" % (i, reps, num_topics, t2)\n",
    "                print(msg)\n",
    "        \n",
    "        #Print info\n",
    "        counter += reps\n",
    "        t2 = round(time.time()-t0)\n",
    "        t2 = \"\"\"%d'%d\" \"\"\" % ((t2-t2%60)/60, t2%60)\n",
    "        msg = \"Finished model %d of %d (k = %d): %s\" % (counter, len(range_topics)*reps, num_topics, t2)\n",
    "        print(msg)\n",
    "\n",
    "    #Return dataframe and other output\n",
    "    df.columns = ['num_topics', 'coherence', 'model', 'seed']\n",
    "    return df, model_list, coherences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Expanding the grid search to include data filtering\n",
    "\n",
    "In addition to searching across the number of topics, we will also search across the data filtering hyperparameters, which is to say no_below and no_above. To do this, we will define another function that will call the previous gridsearch function, but will also take in lists of no_below values and no_above values then do a search across each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(texts, range_topics, range_no_below=[15], range_no_above=[0.55], reps=1, file_pkl=None, seedstart=0, iterations=15, passes=50):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for different hyperparameters\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    texts : List of input texts for CoherenceModel (data_words_bigrams)\n",
    "    range_topics : range of number of topics for Gensim LdaModel\n",
    "    range_no_below : range of no_below int values for Gensim Dictionary filter_extremes - \n",
    "                    Keep tokens which are contained in at least `no_below` documents.  Default is 30\n",
    "    range_no_above : range of no_above float values for Gensim Dictionary filter_extremes\n",
    "                    Keep tokens which are contained in no more than `no_above` documents.\n",
    "                    (fraction of total corpus size, not an absolute number). Default is 0.55\n",
    "    reps: repetitions of a particular run. Useful for creating uncertainty intervals\n",
    "    file_pkl : .pkl filename in which to save the data\n",
    "    seedstart: the starting value for the random seed in the gridsearch\n",
    "    **kw_LDA : parameters to LDA model\n",
    "    Returns:\n",
    "    -------\n",
    "    df : dataframe with paramenters, coherence, model\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    import time\n",
    "    df = pd.DataFrame()\n",
    "    #Print info\n",
    "    counter = 0\n",
    "    total = len(range_topics) * len(range_no_below) * len(range_no_above) * reps\n",
    "    print(\"Training %d topics x %d no_below x %d no_above x %d reps = %d models\" % (\n",
    "        len(range_topics), len(range_no_below), len(range_no_above), reps, total))    \n",
    "    #Iterate on all ranges (range_no_below, range_no_above)\n",
    "    for no_above in range_no_above:\n",
    "        for no_below in range_no_below:\n",
    "            #Filter BoW\n",
    "            gen_dict = gensim.corpora.Dictionary(texts)\n",
    "            gen_dict.filter_extremes(no_below=no_below, no_above=no_above, keep_n=1000000)\n",
    "            bow = [gen_dict.doc2bow(doc) for doc in texts]\n",
    "            gen_dict_size = len(gen_dict)\n",
    "\n",
    "            t0 = time.time()\n",
    "            #Run LDA (range_topics * repetitions) times\n",
    "            df0, _, _ = gridsearch_topics(gen_dict, bow, texts, range_topics, reps, seedstart+counter, \n",
    "                                          iterations=iterations, passes=passes)\n",
    "            #Concatenate output to DataFrame\n",
    "            df0 = pd.concat([df0, \n",
    "                           pd.Series([no_below]*len(range_topics)*reps), \n",
    "                           pd.Series([no_above]*len(range_topics)*reps)                             \n",
    "                          ] , axis=1)\n",
    "            df0 = df0.set_index(pd.Index(range(len(df),len(df)+len(df0))))\n",
    "            df0.columns = ['num_topics', 'coherence', 'model', 'seed', 'no_below', 'no_above']\n",
    "            df = pd.concat([df,df0],axis=0)\n",
    "            #Print info\n",
    "            counter += len(range_topics) * reps\n",
    "            t2 = round(time.time()-t0)\n",
    "            t2 = \"\"\"%d'%d\" \"\"\" % ((t2-t2%60)/60, t2%60)\n",
    "            msg = \"Finished iteration %d of %d: num_topics=%s, no_below=%d, no_above=%.2f, Tokens=%5d, %s\" % (\n",
    "                counter, total, str(list(range_topics)), no_below, no_above, gen_dict_size, t2)\n",
    "            print(msg)\n",
    "            #Return dataframe and other output\n",
    "            #df.columns = ['num_topics', 'coherence', 'model', 'seed', 'no_below', 'no_above']\n",
    "            if file_pkl: \n",
    "                    with open(file_pkl,'wb') as output: pickle.dump(df, output)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Running the Gridsearch\n",
    "\n",
    "Now, we run the actual gridsearch. For each search, we specify a certain range of topics (or single topic), as well as the filtering parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range_topics = range(15, 26)\n",
    "df = gridsearch(data_words_bigrams, range_topics, [15], [0.5], \n",
    "                reps = 10, seedstart = 0, iterations=15, passes=50, file_pkl='scied_norefs_gs_run1.pkl')\n",
    "df.sort_values(by='coherence', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range_topics = range(15, 26)\n",
    "df = gridsearch(data_words_bigrams, range_topics, [15], [0.5], \n",
    "                reps = 10, seedstart = 10, iterations=15, passes=50, file_pkl='scied_norefs_gs_seed10.pkl')\n",
    "df.sort_values(by='coherence', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range_topics = range(26, 29)\n",
    "df = gridsearch(data_words_bigrams, range_topics, [15], [0.5], \n",
    "                reps = 40, seedstart = 0, iterations=15, passes=50, file_pkl='scied_norefs_gs_k26-28_seed0-40.pkl')\n",
    "df.sort_values(by='coherence', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range_topics = range(23, 24)\n",
    "df = gridsearch(data_words_bigrams, range_topics, [15], [0.5], \n",
    "                reps = 100, seedstart = 0, iterations=15, passes=50, file_pkl='scied_norefs_rep_k23_seed0-100.pkl')\n",
    "df.sort_values(by='coherence', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range_topics = range(23, 24)\n",
    "df = gridsearch(data_words_bigrams, range_topics, [15], [0.5], \n",
    "                reps = 100, seedstart = 100, iterations=15, passes=50, file_pkl='scied_norefs_rep_k23_seed100-200.pkl')\n",
    "df.sort_values(by='coherence', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range_topics = range(23, 24)\n",
    "df = gridsearch(data_words_bigrams, range_topics, [15], [0.5], \n",
    "                reps = 100, seedstart = 200, iterations=15, passes=50, file_pkl='scied_norefs_rep_k23_seed200-300.pkl')\n",
    "df.sort_values(by='coherence', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1 topics x 1 no_below x 1 no_above x 100 reps = 100 models\n",
      "Finished run 10 of 100 (k = 23): 96'11\" \n",
      "Finished run 20 of 100 (k = 23): 197'50\" \n",
      "Finished run 30 of 100 (k = 23): 298'53\" \n",
      "Finished run 40 of 100 (k = 23): 398'49\" \n",
      "Finished run 50 of 100 (k = 23): 495'51\" \n",
      "Finished run 60 of 100 (k = 23): 593'5\" \n",
      "Finished run 70 of 100 (k = 23): 690'41\" \n",
      "Finished run 80 of 100 (k = 23): 788'39\" \n",
      "Finished run 90 of 100 (k = 23): 886'2\" \n",
      "Finished run 100 of 100 (k = 23): 983'27\" \n",
      "Finished model 100 of 100 (k = 23): 983'27\" \n",
      "Finished iteration 100 of 100: num_topics=[23], no_below=15, no_above=0.50, Tokens=24940, 983'27\" \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>coherence</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>no_below</th>\n",
       "      <th>no_above</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.540861</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>364.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.537526</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>332.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.526819</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>344.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.526692</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>357.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.525204</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>367.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.523739</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>306.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_topics  coherence                                              model  \\\n",
       "64        23.0   0.540861  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "32        23.0   0.537526  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "44        23.0   0.526819  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "57        23.0   0.526692  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "67        23.0   0.525204  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "6         23.0   0.523739  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "\n",
       "     seed  no_below  no_above  \n",
       "64  364.0        15       0.5  \n",
       "32  332.0        15       0.5  \n",
       "44  344.0        15       0.5  \n",
       "57  357.0        15       0.5  \n",
       "67  367.0        15       0.5  \n",
       "6   306.0        15       0.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_topics = range(23, 24)\n",
    "df = gridsearch(data_words_bigrams, range_topics, [15], [0.5], \n",
    "                reps = 100, seedstart = 300, iterations=15, passes=50, file_pkl='scied_norefs_rep_k23_seed300-400.pkl')\n",
    "df.sort_values(by='coherence', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Plotting the gridsearch results\n",
    "\n",
    "We can use these results to extract the most coherent models out of the run, as well as plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import gridsearch_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "studying alpha. it is symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum 0.511208 at num_topics=23 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gridsearch_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>coherence</th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>no_below</th>\n",
       "      <th>no_above</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.512252</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>330.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.521276</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.537526</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>332.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.513297</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>333.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.511433</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>334.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.492260</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>335.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.518580</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>336.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.500324</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>337.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.515808</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>338.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.516762</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.517661</td>\n",
       "      <td>LdaModel(num_terms=24940, num_topics=23, decay...</td>\n",
       "      <td>340.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_topics  coherence                                              model  \\\n",
       "30        23.0   0.512252  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "31        23.0   0.521276  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "32        23.0   0.537526  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "33        23.0   0.513297  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "34        23.0   0.511433  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "35        23.0   0.492260  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "36        23.0   0.518580  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "37        23.0   0.500324  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "38        23.0   0.515808  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "39        23.0   0.516762  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "40        23.0   0.517661  LdaModel(num_terms=24940, num_topics=23, decay...   \n",
       "\n",
       "     seed  no_below  no_above  \n",
       "30  330.0        15       0.5  \n",
       "31  331.0        15       0.5  \n",
       "32  332.0        15       0.5  \n",
       "33  333.0        15       0.5  \n",
       "34  334.0        15       0.5  \n",
       "35  335.0        15       0.5  \n",
       "36  336.0        15       0.5  \n",
       "37  337.0        15       0.5  \n",
       "38  338.0        15       0.5  \n",
       "39  339.0        15       0.5  \n",
       "40  340.0        15       0.5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.019*\"laboratory\" + 0.018*\"biology\" + 0.014*\"percent\" + 0.013*\"principle\" + 0.010*\"chemistry\" + 0.010*\"objective\" + 0.008*\"list\" + 0.008*\"physical\" + 0.007*\"field\" + 0.006*\"scientific\"'),\n",
       " (1,\n",
       "  '0.034*\"lesson\" + 0.015*\"preservice_teacher\" + 0.011*\"belief\" + 0.009*\"focus\" + 0.008*\"investigation\" + 0.007*\"interview\" + 0.007*\"scienti\" + 0.007*\"talk\" + 0.007*\"explanation\" + 0.007*\"rst\"'),\n",
       " (2,\n",
       "  '0.175*\"child\" + 0.022*\"parent\" + 0.021*\"age\" + 0.019*\"girl\" + 0.014*\"grade\" + 0.012*\"interest\" + 0.012*\"boy\" + 0.009*\"animal\" + 0.008*\"object\" + 0.008*\"interview\"'),\n",
       " (3,\n",
       "  '0.021*\"participant\" + 0.019*\"project\" + 0.013*\"interview\" + 0.007*\"lab\" + 0.007*\"focus\" + 0.006*\"community\" + 0.006*\"professional_development\" + 0.006*\"strategy\" + 0.006*\"professional\" + 0.006*\"team\"'),\n",
       " (4,\n",
       "  '0.020*\"earth\" + 0.014*\"light\" + 0.013*\"explanation\" + 0.012*\"object\" + 0.011*\"force\" + 0.010*\"physic\" + 0.009*\"phenomenon\" + 0.008*\"metaphor\" + 0.008*\"energy\" + 0.007*\"figure\"'),\n",
       " (5,\n",
       "  '0.027*\"attitude\" + 0.013*\"stem\" + 0.013*\"model\" + 0.012*\"achievement\" + 0.012*\"variable\" + 0.011*\"factor\" + 0.008*\"female\" + 0.008*\"survey\" + 0.008*\"et_al\" + 0.008*\"gender\"'),\n",
       " (6,\n",
       "  '0.047*\"item\" + 0.039*\"score\" + 0.019*\"measure\" + 0.013*\"achievement\" + 0.010*\"scale\" + 0.010*\"low\" + 0.009*\"response\" + 0.009*\"table\" + 0.009*\"instrument\" + 0.009*\"grade\"'),\n",
       " (7,\n",
       "  '0.016*\"elementary\" + 0.010*\"training\" + 0.009*\"elementary_school\" + 0.008*\"objective\" + 0.008*\"evaluation\" + 0.008*\"skill\" + 0.007*\"project\" + 0.006*\"plan\" + 0.006*\"field\" + 0.006*\"unit\"'),\n",
       " (8,\n",
       "  '0.014*\"language\" + 0.011*\"context\" + 0.011*\"identity\" + 0.011*\"discourse\" + 0.009*\"engage\" + 0.009*\"interaction\" + 0.008*\"al\" + 0.008*\"focus\" + 0.008*\"talk\" + 0.006*\"resource\"'),\n",
       " (9,\n",
       "  '0.017*\"new_york\" + 0.007*\"book\" + 0.006*\"dr\" + 0.006*\"committee\" + 0.006*\"pp\" + 0.006*\"association\" + 0.006*\"american\" + 0.005*\"conservation\" + 0.005*\"city\" + 0.004*\"member\"'),\n",
       " (10,\n",
       "  '0.011*\"man\" + 0.010*\"scientific\" + 0.009*\"world\" + 0.009*\"human\" + 0.008*\"people\" + 0.006*\"social\" + 0.005*\"scientist\" + 0.004*\"society\" + 0.004*\"men\" + 0.004*\"modern\"'),\n",
       " (11,\n",
       "  '0.056*\"model\" + 0.018*\"chemistry\" + 0.008*\"representation\" + 0.006*\"atom\" + 0.006*\"matter\" + 0.006*\"substance\" + 0.006*\"chemical\" + 0.006*\"explain\" + 0.006*\"ection\" + 0.006*\"analogy\"'),\n",
       " (12,\n",
       "  '0.022*\"technology\" + 0.015*\"community\" + 0.015*\"issue\" + 0.013*\"social\" + 0.010*\"environmental\" + 0.009*\"society\" + 0.008*\"environment\" + 0.007*\"people\" + 0.007*\"human\" + 0.006*\"energy\"'),\n",
       " (13,\n",
       "  '0.021*\"task\" + 0.017*\"scientific\" + 0.009*\"structure\" + 0.009*\"behavior\" + 0.008*\"specific\" + 0.007*\"hypothesis\" + 0.007*\"cognitive\" + 0.006*\"theory\" + 0.005*\"strategy\" + 0.005*\"problem_solve\"'),\n",
       " (14,\n",
       "  '0.042*\"physic\" + 0.018*\"mathematics\" + 0.012*\"graduate\" + 0.010*\"institution\" + 0.009*\"national\" + 0.008*\"country\" + 0.007*\"chemistry\" + 0.006*\"academic\" + 0.006*\"department\" + 0.005*\"woman\"'),\n",
       " (15,\n",
       "  '0.020*\"response\" + 0.013*\"conception\" + 0.013*\"no\" + 0.011*\"model\" + 0.010*\"al\" + 0.009*\"scienti\" + 0.008*\"category\" + 0.008*\"et_al\" + 0.008*\"explanation\" + 0.008*\"context\"'),\n",
       " (16,\n",
       "  '0.049*\"text\" + 0.047*\"book\" + 0.036*\"textbook\" + 0.025*\"author\" + 0.021*\"reading\" + 0.021*\"chapter\" + 0.014*\"reader\" + 0.014*\"biology\" + 0.013*\"evolution\" + 0.012*\"topic\"'),\n",
       " (17,\n",
       "  '0.029*\"exhibit\" + 0.025*\"museum\" + 0.020*\"visitor\" + 0.016*\"family\" + 0.015*\"visit\" + 0.011*\"center\" + 0.008*\"informal\" + 0.008*\"interaction\" + 0.006*\"talk\" + 0.006*\"conversation\"'),\n",
       " (18,\n",
       "  '0.018*\"thing\" + 0.013*\"say\" + 0.012*\"go\" + 0.012*\"want\" + 0.011*\"try\" + 0.010*\"people\" + 0.009*\"look\" + 0.009*\"answer\" + 0.008*\"feel\" + 0.007*\"thought\"'),\n",
       " (19,\n",
       "  '0.023*\"scientist\" + 0.017*\"theory\" + 0.016*\"scienti\" + 0.008*\"issue\" + 0.007*\"perspective\" + 0.007*\"context\" + 0.005*\"claim\" + 0.005*\"position\" + 0.005*\"world\" + 0.005*\"belief\"'),\n",
       " (20,\n",
       "  '0.030*\"water\" + 0.012*\"air\" + 0.011*\"plant\" + 0.011*\"heat\" + 0.008*\"food\" + 0.007*\"temperature\" + 0.006*\"weight\" + 0.005*\"gas\" + 0.005*\"experiment\" + 0.005*\"liquid\"'),\n",
       " (21,\n",
       "  '0.045*\"inquiry\" + 0.025*\"assessment\" + 0.022*\"argument\" + 0.015*\"standard\" + 0.015*\"claim\" + 0.014*\"argumentation\" + 0.013*\"explanation\" + 0.010*\"scienti\" + 0.010*\"goal\" + 0.009*\"task\"'),\n",
       " (22,\n",
       "  '0.048*\"pupil\" + 0.011*\"unit\" + 0.009*\"experiment\" + 0.008*\"demonstration\" + 0.007*\"film\" + 0.004*\"project\" + 0.004*\"picture\" + 0.004*\"apparatus\" + 0.004*\"sound\" + 0.004*\"radio\"')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[83].model.print_topics(num_words=10,num_topics=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12,\n",
       "  '0.058*\"chemistry\" + 0.020*\"chemical\" + 0.019*\"substance\" + 0.017*\"matter\" + 0.015*\"atom\" + 0.010*\"property\" + 0.010*\"molecule\" + 0.009*\"element\" + 0.009*\"water\" + 0.009*\"gas\"'),\n",
       " (22,\n",
       "  '0.023*\"plant\" + 0.016*\"energy\" + 0.015*\"biology\" + 0.015*\"food\" + 0.012*\"animal\" + 0.010*\"cell\" + 0.010*\"biological\" + 0.010*\"human\" + 0.008*\"organism\" + 0.008*\"disease\"'),\n",
       " (19,\n",
       "  '0.039*\"earth\" + 0.031*\"evolution\" + 0.012*\"religion\" + 0.012*\"biology\" + 0.007*\"specie\" + 0.007*\"rock\" + 0.006*\"astronomy\" + 0.006*\"evolutionary\" + 0.006*\"universe\" + 0.006*\"human\"'),\n",
       " (8,\n",
       "  '0.071*\"model\" + 0.034*\"explanation\" + 0.013*\"phenomenon\" + 0.011*\"explain\" + 0.009*\"figure\" + 0.007*\"response\" + 0.007*\"represent\" + 0.007*\"construct\" + 0.006*\"representation\" + 0.006*\"interview\"'),\n",
       " (9,\n",
       "  '0.018*\"identity\" + 0.017*\"stem\" + 0.014*\"girl\" + 0.011*\"woman\" + 0.009*\"career\" + 0.008*\"gender\" + 0.008*\"social\" + 0.007*\"female\" + 0.007*\"family\" + 0.006*\"al\"'),\n",
       " (6,\n",
       "  '0.015*\"talk\" + 0.014*\"discourse\" + 0.013*\"scienti\" + 0.009*\"context\" + 0.008*\"interaction\" + 0.008*\"action\" + 0.007*\"rst\" + 0.006*\"conversation\" + 0.006*\"frame\" + 0.006*\"line\"'),\n",
       " (3,\n",
       "  '0.201*\"child\" + 0.023*\"age\" + 0.023*\"parent\" + 0.017*\"grade\" + 0.015*\"object\" + 0.013*\"family\" + 0.011*\"elementary_school\" + 0.010*\"adult\" + 0.009*\"elementary\" + 0.008*\"year_old\"'),\n",
       " (15,\n",
       "  '0.023*\"inquiry\" + 0.016*\"lesson\" + 0.016*\"assessment\" + 0.010*\"scienti\" + 0.010*\"focus\" + 0.010*\"preservice_teacher\" + 0.010*\"belief\" + 0.009*\"no\" + 0.009*\"al\" + 0.008*\"participant\"'),\n",
       " (4,\n",
       "  '0.027*\"language\" + 0.017*\"learner\" + 0.013*\"structure\" + 0.012*\"meaning\" + 0.009*\"representation\" + 0.009*\"word\" + 0.008*\"cognitive\" + 0.007*\"context\" + 0.007*\"et_al\" + 0.006*\"figure\"'),\n",
       " (11,\n",
       "  '0.038*\"physic\" + 0.016*\"force\" + 0.015*\"energy\" + 0.013*\"conception\" + 0.012*\"object\" + 0.009*\"metaphor\" + 0.008*\"analogy\" + 0.007*\"light\" + 0.006*\"physical\" + 0.006*\"motion\"'),\n",
       " (13,\n",
       "  '0.017*\"new_york\" + 0.008*\"american\" + 0.007*\"dr\" + 0.006*\"association\" + 0.006*\"committee\" + 0.006*\"pp\" + 0.005*\"city\" + 0.005*\"journal\" + 0.005*\"member\" + 0.005*\"book\"'),\n",
       " (18,\n",
       "  '0.018*\"interview\" + 0.018*\"exhibit\" + 0.015*\"museum\" + 0.012*\"visitor\" + 0.010*\"center\" + 0.010*\"visit\" + 0.007*\"personal\" + 0.006*\"topic\" + 0.006*\"thing\" + 0.006*\"behavior\"'),\n",
       " (5,\n",
       "  '0.017*\"project\" + 0.012*\"community\" + 0.010*\"engage\" + 0.009*\"focus\" + 0.008*\"goal\" + 0.007*\"participant\" + 0.007*\"tool\" + 0.007*\"opportunity\" + 0.006*\"team\" + 0.006*\"challenge\"'),\n",
       " (17,\n",
       "  '0.057*\"book\" + 0.050*\"text\" + 0.040*\"textbook\" + 0.029*\"author\" + 0.026*\"reading\" + 0.024*\"chapter\" + 0.016*\"reader\" + 0.012*\"read\" + 0.010*\"section\" + 0.009*\"page\"'),\n",
       " (21,\n",
       "  '0.024*\"task\" + 0.012*\"performance\" + 0.011*\"behavior\" + 0.011*\"skill\" + 0.010*\"variable\" + 0.009*\"treatment\" + 0.009*\"score\" + 0.008*\"hypothesis\" + 0.008*\"problem_solve\" + 0.007*\"measure\"'),\n",
       " (1,\n",
       "  '0.016*\"technology\" + 0.013*\"social\" + 0.011*\"issue\" + 0.010*\"society\" + 0.007*\"community\" + 0.007*\"educator\" + 0.007*\"national\" + 0.007*\"country\" + 0.006*\"public\" + 0.006*\"culture\"'),\n",
       " (2,\n",
       "  '0.023*\"scientist\" + 0.020*\"theory\" + 0.011*\"scienti\" + 0.010*\"argument\" + 0.009*\"claim\" + 0.009*\"scientific\" + 0.007*\"issue\" + 0.006*\"belief\" + 0.005*\"position\" + 0.005*\"perspective\"'),\n",
       " (7,\n",
       "  '0.019*\"laboratory\" + 0.015*\"biology\" + 0.011*\"training\" + 0.010*\"mathematics\" + 0.009*\"physic\" + 0.009*\"graduate\" + 0.008*\"preparation\" + 0.008*\"field\" + 0.007*\"taught\" + 0.007*\"instructor\"'),\n",
       " (16,\n",
       "  '0.018*\"principle\" + 0.018*\"objective\" + 0.015*\"scientific\" + 0.013*\"unit\" + 0.010*\"list\" + 0.009*\"topic\" + 0.007*\"statement\" + 0.007*\"specific\" + 0.007*\"field\" + 0.006*\"procedure\"'),\n",
       " (14,\n",
       "  '0.006*\"thing\" + 0.006*\"pupil\" + 0.006*\"man\" + 0.006*\"scientific\" + 0.006*\"world\" + 0.006*\"people\" + 0.004*\"say\" + 0.004*\"mind\" + 0.003*\"scientist\" + 0.003*\"person\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[84].model.print_topics(num_words=10,num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_topic_list(raw_topic_list):\n",
    "    \"\"\"Function to take the topic list, and output just the words without weights. Used for visual inspection of topic correspondence\"\"\"\n",
    "    final_topic_list = []\n",
    "    for topic in raw_topic_list:\n",
    "        final_topic_list.append([word[0] for word in topic[1]])\n",
    "        \n",
    "    return final_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.98660408e-05, 2.24715237e-07, 2.24714796e-07, ...,\n",
       "        2.24714526e-07, 2.24714512e-07, 2.24714512e-07],\n",
       "       [1.71704926e-07, 4.19534445e-06, 1.71704926e-07, ...,\n",
       "        1.71704997e-07, 1.71704954e-07, 1.71704954e-07],\n",
       "       [1.20052377e-07, 7.87755707e-05, 1.20052377e-07, ...,\n",
       "        1.20052434e-07, 1.20052391e-07, 1.20052391e-07],\n",
       "       ...,\n",
       "       [1.12767106e-04, 2.46103468e-07, 2.46103440e-07, ...,\n",
       "        2.46103497e-07, 2.46103440e-07, 2.46103440e-07],\n",
       "       [3.68801819e-04, 1.24112048e-04, 1.99594169e-07, ...,\n",
       "        1.99594183e-07, 1.99594169e-07, 1.99594169e-07],\n",
       "       [4.70038140e-05, 4.37493989e-04, 3.10787946e-05, ...,\n",
       "        7.41729025e-08, 7.41728954e-08, 7.41728954e-08]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[23].model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = df.loc[23].model\n",
    "model2 = df.loc[24].model\n",
    "diffmatrix = model1.diff(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 22,\n",
       " 13,\n",
       " 4,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 5,\n",
       " 11,\n",
       " 13,\n",
       " 9,\n",
       " 21,\n",
       " 6,\n",
       " 12,\n",
       " 3,\n",
       " 20,\n",
       " 15,\n",
       " 7,\n",
       " 15,\n",
       " 14,\n",
       " 16,\n",
       " 19,\n",
       " 5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.argmin(line) for line in diffmatrix[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.027*\"scientist\" + 0.021*\"girl\" + 0.019*\"woman\" + 0.014*\"career\" + 0.010*\"faculty\" + 0.009*\"boy\" + 0.009*\"graduate\" + 0.009*\"undergraduate\" + 0.006*\"people\" + 0.006*\"identity\"'),\n",
       " (1,\n",
       "  '0.027*\"model\" + 0.027*\"inquiry\" + 0.021*\"scienti\" + 0.014*\"theory\" + 0.012*\"context\" + 0.011*\"conception\" + 0.011*\"no\" + 0.010*\"scientist\" + 0.008*\"al\" + 0.007*\"aspect\"'),\n",
       " (2,\n",
       "  '0.087*\"item\" + 0.037*\"response\" + 0.023*\"score\" + 0.018*\"scale\" + 0.017*\"measure\" + 0.014*\"instrument\" + 0.011*\"sample\" + 0.011*\"statement\" + 0.010*\"table\" + 0.010*\"questionnaire\"'),\n",
       " (3,\n",
       "  '0.008*\"man\" + 0.006*\"world\" + 0.006*\"new_york\" + 0.005*\"book\" + 0.005*\"american\" + 0.005*\"day\" + 0.004*\"city\" + 0.004*\"men\" + 0.004*\"people\" + 0.004*\"home\"'),\n",
       " (4,\n",
       "  '0.010*\"elementary\" + 0.009*\"training\" + 0.009*\"mathematics\" + 0.008*\"field\" + 0.008*\"new_york\" + 0.007*\"committee\" + 0.007*\"elementary_school\" + 0.006*\"association\" + 0.006*\"institution\" + 0.006*\"survey\"'),\n",
       " (5,\n",
       "  '0.018*\"scientific\" + 0.013*\"scientist\" + 0.013*\"theory\" + 0.007*\"world\" + 0.005*\"human\" + 0.005*\"claim\" + 0.004*\"argument\" + 0.004*\"believe\" + 0.004*\"thought\" + 0.004*\"law\"'),\n",
       " (6,\n",
       "  '0.016*\"community\" + 0.011*\"context\" + 0.011*\"scienti\" + 0.010*\"social\" + 0.010*\"issue\" + 0.009*\"identity\" + 0.009*\"culture\" + 0.008*\"perspective\" + 0.007*\"cultural\" + 0.007*\"people\"'),\n",
       " (7,\n",
       "  '0.020*\"stem\" + 0.017*\"achievement\" + 0.016*\"mathematics\" + 0.014*\"model\" + 0.012*\"grade\" + 0.012*\"variable\" + 0.010*\"et_al\" + 0.009*\"gender\" + 0.009*\"sample\" + 0.008*\"female\"'),\n",
       " (8,\n",
       "  '0.018*\"technology\" + 0.010*\"social\" + 0.010*\"society\" + 0.009*\"country\" + 0.008*\"national\" + 0.008*\"issue\" + 0.007*\"environmental\" + 0.006*\"public\" + 0.006*\"future\" + 0.005*\"educator\"'),\n",
       " (9,\n",
       "  '0.017*\"explanation\" + 0.012*\"engage\" + 0.012*\"argument\" + 0.011*\"focus\" + 0.010*\"al\" + 0.009*\"model\" + 0.008*\"argumentation\" + 0.008*\"claim\" + 0.008*\"discourse\" + 0.007*\"scienti\"'),\n",
       " (10,\n",
       "  '0.030*\"task\" + 0.018*\"assessment\" + 0.015*\"performance\" + 0.015*\"skill\" + 0.011*\"strategy\" + 0.009*\"score\" + 0.009*\"problem_solve\" + 0.009*\"cognitive\" + 0.009*\"instructional\" + 0.008*\"model\"'),\n",
       " (11,\n",
       "  '0.022*\"water\" + 0.014*\"earth\" + 0.012*\"light\" + 0.009*\"air\" + 0.007*\"experiment\" + 0.007*\"heat\" + 0.005*\"sun\" + 0.005*\"color\" + 0.005*\"rock\" + 0.005*\"small\"'),\n",
       " (12,\n",
       "  '0.039*\"attitude\" + 0.016*\"behavior\" + 0.014*\"variable\" + 0.012*\"significant\" + 0.011*\"measure\" + 0.011*\"factor\" + 0.009*\"relationship\" + 0.009*\"specific\" + 0.009*\"score\" + 0.009*\"influence\"'),\n",
       " (13,\n",
       "  '0.023*\"project\" + 0.010*\"participant\" + 0.008*\"focus\" + 0.007*\"standard\" + 0.007*\"team\" + 0.007*\"goal\" + 0.006*\"professional_development\" + 0.006*\"opportunity\" + 0.006*\"resource\" + 0.005*\"implementation\"'),\n",
       " (14,\n",
       "  '0.024*\"language\" + 0.016*\"meaning\" + 0.012*\"word\" + 0.010*\"metaphor\" + 0.008*\"structure\" + 0.008*\"relation\" + 0.008*\"representation\" + 0.008*\"engineering\" + 0.007*\"discourse\" + 0.007*\"analogy\"'),\n",
       " (15,\n",
       "  '0.012*\"principle\" + 0.009*\"pupil\" + 0.008*\"unit\" + 0.007*\"objective\" + 0.007*\"field\" + 0.007*\"list\" + 0.005*\"topic\" + 0.005*\"interest\" + 0.004*\"biology\" + 0.004*\"scientific\"'),\n",
       " (16,\n",
       "  '0.035*\"biology\" + 0.034*\"preservice_teacher\" + 0.030*\"evolution\" + 0.027*\"belief\" + 0.022*\"instructor\" + 0.017*\"lesson\" + 0.014*\"topic\" + 0.010*\"earth\" + 0.010*\"religion\" + 0.010*\"elementary\"'),\n",
       " (17,\n",
       "  '0.012*\"thing\" + 0.011*\"interview\" + 0.011*\"go\" + 0.010*\"talk\" + 0.009*\"say\" + 0.009*\"lesson\" + 0.009*\"want\" + 0.009*\"try\" + 0.008*\"look\" + 0.008*\"answer\"'),\n",
       " (18,\n",
       "  '0.114*\"child\" + 0.012*\"model\" + 0.011*\"explanation\" + 0.010*\"age\" + 0.009*\"plant\" + 0.008*\"genetics\" + 0.007*\"gene\" + 0.006*\"response\" + 0.006*\"object\" + 0.006*\"biological\"'),\n",
       " (19,\n",
       "  '0.019*\"energy\" + 0.018*\"model\" + 0.013*\"chemistry\" + 0.011*\"force\" + 0.009*\"object\" + 0.008*\"physic\" + 0.008*\"matter\" + 0.007*\"substance\" + 0.007*\"explanation\" + 0.006*\"explain\"'),\n",
       " (20,\n",
       "  '0.058*\"book\" + 0.052*\"text\" + 0.042*\"textbook\" + 0.030*\"author\" + 0.028*\"reading\" + 0.025*\"chapter\" + 0.016*\"reader\" + 0.012*\"read\" + 0.011*\"review\" + 0.011*\"page\"'),\n",
       " (21,\n",
       "  '0.026*\"physic\" + 0.024*\"laboratory\" + 0.024*\"pupil\" + 0.016*\"percent\" + 0.015*\"chemistry\" + 0.011*\"grade\" + 0.011*\"score\" + 0.011*\"experiment\" + 0.009*\"biology\" + 0.007*\"achievement\"'),\n",
       " (22,\n",
       "  '0.031*\"exhibit\" + 0.026*\"museum\" + 0.023*\"family\" + 0.021*\"visitor\" + 0.020*\"parent\" + 0.016*\"visit\" + 0.013*\"center\" + 0.010*\"informal\" + 0.009*\"child\" + 0.007*\"adult\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.print_topics(num_topics=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic from model 1:  ['child', 'elementary', 'grade', 'elementary_school', 'age', 'interest', 'unit', 'young_child', 'thing', 'conservation']\n",
      "Topic from model 2:  ['child', 'earth', 'plant', 'grade', 'water', 'age', 'light', 'object', 'animal', 'rock'] \n",
      "\n",
      "Topic from model 1:  ['exhibit', 'museum', 'family', 'argumentation', 'parent', 'visitor', 'visit', 'child', 'center', 'informal']\n",
      "Topic from model 2:  ['exhibit', 'museum', 'family', 'visitor', 'parent', 'visit', 'center', 'child', 'informal', 'adult'] \n",
      "\n",
      "Topic from model 1:  ['project', 'standard', 'inquiry', 'goal', 'focus', 'educator', 'team', 'national', 'reform', 'implementation']\n",
      "Topic from model 2:  ['participant', 'focus', 'context', 'project', 'scienti', 'community', 'assessment', 'no', 'standard', 'engage'] \n",
      "\n",
      "Topic from model 1:  ['new_york', 'american', 'committee', 'dr', 'association', 'pp', 'member', 'april', 'national', 'city']\n",
      "Topic from model 2:  ['book', 'new_york', 'american', 'pp', 'dr', 'journal', 'author', 'association', 'city', 'page'] \n",
      "\n",
      "Topic from model 1:  ['social', 'technology', 'society', 'people', 'issue', 'human', 'world', 'culture', 'community', 'environmental']\n",
      "Topic from model 2:  ['technology', 'social', 'issue', 'society', 'community', 'country', 'environmental', 'people', 'culture', 'cultural'] \n",
      "\n",
      "Topic from model 1:  ['task', 'structure', 'cognitive', 'performance', 'learner', 'strategy', 'behavior', 'model', 'skill', 'variable']\n",
      "Topic from model 2:  ['task', 'skill', 'performance', 'behavior', 'strategy', 'problem_solve', 'variable', 'instructional', 'condition', 'cognitive'] \n",
      "\n",
      "Topic from model 1:  ['model', 'assessment', 'context', 'scienti', 'al', 'et_al', 'speci', 'focus', 'rst', 'framework']\n",
      "Topic from model 2:  ['participant', 'focus', 'context', 'project', 'scienti', 'community', 'assessment', 'no', 'standard', 'engage'] \n",
      "\n",
      "Topic from model 1:  ['scientific', 'hypothesis', 'model', 'problem_solve', 'solution', 'inquiry', 'solve', 'specific', 'experiment', 'definition']\n",
      "Topic from model 2:  ['task', 'skill', 'performance', 'behavior', 'strategy', 'problem_solve', 'variable', 'instructional', 'condition', 'cognitive'] \n",
      "\n",
      "Topic from model 1:  ['water', 'object', 'light', 'earth', 'force', 'air', 'heat', 'weight', 'explanation', 'ection']\n",
      "Topic from model 2:  ['force', 'object', 'weight', 'answer', 'explanation', 'physic', 'motion', 'response', 'volume', 'mass'] \n",
      "\n",
      "Topic from model 1:  ['lesson', 'inquiry', 'preservice_teacher', 'laboratory', 'observation', 'instructor', 'interview', 'participant', 'observe', 'lab']\n",
      "Topic from model 2:  ['lesson', 'inquiry', 'belief', 'preservice_teacher', 'goal', 'instructor', 'investigation', 'elementary', 'focus', 'curriculum_material'] \n",
      "\n",
      "Topic from model 1:  ['model', 'explanation', 'argument', 'engage', 'claim', 'construct', 'participant', 'focus', 'explain', 'talk']\n",
      "Topic from model 2:  ['discourse', 'scienti', 'talk', 'interaction', 'explanation', 'context', 'argument', 'focus', 'argumentation', 'engage'] \n",
      "\n",
      "Topic from model 1:  ['pupil', 'percent', 'laboratory', 'principle', 'experiment', 'biology', 'unit', 'score', 'film', 'list']\n",
      "Topic from model 2:  ['principle', 'scientific', 'objective', 'list', 'field', 'statement', 'specific', 'basis', 'procedure', 'attitude'] \n",
      "\n",
      "Topic from model 1:  ['community', 'identity', 'stem', 'participant', 'engineering', 'mentor', 'focus', 'woman', 'role', 'engage']\n",
      "Topic from model 2:  ['participant', 'focus', 'context', 'project', 'scienti', 'community', 'assessment', 'no', 'standard', 'engage'] \n",
      "\n",
      "Topic from model 1:  ['item', 'score', 'attitude', 'measure', 'achievement', 'variable', 'response', 'scale', 'factor', 'sample']\n",
      "Topic from model 2:  ['item', 'attitude', 'response', 'scale', 'measure', 'instrument', 'factor', 'score', 'statement', 'sample'] \n",
      "\n",
      "Topic from model 1:  ['thing', 'say', 'man', 'day', 'go', 'world', 'people', 'try', 'look', 'men']\n",
      "Topic from model 2:  ['world', 'man', 'people', 'scientist', 'human', 'thing', 'say', 'men', 'scientific', 'today'] \n",
      "\n",
      "Topic from model 1:  ['book', 'text', 'textbook', 'author', 'chapter', 'reading', 'reader', 'read', 'page', 'review']\n",
      "Topic from model 2:  ['scientist', 'theory', 'scientific', 'book', 'author', 'issue', 'chapter', 'claim', 'scienti', 'argument'] \n",
      "\n",
      "Topic from model 1:  ['plant', 'food', 'animal', 'water', 'soil', 'body', 'tree', 'bird', 'health', 'cell']\n",
      "Topic from model 2:  ['water', 'food', 'air', 'heat', 'plant', 'body', 'produce', 'light', 'energy', 'soil'] \n",
      "\n",
      "Topic from model 1:  ['physic', 'mathematics', 'biology', 'grade', 'survey', 'chemistry', 'graduate', 'percent', 'physical', 'career']\n",
      "Topic from model 2:  ['physic', 'biology', 'percent', 'mathematics', 'grade', 'physical', 'graduate', 'survey', 'chemistry', 'total'] \n",
      "\n",
      "Topic from model 1:  ['objective', 'field', 'training', 'scientific', 'evaluation', 'specific', 'basic', 'project', 'unit', 'plan']\n",
      "Topic from model 2:  ['training', 'elementary', 'project', 'field', 'elementary_school', 'plan', 'service', 'meeting', 'committee', 'professional'] \n",
      "\n",
      "Topic from model 1:  ['language', 'discourse', 'meaning', 'talk', 'interaction', 'scienti', 'word', 'context', 'action', 'metaphor']\n",
      "Topic from model 2:  ['discourse', 'scienti', 'talk', 'interaction', 'explanation', 'context', 'argument', 'focus', 'argumentation', 'engage'] \n",
      "\n",
      "Topic from model 1:  ['biology', 'evolution', 'belief', 'response', 'biological', 'religion', 'misconception', 'believe', 'genetics', 'gene']\n",
      "Topic from model 2:  ['text', 'evolution', 'biology', 'explanation', 'scienti', 'textbook', 'biological', 'genetics', 'base_text', 'argument'] \n",
      "\n",
      "Topic from model 1:  ['chemistry', 'energy', 'chemical', 'substance', 'matter', 'atom', 'molecule', 'particle', 'element', 'electron']\n",
      "Topic from model 2:  ['model', 'energy', 'representation', 'phenomenon', 'explanation', 'matter', 'analogy', 'explain', 'figure', 'represent'] \n",
      "\n",
      "Topic from model 1:  ['scientist', 'theory', 'scienti', 'no', 'claim', 'argument', 'world', 'issue', 'belief', 'context']\n",
      "Topic from model 2:  ['scientist', 'theory', 'scientific', 'book', 'author', 'issue', 'chapter', 'claim', 'scienti', 'argument'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#establish the two models\n",
    "model1 = df.loc[23].model\n",
    "model2 = df.loc[21].model\n",
    "\n",
    "diffmatrix = model1.diff(model2) #create the diff matrix\n",
    "loc_overlap = [np.argmin(line) for line in diffmatrix[0]] #find the locations of the most overlapping topics\n",
    "\n",
    "#testlist = parse_topic_list(model1.show_topics(formatted=False)) #create a formatted list of the words\n",
    "\n",
    "for i, j in enumerate(loc_overlap): #iterate through the number of topics in the examined section of the matrix\n",
    "    print(\"Topic from model 1: \", parse_topic_list(model1.show_topics(num_topics=50,formatted=False))[i]) \n",
    "    print(\"Topic from model 2: \", parse_topic_list(model2.show_topics(num_topics=50,formatted=False))[j], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 4, 3, 18, 13, 15, 3, 15, 8, 20, 1, 11, 3, 16, 21, 7, 17, 14, 12, 1, 6, 19, 7]\n",
      "[ 1  3  4  6  7  8 11 12 13 14 15 16 17 18 19 20 21 22]\n"
     ]
    }
   ],
   "source": [
    "len(loc_overlap)-len(np.unique(loc_overlap))\n",
    "print(loc_overlap)\n",
    "print(np.unique(loc_overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7bf9169aea3bf43030d2045b9506020b24091b3061df9b5cfee19d2eac11c6ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
